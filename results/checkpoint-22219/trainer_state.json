{
  "best_metric": 0.5566219781827183,
  "best_model_checkpoint": "./results\\checkpoint-22219",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 22219,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004500652594626221,
      "grad_norm": 2.2724761962890625,
      "learning_rate": 9.999549934740538e-05,
      "loss": 1.4085,
      "step": 10
    },
    {
      "epoch": 0.0009001305189252442,
      "grad_norm": 1.7863404750823975,
      "learning_rate": 9.999099869481075e-05,
      "loss": 1.277,
      "step": 20
    },
    {
      "epoch": 0.0013501957783878663,
      "grad_norm": 1.9230362176895142,
      "learning_rate": 9.998649804221613e-05,
      "loss": 1.2594,
      "step": 30
    },
    {
      "epoch": 0.0018002610378504884,
      "grad_norm": 1.7758901119232178,
      "learning_rate": 9.99819973896215e-05,
      "loss": 1.1804,
      "step": 40
    },
    {
      "epoch": 0.0022503262973131103,
      "grad_norm": 1.7260867357254028,
      "learning_rate": 9.997749673702687e-05,
      "loss": 1.1403,
      "step": 50
    },
    {
      "epoch": 0.0027003915567757326,
      "grad_norm": 2.2747561931610107,
      "learning_rate": 9.997299608443225e-05,
      "loss": 1.2886,
      "step": 60
    },
    {
      "epoch": 0.0031504568162383545,
      "grad_norm": 1.796319603919983,
      "learning_rate": 9.996849543183762e-05,
      "loss": 1.2214,
      "step": 70
    },
    {
      "epoch": 0.003600522075700977,
      "grad_norm": 1.8770039081573486,
      "learning_rate": 9.9963994779243e-05,
      "loss": 1.2008,
      "step": 80
    },
    {
      "epoch": 0.004050587335163599,
      "grad_norm": 1.7071820497512817,
      "learning_rate": 9.995949412664837e-05,
      "loss": 1.1028,
      "step": 90
    },
    {
      "epoch": 0.004500652594626221,
      "grad_norm": 2.550088405609131,
      "learning_rate": 9.995499347405374e-05,
      "loss": 1.2097,
      "step": 100
    },
    {
      "epoch": 0.0049507178540888425,
      "grad_norm": 2.6366961002349854,
      "learning_rate": 9.995049282145911e-05,
      "loss": 1.2853,
      "step": 110
    },
    {
      "epoch": 0.005400783113551465,
      "grad_norm": 2.0740416049957275,
      "learning_rate": 9.994599216886449e-05,
      "loss": 1.1712,
      "step": 120
    },
    {
      "epoch": 0.005850848373014087,
      "grad_norm": 1.7430881261825562,
      "learning_rate": 9.994149151626986e-05,
      "loss": 1.2511,
      "step": 130
    },
    {
      "epoch": 0.006300913632476709,
      "grad_norm": 1.9091393947601318,
      "learning_rate": 9.993699086367524e-05,
      "loss": 1.2031,
      "step": 140
    },
    {
      "epoch": 0.006750978891939331,
      "grad_norm": 1.973203420639038,
      "learning_rate": 9.993249021108061e-05,
      "loss": 1.1689,
      "step": 150
    },
    {
      "epoch": 0.007201044151401954,
      "grad_norm": 1.9950571060180664,
      "learning_rate": 9.9927989558486e-05,
      "loss": 1.2711,
      "step": 160
    },
    {
      "epoch": 0.0076511094108645756,
      "grad_norm": 2.677593946456909,
      "learning_rate": 9.992348890589136e-05,
      "loss": 1.2374,
      "step": 170
    },
    {
      "epoch": 0.008101174670327197,
      "grad_norm": 1.4087882041931152,
      "learning_rate": 9.991898825329673e-05,
      "loss": 1.1168,
      "step": 180
    },
    {
      "epoch": 0.00855123992978982,
      "grad_norm": 1.487007975578308,
      "learning_rate": 9.991448760070212e-05,
      "loss": 1.103,
      "step": 190
    },
    {
      "epoch": 0.009001305189252441,
      "grad_norm": 1.835168480873108,
      "learning_rate": 9.990998694810748e-05,
      "loss": 1.2092,
      "step": 200
    },
    {
      "epoch": 0.009451370448715064,
      "grad_norm": 3.2712090015411377,
      "learning_rate": 9.990548629551285e-05,
      "loss": 1.0828,
      "step": 210
    },
    {
      "epoch": 0.009901435708177685,
      "grad_norm": 2.453352212905884,
      "learning_rate": 9.990098564291824e-05,
      "loss": 1.2161,
      "step": 220
    },
    {
      "epoch": 0.010351500967640308,
      "grad_norm": 1.5159687995910645,
      "learning_rate": 9.98964849903236e-05,
      "loss": 1.1715,
      "step": 230
    },
    {
      "epoch": 0.01080156622710293,
      "grad_norm": 2.222644805908203,
      "learning_rate": 9.989198433772897e-05,
      "loss": 1.1339,
      "step": 240
    },
    {
      "epoch": 0.011251631486565552,
      "grad_norm": 2.0752370357513428,
      "learning_rate": 9.988748368513436e-05,
      "loss": 1.2032,
      "step": 250
    },
    {
      "epoch": 0.011701696746028174,
      "grad_norm": 1.3127031326293945,
      "learning_rate": 9.988298303253972e-05,
      "loss": 1.1664,
      "step": 260
    },
    {
      "epoch": 0.012151762005490795,
      "grad_norm": 1.7412794828414917,
      "learning_rate": 9.987848237994509e-05,
      "loss": 1.1354,
      "step": 270
    },
    {
      "epoch": 0.012601827264953418,
      "grad_norm": 3.125561237335205,
      "learning_rate": 9.987398172735048e-05,
      "loss": 1.1513,
      "step": 280
    },
    {
      "epoch": 0.01305189252441604,
      "grad_norm": 3.277561902999878,
      "learning_rate": 9.986948107475584e-05,
      "loss": 1.1606,
      "step": 290
    },
    {
      "epoch": 0.013501957783878662,
      "grad_norm": 1.6381314992904663,
      "learning_rate": 9.986498042216121e-05,
      "loss": 1.1531,
      "step": 300
    },
    {
      "epoch": 0.013952023043341285,
      "grad_norm": 1.4508700370788574,
      "learning_rate": 9.98604797695666e-05,
      "loss": 1.1364,
      "step": 310
    },
    {
      "epoch": 0.014402088302803907,
      "grad_norm": 1.882075309753418,
      "learning_rate": 9.985597911697196e-05,
      "loss": 1.2245,
      "step": 320
    },
    {
      "epoch": 0.014852153562266528,
      "grad_norm": 1.9216636419296265,
      "learning_rate": 9.985147846437733e-05,
      "loss": 1.1567,
      "step": 330
    },
    {
      "epoch": 0.015302218821729151,
      "grad_norm": 2.0709564685821533,
      "learning_rate": 9.984697781178272e-05,
      "loss": 1.1807,
      "step": 340
    },
    {
      "epoch": 0.015752284081191774,
      "grad_norm": 1.1104711294174194,
      "learning_rate": 9.984247715918808e-05,
      "loss": 1.1517,
      "step": 350
    },
    {
      "epoch": 0.016202349340654395,
      "grad_norm": 1.1718695163726807,
      "learning_rate": 9.983797650659345e-05,
      "loss": 1.1411,
      "step": 360
    },
    {
      "epoch": 0.016652414600117016,
      "grad_norm": 1.3509193658828735,
      "learning_rate": 9.983347585399884e-05,
      "loss": 1.1491,
      "step": 370
    },
    {
      "epoch": 0.01710247985957964,
      "grad_norm": 2.197598457336426,
      "learning_rate": 9.98289752014042e-05,
      "loss": 1.1815,
      "step": 380
    },
    {
      "epoch": 0.01755254511904226,
      "grad_norm": 1.5694093704223633,
      "learning_rate": 9.982447454880958e-05,
      "loss": 1.1448,
      "step": 390
    },
    {
      "epoch": 0.018002610378504882,
      "grad_norm": 1.4423562288284302,
      "learning_rate": 9.981997389621496e-05,
      "loss": 1.2035,
      "step": 400
    },
    {
      "epoch": 0.018452675637967507,
      "grad_norm": 1.6687666177749634,
      "learning_rate": 9.981547324362032e-05,
      "loss": 1.0628,
      "step": 410
    },
    {
      "epoch": 0.018902740897430128,
      "grad_norm": 2.9782729148864746,
      "learning_rate": 9.981097259102571e-05,
      "loss": 1.1768,
      "step": 420
    },
    {
      "epoch": 0.01935280615689275,
      "grad_norm": 1.1234664916992188,
      "learning_rate": 9.980647193843108e-05,
      "loss": 1.196,
      "step": 430
    },
    {
      "epoch": 0.01980287141635537,
      "grad_norm": 1.4175870418548584,
      "learning_rate": 9.980197128583644e-05,
      "loss": 1.1634,
      "step": 440
    },
    {
      "epoch": 0.020252936675817994,
      "grad_norm": 1.534220576286316,
      "learning_rate": 9.979747063324183e-05,
      "loss": 1.178,
      "step": 450
    },
    {
      "epoch": 0.020703001935280615,
      "grad_norm": 0.9093250632286072,
      "learning_rate": 9.97929699806472e-05,
      "loss": 1.2216,
      "step": 460
    },
    {
      "epoch": 0.021153067194743237,
      "grad_norm": 1.9017165899276733,
      "learning_rate": 9.978846932805256e-05,
      "loss": 1.1835,
      "step": 470
    },
    {
      "epoch": 0.02160313245420586,
      "grad_norm": 1.3443071842193604,
      "learning_rate": 9.978396867545795e-05,
      "loss": 1.1285,
      "step": 480
    },
    {
      "epoch": 0.022053197713668482,
      "grad_norm": 1.7690227031707764,
      "learning_rate": 9.977946802286332e-05,
      "loss": 1.2287,
      "step": 490
    },
    {
      "epoch": 0.022503262973131103,
      "grad_norm": 1.0557527542114258,
      "learning_rate": 9.977496737026868e-05,
      "loss": 1.0622,
      "step": 500
    },
    {
      "epoch": 0.022953328232593728,
      "grad_norm": 1.1136934757232666,
      "learning_rate": 9.977046671767407e-05,
      "loss": 1.1416,
      "step": 510
    },
    {
      "epoch": 0.02340339349205635,
      "grad_norm": 1.2900867462158203,
      "learning_rate": 9.976596606507945e-05,
      "loss": 1.1994,
      "step": 520
    },
    {
      "epoch": 0.02385345875151897,
      "grad_norm": 1.2578169107437134,
      "learning_rate": 9.97614654124848e-05,
      "loss": 1.1466,
      "step": 530
    },
    {
      "epoch": 0.02430352401098159,
      "grad_norm": 1.099229097366333,
      "learning_rate": 9.975696475989019e-05,
      "loss": 1.1799,
      "step": 540
    },
    {
      "epoch": 0.024753589270444215,
      "grad_norm": 1.554672360420227,
      "learning_rate": 9.975246410729557e-05,
      "loss": 1.1257,
      "step": 550
    },
    {
      "epoch": 0.025203654529906836,
      "grad_norm": 2.4212048053741455,
      "learning_rate": 9.974796345470093e-05,
      "loss": 1.1148,
      "step": 560
    },
    {
      "epoch": 0.025653719789369457,
      "grad_norm": 1.1758370399475098,
      "learning_rate": 9.974346280210631e-05,
      "loss": 1.0852,
      "step": 570
    },
    {
      "epoch": 0.02610378504883208,
      "grad_norm": 2.5526561737060547,
      "learning_rate": 9.973896214951169e-05,
      "loss": 1.1454,
      "step": 580
    },
    {
      "epoch": 0.026553850308294703,
      "grad_norm": 0.9510130286216736,
      "learning_rate": 9.973446149691705e-05,
      "loss": 1.2229,
      "step": 590
    },
    {
      "epoch": 0.027003915567757324,
      "grad_norm": 2.083841562271118,
      "learning_rate": 9.972996084432243e-05,
      "loss": 1.2123,
      "step": 600
    },
    {
      "epoch": 0.027453980827219948,
      "grad_norm": 2.276215076446533,
      "learning_rate": 9.972546019172781e-05,
      "loss": 1.199,
      "step": 610
    },
    {
      "epoch": 0.02790404608668257,
      "grad_norm": 1.9326770305633545,
      "learning_rate": 9.972095953913317e-05,
      "loss": 1.1,
      "step": 620
    },
    {
      "epoch": 0.02835411134614519,
      "grad_norm": 1.3690475225448608,
      "learning_rate": 9.971645888653856e-05,
      "loss": 1.1396,
      "step": 630
    },
    {
      "epoch": 0.028804176605607815,
      "grad_norm": 1.3463585376739502,
      "learning_rate": 9.971195823394393e-05,
      "loss": 1.1351,
      "step": 640
    },
    {
      "epoch": 0.029254241865070436,
      "grad_norm": 1.0265629291534424,
      "learning_rate": 9.970745758134929e-05,
      "loss": 1.0896,
      "step": 650
    },
    {
      "epoch": 0.029704307124533057,
      "grad_norm": 2.3730366230010986,
      "learning_rate": 9.970295692875468e-05,
      "loss": 1.1552,
      "step": 660
    },
    {
      "epoch": 0.030154372383995678,
      "grad_norm": 1.3635884523391724,
      "learning_rate": 9.969845627616005e-05,
      "loss": 1.157,
      "step": 670
    },
    {
      "epoch": 0.030604437643458302,
      "grad_norm": 1.5557246208190918,
      "learning_rate": 9.969395562356542e-05,
      "loss": 1.153,
      "step": 680
    },
    {
      "epoch": 0.031054502902920923,
      "grad_norm": 1.4027141332626343,
      "learning_rate": 9.96894549709708e-05,
      "loss": 1.1823,
      "step": 690
    },
    {
      "epoch": 0.03150456816238355,
      "grad_norm": 1.307012915611267,
      "learning_rate": 9.968495431837617e-05,
      "loss": 1.1244,
      "step": 700
    },
    {
      "epoch": 0.031954633421846165,
      "grad_norm": 3.7701327800750732,
      "learning_rate": 9.968045366578154e-05,
      "loss": 1.1814,
      "step": 710
    },
    {
      "epoch": 0.03240469868130879,
      "grad_norm": 2.224433660507202,
      "learning_rate": 9.967595301318692e-05,
      "loss": 1.1564,
      "step": 720
    },
    {
      "epoch": 0.032854763940771414,
      "grad_norm": 1.199216365814209,
      "learning_rate": 9.967145236059229e-05,
      "loss": 1.1476,
      "step": 730
    },
    {
      "epoch": 0.03330482920023403,
      "grad_norm": 2.2834908962249756,
      "learning_rate": 9.966695170799766e-05,
      "loss": 1.1207,
      "step": 740
    },
    {
      "epoch": 0.033754894459696656,
      "grad_norm": 1.290073037147522,
      "learning_rate": 9.966245105540304e-05,
      "loss": 1.092,
      "step": 750
    },
    {
      "epoch": 0.03420495971915928,
      "grad_norm": 1.4845855236053467,
      "learning_rate": 9.965795040280841e-05,
      "loss": 1.1737,
      "step": 760
    },
    {
      "epoch": 0.0346550249786219,
      "grad_norm": 1.889559030532837,
      "learning_rate": 9.965344975021379e-05,
      "loss": 1.0959,
      "step": 770
    },
    {
      "epoch": 0.03510509023808452,
      "grad_norm": 1.1652870178222656,
      "learning_rate": 9.964894909761916e-05,
      "loss": 1.1172,
      "step": 780
    },
    {
      "epoch": 0.03555515549754715,
      "grad_norm": 1.802433729171753,
      "learning_rate": 9.964444844502453e-05,
      "loss": 1.2007,
      "step": 790
    },
    {
      "epoch": 0.036005220757009765,
      "grad_norm": 1.5343159437179565,
      "learning_rate": 9.96399477924299e-05,
      "loss": 1.1811,
      "step": 800
    },
    {
      "epoch": 0.03645528601647239,
      "grad_norm": 1.148144245147705,
      "learning_rate": 9.963544713983528e-05,
      "loss": 1.1585,
      "step": 810
    },
    {
      "epoch": 0.036905351275935014,
      "grad_norm": 1.8406579494476318,
      "learning_rate": 9.963094648724065e-05,
      "loss": 1.1363,
      "step": 820
    },
    {
      "epoch": 0.03735541653539763,
      "grad_norm": 0.9960501790046692,
      "learning_rate": 9.962644583464603e-05,
      "loss": 1.0793,
      "step": 830
    },
    {
      "epoch": 0.037805481794860256,
      "grad_norm": 1.356865644454956,
      "learning_rate": 9.96219451820514e-05,
      "loss": 1.2031,
      "step": 840
    },
    {
      "epoch": 0.03825554705432287,
      "grad_norm": 3.101039171218872,
      "learning_rate": 9.961744452945677e-05,
      "loss": 1.1593,
      "step": 850
    },
    {
      "epoch": 0.0387056123137855,
      "grad_norm": 1.5472503900527954,
      "learning_rate": 9.961294387686215e-05,
      "loss": 1.1139,
      "step": 860
    },
    {
      "epoch": 0.03915567757324812,
      "grad_norm": 1.3901466131210327,
      "learning_rate": 9.960844322426752e-05,
      "loss": 1.173,
      "step": 870
    },
    {
      "epoch": 0.03960574283271074,
      "grad_norm": 1.429843783378601,
      "learning_rate": 9.96039425716729e-05,
      "loss": 1.1532,
      "step": 880
    },
    {
      "epoch": 0.040055808092173364,
      "grad_norm": 1.9879589080810547,
      "learning_rate": 9.959944191907827e-05,
      "loss": 1.123,
      "step": 890
    },
    {
      "epoch": 0.04050587335163599,
      "grad_norm": 1.6687228679656982,
      "learning_rate": 9.959494126648364e-05,
      "loss": 1.1965,
      "step": 900
    },
    {
      "epoch": 0.040955938611098607,
      "grad_norm": 2.2848660945892334,
      "learning_rate": 9.959044061388902e-05,
      "loss": 1.1684,
      "step": 910
    },
    {
      "epoch": 0.04140600387056123,
      "grad_norm": 1.0606833696365356,
      "learning_rate": 9.958593996129439e-05,
      "loss": 1.1388,
      "step": 920
    },
    {
      "epoch": 0.041856069130023855,
      "grad_norm": 1.8514933586120605,
      "learning_rate": 9.958143930869976e-05,
      "loss": 1.1535,
      "step": 930
    },
    {
      "epoch": 0.04230613438948647,
      "grad_norm": 1.2740029096603394,
      "learning_rate": 9.957693865610515e-05,
      "loss": 1.1667,
      "step": 940
    },
    {
      "epoch": 0.0427561996489491,
      "grad_norm": 0.7730690836906433,
      "learning_rate": 9.957243800351051e-05,
      "loss": 1.1008,
      "step": 950
    },
    {
      "epoch": 0.04320626490841172,
      "grad_norm": 1.7116155624389648,
      "learning_rate": 9.956793735091588e-05,
      "loss": 1.1743,
      "step": 960
    },
    {
      "epoch": 0.04365633016787434,
      "grad_norm": 2.8637852668762207,
      "learning_rate": 9.956343669832127e-05,
      "loss": 1.1628,
      "step": 970
    },
    {
      "epoch": 0.044106395427336964,
      "grad_norm": 1.1662946939468384,
      "learning_rate": 9.955893604572663e-05,
      "loss": 1.0634,
      "step": 980
    },
    {
      "epoch": 0.04455646068679959,
      "grad_norm": 0.991036593914032,
      "learning_rate": 9.9554435393132e-05,
      "loss": 1.1508,
      "step": 990
    },
    {
      "epoch": 0.045006525946262206,
      "grad_norm": 3.262594223022461,
      "learning_rate": 9.954993474053739e-05,
      "loss": 1.1504,
      "step": 1000
    },
    {
      "epoch": 0.04545659120572483,
      "grad_norm": 1.450998067855835,
      "learning_rate": 9.954543408794275e-05,
      "loss": 1.1187,
      "step": 1010
    },
    {
      "epoch": 0.045906656465187455,
      "grad_norm": 1.3434691429138184,
      "learning_rate": 9.954093343534813e-05,
      "loss": 1.0418,
      "step": 1020
    },
    {
      "epoch": 0.04635672172465007,
      "grad_norm": 1.7933536767959595,
      "learning_rate": 9.953643278275351e-05,
      "loss": 1.1284,
      "step": 1030
    },
    {
      "epoch": 0.0468067869841127,
      "grad_norm": 1.0947961807250977,
      "learning_rate": 9.953193213015887e-05,
      "loss": 1.1309,
      "step": 1040
    },
    {
      "epoch": 0.04725685224357532,
      "grad_norm": 2.2636938095092773,
      "learning_rate": 9.952743147756425e-05,
      "loss": 1.0836,
      "step": 1050
    },
    {
      "epoch": 0.04770691750303794,
      "grad_norm": 2.347867965698242,
      "learning_rate": 9.952293082496963e-05,
      "loss": 1.0722,
      "step": 1060
    },
    {
      "epoch": 0.048156982762500564,
      "grad_norm": 1.6394098997116089,
      "learning_rate": 9.9518430172375e-05,
      "loss": 1.1507,
      "step": 1070
    },
    {
      "epoch": 0.04860704802196318,
      "grad_norm": 0.8660721182823181,
      "learning_rate": 9.951392951978037e-05,
      "loss": 1.1083,
      "step": 1080
    },
    {
      "epoch": 0.049057113281425806,
      "grad_norm": 1.5953840017318726,
      "learning_rate": 9.950942886718575e-05,
      "loss": 1.1737,
      "step": 1090
    },
    {
      "epoch": 0.04950717854088843,
      "grad_norm": 1.3975895643234253,
      "learning_rate": 9.950492821459111e-05,
      "loss": 1.1078,
      "step": 1100
    },
    {
      "epoch": 0.04995724380035105,
      "grad_norm": 1.446179986000061,
      "learning_rate": 9.950042756199649e-05,
      "loss": 1.1975,
      "step": 1110
    },
    {
      "epoch": 0.05040730905981367,
      "grad_norm": 1.2278622388839722,
      "learning_rate": 9.949592690940188e-05,
      "loss": 1.2232,
      "step": 1120
    },
    {
      "epoch": 0.0508573743192763,
      "grad_norm": 3.898956060409546,
      "learning_rate": 9.949142625680724e-05,
      "loss": 1.1736,
      "step": 1130
    },
    {
      "epoch": 0.051307439578738914,
      "grad_norm": 1.6904771327972412,
      "learning_rate": 9.948692560421261e-05,
      "loss": 1.0952,
      "step": 1140
    },
    {
      "epoch": 0.05175750483820154,
      "grad_norm": 3.111788272857666,
      "learning_rate": 9.9482424951618e-05,
      "loss": 1.1026,
      "step": 1150
    },
    {
      "epoch": 0.05220757009766416,
      "grad_norm": 2.606264114379883,
      "learning_rate": 9.947792429902336e-05,
      "loss": 1.1489,
      "step": 1160
    },
    {
      "epoch": 0.05265763535712678,
      "grad_norm": 0.9546967148780823,
      "learning_rate": 9.947342364642873e-05,
      "loss": 1.1244,
      "step": 1170
    },
    {
      "epoch": 0.053107700616589405,
      "grad_norm": 1.4001678228378296,
      "learning_rate": 9.946892299383412e-05,
      "loss": 1.1889,
      "step": 1180
    },
    {
      "epoch": 0.05355776587605203,
      "grad_norm": 2.7414028644561768,
      "learning_rate": 9.946442234123948e-05,
      "loss": 1.075,
      "step": 1190
    },
    {
      "epoch": 0.05400783113551465,
      "grad_norm": 1.839034080505371,
      "learning_rate": 9.945992168864486e-05,
      "loss": 1.1258,
      "step": 1200
    },
    {
      "epoch": 0.05445789639497727,
      "grad_norm": 1.3077068328857422,
      "learning_rate": 9.945542103605024e-05,
      "loss": 1.146,
      "step": 1210
    },
    {
      "epoch": 0.054907961654439896,
      "grad_norm": 1.605107307434082,
      "learning_rate": 9.94509203834556e-05,
      "loss": 1.1383,
      "step": 1220
    },
    {
      "epoch": 0.055358026913902514,
      "grad_norm": 1.5192334651947021,
      "learning_rate": 9.944641973086099e-05,
      "loss": 1.1767,
      "step": 1230
    },
    {
      "epoch": 0.05580809217336514,
      "grad_norm": 1.5403075218200684,
      "learning_rate": 9.944191907826636e-05,
      "loss": 1.1112,
      "step": 1240
    },
    {
      "epoch": 0.05625815743282776,
      "grad_norm": 1.24766206741333,
      "learning_rate": 9.943741842567172e-05,
      "loss": 1.1191,
      "step": 1250
    },
    {
      "epoch": 0.05670822269229038,
      "grad_norm": 2.4471848011016846,
      "learning_rate": 9.94329177730771e-05,
      "loss": 1.2422,
      "step": 1260
    },
    {
      "epoch": 0.057158287951753005,
      "grad_norm": 1.2680362462997437,
      "learning_rate": 9.942841712048248e-05,
      "loss": 1.1401,
      "step": 1270
    },
    {
      "epoch": 0.05760835321121563,
      "grad_norm": 1.7974687814712524,
      "learning_rate": 9.942391646788784e-05,
      "loss": 1.0821,
      "step": 1280
    },
    {
      "epoch": 0.05805841847067825,
      "grad_norm": 1.1467808485031128,
      "learning_rate": 9.941941581529323e-05,
      "loss": 1.1502,
      "step": 1290
    },
    {
      "epoch": 0.05850848373014087,
      "grad_norm": 1.188021183013916,
      "learning_rate": 9.94149151626986e-05,
      "loss": 1.0465,
      "step": 1300
    },
    {
      "epoch": 0.058958548989603496,
      "grad_norm": 1.428087830543518,
      "learning_rate": 9.941041451010396e-05,
      "loss": 1.1248,
      "step": 1310
    },
    {
      "epoch": 0.05940861424906611,
      "grad_norm": 1.419893503189087,
      "learning_rate": 9.940591385750935e-05,
      "loss": 1.0532,
      "step": 1320
    },
    {
      "epoch": 0.05985867950852874,
      "grad_norm": 1.965745210647583,
      "learning_rate": 9.940141320491472e-05,
      "loss": 1.1398,
      "step": 1330
    },
    {
      "epoch": 0.060308744767991355,
      "grad_norm": 2.859938383102417,
      "learning_rate": 9.939691255232008e-05,
      "loss": 1.1073,
      "step": 1340
    },
    {
      "epoch": 0.06075881002745398,
      "grad_norm": 3.047006130218506,
      "learning_rate": 9.939241189972547e-05,
      "loss": 1.1292,
      "step": 1350
    },
    {
      "epoch": 0.061208875286916604,
      "grad_norm": 1.265039324760437,
      "learning_rate": 9.938791124713084e-05,
      "loss": 1.149,
      "step": 1360
    },
    {
      "epoch": 0.06165894054637922,
      "grad_norm": 1.4286644458770752,
      "learning_rate": 9.93834105945362e-05,
      "loss": 1.1604,
      "step": 1370
    },
    {
      "epoch": 0.062109005805841846,
      "grad_norm": 1.5563838481903076,
      "learning_rate": 9.937890994194159e-05,
      "loss": 1.1376,
      "step": 1380
    },
    {
      "epoch": 0.06255907106530446,
      "grad_norm": 1.332244634628296,
      "learning_rate": 9.937440928934696e-05,
      "loss": 1.089,
      "step": 1390
    },
    {
      "epoch": 0.0630091363247671,
      "grad_norm": 1.074647068977356,
      "learning_rate": 9.936990863675232e-05,
      "loss": 1.0909,
      "step": 1400
    },
    {
      "epoch": 0.06345920158422971,
      "grad_norm": 3.220932960510254,
      "learning_rate": 9.936540798415771e-05,
      "loss": 1.2071,
      "step": 1410
    },
    {
      "epoch": 0.06390926684369233,
      "grad_norm": 1.6433806419372559,
      "learning_rate": 9.936090733156308e-05,
      "loss": 1.119,
      "step": 1420
    },
    {
      "epoch": 0.06435933210315496,
      "grad_norm": 1.031596064567566,
      "learning_rate": 9.935640667896844e-05,
      "loss": 1.1154,
      "step": 1430
    },
    {
      "epoch": 0.06480939736261758,
      "grad_norm": 1.8509199619293213,
      "learning_rate": 9.935190602637383e-05,
      "loss": 1.1896,
      "step": 1440
    },
    {
      "epoch": 0.0652594626220802,
      "grad_norm": 2.548931837081909,
      "learning_rate": 9.93474053737792e-05,
      "loss": 1.1368,
      "step": 1450
    },
    {
      "epoch": 0.06570952788154283,
      "grad_norm": 1.0135504007339478,
      "learning_rate": 9.934290472118458e-05,
      "loss": 1.1578,
      "step": 1460
    },
    {
      "epoch": 0.06615959314100545,
      "grad_norm": 1.151440978050232,
      "learning_rate": 9.933840406858995e-05,
      "loss": 1.0999,
      "step": 1470
    },
    {
      "epoch": 0.06660965840046806,
      "grad_norm": 1.1681218147277832,
      "learning_rate": 9.933390341599533e-05,
      "loss": 1.1608,
      "step": 1480
    },
    {
      "epoch": 0.0670597236599307,
      "grad_norm": 1.4684308767318726,
      "learning_rate": 9.93294027634007e-05,
      "loss": 1.1379,
      "step": 1490
    },
    {
      "epoch": 0.06750978891939331,
      "grad_norm": 1.4948605298995972,
      "learning_rate": 9.932490211080607e-05,
      "loss": 1.1873,
      "step": 1500
    },
    {
      "epoch": 0.06795985417885593,
      "grad_norm": 1.6329796314239502,
      "learning_rate": 9.932040145821145e-05,
      "loss": 1.0934,
      "step": 1510
    },
    {
      "epoch": 0.06840991943831856,
      "grad_norm": 1.5918229818344116,
      "learning_rate": 9.931590080561682e-05,
      "loss": 1.2309,
      "step": 1520
    },
    {
      "epoch": 0.06885998469778118,
      "grad_norm": 1.798935055732727,
      "learning_rate": 9.931140015302219e-05,
      "loss": 1.0954,
      "step": 1530
    },
    {
      "epoch": 0.0693100499572438,
      "grad_norm": 2.298272132873535,
      "learning_rate": 9.930689950042757e-05,
      "loss": 1.0967,
      "step": 1540
    },
    {
      "epoch": 0.06976011521670643,
      "grad_norm": 1.351671814918518,
      "learning_rate": 9.930239884783294e-05,
      "loss": 1.0752,
      "step": 1550
    },
    {
      "epoch": 0.07021018047616905,
      "grad_norm": 1.1727869510650635,
      "learning_rate": 9.929789819523831e-05,
      "loss": 1.1158,
      "step": 1560
    },
    {
      "epoch": 0.07066024573563166,
      "grad_norm": 1.1110587120056152,
      "learning_rate": 9.929339754264369e-05,
      "loss": 1.1925,
      "step": 1570
    },
    {
      "epoch": 0.0711103109950943,
      "grad_norm": 2.3560330867767334,
      "learning_rate": 9.928889689004906e-05,
      "loss": 1.1568,
      "step": 1580
    },
    {
      "epoch": 0.07156037625455691,
      "grad_norm": 0.9480974674224854,
      "learning_rate": 9.928439623745443e-05,
      "loss": 1.1048,
      "step": 1590
    },
    {
      "epoch": 0.07201044151401953,
      "grad_norm": 1.4795770645141602,
      "learning_rate": 9.927989558485981e-05,
      "loss": 1.0221,
      "step": 1600
    },
    {
      "epoch": 0.07246050677348216,
      "grad_norm": 0.9002482295036316,
      "learning_rate": 9.927539493226518e-05,
      "loss": 1.1306,
      "step": 1610
    },
    {
      "epoch": 0.07291057203294478,
      "grad_norm": 2.3210811614990234,
      "learning_rate": 9.927089427967056e-05,
      "loss": 1.1355,
      "step": 1620
    },
    {
      "epoch": 0.0733606372924074,
      "grad_norm": 2.8147404193878174,
      "learning_rate": 9.926639362707593e-05,
      "loss": 1.1907,
      "step": 1630
    },
    {
      "epoch": 0.07381070255187003,
      "grad_norm": 1.6059561967849731,
      "learning_rate": 9.92618929744813e-05,
      "loss": 1.1413,
      "step": 1640
    },
    {
      "epoch": 0.07426076781133265,
      "grad_norm": 1.3555690050125122,
      "learning_rate": 9.925739232188668e-05,
      "loss": 1.1349,
      "step": 1650
    },
    {
      "epoch": 0.07471083307079526,
      "grad_norm": 1.0742779970169067,
      "learning_rate": 9.925289166929205e-05,
      "loss": 1.1728,
      "step": 1660
    },
    {
      "epoch": 0.0751608983302579,
      "grad_norm": 2.347810745239258,
      "learning_rate": 9.924839101669742e-05,
      "loss": 1.0912,
      "step": 1670
    },
    {
      "epoch": 0.07561096358972051,
      "grad_norm": 1.0833827257156372,
      "learning_rate": 9.92438903641028e-05,
      "loss": 1.1504,
      "step": 1680
    },
    {
      "epoch": 0.07606102884918313,
      "grad_norm": 2.713951349258423,
      "learning_rate": 9.923938971150817e-05,
      "loss": 1.085,
      "step": 1690
    },
    {
      "epoch": 0.07651109410864575,
      "grad_norm": 2.3904359340667725,
      "learning_rate": 9.923488905891354e-05,
      "loss": 1.1197,
      "step": 1700
    },
    {
      "epoch": 0.07696115936810838,
      "grad_norm": 1.5950077772140503,
      "learning_rate": 9.923038840631892e-05,
      "loss": 1.1965,
      "step": 1710
    },
    {
      "epoch": 0.077411224627571,
      "grad_norm": 2.030608654022217,
      "learning_rate": 9.922588775372429e-05,
      "loss": 1.1975,
      "step": 1720
    },
    {
      "epoch": 0.07786128988703361,
      "grad_norm": 2.0337860584259033,
      "learning_rate": 9.922138710112967e-05,
      "loss": 1.1727,
      "step": 1730
    },
    {
      "epoch": 0.07831135514649624,
      "grad_norm": 1.1761155128479004,
      "learning_rate": 9.921688644853504e-05,
      "loss": 1.0843,
      "step": 1740
    },
    {
      "epoch": 0.07876142040595886,
      "grad_norm": 2.105093002319336,
      "learning_rate": 9.921238579594043e-05,
      "loss": 1.0754,
      "step": 1750
    },
    {
      "epoch": 0.07921148566542148,
      "grad_norm": 1.7304776906967163,
      "learning_rate": 9.920788514334579e-05,
      "loss": 1.1602,
      "step": 1760
    },
    {
      "epoch": 0.07966155092488411,
      "grad_norm": 3.0155177116394043,
      "learning_rate": 9.920338449075116e-05,
      "loss": 1.1881,
      "step": 1770
    },
    {
      "epoch": 0.08011161618434673,
      "grad_norm": 1.819962978363037,
      "learning_rate": 9.919888383815655e-05,
      "loss": 1.1268,
      "step": 1780
    },
    {
      "epoch": 0.08056168144380935,
      "grad_norm": 1.604137659072876,
      "learning_rate": 9.919438318556191e-05,
      "loss": 1.0713,
      "step": 1790
    },
    {
      "epoch": 0.08101174670327198,
      "grad_norm": 1.6162117719650269,
      "learning_rate": 9.918988253296728e-05,
      "loss": 1.1619,
      "step": 1800
    },
    {
      "epoch": 0.0814618119627346,
      "grad_norm": 1.419413447380066,
      "learning_rate": 9.918538188037267e-05,
      "loss": 1.1304,
      "step": 1810
    },
    {
      "epoch": 0.08191187722219721,
      "grad_norm": 2.137802839279175,
      "learning_rate": 9.918088122777803e-05,
      "loss": 1.1042,
      "step": 1820
    },
    {
      "epoch": 0.08236194248165984,
      "grad_norm": 1.9430140256881714,
      "learning_rate": 9.91763805751834e-05,
      "loss": 1.0738,
      "step": 1830
    },
    {
      "epoch": 0.08281200774112246,
      "grad_norm": 2.1248252391815186,
      "learning_rate": 9.917187992258879e-05,
      "loss": 1.1394,
      "step": 1840
    },
    {
      "epoch": 0.08326207300058508,
      "grad_norm": 1.73574697971344,
      "learning_rate": 9.916737926999415e-05,
      "loss": 1.1475,
      "step": 1850
    },
    {
      "epoch": 0.08371213826004771,
      "grad_norm": 1.9564887285232544,
      "learning_rate": 9.916287861739952e-05,
      "loss": 1.1014,
      "step": 1860
    },
    {
      "epoch": 0.08416220351951033,
      "grad_norm": 1.0539745092391968,
      "learning_rate": 9.915837796480491e-05,
      "loss": 1.0436,
      "step": 1870
    },
    {
      "epoch": 0.08461226877897295,
      "grad_norm": 1.433821201324463,
      "learning_rate": 9.915387731221027e-05,
      "loss": 1.15,
      "step": 1880
    },
    {
      "epoch": 0.08506233403843558,
      "grad_norm": 1.6833393573760986,
      "learning_rate": 9.914937665961564e-05,
      "loss": 1.0876,
      "step": 1890
    },
    {
      "epoch": 0.0855123992978982,
      "grad_norm": 1.3355854749679565,
      "learning_rate": 9.914487600702103e-05,
      "loss": 1.0931,
      "step": 1900
    },
    {
      "epoch": 0.08596246455736081,
      "grad_norm": 1.278701901435852,
      "learning_rate": 9.914037535442639e-05,
      "loss": 1.148,
      "step": 1910
    },
    {
      "epoch": 0.08641252981682344,
      "grad_norm": 1.8793567419052124,
      "learning_rate": 9.913587470183176e-05,
      "loss": 1.1383,
      "step": 1920
    },
    {
      "epoch": 0.08686259507628606,
      "grad_norm": 2.244866371154785,
      "learning_rate": 9.913137404923715e-05,
      "loss": 1.1231,
      "step": 1930
    },
    {
      "epoch": 0.08731266033574868,
      "grad_norm": 1.5792433023452759,
      "learning_rate": 9.912687339664251e-05,
      "loss": 1.0915,
      "step": 1940
    },
    {
      "epoch": 0.08776272559521131,
      "grad_norm": 2.8067574501037598,
      "learning_rate": 9.912237274404788e-05,
      "loss": 1.0794,
      "step": 1950
    },
    {
      "epoch": 0.08821279085467393,
      "grad_norm": 2.165194034576416,
      "learning_rate": 9.911787209145327e-05,
      "loss": 1.0602,
      "step": 1960
    },
    {
      "epoch": 0.08866285611413655,
      "grad_norm": 1.280071496963501,
      "learning_rate": 9.911337143885863e-05,
      "loss": 1.1248,
      "step": 1970
    },
    {
      "epoch": 0.08911292137359918,
      "grad_norm": 1.895021915435791,
      "learning_rate": 9.9108870786264e-05,
      "loss": 1.1171,
      "step": 1980
    },
    {
      "epoch": 0.0895629866330618,
      "grad_norm": 1.152488112449646,
      "learning_rate": 9.910437013366939e-05,
      "loss": 1.1812,
      "step": 1990
    },
    {
      "epoch": 0.09001305189252441,
      "grad_norm": 1.4251708984375,
      "learning_rate": 9.909986948107475e-05,
      "loss": 1.1129,
      "step": 2000
    },
    {
      "epoch": 0.09046311715198704,
      "grad_norm": 1.633333444595337,
      "learning_rate": 9.909536882848014e-05,
      "loss": 1.0631,
      "step": 2010
    },
    {
      "epoch": 0.09091318241144966,
      "grad_norm": 1.0718929767608643,
      "learning_rate": 9.909086817588551e-05,
      "loss": 1.1903,
      "step": 2020
    },
    {
      "epoch": 0.09136324767091228,
      "grad_norm": 2.0166802406311035,
      "learning_rate": 9.908636752329087e-05,
      "loss": 1.2214,
      "step": 2030
    },
    {
      "epoch": 0.09181331293037491,
      "grad_norm": 1.4797286987304688,
      "learning_rate": 9.908186687069626e-05,
      "loss": 1.045,
      "step": 2040
    },
    {
      "epoch": 0.09226337818983753,
      "grad_norm": 1.801303505897522,
      "learning_rate": 9.907736621810163e-05,
      "loss": 1.1928,
      "step": 2050
    },
    {
      "epoch": 0.09271344344930015,
      "grad_norm": 1.6596767902374268,
      "learning_rate": 9.9072865565507e-05,
      "loss": 1.1083,
      "step": 2060
    },
    {
      "epoch": 0.09316350870876278,
      "grad_norm": 1.2562977075576782,
      "learning_rate": 9.906836491291238e-05,
      "loss": 1.1083,
      "step": 2070
    },
    {
      "epoch": 0.0936135739682254,
      "grad_norm": 2.0082225799560547,
      "learning_rate": 9.906386426031775e-05,
      "loss": 1.1233,
      "step": 2080
    },
    {
      "epoch": 0.09406363922768801,
      "grad_norm": 1.2642203569412231,
      "learning_rate": 9.905936360772311e-05,
      "loss": 1.1402,
      "step": 2090
    },
    {
      "epoch": 0.09451370448715064,
      "grad_norm": 2.2173123359680176,
      "learning_rate": 9.90548629551285e-05,
      "loss": 1.1535,
      "step": 2100
    },
    {
      "epoch": 0.09496376974661326,
      "grad_norm": 2.1054370403289795,
      "learning_rate": 9.905036230253388e-05,
      "loss": 1.147,
      "step": 2110
    },
    {
      "epoch": 0.09541383500607588,
      "grad_norm": 2.2348148822784424,
      "learning_rate": 9.904586164993924e-05,
      "loss": 1.1909,
      "step": 2120
    },
    {
      "epoch": 0.09586390026553851,
      "grad_norm": 1.6811436414718628,
      "learning_rate": 9.904136099734462e-05,
      "loss": 1.1195,
      "step": 2130
    },
    {
      "epoch": 0.09631396552500113,
      "grad_norm": 1.711432695388794,
      "learning_rate": 9.903686034475e-05,
      "loss": 1.1609,
      "step": 2140
    },
    {
      "epoch": 0.09676403078446374,
      "grad_norm": 1.2928136587142944,
      "learning_rate": 9.903235969215536e-05,
      "loss": 1.1481,
      "step": 2150
    },
    {
      "epoch": 0.09721409604392636,
      "grad_norm": 2.248379945755005,
      "learning_rate": 9.902785903956074e-05,
      "loss": 1.0908,
      "step": 2160
    },
    {
      "epoch": 0.097664161303389,
      "grad_norm": 1.266714096069336,
      "learning_rate": 9.902335838696612e-05,
      "loss": 1.0592,
      "step": 2170
    },
    {
      "epoch": 0.09811422656285161,
      "grad_norm": 1.5330523252487183,
      "learning_rate": 9.901885773437148e-05,
      "loss": 1.1401,
      "step": 2180
    },
    {
      "epoch": 0.09856429182231423,
      "grad_norm": 0.971896767616272,
      "learning_rate": 9.901435708177686e-05,
      "loss": 1.0302,
      "step": 2190
    },
    {
      "epoch": 0.09901435708177686,
      "grad_norm": 1.558778166770935,
      "learning_rate": 9.900985642918224e-05,
      "loss": 1.0828,
      "step": 2200
    },
    {
      "epoch": 0.09946442234123948,
      "grad_norm": 1.137999176979065,
      "learning_rate": 9.90053557765876e-05,
      "loss": 1.0565,
      "step": 2210
    },
    {
      "epoch": 0.0999144876007021,
      "grad_norm": 1.8548762798309326,
      "learning_rate": 9.900085512399299e-05,
      "loss": 1.1105,
      "step": 2220
    },
    {
      "epoch": 0.10036455286016473,
      "grad_norm": 2.1346988677978516,
      "learning_rate": 9.899635447139836e-05,
      "loss": 1.1167,
      "step": 2230
    },
    {
      "epoch": 0.10081461811962734,
      "grad_norm": 2.090696096420288,
      "learning_rate": 9.899185381880373e-05,
      "loss": 1.0793,
      "step": 2240
    },
    {
      "epoch": 0.10126468337908996,
      "grad_norm": 1.717926263809204,
      "learning_rate": 9.89873531662091e-05,
      "loss": 1.1442,
      "step": 2250
    },
    {
      "epoch": 0.1017147486385526,
      "grad_norm": 1.3019558191299438,
      "learning_rate": 9.898285251361448e-05,
      "loss": 1.0984,
      "step": 2260
    },
    {
      "epoch": 0.10216481389801521,
      "grad_norm": 1.362389326095581,
      "learning_rate": 9.897835186101985e-05,
      "loss": 1.0337,
      "step": 2270
    },
    {
      "epoch": 0.10261487915747783,
      "grad_norm": 1.2212910652160645,
      "learning_rate": 9.897385120842523e-05,
      "loss": 1.1332,
      "step": 2280
    },
    {
      "epoch": 0.10306494441694046,
      "grad_norm": 1.5049794912338257,
      "learning_rate": 9.89693505558306e-05,
      "loss": 1.0855,
      "step": 2290
    },
    {
      "epoch": 0.10351500967640308,
      "grad_norm": 2.1483049392700195,
      "learning_rate": 9.896484990323597e-05,
      "loss": 1.1961,
      "step": 2300
    },
    {
      "epoch": 0.1039650749358657,
      "grad_norm": 2.9810545444488525,
      "learning_rate": 9.896034925064135e-05,
      "loss": 1.1265,
      "step": 2310
    },
    {
      "epoch": 0.10441514019532833,
      "grad_norm": 1.7556096315383911,
      "learning_rate": 9.895584859804672e-05,
      "loss": 1.1273,
      "step": 2320
    },
    {
      "epoch": 0.10486520545479094,
      "grad_norm": 2.081557273864746,
      "learning_rate": 9.89513479454521e-05,
      "loss": 1.1486,
      "step": 2330
    },
    {
      "epoch": 0.10531527071425356,
      "grad_norm": 1.7031219005584717,
      "learning_rate": 9.894684729285747e-05,
      "loss": 1.1298,
      "step": 2340
    },
    {
      "epoch": 0.10576533597371619,
      "grad_norm": 1.1701351404190063,
      "learning_rate": 9.894234664026284e-05,
      "loss": 1.1564,
      "step": 2350
    },
    {
      "epoch": 0.10621540123317881,
      "grad_norm": 1.854634404182434,
      "learning_rate": 9.893784598766822e-05,
      "loss": 1.1131,
      "step": 2360
    },
    {
      "epoch": 0.10666546649264143,
      "grad_norm": 1.1571002006530762,
      "learning_rate": 9.893334533507359e-05,
      "loss": 1.1095,
      "step": 2370
    },
    {
      "epoch": 0.10711553175210406,
      "grad_norm": 1.5809049606323242,
      "learning_rate": 9.892884468247896e-05,
      "loss": 1.1364,
      "step": 2380
    },
    {
      "epoch": 0.10756559701156668,
      "grad_norm": 0.9433055520057678,
      "learning_rate": 9.892434402988434e-05,
      "loss": 1.0469,
      "step": 2390
    },
    {
      "epoch": 0.1080156622710293,
      "grad_norm": 1.116653323173523,
      "learning_rate": 9.891984337728971e-05,
      "loss": 1.182,
      "step": 2400
    },
    {
      "epoch": 0.10846572753049193,
      "grad_norm": 1.198393702507019,
      "learning_rate": 9.891534272469508e-05,
      "loss": 1.1323,
      "step": 2410
    },
    {
      "epoch": 0.10891579278995454,
      "grad_norm": 1.0539195537567139,
      "learning_rate": 9.891084207210046e-05,
      "loss": 1.1933,
      "step": 2420
    },
    {
      "epoch": 0.10936585804941716,
      "grad_norm": 1.570130467414856,
      "learning_rate": 9.890634141950583e-05,
      "loss": 1.1822,
      "step": 2430
    },
    {
      "epoch": 0.10981592330887979,
      "grad_norm": 1.9945919513702393,
      "learning_rate": 9.89018407669112e-05,
      "loss": 1.1106,
      "step": 2440
    },
    {
      "epoch": 0.11026598856834241,
      "grad_norm": 2.4350929260253906,
      "learning_rate": 9.889734011431658e-05,
      "loss": 1.1118,
      "step": 2450
    },
    {
      "epoch": 0.11071605382780503,
      "grad_norm": 1.3495508432388306,
      "learning_rate": 9.889283946172195e-05,
      "loss": 1.1211,
      "step": 2460
    },
    {
      "epoch": 0.11116611908726766,
      "grad_norm": 1.2122443914413452,
      "learning_rate": 9.888833880912733e-05,
      "loss": 1.1065,
      "step": 2470
    },
    {
      "epoch": 0.11161618434673028,
      "grad_norm": 1.4334056377410889,
      "learning_rate": 9.88838381565327e-05,
      "loss": 1.1327,
      "step": 2480
    },
    {
      "epoch": 0.1120662496061929,
      "grad_norm": 1.949770212173462,
      "learning_rate": 9.887933750393807e-05,
      "loss": 1.1458,
      "step": 2490
    },
    {
      "epoch": 0.11251631486565553,
      "grad_norm": 0.8700847625732422,
      "learning_rate": 9.887483685134345e-05,
      "loss": 1.1725,
      "step": 2500
    },
    {
      "epoch": 0.11296638012511814,
      "grad_norm": 1.0111477375030518,
      "learning_rate": 9.887033619874882e-05,
      "loss": 1.0536,
      "step": 2510
    },
    {
      "epoch": 0.11341644538458076,
      "grad_norm": 0.8895622491836548,
      "learning_rate": 9.88658355461542e-05,
      "loss": 1.0545,
      "step": 2520
    },
    {
      "epoch": 0.11386651064404339,
      "grad_norm": 1.8104573488235474,
      "learning_rate": 9.886133489355958e-05,
      "loss": 1.1897,
      "step": 2530
    },
    {
      "epoch": 0.11431657590350601,
      "grad_norm": 1.2022024393081665,
      "learning_rate": 9.885683424096494e-05,
      "loss": 1.0336,
      "step": 2540
    },
    {
      "epoch": 0.11476664116296863,
      "grad_norm": 1.976394534111023,
      "learning_rate": 9.885233358837031e-05,
      "loss": 1.1216,
      "step": 2550
    },
    {
      "epoch": 0.11521670642243126,
      "grad_norm": 1.1940772533416748,
      "learning_rate": 9.88478329357757e-05,
      "loss": 1.0624,
      "step": 2560
    },
    {
      "epoch": 0.11566677168189388,
      "grad_norm": 1.1218549013137817,
      "learning_rate": 9.884333228318106e-05,
      "loss": 1.1293,
      "step": 2570
    },
    {
      "epoch": 0.1161168369413565,
      "grad_norm": 1.8849220275878906,
      "learning_rate": 9.883883163058644e-05,
      "loss": 1.1209,
      "step": 2580
    },
    {
      "epoch": 0.11656690220081913,
      "grad_norm": 1.581091284751892,
      "learning_rate": 9.883433097799182e-05,
      "loss": 1.1684,
      "step": 2590
    },
    {
      "epoch": 0.11701696746028174,
      "grad_norm": 1.1855190992355347,
      "learning_rate": 9.882983032539718e-05,
      "loss": 1.1147,
      "step": 2600
    },
    {
      "epoch": 0.11746703271974436,
      "grad_norm": 2.4534831047058105,
      "learning_rate": 9.882532967280256e-05,
      "loss": 1.078,
      "step": 2610
    },
    {
      "epoch": 0.11791709797920699,
      "grad_norm": 1.2104684114456177,
      "learning_rate": 9.882082902020794e-05,
      "loss": 1.0816,
      "step": 2620
    },
    {
      "epoch": 0.11836716323866961,
      "grad_norm": 2.2824954986572266,
      "learning_rate": 9.88163283676133e-05,
      "loss": 1.0863,
      "step": 2630
    },
    {
      "epoch": 0.11881722849813223,
      "grad_norm": 1.5440752506256104,
      "learning_rate": 9.881182771501868e-05,
      "loss": 1.0802,
      "step": 2640
    },
    {
      "epoch": 0.11926729375759484,
      "grad_norm": 1.789169192314148,
      "learning_rate": 9.880732706242406e-05,
      "loss": 1.0269,
      "step": 2650
    },
    {
      "epoch": 0.11971735901705748,
      "grad_norm": 3.4549381732940674,
      "learning_rate": 9.880282640982942e-05,
      "loss": 1.1586,
      "step": 2660
    },
    {
      "epoch": 0.1201674242765201,
      "grad_norm": 1.6244920492172241,
      "learning_rate": 9.87983257572348e-05,
      "loss": 1.0853,
      "step": 2670
    },
    {
      "epoch": 0.12061748953598271,
      "grad_norm": 2.6108546257019043,
      "learning_rate": 9.879382510464018e-05,
      "loss": 1.1088,
      "step": 2680
    },
    {
      "epoch": 0.12106755479544534,
      "grad_norm": 1.712837815284729,
      "learning_rate": 9.878932445204554e-05,
      "loss": 1.0877,
      "step": 2690
    },
    {
      "epoch": 0.12151762005490796,
      "grad_norm": 1.0591826438903809,
      "learning_rate": 9.878482379945092e-05,
      "loss": 1.0952,
      "step": 2700
    },
    {
      "epoch": 0.12196768531437058,
      "grad_norm": 1.6313966512680054,
      "learning_rate": 9.87803231468563e-05,
      "loss": 1.1142,
      "step": 2710
    },
    {
      "epoch": 0.12241775057383321,
      "grad_norm": 1.827201008796692,
      "learning_rate": 9.877582249426167e-05,
      "loss": 1.1118,
      "step": 2720
    },
    {
      "epoch": 0.12286781583329583,
      "grad_norm": 1.6702308654785156,
      "learning_rate": 9.877132184166704e-05,
      "loss": 1.1261,
      "step": 2730
    },
    {
      "epoch": 0.12331788109275844,
      "grad_norm": 1.4361246824264526,
      "learning_rate": 9.876682118907243e-05,
      "loss": 1.1597,
      "step": 2740
    },
    {
      "epoch": 0.12376794635222108,
      "grad_norm": 1.095674753189087,
      "learning_rate": 9.876232053647779e-05,
      "loss": 1.2031,
      "step": 2750
    },
    {
      "epoch": 0.12421801161168369,
      "grad_norm": 2.35056209564209,
      "learning_rate": 9.875781988388316e-05,
      "loss": 1.0999,
      "step": 2760
    },
    {
      "epoch": 0.12466807687114631,
      "grad_norm": 1.0780904293060303,
      "learning_rate": 9.875331923128855e-05,
      "loss": 1.093,
      "step": 2770
    },
    {
      "epoch": 0.12511814213060893,
      "grad_norm": 1.4420770406723022,
      "learning_rate": 9.874881857869391e-05,
      "loss": 1.0434,
      "step": 2780
    },
    {
      "epoch": 0.12556820739007157,
      "grad_norm": 1.6563196182250977,
      "learning_rate": 9.87443179260993e-05,
      "loss": 1.1555,
      "step": 2790
    },
    {
      "epoch": 0.1260182726495342,
      "grad_norm": 1.0641900300979614,
      "learning_rate": 9.873981727350467e-05,
      "loss": 1.0885,
      "step": 2800
    },
    {
      "epoch": 0.1264683379089968,
      "grad_norm": 2.081044912338257,
      "learning_rate": 9.873531662091003e-05,
      "loss": 1.1235,
      "step": 2810
    },
    {
      "epoch": 0.12691840316845943,
      "grad_norm": 1.2662776708602905,
      "learning_rate": 9.873081596831542e-05,
      "loss": 1.1977,
      "step": 2820
    },
    {
      "epoch": 0.12736846842792204,
      "grad_norm": 2.059966564178467,
      "learning_rate": 9.872631531572079e-05,
      "loss": 1.1044,
      "step": 2830
    },
    {
      "epoch": 0.12781853368738466,
      "grad_norm": 1.538570523262024,
      "learning_rate": 9.872181466312615e-05,
      "loss": 1.0606,
      "step": 2840
    },
    {
      "epoch": 0.1282685989468473,
      "grad_norm": 1.2449839115142822,
      "learning_rate": 9.871731401053154e-05,
      "loss": 1.086,
      "step": 2850
    },
    {
      "epoch": 0.12871866420630992,
      "grad_norm": 1.5942625999450684,
      "learning_rate": 9.871281335793691e-05,
      "loss": 1.1566,
      "step": 2860
    },
    {
      "epoch": 0.12916872946577254,
      "grad_norm": 1.7610819339752197,
      "learning_rate": 9.870831270534227e-05,
      "loss": 1.1278,
      "step": 2870
    },
    {
      "epoch": 0.12961879472523516,
      "grad_norm": 1.3905436992645264,
      "learning_rate": 9.870381205274766e-05,
      "loss": 1.0908,
      "step": 2880
    },
    {
      "epoch": 0.13006885998469778,
      "grad_norm": 1.4418034553527832,
      "learning_rate": 9.869931140015303e-05,
      "loss": 1.1505,
      "step": 2890
    },
    {
      "epoch": 0.1305189252441604,
      "grad_norm": 1.8386292457580566,
      "learning_rate": 9.869481074755839e-05,
      "loss": 1.162,
      "step": 2900
    },
    {
      "epoch": 0.130968990503623,
      "grad_norm": 1.7709436416625977,
      "learning_rate": 9.869031009496378e-05,
      "loss": 1.0863,
      "step": 2910
    },
    {
      "epoch": 0.13141905576308566,
      "grad_norm": 1.4584574699401855,
      "learning_rate": 9.868580944236915e-05,
      "loss": 1.1478,
      "step": 2920
    },
    {
      "epoch": 0.13186912102254827,
      "grad_norm": 1.2391235828399658,
      "learning_rate": 9.868130878977452e-05,
      "loss": 1.1692,
      "step": 2930
    },
    {
      "epoch": 0.1323191862820109,
      "grad_norm": 2.1002705097198486,
      "learning_rate": 9.86768081371799e-05,
      "loss": 1.2181,
      "step": 2940
    },
    {
      "epoch": 0.1327692515414735,
      "grad_norm": 1.0509905815124512,
      "learning_rate": 9.867230748458527e-05,
      "loss": 1.1347,
      "step": 2950
    },
    {
      "epoch": 0.13321931680093613,
      "grad_norm": 2.208353042602539,
      "learning_rate": 9.866780683199065e-05,
      "loss": 1.0571,
      "step": 2960
    },
    {
      "epoch": 0.13366938206039874,
      "grad_norm": 1.5460069179534912,
      "learning_rate": 9.866330617939602e-05,
      "loss": 1.0656,
      "step": 2970
    },
    {
      "epoch": 0.1341194473198614,
      "grad_norm": 1.3842018842697144,
      "learning_rate": 9.865880552680139e-05,
      "loss": 1.1056,
      "step": 2980
    },
    {
      "epoch": 0.134569512579324,
      "grad_norm": 2.1556754112243652,
      "learning_rate": 9.865430487420677e-05,
      "loss": 1.1092,
      "step": 2990
    },
    {
      "epoch": 0.13501957783878663,
      "grad_norm": 1.4920183420181274,
      "learning_rate": 9.864980422161214e-05,
      "loss": 1.0548,
      "step": 3000
    },
    {
      "epoch": 0.13546964309824924,
      "grad_norm": 0.9145240783691406,
      "learning_rate": 9.864530356901751e-05,
      "loss": 1.0145,
      "step": 3010
    },
    {
      "epoch": 0.13591970835771186,
      "grad_norm": 1.9741569757461548,
      "learning_rate": 9.864080291642289e-05,
      "loss": 1.1457,
      "step": 3020
    },
    {
      "epoch": 0.13636977361717448,
      "grad_norm": 1.2404499053955078,
      "learning_rate": 9.863630226382826e-05,
      "loss": 1.1295,
      "step": 3030
    },
    {
      "epoch": 0.13681983887663712,
      "grad_norm": 1.423869013786316,
      "learning_rate": 9.863180161123363e-05,
      "loss": 1.0687,
      "step": 3040
    },
    {
      "epoch": 0.13726990413609974,
      "grad_norm": 1.2569642066955566,
      "learning_rate": 9.862730095863901e-05,
      "loss": 1.1244,
      "step": 3050
    },
    {
      "epoch": 0.13771996939556236,
      "grad_norm": 1.3993736505508423,
      "learning_rate": 9.862280030604438e-05,
      "loss": 1.2385,
      "step": 3060
    },
    {
      "epoch": 0.13817003465502498,
      "grad_norm": 3.0401089191436768,
      "learning_rate": 9.861829965344976e-05,
      "loss": 1.2056,
      "step": 3070
    },
    {
      "epoch": 0.1386200999144876,
      "grad_norm": 1.8570592403411865,
      "learning_rate": 9.861379900085513e-05,
      "loss": 1.1586,
      "step": 3080
    },
    {
      "epoch": 0.1390701651739502,
      "grad_norm": 1.3409615755081177,
      "learning_rate": 9.86092983482605e-05,
      "loss": 1.117,
      "step": 3090
    },
    {
      "epoch": 0.13952023043341286,
      "grad_norm": 1.6870336532592773,
      "learning_rate": 9.860479769566588e-05,
      "loss": 1.0877,
      "step": 3100
    },
    {
      "epoch": 0.13997029569287547,
      "grad_norm": 1.9845584630966187,
      "learning_rate": 9.860029704307125e-05,
      "loss": 1.1192,
      "step": 3110
    },
    {
      "epoch": 0.1404203609523381,
      "grad_norm": 1.0393409729003906,
      "learning_rate": 9.859579639047662e-05,
      "loss": 1.0912,
      "step": 3120
    },
    {
      "epoch": 0.1408704262118007,
      "grad_norm": 1.7695167064666748,
      "learning_rate": 9.8591295737882e-05,
      "loss": 1.1768,
      "step": 3130
    },
    {
      "epoch": 0.14132049147126333,
      "grad_norm": 1.463855504989624,
      "learning_rate": 9.858679508528737e-05,
      "loss": 1.0815,
      "step": 3140
    },
    {
      "epoch": 0.14177055673072594,
      "grad_norm": 1.8244684934616089,
      "learning_rate": 9.858229443269274e-05,
      "loss": 1.1327,
      "step": 3150
    },
    {
      "epoch": 0.1422206219901886,
      "grad_norm": 1.420291543006897,
      "learning_rate": 9.857779378009812e-05,
      "loss": 1.1456,
      "step": 3160
    },
    {
      "epoch": 0.1426706872496512,
      "grad_norm": 1.3888938426971436,
      "learning_rate": 9.857329312750349e-05,
      "loss": 1.1285,
      "step": 3170
    },
    {
      "epoch": 0.14312075250911382,
      "grad_norm": 1.371786117553711,
      "learning_rate": 9.856879247490886e-05,
      "loss": 1.1535,
      "step": 3180
    },
    {
      "epoch": 0.14357081776857644,
      "grad_norm": 2.6582083702087402,
      "learning_rate": 9.856429182231424e-05,
      "loss": 1.0781,
      "step": 3190
    },
    {
      "epoch": 0.14402088302803906,
      "grad_norm": 1.5851616859436035,
      "learning_rate": 9.855979116971961e-05,
      "loss": 1.0882,
      "step": 3200
    },
    {
      "epoch": 0.14447094828750168,
      "grad_norm": 2.2863075733184814,
      "learning_rate": 9.855529051712499e-05,
      "loss": 1.2205,
      "step": 3210
    },
    {
      "epoch": 0.14492101354696432,
      "grad_norm": 1.9238849878311157,
      "learning_rate": 9.855078986453036e-05,
      "loss": 1.1114,
      "step": 3220
    },
    {
      "epoch": 0.14537107880642694,
      "grad_norm": 1.044196367263794,
      "learning_rate": 9.854628921193573e-05,
      "loss": 1.1512,
      "step": 3230
    },
    {
      "epoch": 0.14582114406588956,
      "grad_norm": 1.267967700958252,
      "learning_rate": 9.85417885593411e-05,
      "loss": 1.1229,
      "step": 3240
    },
    {
      "epoch": 0.14627120932535218,
      "grad_norm": 1.4217402935028076,
      "learning_rate": 9.853728790674648e-05,
      "loss": 1.1257,
      "step": 3250
    },
    {
      "epoch": 0.1467212745848148,
      "grad_norm": 2.5110690593719482,
      "learning_rate": 9.853278725415185e-05,
      "loss": 1.141,
      "step": 3260
    },
    {
      "epoch": 0.1471713398442774,
      "grad_norm": 1.480900526046753,
      "learning_rate": 9.852828660155723e-05,
      "loss": 1.0739,
      "step": 3270
    },
    {
      "epoch": 0.14762140510374006,
      "grad_norm": 1.3272305727005005,
      "learning_rate": 9.85237859489626e-05,
      "loss": 1.097,
      "step": 3280
    },
    {
      "epoch": 0.14807147036320267,
      "grad_norm": 2.361457347869873,
      "learning_rate": 9.851928529636797e-05,
      "loss": 1.075,
      "step": 3290
    },
    {
      "epoch": 0.1485215356226653,
      "grad_norm": 1.4665457010269165,
      "learning_rate": 9.851478464377335e-05,
      "loss": 1.0654,
      "step": 3300
    },
    {
      "epoch": 0.1489716008821279,
      "grad_norm": 2.4158620834350586,
      "learning_rate": 9.851028399117872e-05,
      "loss": 1.1737,
      "step": 3310
    },
    {
      "epoch": 0.14942166614159053,
      "grad_norm": 1.1801042556762695,
      "learning_rate": 9.85057833385841e-05,
      "loss": 1.1154,
      "step": 3320
    },
    {
      "epoch": 0.14987173140105314,
      "grad_norm": 2.076162099838257,
      "learning_rate": 9.850128268598947e-05,
      "loss": 1.0725,
      "step": 3330
    },
    {
      "epoch": 0.1503217966605158,
      "grad_norm": 1.3989757299423218,
      "learning_rate": 9.849678203339486e-05,
      "loss": 1.0964,
      "step": 3340
    },
    {
      "epoch": 0.1507718619199784,
      "grad_norm": 1.2880382537841797,
      "learning_rate": 9.849228138080022e-05,
      "loss": 1.119,
      "step": 3350
    },
    {
      "epoch": 0.15122192717944102,
      "grad_norm": 2.2287440299987793,
      "learning_rate": 9.848778072820559e-05,
      "loss": 1.1154,
      "step": 3360
    },
    {
      "epoch": 0.15167199243890364,
      "grad_norm": 2.7925844192504883,
      "learning_rate": 9.848328007561098e-05,
      "loss": 1.1324,
      "step": 3370
    },
    {
      "epoch": 0.15212205769836626,
      "grad_norm": 1.6402174234390259,
      "learning_rate": 9.847877942301634e-05,
      "loss": 1.106,
      "step": 3380
    },
    {
      "epoch": 0.15257212295782888,
      "grad_norm": 0.806789755821228,
      "learning_rate": 9.847427877042171e-05,
      "loss": 1.0959,
      "step": 3390
    },
    {
      "epoch": 0.1530221882172915,
      "grad_norm": 1.6081777811050415,
      "learning_rate": 9.84697781178271e-05,
      "loss": 1.143,
      "step": 3400
    },
    {
      "epoch": 0.15347225347675414,
      "grad_norm": 1.2111907005310059,
      "learning_rate": 9.846527746523246e-05,
      "loss": 1.1547,
      "step": 3410
    },
    {
      "epoch": 0.15392231873621676,
      "grad_norm": 1.4235069751739502,
      "learning_rate": 9.846077681263783e-05,
      "loss": 1.1009,
      "step": 3420
    },
    {
      "epoch": 0.15437238399567937,
      "grad_norm": 2.5473451614379883,
      "learning_rate": 9.845627616004322e-05,
      "loss": 1.0717,
      "step": 3430
    },
    {
      "epoch": 0.154822449255142,
      "grad_norm": 1.5794918537139893,
      "learning_rate": 9.845177550744858e-05,
      "loss": 1.0852,
      "step": 3440
    },
    {
      "epoch": 0.1552725145146046,
      "grad_norm": 2.3040835857391357,
      "learning_rate": 9.844727485485395e-05,
      "loss": 1.1271,
      "step": 3450
    },
    {
      "epoch": 0.15572257977406723,
      "grad_norm": 1.2307758331298828,
      "learning_rate": 9.844277420225934e-05,
      "loss": 1.1196,
      "step": 3460
    },
    {
      "epoch": 0.15617264503352987,
      "grad_norm": 1.1177942752838135,
      "learning_rate": 9.84382735496647e-05,
      "loss": 1.0839,
      "step": 3470
    },
    {
      "epoch": 0.1566227102929925,
      "grad_norm": 2.507908821105957,
      "learning_rate": 9.843377289707007e-05,
      "loss": 1.1411,
      "step": 3480
    },
    {
      "epoch": 0.1570727755524551,
      "grad_norm": 1.3948771953582764,
      "learning_rate": 9.842927224447546e-05,
      "loss": 1.1414,
      "step": 3490
    },
    {
      "epoch": 0.15752284081191772,
      "grad_norm": 1.4072723388671875,
      "learning_rate": 9.842477159188082e-05,
      "loss": 1.0824,
      "step": 3500
    },
    {
      "epoch": 0.15797290607138034,
      "grad_norm": 1.3642914295196533,
      "learning_rate": 9.84202709392862e-05,
      "loss": 1.1447,
      "step": 3510
    },
    {
      "epoch": 0.15842297133084296,
      "grad_norm": 1.4484481811523438,
      "learning_rate": 9.841577028669158e-05,
      "loss": 1.1041,
      "step": 3520
    },
    {
      "epoch": 0.1588730365903056,
      "grad_norm": 2.6267967224121094,
      "learning_rate": 9.841126963409694e-05,
      "loss": 1.123,
      "step": 3530
    },
    {
      "epoch": 0.15932310184976822,
      "grad_norm": 1.1378209590911865,
      "learning_rate": 9.840676898150231e-05,
      "loss": 1.0806,
      "step": 3540
    },
    {
      "epoch": 0.15977316710923084,
      "grad_norm": 1.3272981643676758,
      "learning_rate": 9.84022683289077e-05,
      "loss": 1.1238,
      "step": 3550
    },
    {
      "epoch": 0.16022323236869346,
      "grad_norm": 1.1321569681167603,
      "learning_rate": 9.839776767631306e-05,
      "loss": 1.1058,
      "step": 3560
    },
    {
      "epoch": 0.16067329762815608,
      "grad_norm": 1.2264254093170166,
      "learning_rate": 9.839326702371844e-05,
      "loss": 1.0948,
      "step": 3570
    },
    {
      "epoch": 0.1611233628876187,
      "grad_norm": 1.5798877477645874,
      "learning_rate": 9.838876637112382e-05,
      "loss": 1.0925,
      "step": 3580
    },
    {
      "epoch": 0.16157342814708134,
      "grad_norm": 1.5651262998580933,
      "learning_rate": 9.83842657185292e-05,
      "loss": 1.131,
      "step": 3590
    },
    {
      "epoch": 0.16202349340654396,
      "grad_norm": 1.1416082382202148,
      "learning_rate": 9.837976506593457e-05,
      "loss": 1.0626,
      "step": 3600
    },
    {
      "epoch": 0.16247355866600657,
      "grad_norm": 1.7793244123458862,
      "learning_rate": 9.837526441333994e-05,
      "loss": 1.057,
      "step": 3610
    },
    {
      "epoch": 0.1629236239254692,
      "grad_norm": 2.613308906555176,
      "learning_rate": 9.837076376074532e-05,
      "loss": 1.0889,
      "step": 3620
    },
    {
      "epoch": 0.1633736891849318,
      "grad_norm": 1.2556349039077759,
      "learning_rate": 9.836626310815069e-05,
      "loss": 1.1363,
      "step": 3630
    },
    {
      "epoch": 0.16382375444439443,
      "grad_norm": 3.285463809967041,
      "learning_rate": 9.836176245555606e-05,
      "loss": 1.0794,
      "step": 3640
    },
    {
      "epoch": 0.16427381970385707,
      "grad_norm": 1.541549801826477,
      "learning_rate": 9.835726180296144e-05,
      "loss": 1.2145,
      "step": 3650
    },
    {
      "epoch": 0.1647238849633197,
      "grad_norm": 1.5443978309631348,
      "learning_rate": 9.835276115036681e-05,
      "loss": 1.1235,
      "step": 3660
    },
    {
      "epoch": 0.1651739502227823,
      "grad_norm": 1.2972668409347534,
      "learning_rate": 9.834826049777218e-05,
      "loss": 1.054,
      "step": 3670
    },
    {
      "epoch": 0.16562401548224492,
      "grad_norm": 0.9810883402824402,
      "learning_rate": 9.834375984517756e-05,
      "loss": 1.1997,
      "step": 3680
    },
    {
      "epoch": 0.16607408074170754,
      "grad_norm": 1.1355971097946167,
      "learning_rate": 9.833925919258293e-05,
      "loss": 1.1276,
      "step": 3690
    },
    {
      "epoch": 0.16652414600117016,
      "grad_norm": 1.3670769929885864,
      "learning_rate": 9.83347585399883e-05,
      "loss": 1.0219,
      "step": 3700
    },
    {
      "epoch": 0.1669742112606328,
      "grad_norm": 1.5918631553649902,
      "learning_rate": 9.833025788739368e-05,
      "loss": 1.0889,
      "step": 3710
    },
    {
      "epoch": 0.16742427652009542,
      "grad_norm": 1.5076981782913208,
      "learning_rate": 9.832575723479905e-05,
      "loss": 1.0885,
      "step": 3720
    },
    {
      "epoch": 0.16787434177955804,
      "grad_norm": 1.5236027240753174,
      "learning_rate": 9.832125658220443e-05,
      "loss": 1.1796,
      "step": 3730
    },
    {
      "epoch": 0.16832440703902066,
      "grad_norm": 2.734354019165039,
      "learning_rate": 9.83167559296098e-05,
      "loss": 1.0533,
      "step": 3740
    },
    {
      "epoch": 0.16877447229848327,
      "grad_norm": 1.070342779159546,
      "learning_rate": 9.831225527701517e-05,
      "loss": 1.1358,
      "step": 3750
    },
    {
      "epoch": 0.1692245375579459,
      "grad_norm": 1.4823747873306274,
      "learning_rate": 9.830775462442055e-05,
      "loss": 1.1347,
      "step": 3760
    },
    {
      "epoch": 0.16967460281740854,
      "grad_norm": 2.4118568897247314,
      "learning_rate": 9.830325397182592e-05,
      "loss": 1.1259,
      "step": 3770
    },
    {
      "epoch": 0.17012466807687115,
      "grad_norm": 1.5567532777786255,
      "learning_rate": 9.82987533192313e-05,
      "loss": 1.1918,
      "step": 3780
    },
    {
      "epoch": 0.17057473333633377,
      "grad_norm": 1.513161063194275,
      "learning_rate": 9.829425266663667e-05,
      "loss": 1.1778,
      "step": 3790
    },
    {
      "epoch": 0.1710247985957964,
      "grad_norm": 1.7706934213638306,
      "learning_rate": 9.828975201404204e-05,
      "loss": 1.1596,
      "step": 3800
    },
    {
      "epoch": 0.171474863855259,
      "grad_norm": 1.208297848701477,
      "learning_rate": 9.828525136144742e-05,
      "loss": 1.0946,
      "step": 3810
    },
    {
      "epoch": 0.17192492911472163,
      "grad_norm": 1.9069249629974365,
      "learning_rate": 9.828075070885279e-05,
      "loss": 1.1498,
      "step": 3820
    },
    {
      "epoch": 0.17237499437418427,
      "grad_norm": 2.130568265914917,
      "learning_rate": 9.827625005625816e-05,
      "loss": 1.2397,
      "step": 3830
    },
    {
      "epoch": 0.1728250596336469,
      "grad_norm": 1.2705215215682983,
      "learning_rate": 9.827174940366354e-05,
      "loss": 1.1403,
      "step": 3840
    },
    {
      "epoch": 0.1732751248931095,
      "grad_norm": 1.422611117362976,
      "learning_rate": 9.826724875106891e-05,
      "loss": 1.0807,
      "step": 3850
    },
    {
      "epoch": 0.17372519015257212,
      "grad_norm": 1.2962371110916138,
      "learning_rate": 9.826274809847428e-05,
      "loss": 1.1241,
      "step": 3860
    },
    {
      "epoch": 0.17417525541203474,
      "grad_norm": 1.7975112199783325,
      "learning_rate": 9.825824744587966e-05,
      "loss": 1.0321,
      "step": 3870
    },
    {
      "epoch": 0.17462532067149736,
      "grad_norm": 1.6768416166305542,
      "learning_rate": 9.825374679328503e-05,
      "loss": 1.0689,
      "step": 3880
    },
    {
      "epoch": 0.17507538593095998,
      "grad_norm": 1.1239269971847534,
      "learning_rate": 9.82492461406904e-05,
      "loss": 1.1052,
      "step": 3890
    },
    {
      "epoch": 0.17552545119042262,
      "grad_norm": 2.9023334980010986,
      "learning_rate": 9.824474548809578e-05,
      "loss": 1.1417,
      "step": 3900
    },
    {
      "epoch": 0.17597551644988524,
      "grad_norm": 1.572805643081665,
      "learning_rate": 9.824024483550115e-05,
      "loss": 1.0847,
      "step": 3910
    },
    {
      "epoch": 0.17642558170934786,
      "grad_norm": 1.6031386852264404,
      "learning_rate": 9.823574418290653e-05,
      "loss": 1.1228,
      "step": 3920
    },
    {
      "epoch": 0.17687564696881047,
      "grad_norm": 1.655935525894165,
      "learning_rate": 9.82312435303119e-05,
      "loss": 1.1847,
      "step": 3930
    },
    {
      "epoch": 0.1773257122282731,
      "grad_norm": 2.0881237983703613,
      "learning_rate": 9.822674287771727e-05,
      "loss": 1.117,
      "step": 3940
    },
    {
      "epoch": 0.1777757774877357,
      "grad_norm": 1.7270547151565552,
      "learning_rate": 9.822224222512265e-05,
      "loss": 1.1248,
      "step": 3950
    },
    {
      "epoch": 0.17822584274719835,
      "grad_norm": 1.5482590198516846,
      "learning_rate": 9.821774157252802e-05,
      "loss": 1.0755,
      "step": 3960
    },
    {
      "epoch": 0.17867590800666097,
      "grad_norm": 1.7765798568725586,
      "learning_rate": 9.821324091993339e-05,
      "loss": 1.0426,
      "step": 3970
    },
    {
      "epoch": 0.1791259732661236,
      "grad_norm": 2.118722915649414,
      "learning_rate": 9.820874026733877e-05,
      "loss": 1.0908,
      "step": 3980
    },
    {
      "epoch": 0.1795760385255862,
      "grad_norm": 1.1859781742095947,
      "learning_rate": 9.820423961474414e-05,
      "loss": 1.1709,
      "step": 3990
    },
    {
      "epoch": 0.18002610378504882,
      "grad_norm": 1.0117706060409546,
      "learning_rate": 9.819973896214951e-05,
      "loss": 1.115,
      "step": 4000
    },
    {
      "epoch": 0.18047616904451144,
      "grad_norm": 0.970751941204071,
      "learning_rate": 9.819523830955489e-05,
      "loss": 1.1008,
      "step": 4010
    },
    {
      "epoch": 0.1809262343039741,
      "grad_norm": 1.146525502204895,
      "learning_rate": 9.819073765696026e-05,
      "loss": 1.1423,
      "step": 4020
    },
    {
      "epoch": 0.1813762995634367,
      "grad_norm": 2.393697738647461,
      "learning_rate": 9.818623700436563e-05,
      "loss": 1.0937,
      "step": 4030
    },
    {
      "epoch": 0.18182636482289932,
      "grad_norm": 2.111043930053711,
      "learning_rate": 9.818173635177101e-05,
      "loss": 1.0966,
      "step": 4040
    },
    {
      "epoch": 0.18227643008236194,
      "grad_norm": 1.8864198923110962,
      "learning_rate": 9.817723569917638e-05,
      "loss": 1.102,
      "step": 4050
    },
    {
      "epoch": 0.18272649534182456,
      "grad_norm": 1.4715508222579956,
      "learning_rate": 9.817273504658176e-05,
      "loss": 1.197,
      "step": 4060
    },
    {
      "epoch": 0.18317656060128717,
      "grad_norm": 1.158396601676941,
      "learning_rate": 9.816823439398713e-05,
      "loss": 1.099,
      "step": 4070
    },
    {
      "epoch": 0.18362662586074982,
      "grad_norm": 1.8718358278274536,
      "learning_rate": 9.81637337413925e-05,
      "loss": 1.0717,
      "step": 4080
    },
    {
      "epoch": 0.18407669112021244,
      "grad_norm": 1.068461298942566,
      "learning_rate": 9.815923308879788e-05,
      "loss": 1.17,
      "step": 4090
    },
    {
      "epoch": 0.18452675637967506,
      "grad_norm": 3.4569969177246094,
      "learning_rate": 9.815473243620325e-05,
      "loss": 1.0522,
      "step": 4100
    },
    {
      "epoch": 0.18497682163913767,
      "grad_norm": 2.1346821784973145,
      "learning_rate": 9.815023178360862e-05,
      "loss": 1.0722,
      "step": 4110
    },
    {
      "epoch": 0.1854268868986003,
      "grad_norm": 2.809138774871826,
      "learning_rate": 9.814573113101401e-05,
      "loss": 1.1019,
      "step": 4120
    },
    {
      "epoch": 0.1858769521580629,
      "grad_norm": 1.8383686542510986,
      "learning_rate": 9.814123047841937e-05,
      "loss": 1.1348,
      "step": 4130
    },
    {
      "epoch": 0.18632701741752555,
      "grad_norm": 1.403946042060852,
      "learning_rate": 9.813672982582474e-05,
      "loss": 1.1023,
      "step": 4140
    },
    {
      "epoch": 0.18677708267698817,
      "grad_norm": 1.6385338306427002,
      "learning_rate": 9.813222917323013e-05,
      "loss": 1.1333,
      "step": 4150
    },
    {
      "epoch": 0.1872271479364508,
      "grad_norm": 1.7444159984588623,
      "learning_rate": 9.812772852063549e-05,
      "loss": 1.1389,
      "step": 4160
    },
    {
      "epoch": 0.1876772131959134,
      "grad_norm": 2.30859112739563,
      "learning_rate": 9.812322786804087e-05,
      "loss": 1.1688,
      "step": 4170
    },
    {
      "epoch": 0.18812727845537602,
      "grad_norm": 2.900463581085205,
      "learning_rate": 9.811872721544625e-05,
      "loss": 1.1057,
      "step": 4180
    },
    {
      "epoch": 0.18857734371483864,
      "grad_norm": 2.275184392929077,
      "learning_rate": 9.811422656285161e-05,
      "loss": 1.1227,
      "step": 4190
    },
    {
      "epoch": 0.1890274089743013,
      "grad_norm": 1.9285674095153809,
      "learning_rate": 9.810972591025699e-05,
      "loss": 1.1299,
      "step": 4200
    },
    {
      "epoch": 0.1894774742337639,
      "grad_norm": 2.442753553390503,
      "learning_rate": 9.810522525766237e-05,
      "loss": 1.1059,
      "step": 4210
    },
    {
      "epoch": 0.18992753949322652,
      "grad_norm": 1.8504575490951538,
      "learning_rate": 9.810072460506773e-05,
      "loss": 1.0795,
      "step": 4220
    },
    {
      "epoch": 0.19037760475268914,
      "grad_norm": 2.4273107051849365,
      "learning_rate": 9.80962239524731e-05,
      "loss": 1.0645,
      "step": 4230
    },
    {
      "epoch": 0.19082767001215176,
      "grad_norm": 2.4463393688201904,
      "learning_rate": 9.80917232998785e-05,
      "loss": 1.1245,
      "step": 4240
    },
    {
      "epoch": 0.19127773527161437,
      "grad_norm": 1.3700047731399536,
      "learning_rate": 9.808722264728385e-05,
      "loss": 1.2067,
      "step": 4250
    },
    {
      "epoch": 0.19172780053107702,
      "grad_norm": 1.4985779523849487,
      "learning_rate": 9.808272199468923e-05,
      "loss": 1.0957,
      "step": 4260
    },
    {
      "epoch": 0.19217786579053964,
      "grad_norm": 1.078995704650879,
      "learning_rate": 9.807822134209461e-05,
      "loss": 1.0684,
      "step": 4270
    },
    {
      "epoch": 0.19262793105000225,
      "grad_norm": 2.382474660873413,
      "learning_rate": 9.807372068949999e-05,
      "loss": 1.1117,
      "step": 4280
    },
    {
      "epoch": 0.19307799630946487,
      "grad_norm": 1.9226549863815308,
      "learning_rate": 9.806922003690535e-05,
      "loss": 1.0497,
      "step": 4290
    },
    {
      "epoch": 0.1935280615689275,
      "grad_norm": 1.1493440866470337,
      "learning_rate": 9.806471938431074e-05,
      "loss": 1.0923,
      "step": 4300
    },
    {
      "epoch": 0.1939781268283901,
      "grad_norm": 1.6477843523025513,
      "learning_rate": 9.806021873171611e-05,
      "loss": 1.1046,
      "step": 4310
    },
    {
      "epoch": 0.19442819208785272,
      "grad_norm": 1.0810438394546509,
      "learning_rate": 9.805571807912147e-05,
      "loss": 1.0844,
      "step": 4320
    },
    {
      "epoch": 0.19487825734731537,
      "grad_norm": 1.8271913528442383,
      "learning_rate": 9.805121742652686e-05,
      "loss": 1.0914,
      "step": 4330
    },
    {
      "epoch": 0.195328322606778,
      "grad_norm": 1.4442026615142822,
      "learning_rate": 9.804671677393223e-05,
      "loss": 1.0276,
      "step": 4340
    },
    {
      "epoch": 0.1957783878662406,
      "grad_norm": 1.5705026388168335,
      "learning_rate": 9.804221612133759e-05,
      "loss": 1.1517,
      "step": 4350
    },
    {
      "epoch": 0.19622845312570322,
      "grad_norm": 0.8912438154220581,
      "learning_rate": 9.803771546874298e-05,
      "loss": 1.1983,
      "step": 4360
    },
    {
      "epoch": 0.19667851838516584,
      "grad_norm": 1.570760726928711,
      "learning_rate": 9.803321481614835e-05,
      "loss": 1.1053,
      "step": 4370
    },
    {
      "epoch": 0.19712858364462846,
      "grad_norm": 2.1574149131774902,
      "learning_rate": 9.802871416355372e-05,
      "loss": 1.2001,
      "step": 4380
    },
    {
      "epoch": 0.1975786489040911,
      "grad_norm": 0.9561978578567505,
      "learning_rate": 9.80242135109591e-05,
      "loss": 1.1404,
      "step": 4390
    },
    {
      "epoch": 0.19802871416355372,
      "grad_norm": 2.744497776031494,
      "learning_rate": 9.801971285836447e-05,
      "loss": 1.1523,
      "step": 4400
    },
    {
      "epoch": 0.19847877942301634,
      "grad_norm": 2.356196641921997,
      "learning_rate": 9.801521220576985e-05,
      "loss": 1.0452,
      "step": 4410
    },
    {
      "epoch": 0.19892884468247896,
      "grad_norm": 1.161684274673462,
      "learning_rate": 9.801071155317522e-05,
      "loss": 1.1554,
      "step": 4420
    },
    {
      "epoch": 0.19937890994194157,
      "grad_norm": 2.359982490539551,
      "learning_rate": 9.800621090058059e-05,
      "loss": 1.0718,
      "step": 4430
    },
    {
      "epoch": 0.1998289752014042,
      "grad_norm": 1.9584563970565796,
      "learning_rate": 9.800171024798597e-05,
      "loss": 1.1024,
      "step": 4440
    },
    {
      "epoch": 0.20027904046086684,
      "grad_norm": 0.7553575038909912,
      "learning_rate": 9.799720959539134e-05,
      "loss": 1.0879,
      "step": 4450
    },
    {
      "epoch": 0.20072910572032945,
      "grad_norm": 2.6733744144439697,
      "learning_rate": 9.799270894279671e-05,
      "loss": 1.135,
      "step": 4460
    },
    {
      "epoch": 0.20117917097979207,
      "grad_norm": 1.059086561203003,
      "learning_rate": 9.798820829020209e-05,
      "loss": 1.1432,
      "step": 4470
    },
    {
      "epoch": 0.2016292362392547,
      "grad_norm": 1.3368409872055054,
      "learning_rate": 9.798370763760746e-05,
      "loss": 1.0944,
      "step": 4480
    },
    {
      "epoch": 0.2020793014987173,
      "grad_norm": 2.2497267723083496,
      "learning_rate": 9.797920698501283e-05,
      "loss": 1.1761,
      "step": 4490
    },
    {
      "epoch": 0.20252936675817992,
      "grad_norm": 1.8160403966903687,
      "learning_rate": 9.797470633241821e-05,
      "loss": 1.0548,
      "step": 4500
    },
    {
      "epoch": 0.20297943201764257,
      "grad_norm": 2.3492424488067627,
      "learning_rate": 9.797020567982358e-05,
      "loss": 1.0455,
      "step": 4510
    },
    {
      "epoch": 0.2034294972771052,
      "grad_norm": 1.3785412311553955,
      "learning_rate": 9.796570502722895e-05,
      "loss": 1.0402,
      "step": 4520
    },
    {
      "epoch": 0.2038795625365678,
      "grad_norm": 2.0948050022125244,
      "learning_rate": 9.796120437463433e-05,
      "loss": 1.2472,
      "step": 4530
    },
    {
      "epoch": 0.20432962779603042,
      "grad_norm": 2.1021413803100586,
      "learning_rate": 9.79567037220397e-05,
      "loss": 1.0528,
      "step": 4540
    },
    {
      "epoch": 0.20477969305549304,
      "grad_norm": 1.6743431091308594,
      "learning_rate": 9.795220306944508e-05,
      "loss": 1.0644,
      "step": 4550
    },
    {
      "epoch": 0.20522975831495566,
      "grad_norm": 1.315136194229126,
      "learning_rate": 9.794770241685045e-05,
      "loss": 1.1162,
      "step": 4560
    },
    {
      "epoch": 0.2056798235744183,
      "grad_norm": 1.6999057531356812,
      "learning_rate": 9.794320176425582e-05,
      "loss": 1.1463,
      "step": 4570
    },
    {
      "epoch": 0.20612988883388092,
      "grad_norm": 1.442358136177063,
      "learning_rate": 9.79387011116612e-05,
      "loss": 1.1362,
      "step": 4580
    },
    {
      "epoch": 0.20657995409334354,
      "grad_norm": 0.9224885702133179,
      "learning_rate": 9.793420045906657e-05,
      "loss": 1.1261,
      "step": 4590
    },
    {
      "epoch": 0.20703001935280615,
      "grad_norm": 1.8926684856414795,
      "learning_rate": 9.792969980647194e-05,
      "loss": 1.0915,
      "step": 4600
    },
    {
      "epoch": 0.20748008461226877,
      "grad_norm": 1.3557034730911255,
      "learning_rate": 9.792519915387732e-05,
      "loss": 1.1356,
      "step": 4610
    },
    {
      "epoch": 0.2079301498717314,
      "grad_norm": 1.1812559366226196,
      "learning_rate": 9.792069850128269e-05,
      "loss": 1.1519,
      "step": 4620
    },
    {
      "epoch": 0.20838021513119404,
      "grad_norm": 1.1235815286636353,
      "learning_rate": 9.791619784868806e-05,
      "loss": 1.1195,
      "step": 4630
    },
    {
      "epoch": 0.20883028039065665,
      "grad_norm": 2.3848884105682373,
      "learning_rate": 9.791169719609344e-05,
      "loss": 1.0883,
      "step": 4640
    },
    {
      "epoch": 0.20928034565011927,
      "grad_norm": 1.0411499738693237,
      "learning_rate": 9.790719654349881e-05,
      "loss": 1.099,
      "step": 4650
    },
    {
      "epoch": 0.2097304109095819,
      "grad_norm": 2.3813118934631348,
      "learning_rate": 9.790269589090419e-05,
      "loss": 1.0824,
      "step": 4660
    },
    {
      "epoch": 0.2101804761690445,
      "grad_norm": 0.8800971508026123,
      "learning_rate": 9.789819523830956e-05,
      "loss": 1.1133,
      "step": 4670
    },
    {
      "epoch": 0.21063054142850712,
      "grad_norm": 1.490515947341919,
      "learning_rate": 9.789369458571493e-05,
      "loss": 1.1103,
      "step": 4680
    },
    {
      "epoch": 0.21108060668796977,
      "grad_norm": 2.1835379600524902,
      "learning_rate": 9.78891939331203e-05,
      "loss": 1.1392,
      "step": 4690
    },
    {
      "epoch": 0.21153067194743239,
      "grad_norm": 1.8895214796066284,
      "learning_rate": 9.788469328052568e-05,
      "loss": 1.1341,
      "step": 4700
    },
    {
      "epoch": 0.211980737206895,
      "grad_norm": 1.7677570581436157,
      "learning_rate": 9.788019262793105e-05,
      "loss": 1.0797,
      "step": 4710
    },
    {
      "epoch": 0.21243080246635762,
      "grad_norm": 2.332491159439087,
      "learning_rate": 9.787569197533643e-05,
      "loss": 1.1168,
      "step": 4720
    },
    {
      "epoch": 0.21288086772582024,
      "grad_norm": 1.2677230834960938,
      "learning_rate": 9.78711913227418e-05,
      "loss": 1.0338,
      "step": 4730
    },
    {
      "epoch": 0.21333093298528286,
      "grad_norm": 2.14689564704895,
      "learning_rate": 9.786669067014717e-05,
      "loss": 1.0071,
      "step": 4740
    },
    {
      "epoch": 0.2137809982447455,
      "grad_norm": 3.1455554962158203,
      "learning_rate": 9.786219001755255e-05,
      "loss": 1.1438,
      "step": 4750
    },
    {
      "epoch": 0.21423106350420812,
      "grad_norm": 2.0292930603027344,
      "learning_rate": 9.785768936495792e-05,
      "loss": 1.0749,
      "step": 4760
    },
    {
      "epoch": 0.21468112876367074,
      "grad_norm": 1.508325457572937,
      "learning_rate": 9.78531887123633e-05,
      "loss": 1.0888,
      "step": 4770
    },
    {
      "epoch": 0.21513119402313335,
      "grad_norm": 2.5492687225341797,
      "learning_rate": 9.784868805976867e-05,
      "loss": 1.1404,
      "step": 4780
    },
    {
      "epoch": 0.21558125928259597,
      "grad_norm": 1.0983251333236694,
      "learning_rate": 9.784418740717404e-05,
      "loss": 1.1336,
      "step": 4790
    },
    {
      "epoch": 0.2160313245420586,
      "grad_norm": 1.0768264532089233,
      "learning_rate": 9.783968675457942e-05,
      "loss": 1.0895,
      "step": 4800
    },
    {
      "epoch": 0.2164813898015212,
      "grad_norm": 2.292938232421875,
      "learning_rate": 9.783518610198479e-05,
      "loss": 1.1433,
      "step": 4810
    },
    {
      "epoch": 0.21693145506098385,
      "grad_norm": 1.3340829610824585,
      "learning_rate": 9.783068544939016e-05,
      "loss": 1.1143,
      "step": 4820
    },
    {
      "epoch": 0.21738152032044647,
      "grad_norm": 1.217544436454773,
      "learning_rate": 9.782618479679554e-05,
      "loss": 1.0425,
      "step": 4830
    },
    {
      "epoch": 0.2178315855799091,
      "grad_norm": 2.144092082977295,
      "learning_rate": 9.782168414420091e-05,
      "loss": 1.1302,
      "step": 4840
    },
    {
      "epoch": 0.2182816508393717,
      "grad_norm": 1.4545625448226929,
      "learning_rate": 9.781718349160628e-05,
      "loss": 1.1454,
      "step": 4850
    },
    {
      "epoch": 0.21873171609883432,
      "grad_norm": 2.7325618267059326,
      "learning_rate": 9.781268283901166e-05,
      "loss": 1.1321,
      "step": 4860
    },
    {
      "epoch": 0.21918178135829694,
      "grad_norm": 1.2063437700271606,
      "learning_rate": 9.780818218641703e-05,
      "loss": 1.1608,
      "step": 4870
    },
    {
      "epoch": 0.21963184661775959,
      "grad_norm": 0.9299390316009521,
      "learning_rate": 9.78036815338224e-05,
      "loss": 1.1213,
      "step": 4880
    },
    {
      "epoch": 0.2200819118772222,
      "grad_norm": 1.3398618698120117,
      "learning_rate": 9.779918088122778e-05,
      "loss": 1.1415,
      "step": 4890
    },
    {
      "epoch": 0.22053197713668482,
      "grad_norm": 1.6122500896453857,
      "learning_rate": 9.779468022863317e-05,
      "loss": 1.1697,
      "step": 4900
    },
    {
      "epoch": 0.22098204239614744,
      "grad_norm": 1.6235861778259277,
      "learning_rate": 9.779017957603853e-05,
      "loss": 1.1217,
      "step": 4910
    },
    {
      "epoch": 0.22143210765561006,
      "grad_norm": 2.005943536758423,
      "learning_rate": 9.77856789234439e-05,
      "loss": 1.0608,
      "step": 4920
    },
    {
      "epoch": 0.22188217291507267,
      "grad_norm": 0.9442667961120605,
      "learning_rate": 9.778117827084929e-05,
      "loss": 1.0524,
      "step": 4930
    },
    {
      "epoch": 0.22233223817453532,
      "grad_norm": 1.805290937423706,
      "learning_rate": 9.777667761825465e-05,
      "loss": 1.1219,
      "step": 4940
    },
    {
      "epoch": 0.22278230343399794,
      "grad_norm": 0.9720779657363892,
      "learning_rate": 9.777217696566002e-05,
      "loss": 0.999,
      "step": 4950
    },
    {
      "epoch": 0.22323236869346055,
      "grad_norm": 2.069472551345825,
      "learning_rate": 9.776767631306541e-05,
      "loss": 1.1285,
      "step": 4960
    },
    {
      "epoch": 0.22368243395292317,
      "grad_norm": 1.31186044216156,
      "learning_rate": 9.776317566047078e-05,
      "loss": 1.0787,
      "step": 4970
    },
    {
      "epoch": 0.2241324992123858,
      "grad_norm": 1.7940155267715454,
      "learning_rate": 9.775867500787614e-05,
      "loss": 1.113,
      "step": 4980
    },
    {
      "epoch": 0.2245825644718484,
      "grad_norm": 1.004896640777588,
      "learning_rate": 9.775417435528153e-05,
      "loss": 1.1433,
      "step": 4990
    },
    {
      "epoch": 0.22503262973131105,
      "grad_norm": 3.1057586669921875,
      "learning_rate": 9.77496737026869e-05,
      "loss": 1.1,
      "step": 5000
    },
    {
      "epoch": 0.22548269499077367,
      "grad_norm": 2.666752576828003,
      "learning_rate": 9.774517305009226e-05,
      "loss": 1.033,
      "step": 5010
    },
    {
      "epoch": 0.2259327602502363,
      "grad_norm": 1.3890584707260132,
      "learning_rate": 9.774067239749765e-05,
      "loss": 1.0227,
      "step": 5020
    },
    {
      "epoch": 0.2263828255096989,
      "grad_norm": 2.161341428756714,
      "learning_rate": 9.773617174490302e-05,
      "loss": 1.2027,
      "step": 5030
    },
    {
      "epoch": 0.22683289076916152,
      "grad_norm": 1.482864499092102,
      "learning_rate": 9.773167109230838e-05,
      "loss": 1.0741,
      "step": 5040
    },
    {
      "epoch": 0.22728295602862414,
      "grad_norm": 1.6510294675827026,
      "learning_rate": 9.772717043971377e-05,
      "loss": 1.1333,
      "step": 5050
    },
    {
      "epoch": 0.22773302128808678,
      "grad_norm": 2.07063889503479,
      "learning_rate": 9.772266978711914e-05,
      "loss": 1.0429,
      "step": 5060
    },
    {
      "epoch": 0.2281830865475494,
      "grad_norm": 2.4059526920318604,
      "learning_rate": 9.77181691345245e-05,
      "loss": 1.1461,
      "step": 5070
    },
    {
      "epoch": 0.22863315180701202,
      "grad_norm": 1.1349319219589233,
      "learning_rate": 9.771366848192989e-05,
      "loss": 1.0554,
      "step": 5080
    },
    {
      "epoch": 0.22908321706647464,
      "grad_norm": 1.8618652820587158,
      "learning_rate": 9.770916782933526e-05,
      "loss": 1.0981,
      "step": 5090
    },
    {
      "epoch": 0.22953328232593725,
      "grad_norm": 2.0133397579193115,
      "learning_rate": 9.770466717674062e-05,
      "loss": 1.1583,
      "step": 5100
    },
    {
      "epoch": 0.22998334758539987,
      "grad_norm": 1.606138825416565,
      "learning_rate": 9.770016652414601e-05,
      "loss": 1.1199,
      "step": 5110
    },
    {
      "epoch": 0.23043341284486252,
      "grad_norm": 1.4725925922393799,
      "learning_rate": 9.769566587155138e-05,
      "loss": 1.1914,
      "step": 5120
    },
    {
      "epoch": 0.23088347810432513,
      "grad_norm": 2.045295476913452,
      "learning_rate": 9.769116521895674e-05,
      "loss": 1.088,
      "step": 5130
    },
    {
      "epoch": 0.23133354336378775,
      "grad_norm": 3.377671003341675,
      "learning_rate": 9.768666456636213e-05,
      "loss": 1.155,
      "step": 5140
    },
    {
      "epoch": 0.23178360862325037,
      "grad_norm": 1.237445592880249,
      "learning_rate": 9.76821639137675e-05,
      "loss": 1.0878,
      "step": 5150
    },
    {
      "epoch": 0.232233673882713,
      "grad_norm": 1.109788417816162,
      "learning_rate": 9.767766326117287e-05,
      "loss": 1.0642,
      "step": 5160
    },
    {
      "epoch": 0.2326837391421756,
      "grad_norm": 2.4467954635620117,
      "learning_rate": 9.767316260857825e-05,
      "loss": 1.183,
      "step": 5170
    },
    {
      "epoch": 0.23313380440163825,
      "grad_norm": 1.6911238431930542,
      "learning_rate": 9.766866195598363e-05,
      "loss": 1.1524,
      "step": 5180
    },
    {
      "epoch": 0.23358386966110087,
      "grad_norm": 2.1854612827301025,
      "learning_rate": 9.7664161303389e-05,
      "loss": 1.0722,
      "step": 5190
    },
    {
      "epoch": 0.23403393492056349,
      "grad_norm": 1.6892534494400024,
      "learning_rate": 9.765966065079437e-05,
      "loss": 1.0779,
      "step": 5200
    },
    {
      "epoch": 0.2344840001800261,
      "grad_norm": 1.1630547046661377,
      "learning_rate": 9.765515999819975e-05,
      "loss": 1.0866,
      "step": 5210
    },
    {
      "epoch": 0.23493406543948872,
      "grad_norm": 1.9125860929489136,
      "learning_rate": 9.765065934560512e-05,
      "loss": 1.0968,
      "step": 5220
    },
    {
      "epoch": 0.23538413069895134,
      "grad_norm": 1.5158605575561523,
      "learning_rate": 9.76461586930105e-05,
      "loss": 1.1044,
      "step": 5230
    },
    {
      "epoch": 0.23583419595841398,
      "grad_norm": 1.2942371368408203,
      "learning_rate": 9.764165804041587e-05,
      "loss": 1.0752,
      "step": 5240
    },
    {
      "epoch": 0.2362842612178766,
      "grad_norm": 1.1802998781204224,
      "learning_rate": 9.763715738782124e-05,
      "loss": 1.138,
      "step": 5250
    },
    {
      "epoch": 0.23673432647733922,
      "grad_norm": 2.354408025741577,
      "learning_rate": 9.763265673522662e-05,
      "loss": 1.1164,
      "step": 5260
    },
    {
      "epoch": 0.23718439173680184,
      "grad_norm": 1.2245497703552246,
      "learning_rate": 9.762815608263199e-05,
      "loss": 1.1936,
      "step": 5270
    },
    {
      "epoch": 0.23763445699626445,
      "grad_norm": 1.7197502851486206,
      "learning_rate": 9.762365543003736e-05,
      "loss": 1.0516,
      "step": 5280
    },
    {
      "epoch": 0.23808452225572707,
      "grad_norm": 1.0899618864059448,
      "learning_rate": 9.761915477744274e-05,
      "loss": 1.0805,
      "step": 5290
    },
    {
      "epoch": 0.2385345875151897,
      "grad_norm": 1.3369617462158203,
      "learning_rate": 9.761465412484811e-05,
      "loss": 1.1453,
      "step": 5300
    },
    {
      "epoch": 0.23898465277465233,
      "grad_norm": 1.6667203903198242,
      "learning_rate": 9.761015347225348e-05,
      "loss": 1.0988,
      "step": 5310
    },
    {
      "epoch": 0.23943471803411495,
      "grad_norm": 1.3952281475067139,
      "learning_rate": 9.760565281965886e-05,
      "loss": 1.0279,
      "step": 5320
    },
    {
      "epoch": 0.23988478329357757,
      "grad_norm": 1.8624581098556519,
      "learning_rate": 9.760115216706423e-05,
      "loss": 1.0484,
      "step": 5330
    },
    {
      "epoch": 0.2403348485530402,
      "grad_norm": 1.7758042812347412,
      "learning_rate": 9.75966515144696e-05,
      "loss": 1.081,
      "step": 5340
    },
    {
      "epoch": 0.2407849138125028,
      "grad_norm": 1.9357082843780518,
      "learning_rate": 9.759215086187498e-05,
      "loss": 1.081,
      "step": 5350
    },
    {
      "epoch": 0.24123497907196542,
      "grad_norm": 1.6006251573562622,
      "learning_rate": 9.758765020928035e-05,
      "loss": 1.083,
      "step": 5360
    },
    {
      "epoch": 0.24168504433142807,
      "grad_norm": 1.5010178089141846,
      "learning_rate": 9.758314955668572e-05,
      "loss": 1.1338,
      "step": 5370
    },
    {
      "epoch": 0.24213510959089068,
      "grad_norm": 0.7567880749702454,
      "learning_rate": 9.75786489040911e-05,
      "loss": 1.0631,
      "step": 5380
    },
    {
      "epoch": 0.2425851748503533,
      "grad_norm": 1.2015910148620605,
      "learning_rate": 9.757414825149647e-05,
      "loss": 1.0644,
      "step": 5390
    },
    {
      "epoch": 0.24303524010981592,
      "grad_norm": 1.5450148582458496,
      "learning_rate": 9.756964759890185e-05,
      "loss": 1.1089,
      "step": 5400
    },
    {
      "epoch": 0.24348530536927854,
      "grad_norm": 1.5869579315185547,
      "learning_rate": 9.756514694630722e-05,
      "loss": 1.0671,
      "step": 5410
    },
    {
      "epoch": 0.24393537062874115,
      "grad_norm": 1.5933623313903809,
      "learning_rate": 9.756064629371259e-05,
      "loss": 1.1104,
      "step": 5420
    },
    {
      "epoch": 0.2443854358882038,
      "grad_norm": 1.397110104560852,
      "learning_rate": 9.755614564111797e-05,
      "loss": 1.0786,
      "step": 5430
    },
    {
      "epoch": 0.24483550114766642,
      "grad_norm": 2.5934031009674072,
      "learning_rate": 9.755164498852334e-05,
      "loss": 1.1563,
      "step": 5440
    },
    {
      "epoch": 0.24528556640712904,
      "grad_norm": 1.3617154359817505,
      "learning_rate": 9.754714433592871e-05,
      "loss": 1.0685,
      "step": 5450
    },
    {
      "epoch": 0.24573563166659165,
      "grad_norm": 1.2201632261276245,
      "learning_rate": 9.754264368333409e-05,
      "loss": 1.0963,
      "step": 5460
    },
    {
      "epoch": 0.24618569692605427,
      "grad_norm": 1.370389461517334,
      "learning_rate": 9.753814303073946e-05,
      "loss": 1.0954,
      "step": 5470
    },
    {
      "epoch": 0.2466357621855169,
      "grad_norm": 1.1029489040374756,
      "learning_rate": 9.753364237814483e-05,
      "loss": 1.1378,
      "step": 5480
    },
    {
      "epoch": 0.24708582744497953,
      "grad_norm": 2.054689407348633,
      "learning_rate": 9.752914172555021e-05,
      "loss": 1.1462,
      "step": 5490
    },
    {
      "epoch": 0.24753589270444215,
      "grad_norm": 2.0017802715301514,
      "learning_rate": 9.752464107295558e-05,
      "loss": 1.1263,
      "step": 5500
    },
    {
      "epoch": 0.24798595796390477,
      "grad_norm": 1.3924328088760376,
      "learning_rate": 9.752014042036096e-05,
      "loss": 1.0765,
      "step": 5510
    },
    {
      "epoch": 0.24843602322336739,
      "grad_norm": 1.6730271577835083,
      "learning_rate": 9.751563976776633e-05,
      "loss": 1.1659,
      "step": 5520
    },
    {
      "epoch": 0.24888608848283,
      "grad_norm": 1.733441948890686,
      "learning_rate": 9.75111391151717e-05,
      "loss": 1.1653,
      "step": 5530
    },
    {
      "epoch": 0.24933615374229262,
      "grad_norm": 2.1361005306243896,
      "learning_rate": 9.750663846257708e-05,
      "loss": 1.0919,
      "step": 5540
    },
    {
      "epoch": 0.24978621900175527,
      "grad_norm": 1.4134718179702759,
      "learning_rate": 9.750213780998245e-05,
      "loss": 1.0583,
      "step": 5550
    },
    {
      "epoch": 0.25023628426121786,
      "grad_norm": 1.49713933467865,
      "learning_rate": 9.749763715738782e-05,
      "loss": 1.1412,
      "step": 5560
    },
    {
      "epoch": 0.2506863495206805,
      "grad_norm": 1.1309535503387451,
      "learning_rate": 9.74931365047932e-05,
      "loss": 1.0245,
      "step": 5570
    },
    {
      "epoch": 0.25113641478014315,
      "grad_norm": 2.547804117202759,
      "learning_rate": 9.748863585219857e-05,
      "loss": 1.1712,
      "step": 5580
    },
    {
      "epoch": 0.25158648003960576,
      "grad_norm": 1.442479133605957,
      "learning_rate": 9.748413519960394e-05,
      "loss": 1.0309,
      "step": 5590
    },
    {
      "epoch": 0.2520365452990684,
      "grad_norm": 1.3781683444976807,
      "learning_rate": 9.747963454700932e-05,
      "loss": 1.1377,
      "step": 5600
    },
    {
      "epoch": 0.252486610558531,
      "grad_norm": 0.8564046621322632,
      "learning_rate": 9.747513389441469e-05,
      "loss": 1.1567,
      "step": 5610
    },
    {
      "epoch": 0.2529366758179936,
      "grad_norm": 1.0018659830093384,
      "learning_rate": 9.747063324182006e-05,
      "loss": 1.0858,
      "step": 5620
    },
    {
      "epoch": 0.25338674107745623,
      "grad_norm": 1.7878888845443726,
      "learning_rate": 9.746613258922544e-05,
      "loss": 1.1264,
      "step": 5630
    },
    {
      "epoch": 0.25383680633691885,
      "grad_norm": 2.0857303142547607,
      "learning_rate": 9.746163193663081e-05,
      "loss": 1.1854,
      "step": 5640
    },
    {
      "epoch": 0.25428687159638147,
      "grad_norm": 1.3479291200637817,
      "learning_rate": 9.745713128403619e-05,
      "loss": 1.1788,
      "step": 5650
    },
    {
      "epoch": 0.2547369368558441,
      "grad_norm": 1.7047713994979858,
      "learning_rate": 9.745263063144157e-05,
      "loss": 1.1527,
      "step": 5660
    },
    {
      "epoch": 0.2551870021153067,
      "grad_norm": 1.0972172021865845,
      "learning_rate": 9.744812997884693e-05,
      "loss": 1.1029,
      "step": 5670
    },
    {
      "epoch": 0.2556370673747693,
      "grad_norm": 1.7320657968521118,
      "learning_rate": 9.74436293262523e-05,
      "loss": 1.148,
      "step": 5680
    },
    {
      "epoch": 0.25608713263423194,
      "grad_norm": 1.4142088890075684,
      "learning_rate": 9.74391286736577e-05,
      "loss": 1.1305,
      "step": 5690
    },
    {
      "epoch": 0.2565371978936946,
      "grad_norm": 1.6012715101242065,
      "learning_rate": 9.743462802106305e-05,
      "loss": 1.0282,
      "step": 5700
    },
    {
      "epoch": 0.25698726315315723,
      "grad_norm": 1.6489591598510742,
      "learning_rate": 9.743012736846844e-05,
      "loss": 1.1024,
      "step": 5710
    },
    {
      "epoch": 0.25743732841261985,
      "grad_norm": 0.9819228649139404,
      "learning_rate": 9.742562671587381e-05,
      "loss": 1.079,
      "step": 5720
    },
    {
      "epoch": 0.25788739367208247,
      "grad_norm": 1.2083265781402588,
      "learning_rate": 9.742112606327917e-05,
      "loss": 1.1746,
      "step": 5730
    },
    {
      "epoch": 0.2583374589315451,
      "grad_norm": 1.1224359273910522,
      "learning_rate": 9.741662541068456e-05,
      "loss": 1.0637,
      "step": 5740
    },
    {
      "epoch": 0.2587875241910077,
      "grad_norm": 2.1996099948883057,
      "learning_rate": 9.741212475808994e-05,
      "loss": 1.0828,
      "step": 5750
    },
    {
      "epoch": 0.2592375894504703,
      "grad_norm": 2.5352725982666016,
      "learning_rate": 9.74076241054953e-05,
      "loss": 1.1234,
      "step": 5760
    },
    {
      "epoch": 0.25968765470993294,
      "grad_norm": 1.2689906358718872,
      "learning_rate": 9.740312345290068e-05,
      "loss": 1.0355,
      "step": 5770
    },
    {
      "epoch": 0.26013771996939555,
      "grad_norm": 1.6324931383132935,
      "learning_rate": 9.739862280030606e-05,
      "loss": 1.1078,
      "step": 5780
    },
    {
      "epoch": 0.26058778522885817,
      "grad_norm": 1.5304423570632935,
      "learning_rate": 9.739412214771142e-05,
      "loss": 1.1042,
      "step": 5790
    },
    {
      "epoch": 0.2610378504883208,
      "grad_norm": 1.276408076286316,
      "learning_rate": 9.73896214951168e-05,
      "loss": 1.1148,
      "step": 5800
    },
    {
      "epoch": 0.2614879157477834,
      "grad_norm": 0.7902279496192932,
      "learning_rate": 9.738512084252218e-05,
      "loss": 1.0994,
      "step": 5810
    },
    {
      "epoch": 0.261937981007246,
      "grad_norm": 3.010037899017334,
      "learning_rate": 9.738062018992754e-05,
      "loss": 1.1106,
      "step": 5820
    },
    {
      "epoch": 0.2623880462667087,
      "grad_norm": 1.6676260232925415,
      "learning_rate": 9.737611953733292e-05,
      "loss": 1.0704,
      "step": 5830
    },
    {
      "epoch": 0.2628381115261713,
      "grad_norm": 0.7932345867156982,
      "learning_rate": 9.73716188847383e-05,
      "loss": 1.1143,
      "step": 5840
    },
    {
      "epoch": 0.26328817678563393,
      "grad_norm": 1.0426567792892456,
      "learning_rate": 9.736711823214366e-05,
      "loss": 1.1064,
      "step": 5850
    },
    {
      "epoch": 0.26373824204509655,
      "grad_norm": 1.5142837762832642,
      "learning_rate": 9.736261757954904e-05,
      "loss": 1.106,
      "step": 5860
    },
    {
      "epoch": 0.26418830730455917,
      "grad_norm": 2.2723283767700195,
      "learning_rate": 9.735811692695442e-05,
      "loss": 1.0467,
      "step": 5870
    },
    {
      "epoch": 0.2646383725640218,
      "grad_norm": 2.0826728343963623,
      "learning_rate": 9.735361627435978e-05,
      "loss": 1.1159,
      "step": 5880
    },
    {
      "epoch": 0.2650884378234844,
      "grad_norm": 1.2546324729919434,
      "learning_rate": 9.734911562176517e-05,
      "loss": 1.0475,
      "step": 5890
    },
    {
      "epoch": 0.265538503082947,
      "grad_norm": 1.9651153087615967,
      "learning_rate": 9.734461496917054e-05,
      "loss": 1.0885,
      "step": 5900
    },
    {
      "epoch": 0.26598856834240964,
      "grad_norm": 1.5653351545333862,
      "learning_rate": 9.73401143165759e-05,
      "loss": 1.0706,
      "step": 5910
    },
    {
      "epoch": 0.26643863360187225,
      "grad_norm": 1.4983817338943481,
      "learning_rate": 9.733561366398129e-05,
      "loss": 1.1463,
      "step": 5920
    },
    {
      "epoch": 0.26688869886133487,
      "grad_norm": 2.0452682971954346,
      "learning_rate": 9.733111301138666e-05,
      "loss": 1.1301,
      "step": 5930
    },
    {
      "epoch": 0.2673387641207975,
      "grad_norm": 1.1894770860671997,
      "learning_rate": 9.732661235879202e-05,
      "loss": 1.0827,
      "step": 5940
    },
    {
      "epoch": 0.26778882938026016,
      "grad_norm": 1.2184600830078125,
      "learning_rate": 9.732211170619741e-05,
      "loss": 1.1435,
      "step": 5950
    },
    {
      "epoch": 0.2682388946397228,
      "grad_norm": 2.294457197189331,
      "learning_rate": 9.731761105360278e-05,
      "loss": 1.1544,
      "step": 5960
    },
    {
      "epoch": 0.2686889598991854,
      "grad_norm": 1.2543679475784302,
      "learning_rate": 9.731311040100815e-05,
      "loss": 1.1376,
      "step": 5970
    },
    {
      "epoch": 0.269139025158648,
      "grad_norm": 1.7299137115478516,
      "learning_rate": 9.730860974841353e-05,
      "loss": 1.0285,
      "step": 5980
    },
    {
      "epoch": 0.26958909041811063,
      "grad_norm": 1.5392855405807495,
      "learning_rate": 9.73041090958189e-05,
      "loss": 1.1634,
      "step": 5990
    },
    {
      "epoch": 0.27003915567757325,
      "grad_norm": 1.1986582279205322,
      "learning_rate": 9.729960844322428e-05,
      "loss": 1.1354,
      "step": 6000
    },
    {
      "epoch": 0.27048922093703587,
      "grad_norm": 1.7325451374053955,
      "learning_rate": 9.729510779062965e-05,
      "loss": 1.0583,
      "step": 6010
    },
    {
      "epoch": 0.2709392861964985,
      "grad_norm": 1.3296804428100586,
      "learning_rate": 9.729060713803502e-05,
      "loss": 1.074,
      "step": 6020
    },
    {
      "epoch": 0.2713893514559611,
      "grad_norm": 1.3367630243301392,
      "learning_rate": 9.72861064854404e-05,
      "loss": 1.0534,
      "step": 6030
    },
    {
      "epoch": 0.2718394167154237,
      "grad_norm": 2.485687494277954,
      "learning_rate": 9.728160583284577e-05,
      "loss": 1.0882,
      "step": 6040
    },
    {
      "epoch": 0.27228948197488634,
      "grad_norm": 1.4820382595062256,
      "learning_rate": 9.727710518025114e-05,
      "loss": 1.0908,
      "step": 6050
    },
    {
      "epoch": 0.27273954723434896,
      "grad_norm": 2.0969231128692627,
      "learning_rate": 9.727260452765652e-05,
      "loss": 1.0971,
      "step": 6060
    },
    {
      "epoch": 0.27318961249381163,
      "grad_norm": 1.9515550136566162,
      "learning_rate": 9.726810387506189e-05,
      "loss": 1.1296,
      "step": 6070
    },
    {
      "epoch": 0.27363967775327425,
      "grad_norm": 1.7318236827850342,
      "learning_rate": 9.726360322246726e-05,
      "loss": 1.0665,
      "step": 6080
    },
    {
      "epoch": 0.27408974301273686,
      "grad_norm": 2.606884717941284,
      "learning_rate": 9.725910256987264e-05,
      "loss": 1.1606,
      "step": 6090
    },
    {
      "epoch": 0.2745398082721995,
      "grad_norm": 1.2671351432800293,
      "learning_rate": 9.725460191727801e-05,
      "loss": 1.0654,
      "step": 6100
    },
    {
      "epoch": 0.2749898735316621,
      "grad_norm": 2.0600337982177734,
      "learning_rate": 9.725010126468338e-05,
      "loss": 1.0303,
      "step": 6110
    },
    {
      "epoch": 0.2754399387911247,
      "grad_norm": 1.856627345085144,
      "learning_rate": 9.724560061208876e-05,
      "loss": 1.0611,
      "step": 6120
    },
    {
      "epoch": 0.27589000405058733,
      "grad_norm": 1.4666401147842407,
      "learning_rate": 9.724109995949413e-05,
      "loss": 1.1761,
      "step": 6130
    },
    {
      "epoch": 0.27634006931004995,
      "grad_norm": 1.1714152097702026,
      "learning_rate": 9.72365993068995e-05,
      "loss": 1.0479,
      "step": 6140
    },
    {
      "epoch": 0.27679013456951257,
      "grad_norm": 1.1463700532913208,
      "learning_rate": 9.723209865430488e-05,
      "loss": 1.0845,
      "step": 6150
    },
    {
      "epoch": 0.2772401998289752,
      "grad_norm": 1.2283189296722412,
      "learning_rate": 9.722759800171025e-05,
      "loss": 1.0812,
      "step": 6160
    },
    {
      "epoch": 0.2776902650884378,
      "grad_norm": 1.061301827430725,
      "learning_rate": 9.722309734911563e-05,
      "loss": 1.0461,
      "step": 6170
    },
    {
      "epoch": 0.2781403303479004,
      "grad_norm": 2.0485470294952393,
      "learning_rate": 9.7218596696521e-05,
      "loss": 1.0408,
      "step": 6180
    },
    {
      "epoch": 0.2785903956073631,
      "grad_norm": 1.5575810670852661,
      "learning_rate": 9.721409604392637e-05,
      "loss": 1.0969,
      "step": 6190
    },
    {
      "epoch": 0.2790404608668257,
      "grad_norm": 1.3270567655563354,
      "learning_rate": 9.720959539133175e-05,
      "loss": 1.0279,
      "step": 6200
    },
    {
      "epoch": 0.27949052612628833,
      "grad_norm": 1.4497544765472412,
      "learning_rate": 9.720509473873712e-05,
      "loss": 1.1088,
      "step": 6210
    },
    {
      "epoch": 0.27994059138575095,
      "grad_norm": 2.5128095149993896,
      "learning_rate": 9.72005940861425e-05,
      "loss": 1.0554,
      "step": 6220
    },
    {
      "epoch": 0.28039065664521357,
      "grad_norm": 1.2176710367202759,
      "learning_rate": 9.719609343354787e-05,
      "loss": 1.0746,
      "step": 6230
    },
    {
      "epoch": 0.2808407219046762,
      "grad_norm": 1.2769113779067993,
      "learning_rate": 9.719159278095324e-05,
      "loss": 1.0737,
      "step": 6240
    },
    {
      "epoch": 0.2812907871641388,
      "grad_norm": 1.3795818090438843,
      "learning_rate": 9.718709212835862e-05,
      "loss": 1.1226,
      "step": 6250
    },
    {
      "epoch": 0.2817408524236014,
      "grad_norm": 1.3583214282989502,
      "learning_rate": 9.718259147576399e-05,
      "loss": 1.0706,
      "step": 6260
    },
    {
      "epoch": 0.28219091768306404,
      "grad_norm": 2.4174604415893555,
      "learning_rate": 9.717809082316936e-05,
      "loss": 1.1287,
      "step": 6270
    },
    {
      "epoch": 0.28264098294252665,
      "grad_norm": 3.4958720207214355,
      "learning_rate": 9.717359017057474e-05,
      "loss": 1.0852,
      "step": 6280
    },
    {
      "epoch": 0.28309104820198927,
      "grad_norm": 1.3354368209838867,
      "learning_rate": 9.716908951798011e-05,
      "loss": 1.0099,
      "step": 6290
    },
    {
      "epoch": 0.2835411134614519,
      "grad_norm": 1.3029060363769531,
      "learning_rate": 9.716458886538548e-05,
      "loss": 1.1126,
      "step": 6300
    },
    {
      "epoch": 0.2839911787209145,
      "grad_norm": 0.9395169019699097,
      "learning_rate": 9.716008821279086e-05,
      "loss": 1.0144,
      "step": 6310
    },
    {
      "epoch": 0.2844412439803772,
      "grad_norm": 1.3014979362487793,
      "learning_rate": 9.715558756019624e-05,
      "loss": 1.118,
      "step": 6320
    },
    {
      "epoch": 0.2848913092398398,
      "grad_norm": 1.8126630783081055,
      "learning_rate": 9.71510869076016e-05,
      "loss": 1.0525,
      "step": 6330
    },
    {
      "epoch": 0.2853413744993024,
      "grad_norm": 1.7180559635162354,
      "learning_rate": 9.714658625500698e-05,
      "loss": 1.103,
      "step": 6340
    },
    {
      "epoch": 0.28579143975876503,
      "grad_norm": 1.7733163833618164,
      "learning_rate": 9.714208560241236e-05,
      "loss": 1.1356,
      "step": 6350
    },
    {
      "epoch": 0.28624150501822765,
      "grad_norm": 1.6222928762435913,
      "learning_rate": 9.713758494981772e-05,
      "loss": 1.0913,
      "step": 6360
    },
    {
      "epoch": 0.28669157027769027,
      "grad_norm": 1.4981731176376343,
      "learning_rate": 9.71330842972231e-05,
      "loss": 1.0848,
      "step": 6370
    },
    {
      "epoch": 0.2871416355371529,
      "grad_norm": 1.1338857412338257,
      "learning_rate": 9.712858364462849e-05,
      "loss": 0.9739,
      "step": 6380
    },
    {
      "epoch": 0.2875917007966155,
      "grad_norm": 1.334036946296692,
      "learning_rate": 9.712408299203385e-05,
      "loss": 1.0682,
      "step": 6390
    },
    {
      "epoch": 0.2880417660560781,
      "grad_norm": 2.641007661819458,
      "learning_rate": 9.711958233943922e-05,
      "loss": 1.1438,
      "step": 6400
    },
    {
      "epoch": 0.28849183131554074,
      "grad_norm": 1.5263781547546387,
      "learning_rate": 9.71150816868446e-05,
      "loss": 1.104,
      "step": 6410
    },
    {
      "epoch": 0.28894189657500335,
      "grad_norm": 1.8927174806594849,
      "learning_rate": 9.711058103424997e-05,
      "loss": 1.1131,
      "step": 6420
    },
    {
      "epoch": 0.28939196183446597,
      "grad_norm": 1.6699988842010498,
      "learning_rate": 9.710608038165534e-05,
      "loss": 1.0885,
      "step": 6430
    },
    {
      "epoch": 0.28984202709392864,
      "grad_norm": 1.6440541744232178,
      "learning_rate": 9.710157972906073e-05,
      "loss": 1.0377,
      "step": 6440
    },
    {
      "epoch": 0.29029209235339126,
      "grad_norm": 0.86142897605896,
      "learning_rate": 9.709707907646609e-05,
      "loss": 1.1384,
      "step": 6450
    },
    {
      "epoch": 0.2907421576128539,
      "grad_norm": 0.9325583577156067,
      "learning_rate": 9.709257842387146e-05,
      "loss": 1.1391,
      "step": 6460
    },
    {
      "epoch": 0.2911922228723165,
      "grad_norm": 1.617456316947937,
      "learning_rate": 9.708807777127685e-05,
      "loss": 1.1539,
      "step": 6470
    },
    {
      "epoch": 0.2916422881317791,
      "grad_norm": 2.6791365146636963,
      "learning_rate": 9.708357711868221e-05,
      "loss": 1.0516,
      "step": 6480
    },
    {
      "epoch": 0.29209235339124173,
      "grad_norm": 2.5408997535705566,
      "learning_rate": 9.70790764660876e-05,
      "loss": 1.1288,
      "step": 6490
    },
    {
      "epoch": 0.29254241865070435,
      "grad_norm": 1.1138815879821777,
      "learning_rate": 9.707457581349297e-05,
      "loss": 1.0885,
      "step": 6500
    },
    {
      "epoch": 0.29299248391016697,
      "grad_norm": 2.268321990966797,
      "learning_rate": 9.707007516089833e-05,
      "loss": 1.2167,
      "step": 6510
    },
    {
      "epoch": 0.2934425491696296,
      "grad_norm": 1.8484337329864502,
      "learning_rate": 9.706557450830372e-05,
      "loss": 1.0615,
      "step": 6520
    },
    {
      "epoch": 0.2938926144290922,
      "grad_norm": 1.9132455587387085,
      "learning_rate": 9.706107385570909e-05,
      "loss": 1.1182,
      "step": 6530
    },
    {
      "epoch": 0.2943426796885548,
      "grad_norm": 1.5955301523208618,
      "learning_rate": 9.705657320311445e-05,
      "loss": 1.1318,
      "step": 6540
    },
    {
      "epoch": 0.29479274494801744,
      "grad_norm": 1.5953569412231445,
      "learning_rate": 9.705207255051984e-05,
      "loss": 1.0882,
      "step": 6550
    },
    {
      "epoch": 0.2952428102074801,
      "grad_norm": 1.5692814588546753,
      "learning_rate": 9.704757189792521e-05,
      "loss": 1.1791,
      "step": 6560
    },
    {
      "epoch": 0.29569287546694273,
      "grad_norm": 1.2682838439941406,
      "learning_rate": 9.704307124533057e-05,
      "loss": 1.1254,
      "step": 6570
    },
    {
      "epoch": 0.29614294072640535,
      "grad_norm": 1.5926182270050049,
      "learning_rate": 9.703857059273596e-05,
      "loss": 1.0496,
      "step": 6580
    },
    {
      "epoch": 0.29659300598586796,
      "grad_norm": 1.2910089492797852,
      "learning_rate": 9.703406994014133e-05,
      "loss": 1.1449,
      "step": 6590
    },
    {
      "epoch": 0.2970430712453306,
      "grad_norm": 1.6993205547332764,
      "learning_rate": 9.702956928754669e-05,
      "loss": 1.1461,
      "step": 6600
    },
    {
      "epoch": 0.2974931365047932,
      "grad_norm": 1.1162464618682861,
      "learning_rate": 9.702506863495208e-05,
      "loss": 1.0587,
      "step": 6610
    },
    {
      "epoch": 0.2979432017642558,
      "grad_norm": 1.2033771276474,
      "learning_rate": 9.702056798235745e-05,
      "loss": 1.0659,
      "step": 6620
    },
    {
      "epoch": 0.29839326702371843,
      "grad_norm": 1.4593697786331177,
      "learning_rate": 9.701606732976281e-05,
      "loss": 1.0776,
      "step": 6630
    },
    {
      "epoch": 0.29884333228318105,
      "grad_norm": 1.4582374095916748,
      "learning_rate": 9.70115666771682e-05,
      "loss": 1.0683,
      "step": 6640
    },
    {
      "epoch": 0.29929339754264367,
      "grad_norm": 2.157458543777466,
      "learning_rate": 9.700706602457357e-05,
      "loss": 1.166,
      "step": 6650
    },
    {
      "epoch": 0.2997434628021063,
      "grad_norm": 1.8675562143325806,
      "learning_rate": 9.700256537197893e-05,
      "loss": 1.1345,
      "step": 6660
    },
    {
      "epoch": 0.3001935280615689,
      "grad_norm": 1.6103594303131104,
      "learning_rate": 9.699806471938432e-05,
      "loss": 1.0973,
      "step": 6670
    },
    {
      "epoch": 0.3006435933210316,
      "grad_norm": 2.847984552383423,
      "learning_rate": 9.69935640667897e-05,
      "loss": 1.0881,
      "step": 6680
    },
    {
      "epoch": 0.3010936585804942,
      "grad_norm": 1.0829001665115356,
      "learning_rate": 9.698906341419505e-05,
      "loss": 1.0697,
      "step": 6690
    },
    {
      "epoch": 0.3015437238399568,
      "grad_norm": 1.6499192714691162,
      "learning_rate": 9.698456276160044e-05,
      "loss": 1.101,
      "step": 6700
    },
    {
      "epoch": 0.30199378909941943,
      "grad_norm": 1.2915277481079102,
      "learning_rate": 9.698006210900581e-05,
      "loss": 1.17,
      "step": 6710
    },
    {
      "epoch": 0.30244385435888205,
      "grad_norm": 1.4873493909835815,
      "learning_rate": 9.697556145641117e-05,
      "loss": 1.0716,
      "step": 6720
    },
    {
      "epoch": 0.30289391961834466,
      "grad_norm": 2.1971166133880615,
      "learning_rate": 9.697106080381656e-05,
      "loss": 1.0522,
      "step": 6730
    },
    {
      "epoch": 0.3033439848778073,
      "grad_norm": 1.102748155593872,
      "learning_rate": 9.696656015122194e-05,
      "loss": 1.1419,
      "step": 6740
    },
    {
      "epoch": 0.3037940501372699,
      "grad_norm": 1.7414292097091675,
      "learning_rate": 9.69620594986273e-05,
      "loss": 1.0637,
      "step": 6750
    },
    {
      "epoch": 0.3042441153967325,
      "grad_norm": 1.288832187652588,
      "learning_rate": 9.695755884603268e-05,
      "loss": 1.0451,
      "step": 6760
    },
    {
      "epoch": 0.30469418065619513,
      "grad_norm": 1.699715495109558,
      "learning_rate": 9.695305819343806e-05,
      "loss": 1.0704,
      "step": 6770
    },
    {
      "epoch": 0.30514424591565775,
      "grad_norm": 2.562488555908203,
      "learning_rate": 9.694855754084343e-05,
      "loss": 1.0375,
      "step": 6780
    },
    {
      "epoch": 0.30559431117512037,
      "grad_norm": 1.5764564275741577,
      "learning_rate": 9.69440568882488e-05,
      "loss": 1.0567,
      "step": 6790
    },
    {
      "epoch": 0.306044376434583,
      "grad_norm": 2.9445972442626953,
      "learning_rate": 9.693955623565418e-05,
      "loss": 1.1229,
      "step": 6800
    },
    {
      "epoch": 0.30649444169404566,
      "grad_norm": 1.6981180906295776,
      "learning_rate": 9.693505558305955e-05,
      "loss": 1.1167,
      "step": 6810
    },
    {
      "epoch": 0.3069445069535083,
      "grad_norm": 1.39787757396698,
      "learning_rate": 9.693055493046492e-05,
      "loss": 1.0226,
      "step": 6820
    },
    {
      "epoch": 0.3073945722129709,
      "grad_norm": 1.3125815391540527,
      "learning_rate": 9.69260542778703e-05,
      "loss": 1.0735,
      "step": 6830
    },
    {
      "epoch": 0.3078446374724335,
      "grad_norm": 1.5219448804855347,
      "learning_rate": 9.692155362527567e-05,
      "loss": 1.1293,
      "step": 6840
    },
    {
      "epoch": 0.30829470273189613,
      "grad_norm": 1.2000999450683594,
      "learning_rate": 9.691705297268105e-05,
      "loss": 1.0982,
      "step": 6850
    },
    {
      "epoch": 0.30874476799135875,
      "grad_norm": 1.224250316619873,
      "learning_rate": 9.691255232008642e-05,
      "loss": 1.0255,
      "step": 6860
    },
    {
      "epoch": 0.30919483325082137,
      "grad_norm": 1.1488131284713745,
      "learning_rate": 9.690805166749179e-05,
      "loss": 1.0208,
      "step": 6870
    },
    {
      "epoch": 0.309644898510284,
      "grad_norm": 2.6480538845062256,
      "learning_rate": 9.690355101489717e-05,
      "loss": 1.0798,
      "step": 6880
    },
    {
      "epoch": 0.3100949637697466,
      "grad_norm": 1.856871247291565,
      "learning_rate": 9.689905036230254e-05,
      "loss": 1.1045,
      "step": 6890
    },
    {
      "epoch": 0.3105450290292092,
      "grad_norm": 1.6258838176727295,
      "learning_rate": 9.689454970970791e-05,
      "loss": 1.1583,
      "step": 6900
    },
    {
      "epoch": 0.31099509428867184,
      "grad_norm": 2.348437547683716,
      "learning_rate": 9.689004905711329e-05,
      "loss": 1.1025,
      "step": 6910
    },
    {
      "epoch": 0.31144515954813445,
      "grad_norm": 2.35874605178833,
      "learning_rate": 9.688554840451866e-05,
      "loss": 1.1296,
      "step": 6920
    },
    {
      "epoch": 0.3118952248075971,
      "grad_norm": 3.0012412071228027,
      "learning_rate": 9.688104775192403e-05,
      "loss": 1.0747,
      "step": 6930
    },
    {
      "epoch": 0.31234529006705974,
      "grad_norm": 1.2605745792388916,
      "learning_rate": 9.687654709932941e-05,
      "loss": 1.1253,
      "step": 6940
    },
    {
      "epoch": 0.31279535532652236,
      "grad_norm": 1.8969395160675049,
      "learning_rate": 9.687204644673478e-05,
      "loss": 1.0351,
      "step": 6950
    },
    {
      "epoch": 0.313245420585985,
      "grad_norm": 2.6101627349853516,
      "learning_rate": 9.686754579414015e-05,
      "loss": 1.1517,
      "step": 6960
    },
    {
      "epoch": 0.3136954858454476,
      "grad_norm": 1.6429293155670166,
      "learning_rate": 9.686304514154553e-05,
      "loss": 1.1671,
      "step": 6970
    },
    {
      "epoch": 0.3141455511049102,
      "grad_norm": 1.5250747203826904,
      "learning_rate": 9.68585444889509e-05,
      "loss": 1.0414,
      "step": 6980
    },
    {
      "epoch": 0.31459561636437283,
      "grad_norm": 1.5093401670455933,
      "learning_rate": 9.685404383635628e-05,
      "loss": 1.1241,
      "step": 6990
    },
    {
      "epoch": 0.31504568162383545,
      "grad_norm": 1.335174560546875,
      "learning_rate": 9.684954318376165e-05,
      "loss": 1.0828,
      "step": 7000
    },
    {
      "epoch": 0.31549574688329807,
      "grad_norm": 1.397367238998413,
      "learning_rate": 9.684504253116702e-05,
      "loss": 1.0386,
      "step": 7010
    },
    {
      "epoch": 0.3159458121427607,
      "grad_norm": 1.902592658996582,
      "learning_rate": 9.68405418785724e-05,
      "loss": 1.0986,
      "step": 7020
    },
    {
      "epoch": 0.3163958774022233,
      "grad_norm": 1.2059179544448853,
      "learning_rate": 9.683604122597777e-05,
      "loss": 1.0098,
      "step": 7030
    },
    {
      "epoch": 0.3168459426616859,
      "grad_norm": 1.1454061269760132,
      "learning_rate": 9.683154057338316e-05,
      "loss": 1.1291,
      "step": 7040
    },
    {
      "epoch": 0.3172960079211486,
      "grad_norm": 1.839970588684082,
      "learning_rate": 9.682703992078852e-05,
      "loss": 1.0604,
      "step": 7050
    },
    {
      "epoch": 0.3177460731806112,
      "grad_norm": 1.6640270948410034,
      "learning_rate": 9.682253926819389e-05,
      "loss": 0.9686,
      "step": 7060
    },
    {
      "epoch": 0.31819613844007383,
      "grad_norm": 1.5187040567398071,
      "learning_rate": 9.681803861559928e-05,
      "loss": 1.0753,
      "step": 7070
    },
    {
      "epoch": 0.31864620369953645,
      "grad_norm": 1.2485085725784302,
      "learning_rate": 9.681353796300464e-05,
      "loss": 1.0518,
      "step": 7080
    },
    {
      "epoch": 0.31909626895899906,
      "grad_norm": 1.8854175806045532,
      "learning_rate": 9.680903731041001e-05,
      "loss": 1.138,
      "step": 7090
    },
    {
      "epoch": 0.3195463342184617,
      "grad_norm": 2.580869436264038,
      "learning_rate": 9.68045366578154e-05,
      "loss": 1.0819,
      "step": 7100
    },
    {
      "epoch": 0.3199963994779243,
      "grad_norm": 1.1403687000274658,
      "learning_rate": 9.680003600522076e-05,
      "loss": 1.0914,
      "step": 7110
    },
    {
      "epoch": 0.3204464647373869,
      "grad_norm": 1.3879846334457397,
      "learning_rate": 9.679553535262613e-05,
      "loss": 1.1025,
      "step": 7120
    },
    {
      "epoch": 0.32089652999684953,
      "grad_norm": 1.8570282459259033,
      "learning_rate": 9.679103470003152e-05,
      "loss": 1.1774,
      "step": 7130
    },
    {
      "epoch": 0.32134659525631215,
      "grad_norm": 1.0643068552017212,
      "learning_rate": 9.678653404743688e-05,
      "loss": 1.1288,
      "step": 7140
    },
    {
      "epoch": 0.32179666051577477,
      "grad_norm": 0.9695835113525391,
      "learning_rate": 9.678203339484225e-05,
      "loss": 1.0901,
      "step": 7150
    },
    {
      "epoch": 0.3222467257752374,
      "grad_norm": 2.4505093097686768,
      "learning_rate": 9.677753274224764e-05,
      "loss": 1.1105,
      "step": 7160
    },
    {
      "epoch": 0.32269679103470006,
      "grad_norm": 1.9899247884750366,
      "learning_rate": 9.6773032089653e-05,
      "loss": 1.1474,
      "step": 7170
    },
    {
      "epoch": 0.3231468562941627,
      "grad_norm": 1.215132713317871,
      "learning_rate": 9.676853143705837e-05,
      "loss": 1.0533,
      "step": 7180
    },
    {
      "epoch": 0.3235969215536253,
      "grad_norm": 1.6737314462661743,
      "learning_rate": 9.676403078446376e-05,
      "loss": 1.0782,
      "step": 7190
    },
    {
      "epoch": 0.3240469868130879,
      "grad_norm": 1.354621171951294,
      "learning_rate": 9.675953013186912e-05,
      "loss": 1.087,
      "step": 7200
    },
    {
      "epoch": 0.32449705207255053,
      "grad_norm": 2.099672317504883,
      "learning_rate": 9.67550294792745e-05,
      "loss": 1.1675,
      "step": 7210
    },
    {
      "epoch": 0.32494711733201315,
      "grad_norm": 1.146599531173706,
      "learning_rate": 9.675052882667988e-05,
      "loss": 1.0391,
      "step": 7220
    },
    {
      "epoch": 0.32539718259147576,
      "grad_norm": 1.5395809412002563,
      "learning_rate": 9.674602817408524e-05,
      "loss": 1.0562,
      "step": 7230
    },
    {
      "epoch": 0.3258472478509384,
      "grad_norm": 1.154498815536499,
      "learning_rate": 9.674152752149062e-05,
      "loss": 1.0784,
      "step": 7240
    },
    {
      "epoch": 0.326297313110401,
      "grad_norm": 1.1301265954971313,
      "learning_rate": 9.6737026868896e-05,
      "loss": 1.232,
      "step": 7250
    },
    {
      "epoch": 0.3267473783698636,
      "grad_norm": 1.0723127126693726,
      "learning_rate": 9.673252621630136e-05,
      "loss": 1.0669,
      "step": 7260
    },
    {
      "epoch": 0.32719744362932623,
      "grad_norm": 1.6320772171020508,
      "learning_rate": 9.672802556370674e-05,
      "loss": 1.0845,
      "step": 7270
    },
    {
      "epoch": 0.32764750888878885,
      "grad_norm": 1.785281777381897,
      "learning_rate": 9.672352491111212e-05,
      "loss": 1.0973,
      "step": 7280
    },
    {
      "epoch": 0.32809757414825147,
      "grad_norm": 1.092491626739502,
      "learning_rate": 9.671902425851748e-05,
      "loss": 1.0778,
      "step": 7290
    },
    {
      "epoch": 0.32854763940771414,
      "grad_norm": 1.5262057781219482,
      "learning_rate": 9.671452360592287e-05,
      "loss": 1.0631,
      "step": 7300
    },
    {
      "epoch": 0.32899770466717676,
      "grad_norm": 1.1224371194839478,
      "learning_rate": 9.671002295332824e-05,
      "loss": 1.0741,
      "step": 7310
    },
    {
      "epoch": 0.3294477699266394,
      "grad_norm": 1.6999491453170776,
      "learning_rate": 9.67055223007336e-05,
      "loss": 1.1034,
      "step": 7320
    },
    {
      "epoch": 0.329897835186102,
      "grad_norm": 0.9464209675788879,
      "learning_rate": 9.670102164813899e-05,
      "loss": 1.0746,
      "step": 7330
    },
    {
      "epoch": 0.3303479004455646,
      "grad_norm": 1.1599979400634766,
      "learning_rate": 9.669652099554437e-05,
      "loss": 1.1335,
      "step": 7340
    },
    {
      "epoch": 0.33079796570502723,
      "grad_norm": 3.3850185871124268,
      "learning_rate": 9.669202034294973e-05,
      "loss": 1.148,
      "step": 7350
    },
    {
      "epoch": 0.33124803096448985,
      "grad_norm": 1.9902855157852173,
      "learning_rate": 9.668751969035511e-05,
      "loss": 1.0985,
      "step": 7360
    },
    {
      "epoch": 0.33169809622395247,
      "grad_norm": 1.280229926109314,
      "learning_rate": 9.668301903776049e-05,
      "loss": 1.044,
      "step": 7370
    },
    {
      "epoch": 0.3321481614834151,
      "grad_norm": 1.5408278703689575,
      "learning_rate": 9.667851838516585e-05,
      "loss": 1.0709,
      "step": 7380
    },
    {
      "epoch": 0.3325982267428777,
      "grad_norm": 1.0459445714950562,
      "learning_rate": 9.667401773257123e-05,
      "loss": 1.1113,
      "step": 7390
    },
    {
      "epoch": 0.3330482920023403,
      "grad_norm": 1.1056156158447266,
      "learning_rate": 9.66695170799766e-05,
      "loss": 1.1501,
      "step": 7400
    },
    {
      "epoch": 0.33349835726180294,
      "grad_norm": 1.8735461235046387,
      "learning_rate": 9.666501642738197e-05,
      "loss": 1.0547,
      "step": 7410
    },
    {
      "epoch": 0.3339484225212656,
      "grad_norm": 1.9434205293655396,
      "learning_rate": 9.666051577478735e-05,
      "loss": 1.1032,
      "step": 7420
    },
    {
      "epoch": 0.3343984877807282,
      "grad_norm": 1.6596940755844116,
      "learning_rate": 9.665601512219273e-05,
      "loss": 1.0554,
      "step": 7430
    },
    {
      "epoch": 0.33484855304019084,
      "grad_norm": 1.817220687866211,
      "learning_rate": 9.665151446959809e-05,
      "loss": 1.1042,
      "step": 7440
    },
    {
      "epoch": 0.33529861829965346,
      "grad_norm": 1.4609712362289429,
      "learning_rate": 9.664701381700347e-05,
      "loss": 1.1208,
      "step": 7450
    },
    {
      "epoch": 0.3357486835591161,
      "grad_norm": 1.3103102445602417,
      "learning_rate": 9.664251316440885e-05,
      "loss": 1.12,
      "step": 7460
    },
    {
      "epoch": 0.3361987488185787,
      "grad_norm": 1.9768030643463135,
      "learning_rate": 9.663801251181421e-05,
      "loss": 1.1235,
      "step": 7470
    },
    {
      "epoch": 0.3366488140780413,
      "grad_norm": 1.55101478099823,
      "learning_rate": 9.66335118592196e-05,
      "loss": 1.1011,
      "step": 7480
    },
    {
      "epoch": 0.33709887933750393,
      "grad_norm": 1.3943039178848267,
      "learning_rate": 9.662901120662497e-05,
      "loss": 1.0788,
      "step": 7490
    },
    {
      "epoch": 0.33754894459696655,
      "grad_norm": 2.8272955417633057,
      "learning_rate": 9.662451055403033e-05,
      "loss": 1.0975,
      "step": 7500
    },
    {
      "epoch": 0.33799900985642917,
      "grad_norm": 1.1385438442230225,
      "learning_rate": 9.662000990143572e-05,
      "loss": 1.0848,
      "step": 7510
    },
    {
      "epoch": 0.3384490751158918,
      "grad_norm": 1.7925300598144531,
      "learning_rate": 9.661550924884109e-05,
      "loss": 1.0732,
      "step": 7520
    },
    {
      "epoch": 0.3388991403753544,
      "grad_norm": 2.46777606010437,
      "learning_rate": 9.661100859624645e-05,
      "loss": 1.1392,
      "step": 7530
    },
    {
      "epoch": 0.3393492056348171,
      "grad_norm": 2.3301711082458496,
      "learning_rate": 9.660650794365184e-05,
      "loss": 1.1357,
      "step": 7540
    },
    {
      "epoch": 0.3397992708942797,
      "grad_norm": 2.9135050773620605,
      "learning_rate": 9.660200729105721e-05,
      "loss": 1.0093,
      "step": 7550
    },
    {
      "epoch": 0.3402493361537423,
      "grad_norm": 0.9419408440589905,
      "learning_rate": 9.659750663846258e-05,
      "loss": 1.1774,
      "step": 7560
    },
    {
      "epoch": 0.3406994014132049,
      "grad_norm": 2.1693875789642334,
      "learning_rate": 9.659300598586796e-05,
      "loss": 1.1273,
      "step": 7570
    },
    {
      "epoch": 0.34114946667266755,
      "grad_norm": 1.6957257986068726,
      "learning_rate": 9.658850533327333e-05,
      "loss": 1.0693,
      "step": 7580
    },
    {
      "epoch": 0.34159953193213016,
      "grad_norm": 1.1558164358139038,
      "learning_rate": 9.65840046806787e-05,
      "loss": 1.1368,
      "step": 7590
    },
    {
      "epoch": 0.3420495971915928,
      "grad_norm": 1.801780104637146,
      "learning_rate": 9.657950402808408e-05,
      "loss": 1.0763,
      "step": 7600
    },
    {
      "epoch": 0.3424996624510554,
      "grad_norm": 1.4015904664993286,
      "learning_rate": 9.657500337548945e-05,
      "loss": 1.1301,
      "step": 7610
    },
    {
      "epoch": 0.342949727710518,
      "grad_norm": 1.9809068441390991,
      "learning_rate": 9.657050272289483e-05,
      "loss": 1.108,
      "step": 7620
    },
    {
      "epoch": 0.34339979296998063,
      "grad_norm": 1.279573678970337,
      "learning_rate": 9.65660020703002e-05,
      "loss": 1.0059,
      "step": 7630
    },
    {
      "epoch": 0.34384985822944325,
      "grad_norm": 1.1341711282730103,
      "learning_rate": 9.656150141770557e-05,
      "loss": 1.0957,
      "step": 7640
    },
    {
      "epoch": 0.34429992348890587,
      "grad_norm": 2.118781328201294,
      "learning_rate": 9.655700076511095e-05,
      "loss": 1.0632,
      "step": 7650
    },
    {
      "epoch": 0.34474998874836854,
      "grad_norm": 1.3590549230575562,
      "learning_rate": 9.655250011251632e-05,
      "loss": 1.1791,
      "step": 7660
    },
    {
      "epoch": 0.34520005400783116,
      "grad_norm": 1.0367298126220703,
      "learning_rate": 9.65479994599217e-05,
      "loss": 1.034,
      "step": 7670
    },
    {
      "epoch": 0.3456501192672938,
      "grad_norm": 2.1418583393096924,
      "learning_rate": 9.654349880732707e-05,
      "loss": 1.0754,
      "step": 7680
    },
    {
      "epoch": 0.3461001845267564,
      "grad_norm": 1.2466782331466675,
      "learning_rate": 9.653899815473244e-05,
      "loss": 1.0475,
      "step": 7690
    },
    {
      "epoch": 0.346550249786219,
      "grad_norm": 1.6053954362869263,
      "learning_rate": 9.653449750213781e-05,
      "loss": 1.0843,
      "step": 7700
    },
    {
      "epoch": 0.34700031504568163,
      "grad_norm": 1.6677323579788208,
      "learning_rate": 9.652999684954319e-05,
      "loss": 1.1428,
      "step": 7710
    },
    {
      "epoch": 0.34745038030514425,
      "grad_norm": 2.4176061153411865,
      "learning_rate": 9.652549619694856e-05,
      "loss": 1.0035,
      "step": 7720
    },
    {
      "epoch": 0.34790044556460686,
      "grad_norm": 1.4335285425186157,
      "learning_rate": 9.652099554435394e-05,
      "loss": 1.0615,
      "step": 7730
    },
    {
      "epoch": 0.3483505108240695,
      "grad_norm": 1.6035577058792114,
      "learning_rate": 9.651649489175931e-05,
      "loss": 1.0553,
      "step": 7740
    },
    {
      "epoch": 0.3488005760835321,
      "grad_norm": 1.715802788734436,
      "learning_rate": 9.651199423916468e-05,
      "loss": 1.066,
      "step": 7750
    },
    {
      "epoch": 0.3492506413429947,
      "grad_norm": 1.606191635131836,
      "learning_rate": 9.650749358657006e-05,
      "loss": 1.1081,
      "step": 7760
    },
    {
      "epoch": 0.34970070660245733,
      "grad_norm": 3.1927084922790527,
      "learning_rate": 9.650299293397543e-05,
      "loss": 1.0651,
      "step": 7770
    },
    {
      "epoch": 0.35015077186191995,
      "grad_norm": 1.2954782247543335,
      "learning_rate": 9.64984922813808e-05,
      "loss": 1.155,
      "step": 7780
    },
    {
      "epoch": 0.3506008371213826,
      "grad_norm": 2.155492067337036,
      "learning_rate": 9.649399162878618e-05,
      "loss": 1.1839,
      "step": 7790
    },
    {
      "epoch": 0.35105090238084524,
      "grad_norm": 1.759271264076233,
      "learning_rate": 9.648949097619155e-05,
      "loss": 1.0721,
      "step": 7800
    },
    {
      "epoch": 0.35150096764030786,
      "grad_norm": 2.080829381942749,
      "learning_rate": 9.648499032359692e-05,
      "loss": 1.057,
      "step": 7810
    },
    {
      "epoch": 0.3519510328997705,
      "grad_norm": 0.9039632678031921,
      "learning_rate": 9.648048967100231e-05,
      "loss": 1.1501,
      "step": 7820
    },
    {
      "epoch": 0.3524010981592331,
      "grad_norm": 1.0685888528823853,
      "learning_rate": 9.647598901840767e-05,
      "loss": 1.164,
      "step": 7830
    },
    {
      "epoch": 0.3528511634186957,
      "grad_norm": 1.6579418182373047,
      "learning_rate": 9.647148836581305e-05,
      "loss": 1.1431,
      "step": 7840
    },
    {
      "epoch": 0.35330122867815833,
      "grad_norm": 1.6914111375808716,
      "learning_rate": 9.646698771321843e-05,
      "loss": 1.0688,
      "step": 7850
    },
    {
      "epoch": 0.35375129393762095,
      "grad_norm": 2.3870131969451904,
      "learning_rate": 9.646248706062379e-05,
      "loss": 1.0921,
      "step": 7860
    },
    {
      "epoch": 0.35420135919708357,
      "grad_norm": 2.423434257507324,
      "learning_rate": 9.645798640802917e-05,
      "loss": 1.1664,
      "step": 7870
    },
    {
      "epoch": 0.3546514244565462,
      "grad_norm": 1.2504500150680542,
      "learning_rate": 9.645348575543455e-05,
      "loss": 1.0268,
      "step": 7880
    },
    {
      "epoch": 0.3551014897160088,
      "grad_norm": 2.426757574081421,
      "learning_rate": 9.644898510283991e-05,
      "loss": 1.08,
      "step": 7890
    },
    {
      "epoch": 0.3555515549754714,
      "grad_norm": 1.339676022529602,
      "learning_rate": 9.644448445024529e-05,
      "loss": 1.168,
      "step": 7900
    },
    {
      "epoch": 0.3560016202349341,
      "grad_norm": 1.3031730651855469,
      "learning_rate": 9.643998379765067e-05,
      "loss": 1.1126,
      "step": 7910
    },
    {
      "epoch": 0.3564516854943967,
      "grad_norm": 2.2705912590026855,
      "learning_rate": 9.643548314505603e-05,
      "loss": 1.1001,
      "step": 7920
    },
    {
      "epoch": 0.3569017507538593,
      "grad_norm": 1.64513099193573,
      "learning_rate": 9.643098249246141e-05,
      "loss": 1.0169,
      "step": 7930
    },
    {
      "epoch": 0.35735181601332194,
      "grad_norm": 1.796514868736267,
      "learning_rate": 9.64264818398668e-05,
      "loss": 1.1625,
      "step": 7940
    },
    {
      "epoch": 0.35780188127278456,
      "grad_norm": 1.4987126588821411,
      "learning_rate": 9.642198118727215e-05,
      "loss": 1.0994,
      "step": 7950
    },
    {
      "epoch": 0.3582519465322472,
      "grad_norm": 1.711601734161377,
      "learning_rate": 9.641748053467753e-05,
      "loss": 1.0781,
      "step": 7960
    },
    {
      "epoch": 0.3587020117917098,
      "grad_norm": 0.9383304119110107,
      "learning_rate": 9.641297988208292e-05,
      "loss": 1.0652,
      "step": 7970
    },
    {
      "epoch": 0.3591520770511724,
      "grad_norm": 1.51307213306427,
      "learning_rate": 9.640847922948828e-05,
      "loss": 1.0796,
      "step": 7980
    },
    {
      "epoch": 0.35960214231063503,
      "grad_norm": 1.5911850929260254,
      "learning_rate": 9.640397857689365e-05,
      "loss": 1.0271,
      "step": 7990
    },
    {
      "epoch": 0.36005220757009765,
      "grad_norm": 1.8009001016616821,
      "learning_rate": 9.639947792429904e-05,
      "loss": 1.1371,
      "step": 8000
    },
    {
      "epoch": 0.36050227282956027,
      "grad_norm": 1.5115267038345337,
      "learning_rate": 9.63949772717044e-05,
      "loss": 1.1661,
      "step": 8010
    },
    {
      "epoch": 0.3609523380890229,
      "grad_norm": 1.1744403839111328,
      "learning_rate": 9.639047661910977e-05,
      "loss": 1.0906,
      "step": 8020
    },
    {
      "epoch": 0.36140240334848556,
      "grad_norm": 1.8632317781448364,
      "learning_rate": 9.638597596651516e-05,
      "loss": 1.1432,
      "step": 8030
    },
    {
      "epoch": 0.3618524686079482,
      "grad_norm": 1.7739770412445068,
      "learning_rate": 9.638147531392052e-05,
      "loss": 1.0609,
      "step": 8040
    },
    {
      "epoch": 0.3623025338674108,
      "grad_norm": 1.7596323490142822,
      "learning_rate": 9.637697466132589e-05,
      "loss": 1.1284,
      "step": 8050
    },
    {
      "epoch": 0.3627525991268734,
      "grad_norm": 2.2322165966033936,
      "learning_rate": 9.637247400873128e-05,
      "loss": 1.1513,
      "step": 8060
    },
    {
      "epoch": 0.363202664386336,
      "grad_norm": 0.886347770690918,
      "learning_rate": 9.636797335613664e-05,
      "loss": 1.1153,
      "step": 8070
    },
    {
      "epoch": 0.36365272964579864,
      "grad_norm": 1.9590553045272827,
      "learning_rate": 9.636347270354203e-05,
      "loss": 1.1189,
      "step": 8080
    },
    {
      "epoch": 0.36410279490526126,
      "grad_norm": 1.4647886753082275,
      "learning_rate": 9.63589720509474e-05,
      "loss": 1.0865,
      "step": 8090
    },
    {
      "epoch": 0.3645528601647239,
      "grad_norm": 1.7940597534179688,
      "learning_rate": 9.635447139835276e-05,
      "loss": 1.1165,
      "step": 8100
    },
    {
      "epoch": 0.3650029254241865,
      "grad_norm": 1.6103239059448242,
      "learning_rate": 9.634997074575815e-05,
      "loss": 1.1545,
      "step": 8110
    },
    {
      "epoch": 0.3654529906836491,
      "grad_norm": 2.0062756538391113,
      "learning_rate": 9.634547009316352e-05,
      "loss": 1.1277,
      "step": 8120
    },
    {
      "epoch": 0.36590305594311173,
      "grad_norm": 1.535688877105713,
      "learning_rate": 9.634096944056888e-05,
      "loss": 1.0355,
      "step": 8130
    },
    {
      "epoch": 0.36635312120257435,
      "grad_norm": 1.528552770614624,
      "learning_rate": 9.633646878797427e-05,
      "loss": 1.0564,
      "step": 8140
    },
    {
      "epoch": 0.366803186462037,
      "grad_norm": 1.38302481174469,
      "learning_rate": 9.633196813537964e-05,
      "loss": 1.0887,
      "step": 8150
    },
    {
      "epoch": 0.36725325172149964,
      "grad_norm": 1.5929850339889526,
      "learning_rate": 9.6327467482785e-05,
      "loss": 1.1033,
      "step": 8160
    },
    {
      "epoch": 0.36770331698096226,
      "grad_norm": 1.9874080419540405,
      "learning_rate": 9.632296683019039e-05,
      "loss": 1.1484,
      "step": 8170
    },
    {
      "epoch": 0.3681533822404249,
      "grad_norm": 1.3205350637435913,
      "learning_rate": 9.631846617759576e-05,
      "loss": 1.0708,
      "step": 8180
    },
    {
      "epoch": 0.3686034474998875,
      "grad_norm": 1.5665497779846191,
      "learning_rate": 9.631396552500112e-05,
      "loss": 1.0695,
      "step": 8190
    },
    {
      "epoch": 0.3690535127593501,
      "grad_norm": 1.9303001165390015,
      "learning_rate": 9.630946487240651e-05,
      "loss": 1.0333,
      "step": 8200
    },
    {
      "epoch": 0.36950357801881273,
      "grad_norm": 1.4428763389587402,
      "learning_rate": 9.630496421981188e-05,
      "loss": 1.0558,
      "step": 8210
    },
    {
      "epoch": 0.36995364327827535,
      "grad_norm": 1.2990940809249878,
      "learning_rate": 9.630046356721724e-05,
      "loss": 1.1502,
      "step": 8220
    },
    {
      "epoch": 0.37040370853773796,
      "grad_norm": 0.9706844091415405,
      "learning_rate": 9.629596291462263e-05,
      "loss": 1.0391,
      "step": 8230
    },
    {
      "epoch": 0.3708537737972006,
      "grad_norm": 1.7271459102630615,
      "learning_rate": 9.6291462262028e-05,
      "loss": 1.0984,
      "step": 8240
    },
    {
      "epoch": 0.3713038390566632,
      "grad_norm": 2.059619188308716,
      "learning_rate": 9.628696160943336e-05,
      "loss": 1.1597,
      "step": 8250
    },
    {
      "epoch": 0.3717539043161258,
      "grad_norm": 1.436106562614441,
      "learning_rate": 9.628246095683875e-05,
      "loss": 1.136,
      "step": 8260
    },
    {
      "epoch": 0.37220396957558843,
      "grad_norm": 1.7698094844818115,
      "learning_rate": 9.627796030424412e-05,
      "loss": 1.1166,
      "step": 8270
    },
    {
      "epoch": 0.3726540348350511,
      "grad_norm": 2.086784839630127,
      "learning_rate": 9.627345965164948e-05,
      "loss": 1.069,
      "step": 8280
    },
    {
      "epoch": 0.3731041000945137,
      "grad_norm": 1.5023490190505981,
      "learning_rate": 9.626895899905487e-05,
      "loss": 1.0336,
      "step": 8290
    },
    {
      "epoch": 0.37355416535397634,
      "grad_norm": 1.382399559020996,
      "learning_rate": 9.626445834646024e-05,
      "loss": 1.1294,
      "step": 8300
    },
    {
      "epoch": 0.37400423061343896,
      "grad_norm": 0.9928284287452698,
      "learning_rate": 9.62599576938656e-05,
      "loss": 1.1202,
      "step": 8310
    },
    {
      "epoch": 0.3744542958729016,
      "grad_norm": 1.7490313053131104,
      "learning_rate": 9.625545704127099e-05,
      "loss": 1.1115,
      "step": 8320
    },
    {
      "epoch": 0.3749043611323642,
      "grad_norm": 1.5193954706192017,
      "learning_rate": 9.625095638867637e-05,
      "loss": 1.0818,
      "step": 8330
    },
    {
      "epoch": 0.3753544263918268,
      "grad_norm": 1.993971586227417,
      "learning_rate": 9.624645573608173e-05,
      "loss": 1.1196,
      "step": 8340
    },
    {
      "epoch": 0.37580449165128943,
      "grad_norm": 1.7574317455291748,
      "learning_rate": 9.624195508348711e-05,
      "loss": 1.1251,
      "step": 8350
    },
    {
      "epoch": 0.37625455691075205,
      "grad_norm": 1.522311806678772,
      "learning_rate": 9.623745443089249e-05,
      "loss": 1.118,
      "step": 8360
    },
    {
      "epoch": 0.37670462217021466,
      "grad_norm": 1.0182812213897705,
      "learning_rate": 9.623295377829786e-05,
      "loss": 1.117,
      "step": 8370
    },
    {
      "epoch": 0.3771546874296773,
      "grad_norm": 1.5490949153900146,
      "learning_rate": 9.622845312570323e-05,
      "loss": 1.0986,
      "step": 8380
    },
    {
      "epoch": 0.3776047526891399,
      "grad_norm": 1.2957333326339722,
      "learning_rate": 9.622395247310861e-05,
      "loss": 1.0549,
      "step": 8390
    },
    {
      "epoch": 0.3780548179486026,
      "grad_norm": 1.8870124816894531,
      "learning_rate": 9.621945182051398e-05,
      "loss": 1.1022,
      "step": 8400
    },
    {
      "epoch": 0.3785048832080652,
      "grad_norm": 1.4795578718185425,
      "learning_rate": 9.621495116791935e-05,
      "loss": 1.0379,
      "step": 8410
    },
    {
      "epoch": 0.3789549484675278,
      "grad_norm": 1.2193225622177124,
      "learning_rate": 9.621045051532473e-05,
      "loss": 1.0844,
      "step": 8420
    },
    {
      "epoch": 0.3794050137269904,
      "grad_norm": 1.4112225770950317,
      "learning_rate": 9.62059498627301e-05,
      "loss": 1.102,
      "step": 8430
    },
    {
      "epoch": 0.37985507898645304,
      "grad_norm": 2.265878915786743,
      "learning_rate": 9.620144921013548e-05,
      "loss": 1.0939,
      "step": 8440
    },
    {
      "epoch": 0.38030514424591566,
      "grad_norm": 1.4580976963043213,
      "learning_rate": 9.619694855754085e-05,
      "loss": 1.0857,
      "step": 8450
    },
    {
      "epoch": 0.3807552095053783,
      "grad_norm": 2.246206045150757,
      "learning_rate": 9.619244790494622e-05,
      "loss": 1.0598,
      "step": 8460
    },
    {
      "epoch": 0.3812052747648409,
      "grad_norm": 0.9907854199409485,
      "learning_rate": 9.61879472523516e-05,
      "loss": 1.0149,
      "step": 8470
    },
    {
      "epoch": 0.3816553400243035,
      "grad_norm": 1.0772056579589844,
      "learning_rate": 9.618344659975697e-05,
      "loss": 1.1063,
      "step": 8480
    },
    {
      "epoch": 0.38210540528376613,
      "grad_norm": 1.1478278636932373,
      "learning_rate": 9.617894594716234e-05,
      "loss": 1.1039,
      "step": 8490
    },
    {
      "epoch": 0.38255547054322875,
      "grad_norm": 2.6861207485198975,
      "learning_rate": 9.617444529456772e-05,
      "loss": 1.0495,
      "step": 8500
    },
    {
      "epoch": 0.38300553580269137,
      "grad_norm": 1.3024581670761108,
      "learning_rate": 9.616994464197309e-05,
      "loss": 1.0916,
      "step": 8510
    },
    {
      "epoch": 0.38345560106215404,
      "grad_norm": 1.336606502532959,
      "learning_rate": 9.616544398937846e-05,
      "loss": 1.1642,
      "step": 8520
    },
    {
      "epoch": 0.38390566632161666,
      "grad_norm": 1.2152513265609741,
      "learning_rate": 9.616094333678384e-05,
      "loss": 1.0583,
      "step": 8530
    },
    {
      "epoch": 0.3843557315810793,
      "grad_norm": 2.0416676998138428,
      "learning_rate": 9.615644268418921e-05,
      "loss": 1.0364,
      "step": 8540
    },
    {
      "epoch": 0.3848057968405419,
      "grad_norm": 1.9068379402160645,
      "learning_rate": 9.615194203159458e-05,
      "loss": 1.0864,
      "step": 8550
    },
    {
      "epoch": 0.3852558621000045,
      "grad_norm": 1.544946312904358,
      "learning_rate": 9.614744137899996e-05,
      "loss": 1.0673,
      "step": 8560
    },
    {
      "epoch": 0.3857059273594671,
      "grad_norm": 2.6892640590667725,
      "learning_rate": 9.614294072640533e-05,
      "loss": 1.1019,
      "step": 8570
    },
    {
      "epoch": 0.38615599261892974,
      "grad_norm": 1.6426379680633545,
      "learning_rate": 9.61384400738107e-05,
      "loss": 1.018,
      "step": 8580
    },
    {
      "epoch": 0.38660605787839236,
      "grad_norm": 1.671665072441101,
      "learning_rate": 9.613393942121608e-05,
      "loss": 1.0669,
      "step": 8590
    },
    {
      "epoch": 0.387056123137855,
      "grad_norm": 1.155245065689087,
      "learning_rate": 9.612943876862145e-05,
      "loss": 1.1047,
      "step": 8600
    },
    {
      "epoch": 0.3875061883973176,
      "grad_norm": 1.6318453550338745,
      "learning_rate": 9.612493811602683e-05,
      "loss": 1.2001,
      "step": 8610
    },
    {
      "epoch": 0.3879562536567802,
      "grad_norm": 1.9390205144882202,
      "learning_rate": 9.61204374634322e-05,
      "loss": 1.1272,
      "step": 8620
    },
    {
      "epoch": 0.38840631891624283,
      "grad_norm": 1.263513207435608,
      "learning_rate": 9.611593681083759e-05,
      "loss": 1.0935,
      "step": 8630
    },
    {
      "epoch": 0.38885638417570545,
      "grad_norm": 2.0625133514404297,
      "learning_rate": 9.611143615824295e-05,
      "loss": 1.0631,
      "step": 8640
    },
    {
      "epoch": 0.3893064494351681,
      "grad_norm": 1.76582670211792,
      "learning_rate": 9.610693550564832e-05,
      "loss": 1.0642,
      "step": 8650
    },
    {
      "epoch": 0.38975651469463074,
      "grad_norm": 1.9385663270950317,
      "learning_rate": 9.610243485305371e-05,
      "loss": 1.1157,
      "step": 8660
    },
    {
      "epoch": 0.39020657995409336,
      "grad_norm": 1.380845069885254,
      "learning_rate": 9.609793420045907e-05,
      "loss": 1.0706,
      "step": 8670
    },
    {
      "epoch": 0.390656645213556,
      "grad_norm": 1.248680591583252,
      "learning_rate": 9.609343354786444e-05,
      "loss": 1.0341,
      "step": 8680
    },
    {
      "epoch": 0.3911067104730186,
      "grad_norm": 2.177056074142456,
      "learning_rate": 9.608893289526983e-05,
      "loss": 1.1106,
      "step": 8690
    },
    {
      "epoch": 0.3915567757324812,
      "grad_norm": 1.5152641534805298,
      "learning_rate": 9.608443224267519e-05,
      "loss": 1.0703,
      "step": 8700
    },
    {
      "epoch": 0.39200684099194383,
      "grad_norm": 1.0128068923950195,
      "learning_rate": 9.607993159008056e-05,
      "loss": 1.0554,
      "step": 8710
    },
    {
      "epoch": 0.39245690625140645,
      "grad_norm": 0.9664223790168762,
      "learning_rate": 9.607543093748595e-05,
      "loss": 1.0695,
      "step": 8720
    },
    {
      "epoch": 0.39290697151086906,
      "grad_norm": 1.6704955101013184,
      "learning_rate": 9.607093028489131e-05,
      "loss": 1.0774,
      "step": 8730
    },
    {
      "epoch": 0.3933570367703317,
      "grad_norm": 1.8830244541168213,
      "learning_rate": 9.606642963229668e-05,
      "loss": 1.0744,
      "step": 8740
    },
    {
      "epoch": 0.3938071020297943,
      "grad_norm": 1.160176157951355,
      "learning_rate": 9.606192897970207e-05,
      "loss": 1.1183,
      "step": 8750
    },
    {
      "epoch": 0.3942571672892569,
      "grad_norm": 1.8777154684066772,
      "learning_rate": 9.605742832710743e-05,
      "loss": 1.1612,
      "step": 8760
    },
    {
      "epoch": 0.3947072325487196,
      "grad_norm": 1.6965649127960205,
      "learning_rate": 9.60529276745128e-05,
      "loss": 1.1101,
      "step": 8770
    },
    {
      "epoch": 0.3951572978081822,
      "grad_norm": 1.2141586542129517,
      "learning_rate": 9.604842702191819e-05,
      "loss": 1.0838,
      "step": 8780
    },
    {
      "epoch": 0.3956073630676448,
      "grad_norm": 0.9748980402946472,
      "learning_rate": 9.604392636932355e-05,
      "loss": 1.0906,
      "step": 8790
    },
    {
      "epoch": 0.39605742832710744,
      "grad_norm": 1.022167444229126,
      "learning_rate": 9.603942571672892e-05,
      "loss": 1.0542,
      "step": 8800
    },
    {
      "epoch": 0.39650749358657006,
      "grad_norm": 1.301954746246338,
      "learning_rate": 9.603492506413431e-05,
      "loss": 1.0846,
      "step": 8810
    },
    {
      "epoch": 0.3969575588460327,
      "grad_norm": 1.094980239868164,
      "learning_rate": 9.603042441153967e-05,
      "loss": 1.176,
      "step": 8820
    },
    {
      "epoch": 0.3974076241054953,
      "grad_norm": 1.3714853525161743,
      "learning_rate": 9.602592375894505e-05,
      "loss": 1.0934,
      "step": 8830
    },
    {
      "epoch": 0.3978576893649579,
      "grad_norm": 1.3981729745864868,
      "learning_rate": 9.602142310635043e-05,
      "loss": 1.1005,
      "step": 8840
    },
    {
      "epoch": 0.39830775462442053,
      "grad_norm": 1.6993262767791748,
      "learning_rate": 9.601692245375579e-05,
      "loss": 1.0525,
      "step": 8850
    },
    {
      "epoch": 0.39875781988388315,
      "grad_norm": 1.463334321975708,
      "learning_rate": 9.601242180116117e-05,
      "loss": 1.0495,
      "step": 8860
    },
    {
      "epoch": 0.39920788514334576,
      "grad_norm": 1.0033235549926758,
      "learning_rate": 9.600792114856655e-05,
      "loss": 1.0719,
      "step": 8870
    },
    {
      "epoch": 0.3996579504028084,
      "grad_norm": 2.0246288776397705,
      "learning_rate": 9.600342049597191e-05,
      "loss": 1.0728,
      "step": 8880
    },
    {
      "epoch": 0.40010801566227105,
      "grad_norm": 0.9775874018669128,
      "learning_rate": 9.59989198433773e-05,
      "loss": 1.0425,
      "step": 8890
    },
    {
      "epoch": 0.4005580809217337,
      "grad_norm": 1.211321473121643,
      "learning_rate": 9.599441919078267e-05,
      "loss": 1.0783,
      "step": 8900
    },
    {
      "epoch": 0.4010081461811963,
      "grad_norm": 1.091701626777649,
      "learning_rate": 9.598991853818803e-05,
      "loss": 1.1155,
      "step": 8910
    },
    {
      "epoch": 0.4014582114406589,
      "grad_norm": 1.0968629121780396,
      "learning_rate": 9.598541788559342e-05,
      "loss": 1.09,
      "step": 8920
    },
    {
      "epoch": 0.4019082767001215,
      "grad_norm": 1.3675658702850342,
      "learning_rate": 9.59809172329988e-05,
      "loss": 1.1579,
      "step": 8930
    },
    {
      "epoch": 0.40235834195958414,
      "grad_norm": 1.6547458171844482,
      "learning_rate": 9.597641658040416e-05,
      "loss": 1.118,
      "step": 8940
    },
    {
      "epoch": 0.40280840721904676,
      "grad_norm": 1.1878173351287842,
      "learning_rate": 9.597191592780954e-05,
      "loss": 1.107,
      "step": 8950
    },
    {
      "epoch": 0.4032584724785094,
      "grad_norm": 1.1668027639389038,
      "learning_rate": 9.596741527521492e-05,
      "loss": 1.0711,
      "step": 8960
    },
    {
      "epoch": 0.403708537737972,
      "grad_norm": 1.9976139068603516,
      "learning_rate": 9.596291462262028e-05,
      "loss": 1.0744,
      "step": 8970
    },
    {
      "epoch": 0.4041586029974346,
      "grad_norm": 1.4874221086502075,
      "learning_rate": 9.595841397002566e-05,
      "loss": 1.1158,
      "step": 8980
    },
    {
      "epoch": 0.40460866825689723,
      "grad_norm": 2.7421553134918213,
      "learning_rate": 9.595391331743104e-05,
      "loss": 1.1117,
      "step": 8990
    },
    {
      "epoch": 0.40505873351635985,
      "grad_norm": 1.589342474937439,
      "learning_rate": 9.59494126648364e-05,
      "loss": 1.0778,
      "step": 9000
    },
    {
      "epoch": 0.4055087987758225,
      "grad_norm": 2.921548366546631,
      "learning_rate": 9.594491201224178e-05,
      "loss": 1.1146,
      "step": 9010
    },
    {
      "epoch": 0.40595886403528514,
      "grad_norm": 1.63603675365448,
      "learning_rate": 9.594041135964716e-05,
      "loss": 1.0463,
      "step": 9020
    },
    {
      "epoch": 0.40640892929474776,
      "grad_norm": 0.9443750977516174,
      "learning_rate": 9.593591070705252e-05,
      "loss": 1.0828,
      "step": 9030
    },
    {
      "epoch": 0.4068589945542104,
      "grad_norm": 1.1876641511917114,
      "learning_rate": 9.59314100544579e-05,
      "loss": 1.0098,
      "step": 9040
    },
    {
      "epoch": 0.407309059813673,
      "grad_norm": 1.0969057083129883,
      "learning_rate": 9.592690940186328e-05,
      "loss": 1.0619,
      "step": 9050
    },
    {
      "epoch": 0.4077591250731356,
      "grad_norm": 1.2789441347122192,
      "learning_rate": 9.592240874926864e-05,
      "loss": 1.1146,
      "step": 9060
    },
    {
      "epoch": 0.4082091903325982,
      "grad_norm": 1.9272249937057495,
      "learning_rate": 9.591790809667403e-05,
      "loss": 1.1126,
      "step": 9070
    },
    {
      "epoch": 0.40865925559206084,
      "grad_norm": 1.9054532051086426,
      "learning_rate": 9.59134074440794e-05,
      "loss": 1.0889,
      "step": 9080
    },
    {
      "epoch": 0.40910932085152346,
      "grad_norm": 1.3962199687957764,
      "learning_rate": 9.590890679148476e-05,
      "loss": 1.0878,
      "step": 9090
    },
    {
      "epoch": 0.4095593861109861,
      "grad_norm": 1.616708517074585,
      "learning_rate": 9.590440613889015e-05,
      "loss": 1.131,
      "step": 9100
    },
    {
      "epoch": 0.4100094513704487,
      "grad_norm": 1.3041160106658936,
      "learning_rate": 9.589990548629552e-05,
      "loss": 1.1106,
      "step": 9110
    },
    {
      "epoch": 0.4104595166299113,
      "grad_norm": 1.097493290901184,
      "learning_rate": 9.589540483370088e-05,
      "loss": 1.0869,
      "step": 9120
    },
    {
      "epoch": 0.41090958188937393,
      "grad_norm": 1.0544120073318481,
      "learning_rate": 9.589090418110627e-05,
      "loss": 1.0404,
      "step": 9130
    },
    {
      "epoch": 0.4113596471488366,
      "grad_norm": 1.485298991203308,
      "learning_rate": 9.588640352851164e-05,
      "loss": 1.0661,
      "step": 9140
    },
    {
      "epoch": 0.4118097124082992,
      "grad_norm": 1.701328158378601,
      "learning_rate": 9.588190287591701e-05,
      "loss": 1.1131,
      "step": 9150
    },
    {
      "epoch": 0.41225977766776184,
      "grad_norm": 1.5326634645462036,
      "learning_rate": 9.587740222332239e-05,
      "loss": 1.013,
      "step": 9160
    },
    {
      "epoch": 0.41270984292722446,
      "grad_norm": 1.3971344232559204,
      "learning_rate": 9.587290157072776e-05,
      "loss": 1.1017,
      "step": 9170
    },
    {
      "epoch": 0.4131599081866871,
      "grad_norm": 1.256372332572937,
      "learning_rate": 9.586840091813314e-05,
      "loss": 1.0224,
      "step": 9180
    },
    {
      "epoch": 0.4136099734461497,
      "grad_norm": 1.4770150184631348,
      "learning_rate": 9.586390026553851e-05,
      "loss": 1.0708,
      "step": 9190
    },
    {
      "epoch": 0.4140600387056123,
      "grad_norm": 0.9145318269729614,
      "learning_rate": 9.585939961294388e-05,
      "loss": 1.0308,
      "step": 9200
    },
    {
      "epoch": 0.4145101039650749,
      "grad_norm": 1.307600736618042,
      "learning_rate": 9.585489896034926e-05,
      "loss": 1.0532,
      "step": 9210
    },
    {
      "epoch": 0.41496016922453755,
      "grad_norm": 2.1053194999694824,
      "learning_rate": 9.585039830775463e-05,
      "loss": 1.0898,
      "step": 9220
    },
    {
      "epoch": 0.41541023448400016,
      "grad_norm": 1.2594677209854126,
      "learning_rate": 9.584589765516e-05,
      "loss": 1.1206,
      "step": 9230
    },
    {
      "epoch": 0.4158602997434628,
      "grad_norm": 1.9234018325805664,
      "learning_rate": 9.584139700256538e-05,
      "loss": 1.0845,
      "step": 9240
    },
    {
      "epoch": 0.4163103650029254,
      "grad_norm": 1.3735647201538086,
      "learning_rate": 9.583689634997075e-05,
      "loss": 1.1212,
      "step": 9250
    },
    {
      "epoch": 0.41676043026238807,
      "grad_norm": 1.1167103052139282,
      "learning_rate": 9.583239569737612e-05,
      "loss": 1.0626,
      "step": 9260
    },
    {
      "epoch": 0.4172104955218507,
      "grad_norm": 1.3391354084014893,
      "learning_rate": 9.58278950447815e-05,
      "loss": 1.1751,
      "step": 9270
    },
    {
      "epoch": 0.4176605607813133,
      "grad_norm": 2.6448240280151367,
      "learning_rate": 9.582339439218687e-05,
      "loss": 1.1182,
      "step": 9280
    },
    {
      "epoch": 0.4181106260407759,
      "grad_norm": 1.585154414176941,
      "learning_rate": 9.581889373959224e-05,
      "loss": 1.0705,
      "step": 9290
    },
    {
      "epoch": 0.41856069130023854,
      "grad_norm": 1.6769609451293945,
      "learning_rate": 9.581439308699762e-05,
      "loss": 1.11,
      "step": 9300
    },
    {
      "epoch": 0.41901075655970116,
      "grad_norm": 1.4884026050567627,
      "learning_rate": 9.580989243440299e-05,
      "loss": 1.1425,
      "step": 9310
    },
    {
      "epoch": 0.4194608218191638,
      "grad_norm": 1.116245985031128,
      "learning_rate": 9.580539178180837e-05,
      "loss": 1.0801,
      "step": 9320
    },
    {
      "epoch": 0.4199108870786264,
      "grad_norm": 2.1418075561523438,
      "learning_rate": 9.580089112921374e-05,
      "loss": 1.0443,
      "step": 9330
    },
    {
      "epoch": 0.420360952338089,
      "grad_norm": 1.4510900974273682,
      "learning_rate": 9.579639047661911e-05,
      "loss": 1.0766,
      "step": 9340
    },
    {
      "epoch": 0.42081101759755163,
      "grad_norm": 1.132174015045166,
      "learning_rate": 9.579188982402449e-05,
      "loss": 1.1321,
      "step": 9350
    },
    {
      "epoch": 0.42126108285701425,
      "grad_norm": 1.6256518363952637,
      "learning_rate": 9.578738917142986e-05,
      "loss": 1.0745,
      "step": 9360
    },
    {
      "epoch": 0.42171114811647686,
      "grad_norm": 1.224849820137024,
      "learning_rate": 9.578288851883523e-05,
      "loss": 1.1067,
      "step": 9370
    },
    {
      "epoch": 0.42216121337593954,
      "grad_norm": 1.3174527883529663,
      "learning_rate": 9.577838786624061e-05,
      "loss": 1.1091,
      "step": 9380
    },
    {
      "epoch": 0.42261127863540215,
      "grad_norm": 2.0508038997650146,
      "learning_rate": 9.577388721364598e-05,
      "loss": 1.1064,
      "step": 9390
    },
    {
      "epoch": 0.42306134389486477,
      "grad_norm": 0.8845552802085876,
      "learning_rate": 9.576938656105135e-05,
      "loss": 1.0598,
      "step": 9400
    },
    {
      "epoch": 0.4235114091543274,
      "grad_norm": 2.3596861362457275,
      "learning_rate": 9.576488590845674e-05,
      "loss": 1.1587,
      "step": 9410
    },
    {
      "epoch": 0.42396147441379,
      "grad_norm": 2.0985496044158936,
      "learning_rate": 9.57603852558621e-05,
      "loss": 1.0533,
      "step": 9420
    },
    {
      "epoch": 0.4244115396732526,
      "grad_norm": 2.1179141998291016,
      "learning_rate": 9.575588460326748e-05,
      "loss": 1.0451,
      "step": 9430
    },
    {
      "epoch": 0.42486160493271524,
      "grad_norm": 1.4062544107437134,
      "learning_rate": 9.575138395067286e-05,
      "loss": 1.0473,
      "step": 9440
    },
    {
      "epoch": 0.42531167019217786,
      "grad_norm": 0.9972003698348999,
      "learning_rate": 9.574688329807822e-05,
      "loss": 1.1461,
      "step": 9450
    },
    {
      "epoch": 0.4257617354516405,
      "grad_norm": 1.686246395111084,
      "learning_rate": 9.57423826454836e-05,
      "loss": 1.0577,
      "step": 9460
    },
    {
      "epoch": 0.4262118007111031,
      "grad_norm": 0.8649230599403381,
      "learning_rate": 9.573788199288898e-05,
      "loss": 1.0339,
      "step": 9470
    },
    {
      "epoch": 0.4266618659705657,
      "grad_norm": 1.7611128091812134,
      "learning_rate": 9.573338134029434e-05,
      "loss": 1.0124,
      "step": 9480
    },
    {
      "epoch": 0.42711193123002833,
      "grad_norm": 2.1697375774383545,
      "learning_rate": 9.572888068769972e-05,
      "loss": 1.1192,
      "step": 9490
    },
    {
      "epoch": 0.427561996489491,
      "grad_norm": 1.9294157028198242,
      "learning_rate": 9.57243800351051e-05,
      "loss": 1.0953,
      "step": 9500
    },
    {
      "epoch": 0.4280120617489536,
      "grad_norm": 1.4351335763931274,
      "learning_rate": 9.571987938251046e-05,
      "loss": 1.0691,
      "step": 9510
    },
    {
      "epoch": 0.42846212700841624,
      "grad_norm": 1.536772608757019,
      "learning_rate": 9.571537872991584e-05,
      "loss": 1.0762,
      "step": 9520
    },
    {
      "epoch": 0.42891219226787886,
      "grad_norm": 1.2385677099227905,
      "learning_rate": 9.571087807732122e-05,
      "loss": 1.1518,
      "step": 9530
    },
    {
      "epoch": 0.4293622575273415,
      "grad_norm": 2.427506923675537,
      "learning_rate": 9.570637742472658e-05,
      "loss": 1.0962,
      "step": 9540
    },
    {
      "epoch": 0.4298123227868041,
      "grad_norm": 1.0965156555175781,
      "learning_rate": 9.570187677213196e-05,
      "loss": 1.0663,
      "step": 9550
    },
    {
      "epoch": 0.4302623880462667,
      "grad_norm": 3.4844374656677246,
      "learning_rate": 9.569737611953735e-05,
      "loss": 1.038,
      "step": 9560
    },
    {
      "epoch": 0.4307124533057293,
      "grad_norm": 1.6312800645828247,
      "learning_rate": 9.56928754669427e-05,
      "loss": 0.9988,
      "step": 9570
    },
    {
      "epoch": 0.43116251856519194,
      "grad_norm": 1.8130764961242676,
      "learning_rate": 9.568837481434808e-05,
      "loss": 1.1018,
      "step": 9580
    },
    {
      "epoch": 0.43161258382465456,
      "grad_norm": 1.7333664894104004,
      "learning_rate": 9.568387416175347e-05,
      "loss": 1.1643,
      "step": 9590
    },
    {
      "epoch": 0.4320626490841172,
      "grad_norm": 1.8914299011230469,
      "learning_rate": 9.567937350915883e-05,
      "loss": 1.1043,
      "step": 9600
    },
    {
      "epoch": 0.4325127143435798,
      "grad_norm": 1.3712953329086304,
      "learning_rate": 9.56748728565642e-05,
      "loss": 1.0508,
      "step": 9610
    },
    {
      "epoch": 0.4329627796030424,
      "grad_norm": 1.0071873664855957,
      "learning_rate": 9.567037220396959e-05,
      "loss": 1.1454,
      "step": 9620
    },
    {
      "epoch": 0.4334128448625051,
      "grad_norm": 1.6998541355133057,
      "learning_rate": 9.566587155137495e-05,
      "loss": 1.0361,
      "step": 9630
    },
    {
      "epoch": 0.4338629101219677,
      "grad_norm": 1.3835115432739258,
      "learning_rate": 9.566137089878032e-05,
      "loss": 1.0699,
      "step": 9640
    },
    {
      "epoch": 0.4343129753814303,
      "grad_norm": 1.415359377861023,
      "learning_rate": 9.565687024618571e-05,
      "loss": 1.1242,
      "step": 9650
    },
    {
      "epoch": 0.43476304064089294,
      "grad_norm": 1.1577601432800293,
      "learning_rate": 9.565236959359107e-05,
      "loss": 1.052,
      "step": 9660
    },
    {
      "epoch": 0.43521310590035556,
      "grad_norm": 1.168742299079895,
      "learning_rate": 9.564786894099646e-05,
      "loss": 0.9934,
      "step": 9670
    },
    {
      "epoch": 0.4356631711598182,
      "grad_norm": 1.6747337579727173,
      "learning_rate": 9.564336828840183e-05,
      "loss": 1.0791,
      "step": 9680
    },
    {
      "epoch": 0.4361132364192808,
      "grad_norm": 2.7322897911071777,
      "learning_rate": 9.563886763580719e-05,
      "loss": 1.1281,
      "step": 9690
    },
    {
      "epoch": 0.4365633016787434,
      "grad_norm": 1.3601619005203247,
      "learning_rate": 9.563436698321258e-05,
      "loss": 1.0427,
      "step": 9700
    },
    {
      "epoch": 0.437013366938206,
      "grad_norm": 2.8787925243377686,
      "learning_rate": 9.562986633061795e-05,
      "loss": 1.0119,
      "step": 9710
    },
    {
      "epoch": 0.43746343219766864,
      "grad_norm": 2.6206536293029785,
      "learning_rate": 9.562536567802331e-05,
      "loss": 1.0101,
      "step": 9720
    },
    {
      "epoch": 0.43791349745713126,
      "grad_norm": 1.118854284286499,
      "learning_rate": 9.56208650254287e-05,
      "loss": 1.0165,
      "step": 9730
    },
    {
      "epoch": 0.4383635627165939,
      "grad_norm": 1.0812604427337646,
      "learning_rate": 9.561636437283407e-05,
      "loss": 1.1563,
      "step": 9740
    },
    {
      "epoch": 0.43881362797605655,
      "grad_norm": 1.2624590396881104,
      "learning_rate": 9.561186372023943e-05,
      "loss": 1.0953,
      "step": 9750
    },
    {
      "epoch": 0.43926369323551917,
      "grad_norm": 1.1357842683792114,
      "learning_rate": 9.560736306764482e-05,
      "loss": 1.0645,
      "step": 9760
    },
    {
      "epoch": 0.4397137584949818,
      "grad_norm": 1.3458805084228516,
      "learning_rate": 9.560286241505019e-05,
      "loss": 1.0732,
      "step": 9770
    },
    {
      "epoch": 0.4401638237544444,
      "grad_norm": 1.7982012033462524,
      "learning_rate": 9.559836176245555e-05,
      "loss": 1.0116,
      "step": 9780
    },
    {
      "epoch": 0.440613889013907,
      "grad_norm": 1.989706039428711,
      "learning_rate": 9.559386110986094e-05,
      "loss": 1.1517,
      "step": 9790
    },
    {
      "epoch": 0.44106395427336964,
      "grad_norm": 2.217043876647949,
      "learning_rate": 9.558936045726631e-05,
      "loss": 1.1082,
      "step": 9800
    },
    {
      "epoch": 0.44151401953283226,
      "grad_norm": 1.322838306427002,
      "learning_rate": 9.558485980467167e-05,
      "loss": 1.1166,
      "step": 9810
    },
    {
      "epoch": 0.4419640847922949,
      "grad_norm": 1.6585050821304321,
      "learning_rate": 9.558035915207706e-05,
      "loss": 1.1189,
      "step": 9820
    },
    {
      "epoch": 0.4424141500517575,
      "grad_norm": 1.5472780466079712,
      "learning_rate": 9.557585849948243e-05,
      "loss": 1.1121,
      "step": 9830
    },
    {
      "epoch": 0.4428642153112201,
      "grad_norm": 1.4015820026397705,
      "learning_rate": 9.557135784688779e-05,
      "loss": 1.1043,
      "step": 9840
    },
    {
      "epoch": 0.44331428057068273,
      "grad_norm": 2.0470612049102783,
      "learning_rate": 9.556685719429318e-05,
      "loss": 1.0108,
      "step": 9850
    },
    {
      "epoch": 0.44376434583014535,
      "grad_norm": 1.2380627393722534,
      "learning_rate": 9.556235654169855e-05,
      "loss": 1.074,
      "step": 9860
    },
    {
      "epoch": 0.444214411089608,
      "grad_norm": 2.1268560886383057,
      "learning_rate": 9.555785588910391e-05,
      "loss": 1.0955,
      "step": 9870
    },
    {
      "epoch": 0.44466447634907064,
      "grad_norm": 1.2704505920410156,
      "learning_rate": 9.55533552365093e-05,
      "loss": 1.0136,
      "step": 9880
    },
    {
      "epoch": 0.44511454160853325,
      "grad_norm": 2.226520299911499,
      "learning_rate": 9.554885458391467e-05,
      "loss": 1.0844,
      "step": 9890
    },
    {
      "epoch": 0.44556460686799587,
      "grad_norm": 1.5909192562103271,
      "learning_rate": 9.554435393132003e-05,
      "loss": 1.0923,
      "step": 9900
    },
    {
      "epoch": 0.4460146721274585,
      "grad_norm": 1.0625654458999634,
      "learning_rate": 9.553985327872542e-05,
      "loss": 1.1082,
      "step": 9910
    },
    {
      "epoch": 0.4464647373869211,
      "grad_norm": 2.129354953765869,
      "learning_rate": 9.55353526261308e-05,
      "loss": 1.0754,
      "step": 9920
    },
    {
      "epoch": 0.4469148026463837,
      "grad_norm": 1.7812825441360474,
      "learning_rate": 9.553085197353616e-05,
      "loss": 1.0099,
      "step": 9930
    },
    {
      "epoch": 0.44736486790584634,
      "grad_norm": 3.062814712524414,
      "learning_rate": 9.552635132094154e-05,
      "loss": 1.1314,
      "step": 9940
    },
    {
      "epoch": 0.44781493316530896,
      "grad_norm": 2.120759963989258,
      "learning_rate": 9.552185066834692e-05,
      "loss": 1.0792,
      "step": 9950
    },
    {
      "epoch": 0.4482649984247716,
      "grad_norm": 1.9999122619628906,
      "learning_rate": 9.551735001575229e-05,
      "loss": 1.1059,
      "step": 9960
    },
    {
      "epoch": 0.4487150636842342,
      "grad_norm": 1.6393606662750244,
      "learning_rate": 9.551284936315766e-05,
      "loss": 0.9826,
      "step": 9970
    },
    {
      "epoch": 0.4491651289436968,
      "grad_norm": 2.0387368202209473,
      "learning_rate": 9.550834871056304e-05,
      "loss": 1.0643,
      "step": 9980
    },
    {
      "epoch": 0.4496151942031595,
      "grad_norm": 1.4140464067459106,
      "learning_rate": 9.550384805796841e-05,
      "loss": 1.1089,
      "step": 9990
    },
    {
      "epoch": 0.4500652594626221,
      "grad_norm": 1.4283299446105957,
      "learning_rate": 9.549934740537378e-05,
      "loss": 1.0994,
      "step": 10000
    },
    {
      "epoch": 0.4505153247220847,
      "grad_norm": 1.2624506950378418,
      "learning_rate": 9.549484675277916e-05,
      "loss": 1.0735,
      "step": 10010
    },
    {
      "epoch": 0.45096538998154734,
      "grad_norm": 1.8105027675628662,
      "learning_rate": 9.549034610018453e-05,
      "loss": 1.1053,
      "step": 10020
    },
    {
      "epoch": 0.45141545524100996,
      "grad_norm": 2.6779911518096924,
      "learning_rate": 9.54858454475899e-05,
      "loss": 1.1063,
      "step": 10030
    },
    {
      "epoch": 0.4518655205004726,
      "grad_norm": 1.149130940437317,
      "learning_rate": 9.548134479499528e-05,
      "loss": 1.1184,
      "step": 10040
    },
    {
      "epoch": 0.4523155857599352,
      "grad_norm": 1.552035927772522,
      "learning_rate": 9.547684414240065e-05,
      "loss": 1.1091,
      "step": 10050
    },
    {
      "epoch": 0.4527656510193978,
      "grad_norm": 1.3115545511245728,
      "learning_rate": 9.547234348980603e-05,
      "loss": 1.1128,
      "step": 10060
    },
    {
      "epoch": 0.4532157162788604,
      "grad_norm": 1.938966989517212,
      "learning_rate": 9.54678428372114e-05,
      "loss": 1.1519,
      "step": 10070
    },
    {
      "epoch": 0.45366578153832304,
      "grad_norm": 2.372260808944702,
      "learning_rate": 9.546334218461677e-05,
      "loss": 1.1055,
      "step": 10080
    },
    {
      "epoch": 0.45411584679778566,
      "grad_norm": 2.026069164276123,
      "learning_rate": 9.545884153202215e-05,
      "loss": 1.1262,
      "step": 10090
    },
    {
      "epoch": 0.4545659120572483,
      "grad_norm": 1.3210175037384033,
      "learning_rate": 9.545434087942752e-05,
      "loss": 1.104,
      "step": 10100
    },
    {
      "epoch": 0.4550159773167109,
      "grad_norm": 1.3060996532440186,
      "learning_rate": 9.54498402268329e-05,
      "loss": 1.0567,
      "step": 10110
    },
    {
      "epoch": 0.45546604257617357,
      "grad_norm": 1.6329458951950073,
      "learning_rate": 9.544533957423827e-05,
      "loss": 1.1506,
      "step": 10120
    },
    {
      "epoch": 0.4559161078356362,
      "grad_norm": 2.5824759006500244,
      "learning_rate": 9.544083892164364e-05,
      "loss": 1.136,
      "step": 10130
    },
    {
      "epoch": 0.4563661730950988,
      "grad_norm": 1.934830665588379,
      "learning_rate": 9.543633826904901e-05,
      "loss": 1.0543,
      "step": 10140
    },
    {
      "epoch": 0.4568162383545614,
      "grad_norm": 2.232846736907959,
      "learning_rate": 9.543183761645439e-05,
      "loss": 1.0636,
      "step": 10150
    },
    {
      "epoch": 0.45726630361402404,
      "grad_norm": 1.7774708271026611,
      "learning_rate": 9.542733696385976e-05,
      "loss": 1.1069,
      "step": 10160
    },
    {
      "epoch": 0.45771636887348666,
      "grad_norm": 1.0835968255996704,
      "learning_rate": 9.542283631126514e-05,
      "loss": 0.9876,
      "step": 10170
    },
    {
      "epoch": 0.4581664341329493,
      "grad_norm": 0.7554784417152405,
      "learning_rate": 9.541833565867051e-05,
      "loss": 1.0603,
      "step": 10180
    },
    {
      "epoch": 0.4586164993924119,
      "grad_norm": 1.0337069034576416,
      "learning_rate": 9.541383500607588e-05,
      "loss": 0.999,
      "step": 10190
    },
    {
      "epoch": 0.4590665646518745,
      "grad_norm": 1.0649292469024658,
      "learning_rate": 9.540933435348126e-05,
      "loss": 1.0337,
      "step": 10200
    },
    {
      "epoch": 0.4595166299113371,
      "grad_norm": 1.9887624979019165,
      "learning_rate": 9.540483370088663e-05,
      "loss": 1.1392,
      "step": 10210
    },
    {
      "epoch": 0.45996669517079974,
      "grad_norm": 1.5888150930404663,
      "learning_rate": 9.540033304829202e-05,
      "loss": 1.0562,
      "step": 10220
    },
    {
      "epoch": 0.46041676043026236,
      "grad_norm": 1.3101637363433838,
      "learning_rate": 9.539583239569738e-05,
      "loss": 1.1266,
      "step": 10230
    },
    {
      "epoch": 0.46086682568972503,
      "grad_norm": 1.0261099338531494,
      "learning_rate": 9.539133174310275e-05,
      "loss": 0.9845,
      "step": 10240
    },
    {
      "epoch": 0.46131689094918765,
      "grad_norm": 1.235823392868042,
      "learning_rate": 9.538683109050814e-05,
      "loss": 1.1442,
      "step": 10250
    },
    {
      "epoch": 0.46176695620865027,
      "grad_norm": 1.9782649278640747,
      "learning_rate": 9.53823304379135e-05,
      "loss": 1.1038,
      "step": 10260
    },
    {
      "epoch": 0.4622170214681129,
      "grad_norm": 2.103846788406372,
      "learning_rate": 9.537782978531887e-05,
      "loss": 1.104,
      "step": 10270
    },
    {
      "epoch": 0.4626670867275755,
      "grad_norm": 1.314367413520813,
      "learning_rate": 9.537332913272426e-05,
      "loss": 1.1922,
      "step": 10280
    },
    {
      "epoch": 0.4631171519870381,
      "grad_norm": 2.6630401611328125,
      "learning_rate": 9.536882848012962e-05,
      "loss": 1.1192,
      "step": 10290
    },
    {
      "epoch": 0.46356721724650074,
      "grad_norm": 1.8433321714401245,
      "learning_rate": 9.536432782753499e-05,
      "loss": 1.1082,
      "step": 10300
    },
    {
      "epoch": 0.46401728250596336,
      "grad_norm": 2.058499813079834,
      "learning_rate": 9.535982717494038e-05,
      "loss": 1.073,
      "step": 10310
    },
    {
      "epoch": 0.464467347765426,
      "grad_norm": 2.273474931716919,
      "learning_rate": 9.535532652234574e-05,
      "loss": 1.0922,
      "step": 10320
    },
    {
      "epoch": 0.4649174130248886,
      "grad_norm": 1.307792067527771,
      "learning_rate": 9.535082586975111e-05,
      "loss": 1.1365,
      "step": 10330
    },
    {
      "epoch": 0.4653674782843512,
      "grad_norm": 1.7281898260116577,
      "learning_rate": 9.53463252171565e-05,
      "loss": 1.0876,
      "step": 10340
    },
    {
      "epoch": 0.46581754354381383,
      "grad_norm": 0.9147882461547852,
      "learning_rate": 9.534182456456186e-05,
      "loss": 1.0443,
      "step": 10350
    },
    {
      "epoch": 0.4662676088032765,
      "grad_norm": 1.5402976274490356,
      "learning_rate": 9.533732391196723e-05,
      "loss": 1.0537,
      "step": 10360
    },
    {
      "epoch": 0.4667176740627391,
      "grad_norm": 1.4080102443695068,
      "learning_rate": 9.533282325937262e-05,
      "loss": 1.0386,
      "step": 10370
    },
    {
      "epoch": 0.46716773932220174,
      "grad_norm": 1.0949112176895142,
      "learning_rate": 9.532832260677798e-05,
      "loss": 1.0869,
      "step": 10380
    },
    {
      "epoch": 0.46761780458166435,
      "grad_norm": 1.256048321723938,
      "learning_rate": 9.532382195418335e-05,
      "loss": 1.0834,
      "step": 10390
    },
    {
      "epoch": 0.46806786984112697,
      "grad_norm": 1.8386321067810059,
      "learning_rate": 9.531932130158874e-05,
      "loss": 1.0377,
      "step": 10400
    },
    {
      "epoch": 0.4685179351005896,
      "grad_norm": 0.8986963033676147,
      "learning_rate": 9.53148206489941e-05,
      "loss": 1.0906,
      "step": 10410
    },
    {
      "epoch": 0.4689680003600522,
      "grad_norm": 1.2945243120193481,
      "learning_rate": 9.531031999639948e-05,
      "loss": 1.1158,
      "step": 10420
    },
    {
      "epoch": 0.4694180656195148,
      "grad_norm": 1.2323908805847168,
      "learning_rate": 9.530581934380486e-05,
      "loss": 1.0884,
      "step": 10430
    },
    {
      "epoch": 0.46986813087897744,
      "grad_norm": 1.253861427307129,
      "learning_rate": 9.530131869121022e-05,
      "loss": 1.0425,
      "step": 10440
    },
    {
      "epoch": 0.47031819613844006,
      "grad_norm": 1.6467695236206055,
      "learning_rate": 9.52968180386156e-05,
      "loss": 1.1243,
      "step": 10450
    },
    {
      "epoch": 0.4707682613979027,
      "grad_norm": 1.4854025840759277,
      "learning_rate": 9.529231738602098e-05,
      "loss": 1.1137,
      "step": 10460
    },
    {
      "epoch": 0.4712183266573653,
      "grad_norm": 2.6207969188690186,
      "learning_rate": 9.528781673342634e-05,
      "loss": 1.0565,
      "step": 10470
    },
    {
      "epoch": 0.47166839191682797,
      "grad_norm": 1.740696907043457,
      "learning_rate": 9.528331608083173e-05,
      "loss": 1.082,
      "step": 10480
    },
    {
      "epoch": 0.4721184571762906,
      "grad_norm": 1.5756586790084839,
      "learning_rate": 9.52788154282371e-05,
      "loss": 1.1133,
      "step": 10490
    },
    {
      "epoch": 0.4725685224357532,
      "grad_norm": 1.8264728784561157,
      "learning_rate": 9.527431477564246e-05,
      "loss": 1.1319,
      "step": 10500
    },
    {
      "epoch": 0.4730185876952158,
      "grad_norm": 1.4459763765335083,
      "learning_rate": 9.526981412304785e-05,
      "loss": 1.0712,
      "step": 10510
    },
    {
      "epoch": 0.47346865295467844,
      "grad_norm": 1.7467002868652344,
      "learning_rate": 9.526531347045323e-05,
      "loss": 1.1332,
      "step": 10520
    },
    {
      "epoch": 0.47391871821414105,
      "grad_norm": 1.437525749206543,
      "learning_rate": 9.526081281785859e-05,
      "loss": 1.0454,
      "step": 10530
    },
    {
      "epoch": 0.4743687834736037,
      "grad_norm": 1.5327093601226807,
      "learning_rate": 9.525631216526397e-05,
      "loss": 1.0727,
      "step": 10540
    },
    {
      "epoch": 0.4748188487330663,
      "grad_norm": 1.810513973236084,
      "learning_rate": 9.525181151266935e-05,
      "loss": 1.0258,
      "step": 10550
    },
    {
      "epoch": 0.4752689139925289,
      "grad_norm": 1.070356011390686,
      "learning_rate": 9.52473108600747e-05,
      "loss": 1.0889,
      "step": 10560
    },
    {
      "epoch": 0.4757189792519915,
      "grad_norm": 1.43858802318573,
      "learning_rate": 9.52428102074801e-05,
      "loss": 1.0991,
      "step": 10570
    },
    {
      "epoch": 0.47616904451145414,
      "grad_norm": 1.1107020378112793,
      "learning_rate": 9.523830955488547e-05,
      "loss": 1.0837,
      "step": 10580
    },
    {
      "epoch": 0.47661910977091676,
      "grad_norm": 1.6117388010025024,
      "learning_rate": 9.523380890229083e-05,
      "loss": 1.0095,
      "step": 10590
    },
    {
      "epoch": 0.4770691750303794,
      "grad_norm": 1.7795642614364624,
      "learning_rate": 9.522930824969621e-05,
      "loss": 1.0534,
      "step": 10600
    },
    {
      "epoch": 0.47751924028984205,
      "grad_norm": 2.173553705215454,
      "learning_rate": 9.522480759710159e-05,
      "loss": 1.1091,
      "step": 10610
    },
    {
      "epoch": 0.47796930554930467,
      "grad_norm": 2.767549753189087,
      "learning_rate": 9.522030694450695e-05,
      "loss": 1.1669,
      "step": 10620
    },
    {
      "epoch": 0.4784193708087673,
      "grad_norm": 1.0603346824645996,
      "learning_rate": 9.521580629191233e-05,
      "loss": 1.0629,
      "step": 10630
    },
    {
      "epoch": 0.4788694360682299,
      "grad_norm": 2.0429015159606934,
      "learning_rate": 9.521130563931771e-05,
      "loss": 1.0829,
      "step": 10640
    },
    {
      "epoch": 0.4793195013276925,
      "grad_norm": 1.3955327272415161,
      "learning_rate": 9.520680498672307e-05,
      "loss": 1.1032,
      "step": 10650
    },
    {
      "epoch": 0.47976956658715514,
      "grad_norm": 2.0366439819335938,
      "learning_rate": 9.520230433412846e-05,
      "loss": 1.1917,
      "step": 10660
    },
    {
      "epoch": 0.48021963184661776,
      "grad_norm": 1.9150776863098145,
      "learning_rate": 9.519780368153383e-05,
      "loss": 1.0786,
      "step": 10670
    },
    {
      "epoch": 0.4806696971060804,
      "grad_norm": 1.703418254852295,
      "learning_rate": 9.519330302893919e-05,
      "loss": 1.0806,
      "step": 10680
    },
    {
      "epoch": 0.481119762365543,
      "grad_norm": 1.3724956512451172,
      "learning_rate": 9.518880237634458e-05,
      "loss": 1.1445,
      "step": 10690
    },
    {
      "epoch": 0.4815698276250056,
      "grad_norm": 1.4312947988510132,
      "learning_rate": 9.518430172374995e-05,
      "loss": 1.0738,
      "step": 10700
    },
    {
      "epoch": 0.4820198928844682,
      "grad_norm": 1.222969651222229,
      "learning_rate": 9.517980107115531e-05,
      "loss": 1.1074,
      "step": 10710
    },
    {
      "epoch": 0.48246995814393084,
      "grad_norm": 1.7347055673599243,
      "learning_rate": 9.51753004185607e-05,
      "loss": 1.1161,
      "step": 10720
    },
    {
      "epoch": 0.4829200234033935,
      "grad_norm": 1.0312243700027466,
      "learning_rate": 9.517079976596607e-05,
      "loss": 1.12,
      "step": 10730
    },
    {
      "epoch": 0.48337008866285613,
      "grad_norm": 2.298656702041626,
      "learning_rate": 9.516629911337144e-05,
      "loss": 1.1287,
      "step": 10740
    },
    {
      "epoch": 0.48382015392231875,
      "grad_norm": 1.671778917312622,
      "learning_rate": 9.516179846077682e-05,
      "loss": 1.0843,
      "step": 10750
    },
    {
      "epoch": 0.48427021918178137,
      "grad_norm": 1.901157021522522,
      "learning_rate": 9.515729780818219e-05,
      "loss": 1.1064,
      "step": 10760
    },
    {
      "epoch": 0.484720284441244,
      "grad_norm": 1.204458475112915,
      "learning_rate": 9.515279715558757e-05,
      "loss": 1.0649,
      "step": 10770
    },
    {
      "epoch": 0.4851703497007066,
      "grad_norm": 1.3656365871429443,
      "learning_rate": 9.514829650299294e-05,
      "loss": 1.0894,
      "step": 10780
    },
    {
      "epoch": 0.4856204149601692,
      "grad_norm": 1.2965822219848633,
      "learning_rate": 9.514379585039831e-05,
      "loss": 1.0301,
      "step": 10790
    },
    {
      "epoch": 0.48607048021963184,
      "grad_norm": 1.7490559816360474,
      "learning_rate": 9.513929519780369e-05,
      "loss": 1.0713,
      "step": 10800
    },
    {
      "epoch": 0.48652054547909446,
      "grad_norm": 1.0061602592468262,
      "learning_rate": 9.513479454520906e-05,
      "loss": 1.0247,
      "step": 10810
    },
    {
      "epoch": 0.4869706107385571,
      "grad_norm": 1.9052362442016602,
      "learning_rate": 9.513029389261443e-05,
      "loss": 1.078,
      "step": 10820
    },
    {
      "epoch": 0.4874206759980197,
      "grad_norm": 1.439894676208496,
      "learning_rate": 9.512579324001981e-05,
      "loss": 1.0224,
      "step": 10830
    },
    {
      "epoch": 0.4878707412574823,
      "grad_norm": 1.6990201473236084,
      "learning_rate": 9.512129258742518e-05,
      "loss": 1.0617,
      "step": 10840
    },
    {
      "epoch": 0.488320806516945,
      "grad_norm": 1.0871530771255493,
      "learning_rate": 9.511679193483055e-05,
      "loss": 1.145,
      "step": 10850
    },
    {
      "epoch": 0.4887708717764076,
      "grad_norm": 1.3082480430603027,
      "learning_rate": 9.511229128223593e-05,
      "loss": 1.0769,
      "step": 10860
    },
    {
      "epoch": 0.4892209370358702,
      "grad_norm": 1.6951016187667847,
      "learning_rate": 9.51077906296413e-05,
      "loss": 1.071,
      "step": 10870
    },
    {
      "epoch": 0.48967100229533284,
      "grad_norm": 1.2081897258758545,
      "learning_rate": 9.510328997704667e-05,
      "loss": 1.0745,
      "step": 10880
    },
    {
      "epoch": 0.49012106755479545,
      "grad_norm": 1.4402716159820557,
      "learning_rate": 9.509878932445205e-05,
      "loss": 1.0269,
      "step": 10890
    },
    {
      "epoch": 0.49057113281425807,
      "grad_norm": 1.3598393201828003,
      "learning_rate": 9.509428867185742e-05,
      "loss": 1.0394,
      "step": 10900
    },
    {
      "epoch": 0.4910211980737207,
      "grad_norm": 1.4566404819488525,
      "learning_rate": 9.50897880192628e-05,
      "loss": 1.1095,
      "step": 10910
    },
    {
      "epoch": 0.4914712633331833,
      "grad_norm": 1.3097209930419922,
      "learning_rate": 9.508528736666817e-05,
      "loss": 1.1484,
      "step": 10920
    },
    {
      "epoch": 0.4919213285926459,
      "grad_norm": 1.6448816061019897,
      "learning_rate": 9.508078671407354e-05,
      "loss": 1.0073,
      "step": 10930
    },
    {
      "epoch": 0.49237139385210854,
      "grad_norm": 1.3941476345062256,
      "learning_rate": 9.507628606147892e-05,
      "loss": 1.0599,
      "step": 10940
    },
    {
      "epoch": 0.49282145911157116,
      "grad_norm": 1.9710893630981445,
      "learning_rate": 9.507178540888429e-05,
      "loss": 1.1112,
      "step": 10950
    },
    {
      "epoch": 0.4932715243710338,
      "grad_norm": 1.0378540754318237,
      "learning_rate": 9.506728475628966e-05,
      "loss": 1.0779,
      "step": 10960
    },
    {
      "epoch": 0.49372158963049645,
      "grad_norm": 1.655923843383789,
      "learning_rate": 9.506278410369504e-05,
      "loss": 1.098,
      "step": 10970
    },
    {
      "epoch": 0.49417165488995907,
      "grad_norm": 1.4303406476974487,
      "learning_rate": 9.505828345110041e-05,
      "loss": 1.0824,
      "step": 10980
    },
    {
      "epoch": 0.4946217201494217,
      "grad_norm": 1.836707592010498,
      "learning_rate": 9.505378279850578e-05,
      "loss": 1.1218,
      "step": 10990
    },
    {
      "epoch": 0.4950717854088843,
      "grad_norm": 2.3652613162994385,
      "learning_rate": 9.504928214591117e-05,
      "loss": 0.9462,
      "step": 11000
    },
    {
      "epoch": 0.4955218506683469,
      "grad_norm": 1.0440382957458496,
      "learning_rate": 9.504478149331653e-05,
      "loss": 1.0098,
      "step": 11010
    },
    {
      "epoch": 0.49597191592780954,
      "grad_norm": 1.8805373907089233,
      "learning_rate": 9.50402808407219e-05,
      "loss": 1.055,
      "step": 11020
    },
    {
      "epoch": 0.49642198118727215,
      "grad_norm": 1.0629777908325195,
      "learning_rate": 9.503578018812729e-05,
      "loss": 1.0247,
      "step": 11030
    },
    {
      "epoch": 0.49687204644673477,
      "grad_norm": 1.4226857423782349,
      "learning_rate": 9.503127953553265e-05,
      "loss": 1.0584,
      "step": 11040
    },
    {
      "epoch": 0.4973221117061974,
      "grad_norm": 1.430070161819458,
      "learning_rate": 9.502677888293803e-05,
      "loss": 1.0964,
      "step": 11050
    },
    {
      "epoch": 0.49777217696566,
      "grad_norm": 1.360697865486145,
      "learning_rate": 9.502227823034341e-05,
      "loss": 1.0487,
      "step": 11060
    },
    {
      "epoch": 0.4982222422251226,
      "grad_norm": 1.6171470880508423,
      "learning_rate": 9.501777757774877e-05,
      "loss": 1.1027,
      "step": 11070
    },
    {
      "epoch": 0.49867230748458524,
      "grad_norm": 1.2347115278244019,
      "learning_rate": 9.501327692515415e-05,
      "loss": 1.0834,
      "step": 11080
    },
    {
      "epoch": 0.49912237274404786,
      "grad_norm": 1.125443458557129,
      "learning_rate": 9.500877627255953e-05,
      "loss": 1.0816,
      "step": 11090
    },
    {
      "epoch": 0.49957243800351053,
      "grad_norm": 1.5873435735702515,
      "learning_rate": 9.50042756199649e-05,
      "loss": 1.0162,
      "step": 11100
    },
    {
      "epoch": 0.5000225032629732,
      "grad_norm": 1.245292067527771,
      "learning_rate": 9.499977496737027e-05,
      "loss": 1.1715,
      "step": 11110
    },
    {
      "epoch": 0.5004725685224357,
      "grad_norm": 1.7275365591049194,
      "learning_rate": 9.499527431477565e-05,
      "loss": 1.1116,
      "step": 11120
    },
    {
      "epoch": 0.5009226337818984,
      "grad_norm": 1.395737886428833,
      "learning_rate": 9.499077366218102e-05,
      "loss": 1.121,
      "step": 11130
    },
    {
      "epoch": 0.501372699041361,
      "grad_norm": 1.8916125297546387,
      "learning_rate": 9.498627300958639e-05,
      "loss": 1.1143,
      "step": 11140
    },
    {
      "epoch": 0.5018227643008236,
      "grad_norm": 1.2000370025634766,
      "learning_rate": 9.498177235699178e-05,
      "loss": 1.1001,
      "step": 11150
    },
    {
      "epoch": 0.5022728295602863,
      "grad_norm": 1.8673324584960938,
      "learning_rate": 9.497727170439714e-05,
      "loss": 1.0383,
      "step": 11160
    },
    {
      "epoch": 0.5027228948197489,
      "grad_norm": 1.581479787826538,
      "learning_rate": 9.497277105180251e-05,
      "loss": 1.0726,
      "step": 11170
    },
    {
      "epoch": 0.5031729600792115,
      "grad_norm": 1.1753864288330078,
      "learning_rate": 9.49682703992079e-05,
      "loss": 1.1009,
      "step": 11180
    },
    {
      "epoch": 0.5036230253386741,
      "grad_norm": 1.5715285539627075,
      "learning_rate": 9.496376974661326e-05,
      "loss": 1.1032,
      "step": 11190
    },
    {
      "epoch": 0.5040730905981368,
      "grad_norm": 1.2367701530456543,
      "learning_rate": 9.495926909401863e-05,
      "loss": 1.0969,
      "step": 11200
    },
    {
      "epoch": 0.5045231558575993,
      "grad_norm": 2.3565733432769775,
      "learning_rate": 9.495476844142402e-05,
      "loss": 1.0721,
      "step": 11210
    },
    {
      "epoch": 0.504973221117062,
      "grad_norm": 1.0893677473068237,
      "learning_rate": 9.495026778882938e-05,
      "loss": 1.0351,
      "step": 11220
    },
    {
      "epoch": 0.5054232863765246,
      "grad_norm": 1.5752302408218384,
      "learning_rate": 9.494576713623475e-05,
      "loss": 1.0491,
      "step": 11230
    },
    {
      "epoch": 0.5058733516359872,
      "grad_norm": 0.9796003699302673,
      "learning_rate": 9.494126648364014e-05,
      "loss": 1.0784,
      "step": 11240
    },
    {
      "epoch": 0.5063234168954498,
      "grad_norm": 1.1539617776870728,
      "learning_rate": 9.49367658310455e-05,
      "loss": 1.0931,
      "step": 11250
    },
    {
      "epoch": 0.5067734821549125,
      "grad_norm": 1.863208532333374,
      "learning_rate": 9.493226517845089e-05,
      "loss": 1.0272,
      "step": 11260
    },
    {
      "epoch": 0.507223547414375,
      "grad_norm": 1.116729736328125,
      "learning_rate": 9.492776452585626e-05,
      "loss": 1.0594,
      "step": 11270
    },
    {
      "epoch": 0.5076736126738377,
      "grad_norm": 1.5558604001998901,
      "learning_rate": 9.492326387326162e-05,
      "loss": 1.029,
      "step": 11280
    },
    {
      "epoch": 0.5081236779333004,
      "grad_norm": 1.4115488529205322,
      "learning_rate": 9.4918763220667e-05,
      "loss": 1.1036,
      "step": 11290
    },
    {
      "epoch": 0.5085737431927629,
      "grad_norm": 1.6446568965911865,
      "learning_rate": 9.491426256807238e-05,
      "loss": 1.1171,
      "step": 11300
    },
    {
      "epoch": 0.5090238084522256,
      "grad_norm": 1.2171093225479126,
      "learning_rate": 9.490976191547774e-05,
      "loss": 1.1279,
      "step": 11310
    },
    {
      "epoch": 0.5094738737116882,
      "grad_norm": 1.885116457939148,
      "learning_rate": 9.490526126288313e-05,
      "loss": 1.0405,
      "step": 11320
    },
    {
      "epoch": 0.5099239389711508,
      "grad_norm": 1.3732942342758179,
      "learning_rate": 9.49007606102885e-05,
      "loss": 1.099,
      "step": 11330
    },
    {
      "epoch": 0.5103740042306134,
      "grad_norm": 1.1759034395217896,
      "learning_rate": 9.489625995769386e-05,
      "loss": 1.0664,
      "step": 11340
    },
    {
      "epoch": 0.5108240694900761,
      "grad_norm": 1.2124780416488647,
      "learning_rate": 9.489175930509925e-05,
      "loss": 1.0968,
      "step": 11350
    },
    {
      "epoch": 0.5112741347495386,
      "grad_norm": 0.8602928519248962,
      "learning_rate": 9.488725865250462e-05,
      "loss": 1.0648,
      "step": 11360
    },
    {
      "epoch": 0.5117242000090013,
      "grad_norm": 1.7886216640472412,
      "learning_rate": 9.488275799990998e-05,
      "loss": 1.0809,
      "step": 11370
    },
    {
      "epoch": 0.5121742652684639,
      "grad_norm": 1.7150975465774536,
      "learning_rate": 9.487825734731537e-05,
      "loss": 1.088,
      "step": 11380
    },
    {
      "epoch": 0.5126243305279266,
      "grad_norm": 1.2782384157180786,
      "learning_rate": 9.487375669472074e-05,
      "loss": 1.1106,
      "step": 11390
    },
    {
      "epoch": 0.5130743957873892,
      "grad_norm": 1.9566682577133179,
      "learning_rate": 9.48692560421261e-05,
      "loss": 1.1234,
      "step": 11400
    },
    {
      "epoch": 0.5135244610468518,
      "grad_norm": 1.4642523527145386,
      "learning_rate": 9.486475538953149e-05,
      "loss": 1.0723,
      "step": 11410
    },
    {
      "epoch": 0.5139745263063145,
      "grad_norm": 2.0002338886260986,
      "learning_rate": 9.486025473693686e-05,
      "loss": 1.0679,
      "step": 11420
    },
    {
      "epoch": 0.514424591565777,
      "grad_norm": 2.2286975383758545,
      "learning_rate": 9.485575408434222e-05,
      "loss": 1.091,
      "step": 11430
    },
    {
      "epoch": 0.5148746568252397,
      "grad_norm": 1.3966649770736694,
      "learning_rate": 9.485125343174761e-05,
      "loss": 1.0605,
      "step": 11440
    },
    {
      "epoch": 0.5153247220847023,
      "grad_norm": 2.39213490486145,
      "learning_rate": 9.484675277915298e-05,
      "loss": 1.081,
      "step": 11450
    },
    {
      "epoch": 0.5157747873441649,
      "grad_norm": 3.158583402633667,
      "learning_rate": 9.484225212655836e-05,
      "loss": 1.0377,
      "step": 11460
    },
    {
      "epoch": 0.5162248526036275,
      "grad_norm": 1.528283953666687,
      "learning_rate": 9.483775147396373e-05,
      "loss": 1.133,
      "step": 11470
    },
    {
      "epoch": 0.5166749178630902,
      "grad_norm": 2.0052435398101807,
      "learning_rate": 9.48332508213691e-05,
      "loss": 1.097,
      "step": 11480
    },
    {
      "epoch": 0.5171249831225527,
      "grad_norm": 0.8448987603187561,
      "learning_rate": 9.482875016877448e-05,
      "loss": 1.0179,
      "step": 11490
    },
    {
      "epoch": 0.5175750483820154,
      "grad_norm": 1.521932601928711,
      "learning_rate": 9.482424951617985e-05,
      "loss": 1.0124,
      "step": 11500
    },
    {
      "epoch": 0.518025113641478,
      "grad_norm": 1.3989894390106201,
      "learning_rate": 9.481974886358523e-05,
      "loss": 1.1076,
      "step": 11510
    },
    {
      "epoch": 0.5184751789009406,
      "grad_norm": 1.3140003681182861,
      "learning_rate": 9.48152482109906e-05,
      "loss": 1.0653,
      "step": 11520
    },
    {
      "epoch": 0.5189252441604033,
      "grad_norm": 1.2393113374710083,
      "learning_rate": 9.481074755839597e-05,
      "loss": 1.0595,
      "step": 11530
    },
    {
      "epoch": 0.5193753094198659,
      "grad_norm": 1.3380014896392822,
      "learning_rate": 9.480624690580135e-05,
      "loss": 1.1015,
      "step": 11540
    },
    {
      "epoch": 0.5198253746793285,
      "grad_norm": 1.844309687614441,
      "learning_rate": 9.480174625320672e-05,
      "loss": 1.0296,
      "step": 11550
    },
    {
      "epoch": 0.5202754399387911,
      "grad_norm": 1.6846596002578735,
      "learning_rate": 9.47972456006121e-05,
      "loss": 1.1117,
      "step": 11560
    },
    {
      "epoch": 0.5207255051982538,
      "grad_norm": 1.9993103742599487,
      "learning_rate": 9.479274494801747e-05,
      "loss": 1.1035,
      "step": 11570
    },
    {
      "epoch": 0.5211755704577163,
      "grad_norm": 1.440406084060669,
      "learning_rate": 9.478824429542284e-05,
      "loss": 1.0369,
      "step": 11580
    },
    {
      "epoch": 0.521625635717179,
      "grad_norm": 2.358242988586426,
      "learning_rate": 9.478374364282821e-05,
      "loss": 1.1527,
      "step": 11590
    },
    {
      "epoch": 0.5220757009766416,
      "grad_norm": 2.1169307231903076,
      "learning_rate": 9.477924299023359e-05,
      "loss": 1.1467,
      "step": 11600
    },
    {
      "epoch": 0.5225257662361042,
      "grad_norm": 1.690034031867981,
      "learning_rate": 9.477474233763896e-05,
      "loss": 1.0891,
      "step": 11610
    },
    {
      "epoch": 0.5229758314955668,
      "grad_norm": 2.117523431777954,
      "learning_rate": 9.477024168504434e-05,
      "loss": 1.1086,
      "step": 11620
    },
    {
      "epoch": 0.5234258967550295,
      "grad_norm": 1.6048624515533447,
      "learning_rate": 9.476574103244971e-05,
      "loss": 1.0553,
      "step": 11630
    },
    {
      "epoch": 0.523875962014492,
      "grad_norm": 2.88724422454834,
      "learning_rate": 9.476124037985508e-05,
      "loss": 1.0229,
      "step": 11640
    },
    {
      "epoch": 0.5243260272739547,
      "grad_norm": 1.4958804845809937,
      "learning_rate": 9.475673972726046e-05,
      "loss": 1.0289,
      "step": 11650
    },
    {
      "epoch": 0.5247760925334174,
      "grad_norm": 2.286226272583008,
      "learning_rate": 9.475223907466583e-05,
      "loss": 1.0318,
      "step": 11660
    },
    {
      "epoch": 0.52522615779288,
      "grad_norm": 1.58993399143219,
      "learning_rate": 9.47477384220712e-05,
      "loss": 1.1244,
      "step": 11670
    },
    {
      "epoch": 0.5256762230523426,
      "grad_norm": 2.3789727687835693,
      "learning_rate": 9.474323776947658e-05,
      "loss": 1.0722,
      "step": 11680
    },
    {
      "epoch": 0.5261262883118052,
      "grad_norm": 3.2385432720184326,
      "learning_rate": 9.473873711688195e-05,
      "loss": 1.0766,
      "step": 11690
    },
    {
      "epoch": 0.5265763535712679,
      "grad_norm": 1.513310432434082,
      "learning_rate": 9.473423646428732e-05,
      "loss": 1.0423,
      "step": 11700
    },
    {
      "epoch": 0.5270264188307304,
      "grad_norm": 1.4345815181732178,
      "learning_rate": 9.47297358116927e-05,
      "loss": 1.127,
      "step": 11710
    },
    {
      "epoch": 0.5274764840901931,
      "grad_norm": 2.0776829719543457,
      "learning_rate": 9.472523515909807e-05,
      "loss": 1.0119,
      "step": 11720
    },
    {
      "epoch": 0.5279265493496557,
      "grad_norm": 1.4274537563323975,
      "learning_rate": 9.472073450650344e-05,
      "loss": 1.0568,
      "step": 11730
    },
    {
      "epoch": 0.5283766146091183,
      "grad_norm": 2.7776994705200195,
      "learning_rate": 9.471623385390882e-05,
      "loss": 1.1146,
      "step": 11740
    },
    {
      "epoch": 0.5288266798685809,
      "grad_norm": 1.5211766958236694,
      "learning_rate": 9.471173320131419e-05,
      "loss": 1.0606,
      "step": 11750
    },
    {
      "epoch": 0.5292767451280436,
      "grad_norm": 1.4026538133621216,
      "learning_rate": 9.470723254871957e-05,
      "loss": 1.0539,
      "step": 11760
    },
    {
      "epoch": 0.5297268103875062,
      "grad_norm": 2.590482711791992,
      "learning_rate": 9.470273189612494e-05,
      "loss": 1.0574,
      "step": 11770
    },
    {
      "epoch": 0.5301768756469688,
      "grad_norm": 1.8678386211395264,
      "learning_rate": 9.469823124353031e-05,
      "loss": 1.0671,
      "step": 11780
    },
    {
      "epoch": 0.5306269409064315,
      "grad_norm": 1.5778963565826416,
      "learning_rate": 9.469373059093569e-05,
      "loss": 1.0797,
      "step": 11790
    },
    {
      "epoch": 0.531077006165894,
      "grad_norm": 1.5736221075057983,
      "learning_rate": 9.468922993834106e-05,
      "loss": 1.11,
      "step": 11800
    },
    {
      "epoch": 0.5315270714253567,
      "grad_norm": 2.0138731002807617,
      "learning_rate": 9.468472928574645e-05,
      "loss": 1.1037,
      "step": 11810
    },
    {
      "epoch": 0.5319771366848193,
      "grad_norm": 2.9084579944610596,
      "learning_rate": 9.468022863315181e-05,
      "loss": 1.0809,
      "step": 11820
    },
    {
      "epoch": 0.532427201944282,
      "grad_norm": 1.2952700853347778,
      "learning_rate": 9.467572798055718e-05,
      "loss": 1.0561,
      "step": 11830
    },
    {
      "epoch": 0.5328772672037445,
      "grad_norm": 1.5093499422073364,
      "learning_rate": 9.467122732796257e-05,
      "loss": 1.1138,
      "step": 11840
    },
    {
      "epoch": 0.5333273324632072,
      "grad_norm": 1.317455530166626,
      "learning_rate": 9.466672667536793e-05,
      "loss": 1.0736,
      "step": 11850
    },
    {
      "epoch": 0.5337773977226697,
      "grad_norm": 1.3528766632080078,
      "learning_rate": 9.46622260227733e-05,
      "loss": 1.0589,
      "step": 11860
    },
    {
      "epoch": 0.5342274629821324,
      "grad_norm": 1.6076626777648926,
      "learning_rate": 9.465772537017869e-05,
      "loss": 1.1056,
      "step": 11870
    },
    {
      "epoch": 0.534677528241595,
      "grad_norm": 2.8540148735046387,
      "learning_rate": 9.465322471758405e-05,
      "loss": 1.101,
      "step": 11880
    },
    {
      "epoch": 0.5351275935010577,
      "grad_norm": 2.212973117828369,
      "learning_rate": 9.464872406498942e-05,
      "loss": 1.1507,
      "step": 11890
    },
    {
      "epoch": 0.5355776587605203,
      "grad_norm": 1.2962135076522827,
      "learning_rate": 9.464422341239481e-05,
      "loss": 1.0621,
      "step": 11900
    },
    {
      "epoch": 0.5360277240199829,
      "grad_norm": 1.0862873792648315,
      "learning_rate": 9.463972275980017e-05,
      "loss": 1.0729,
      "step": 11910
    },
    {
      "epoch": 0.5364777892794456,
      "grad_norm": 1.3523391485214233,
      "learning_rate": 9.463522210720554e-05,
      "loss": 1.0222,
      "step": 11920
    },
    {
      "epoch": 0.5369278545389081,
      "grad_norm": 1.5533326864242554,
      "learning_rate": 9.463072145461093e-05,
      "loss": 1.1099,
      "step": 11930
    },
    {
      "epoch": 0.5373779197983708,
      "grad_norm": 1.5226727724075317,
      "learning_rate": 9.462622080201629e-05,
      "loss": 1.0313,
      "step": 11940
    },
    {
      "epoch": 0.5378279850578334,
      "grad_norm": 1.2720928192138672,
      "learning_rate": 9.462172014942166e-05,
      "loss": 0.9811,
      "step": 11950
    },
    {
      "epoch": 0.538278050317296,
      "grad_norm": 1.6576851606369019,
      "learning_rate": 9.461721949682705e-05,
      "loss": 1.0864,
      "step": 11960
    },
    {
      "epoch": 0.5387281155767586,
      "grad_norm": 0.8961746692657471,
      "learning_rate": 9.461271884423241e-05,
      "loss": 1.1404,
      "step": 11970
    },
    {
      "epoch": 0.5391781808362213,
      "grad_norm": 1.5754467248916626,
      "learning_rate": 9.460821819163778e-05,
      "loss": 1.117,
      "step": 11980
    },
    {
      "epoch": 0.5396282460956838,
      "grad_norm": 2.0858154296875,
      "learning_rate": 9.460371753904317e-05,
      "loss": 1.1098,
      "step": 11990
    },
    {
      "epoch": 0.5400783113551465,
      "grad_norm": 1.6479637622833252,
      "learning_rate": 9.459921688644853e-05,
      "loss": 1.0364,
      "step": 12000
    },
    {
      "epoch": 0.5405283766146091,
      "grad_norm": 1.2244961261749268,
      "learning_rate": 9.45947162338539e-05,
      "loss": 1.09,
      "step": 12010
    },
    {
      "epoch": 0.5409784418740717,
      "grad_norm": 2.447455406188965,
      "learning_rate": 9.459021558125929e-05,
      "loss": 1.0543,
      "step": 12020
    },
    {
      "epoch": 0.5414285071335344,
      "grad_norm": 2.9598402976989746,
      "learning_rate": 9.458571492866465e-05,
      "loss": 1.1474,
      "step": 12030
    },
    {
      "epoch": 0.541878572392997,
      "grad_norm": 1.6551034450531006,
      "learning_rate": 9.458121427607003e-05,
      "loss": 1.0707,
      "step": 12040
    },
    {
      "epoch": 0.5423286376524596,
      "grad_norm": 2.3591299057006836,
      "learning_rate": 9.457671362347541e-05,
      "loss": 1.1355,
      "step": 12050
    },
    {
      "epoch": 0.5427787029119222,
      "grad_norm": 1.071982979774475,
      "learning_rate": 9.457221297088077e-05,
      "loss": 1.1333,
      "step": 12060
    },
    {
      "epoch": 0.5432287681713849,
      "grad_norm": 2.178558349609375,
      "learning_rate": 9.456771231828616e-05,
      "loss": 1.1106,
      "step": 12070
    },
    {
      "epoch": 0.5436788334308474,
      "grad_norm": 1.3604313135147095,
      "learning_rate": 9.456321166569153e-05,
      "loss": 1.0806,
      "step": 12080
    },
    {
      "epoch": 0.5441288986903101,
      "grad_norm": 2.1096882820129395,
      "learning_rate": 9.45587110130969e-05,
      "loss": 1.0548,
      "step": 12090
    },
    {
      "epoch": 0.5445789639497727,
      "grad_norm": 2.139091968536377,
      "learning_rate": 9.455421036050228e-05,
      "loss": 1.0864,
      "step": 12100
    },
    {
      "epoch": 0.5450290292092353,
      "grad_norm": 1.9938052892684937,
      "learning_rate": 9.454970970790766e-05,
      "loss": 1.0566,
      "step": 12110
    },
    {
      "epoch": 0.5454790944686979,
      "grad_norm": 1.892736792564392,
      "learning_rate": 9.454520905531303e-05,
      "loss": 1.0844,
      "step": 12120
    },
    {
      "epoch": 0.5459291597281606,
      "grad_norm": 1.8996071815490723,
      "learning_rate": 9.45407084027184e-05,
      "loss": 1.0414,
      "step": 12130
    },
    {
      "epoch": 0.5463792249876233,
      "grad_norm": 1.2688450813293457,
      "learning_rate": 9.453620775012378e-05,
      "loss": 1.0855,
      "step": 12140
    },
    {
      "epoch": 0.5468292902470858,
      "grad_norm": 1.829602837562561,
      "learning_rate": 9.453170709752915e-05,
      "loss": 1.1544,
      "step": 12150
    },
    {
      "epoch": 0.5472793555065485,
      "grad_norm": 1.9188064336776733,
      "learning_rate": 9.452720644493452e-05,
      "loss": 1.0913,
      "step": 12160
    },
    {
      "epoch": 0.547729420766011,
      "grad_norm": 1.6154242753982544,
      "learning_rate": 9.45227057923399e-05,
      "loss": 1.0669,
      "step": 12170
    },
    {
      "epoch": 0.5481794860254737,
      "grad_norm": 2.71218204498291,
      "learning_rate": 9.451820513974527e-05,
      "loss": 1.0999,
      "step": 12180
    },
    {
      "epoch": 0.5486295512849363,
      "grad_norm": 1.813351035118103,
      "learning_rate": 9.451370448715064e-05,
      "loss": 1.079,
      "step": 12190
    },
    {
      "epoch": 0.549079616544399,
      "grad_norm": 2.709176778793335,
      "learning_rate": 9.450920383455602e-05,
      "loss": 1.1619,
      "step": 12200
    },
    {
      "epoch": 0.5495296818038615,
      "grad_norm": 1.7163727283477783,
      "learning_rate": 9.450470318196139e-05,
      "loss": 1.0499,
      "step": 12210
    },
    {
      "epoch": 0.5499797470633242,
      "grad_norm": 1.6223455667495728,
      "learning_rate": 9.450020252936676e-05,
      "loss": 1.0472,
      "step": 12220
    },
    {
      "epoch": 0.5504298123227868,
      "grad_norm": 1.3414479494094849,
      "learning_rate": 9.449570187677214e-05,
      "loss": 1.07,
      "step": 12230
    },
    {
      "epoch": 0.5508798775822494,
      "grad_norm": 2.006636142730713,
      "learning_rate": 9.449120122417751e-05,
      "loss": 1.0548,
      "step": 12240
    },
    {
      "epoch": 0.551329942841712,
      "grad_norm": 1.4425053596496582,
      "learning_rate": 9.448670057158289e-05,
      "loss": 1.0437,
      "step": 12250
    },
    {
      "epoch": 0.5517800081011747,
      "grad_norm": 2.571093797683716,
      "learning_rate": 9.448219991898826e-05,
      "loss": 1.0195,
      "step": 12260
    },
    {
      "epoch": 0.5522300733606373,
      "grad_norm": 3.0834569931030273,
      "learning_rate": 9.447769926639363e-05,
      "loss": 1.0584,
      "step": 12270
    },
    {
      "epoch": 0.5526801386200999,
      "grad_norm": 2.2863645553588867,
      "learning_rate": 9.4473198613799e-05,
      "loss": 1.0683,
      "step": 12280
    },
    {
      "epoch": 0.5531302038795626,
      "grad_norm": 1.687801718711853,
      "learning_rate": 9.446869796120438e-05,
      "loss": 1.0924,
      "step": 12290
    },
    {
      "epoch": 0.5535802691390251,
      "grad_norm": 1.9115267992019653,
      "learning_rate": 9.446419730860975e-05,
      "loss": 1.1459,
      "step": 12300
    },
    {
      "epoch": 0.5540303343984878,
      "grad_norm": 2.1564645767211914,
      "learning_rate": 9.445969665601513e-05,
      "loss": 1.0332,
      "step": 12310
    },
    {
      "epoch": 0.5544803996579504,
      "grad_norm": 1.89044189453125,
      "learning_rate": 9.44551960034205e-05,
      "loss": 1.1037,
      "step": 12320
    },
    {
      "epoch": 0.554930464917413,
      "grad_norm": 2.494743824005127,
      "learning_rate": 9.445069535082587e-05,
      "loss": 1.1421,
      "step": 12330
    },
    {
      "epoch": 0.5553805301768756,
      "grad_norm": 2.2500643730163574,
      "learning_rate": 9.444619469823125e-05,
      "loss": 1.1218,
      "step": 12340
    },
    {
      "epoch": 0.5558305954363383,
      "grad_norm": 1.4887738227844238,
      "learning_rate": 9.444169404563662e-05,
      "loss": 1.1095,
      "step": 12350
    },
    {
      "epoch": 0.5562806606958008,
      "grad_norm": 1.4479564428329468,
      "learning_rate": 9.4437193393042e-05,
      "loss": 0.9777,
      "step": 12360
    },
    {
      "epoch": 0.5567307259552635,
      "grad_norm": 1.2157829999923706,
      "learning_rate": 9.443269274044737e-05,
      "loss": 1.0955,
      "step": 12370
    },
    {
      "epoch": 0.5571807912147262,
      "grad_norm": 1.376224398612976,
      "learning_rate": 9.442819208785274e-05,
      "loss": 1.0512,
      "step": 12380
    },
    {
      "epoch": 0.5576308564741888,
      "grad_norm": 1.896103024482727,
      "learning_rate": 9.442369143525812e-05,
      "loss": 1.1142,
      "step": 12390
    },
    {
      "epoch": 0.5580809217336514,
      "grad_norm": 1.6387102603912354,
      "learning_rate": 9.441919078266349e-05,
      "loss": 1.1174,
      "step": 12400
    },
    {
      "epoch": 0.558530986993114,
      "grad_norm": 1.3371124267578125,
      "learning_rate": 9.441469013006886e-05,
      "loss": 1.1133,
      "step": 12410
    },
    {
      "epoch": 0.5589810522525767,
      "grad_norm": 2.044771432876587,
      "learning_rate": 9.441018947747424e-05,
      "loss": 1.0552,
      "step": 12420
    },
    {
      "epoch": 0.5594311175120392,
      "grad_norm": 1.2771294116973877,
      "learning_rate": 9.440568882487961e-05,
      "loss": 1.0813,
      "step": 12430
    },
    {
      "epoch": 0.5598811827715019,
      "grad_norm": 2.0098061561584473,
      "learning_rate": 9.440118817228498e-05,
      "loss": 1.1042,
      "step": 12440
    },
    {
      "epoch": 0.5603312480309645,
      "grad_norm": 1.6534807682037354,
      "learning_rate": 9.439668751969036e-05,
      "loss": 1.0706,
      "step": 12450
    },
    {
      "epoch": 0.5607813132904271,
      "grad_norm": 1.7235403060913086,
      "learning_rate": 9.439218686709573e-05,
      "loss": 1.0687,
      "step": 12460
    },
    {
      "epoch": 0.5612313785498897,
      "grad_norm": 1.8601906299591064,
      "learning_rate": 9.43876862145011e-05,
      "loss": 1.0317,
      "step": 12470
    },
    {
      "epoch": 0.5616814438093524,
      "grad_norm": 2.6727912425994873,
      "learning_rate": 9.438318556190648e-05,
      "loss": 1.148,
      "step": 12480
    },
    {
      "epoch": 0.5621315090688149,
      "grad_norm": 1.9693524837493896,
      "learning_rate": 9.437868490931185e-05,
      "loss": 1.1217,
      "step": 12490
    },
    {
      "epoch": 0.5625815743282776,
      "grad_norm": 1.7668871879577637,
      "learning_rate": 9.437418425671723e-05,
      "loss": 1.0815,
      "step": 12500
    },
    {
      "epoch": 0.5630316395877403,
      "grad_norm": 1.954869031906128,
      "learning_rate": 9.43696836041226e-05,
      "loss": 1.0628,
      "step": 12510
    },
    {
      "epoch": 0.5634817048472028,
      "grad_norm": 1.417851209640503,
      "learning_rate": 9.436518295152797e-05,
      "loss": 1.1215,
      "step": 12520
    },
    {
      "epoch": 0.5639317701066655,
      "grad_norm": 1.6804383993148804,
      "learning_rate": 9.436068229893335e-05,
      "loss": 1.0977,
      "step": 12530
    },
    {
      "epoch": 0.5643818353661281,
      "grad_norm": 1.3055386543273926,
      "learning_rate": 9.435618164633872e-05,
      "loss": 1.0987,
      "step": 12540
    },
    {
      "epoch": 0.5648319006255907,
      "grad_norm": 1.440930962562561,
      "learning_rate": 9.43516809937441e-05,
      "loss": 1.0796,
      "step": 12550
    },
    {
      "epoch": 0.5652819658850533,
      "grad_norm": 1.591958999633789,
      "learning_rate": 9.434718034114947e-05,
      "loss": 1.0714,
      "step": 12560
    },
    {
      "epoch": 0.565732031144516,
      "grad_norm": 1.601372480392456,
      "learning_rate": 9.434267968855484e-05,
      "loss": 1.0491,
      "step": 12570
    },
    {
      "epoch": 0.5661820964039785,
      "grad_norm": 1.4037134647369385,
      "learning_rate": 9.433817903596021e-05,
      "loss": 1.0832,
      "step": 12580
    },
    {
      "epoch": 0.5666321616634412,
      "grad_norm": 1.875969648361206,
      "learning_rate": 9.43336783833656e-05,
      "loss": 1.0759,
      "step": 12590
    },
    {
      "epoch": 0.5670822269229038,
      "grad_norm": 1.5253932476043701,
      "learning_rate": 9.432917773077096e-05,
      "loss": 1.0574,
      "step": 12600
    },
    {
      "epoch": 0.5675322921823664,
      "grad_norm": 2.0725715160369873,
      "learning_rate": 9.432467707817634e-05,
      "loss": 1.0733,
      "step": 12610
    },
    {
      "epoch": 0.567982357441829,
      "grad_norm": 1.1274268627166748,
      "learning_rate": 9.432017642558172e-05,
      "loss": 1.0981,
      "step": 12620
    },
    {
      "epoch": 0.5684324227012917,
      "grad_norm": 1.6237623691558838,
      "learning_rate": 9.431567577298708e-05,
      "loss": 1.0515,
      "step": 12630
    },
    {
      "epoch": 0.5688824879607544,
      "grad_norm": 1.4879562854766846,
      "learning_rate": 9.431117512039246e-05,
      "loss": 1.0029,
      "step": 12640
    },
    {
      "epoch": 0.5693325532202169,
      "grad_norm": 1.624565601348877,
      "learning_rate": 9.430667446779784e-05,
      "loss": 1.1256,
      "step": 12650
    },
    {
      "epoch": 0.5697826184796796,
      "grad_norm": 2.258716583251953,
      "learning_rate": 9.43021738152032e-05,
      "loss": 1.0622,
      "step": 12660
    },
    {
      "epoch": 0.5702326837391422,
      "grad_norm": 1.4976913928985596,
      "learning_rate": 9.429767316260858e-05,
      "loss": 1.0711,
      "step": 12670
    },
    {
      "epoch": 0.5706827489986048,
      "grad_norm": 2.193099021911621,
      "learning_rate": 9.429317251001396e-05,
      "loss": 1.139,
      "step": 12680
    },
    {
      "epoch": 0.5711328142580674,
      "grad_norm": 1.3475732803344727,
      "learning_rate": 9.428867185741932e-05,
      "loss": 1.0812,
      "step": 12690
    },
    {
      "epoch": 0.5715828795175301,
      "grad_norm": 1.4963016510009766,
      "learning_rate": 9.42841712048247e-05,
      "loss": 1.0982,
      "step": 12700
    },
    {
      "epoch": 0.5720329447769926,
      "grad_norm": 1.1297634840011597,
      "learning_rate": 9.427967055223008e-05,
      "loss": 1.058,
      "step": 12710
    },
    {
      "epoch": 0.5724830100364553,
      "grad_norm": 2.4212839603424072,
      "learning_rate": 9.427516989963545e-05,
      "loss": 1.0878,
      "step": 12720
    },
    {
      "epoch": 0.5729330752959179,
      "grad_norm": 1.705918788909912,
      "learning_rate": 9.427066924704082e-05,
      "loss": 1.1546,
      "step": 12730
    },
    {
      "epoch": 0.5733831405553805,
      "grad_norm": 1.169237494468689,
      "learning_rate": 9.42661685944462e-05,
      "loss": 1.1007,
      "step": 12740
    },
    {
      "epoch": 0.5738332058148432,
      "grad_norm": 2.227264165878296,
      "learning_rate": 9.426166794185157e-05,
      "loss": 1.0787,
      "step": 12750
    },
    {
      "epoch": 0.5742832710743058,
      "grad_norm": 1.353337049484253,
      "learning_rate": 9.425716728925694e-05,
      "loss": 1.0634,
      "step": 12760
    },
    {
      "epoch": 0.5747333363337684,
      "grad_norm": 2.3514564037323,
      "learning_rate": 9.425266663666233e-05,
      "loss": 1.073,
      "step": 12770
    },
    {
      "epoch": 0.575183401593231,
      "grad_norm": 1.2507374286651611,
      "learning_rate": 9.424816598406769e-05,
      "loss": 1.1532,
      "step": 12780
    },
    {
      "epoch": 0.5756334668526937,
      "grad_norm": 1.300954818725586,
      "learning_rate": 9.424366533147306e-05,
      "loss": 1.1173,
      "step": 12790
    },
    {
      "epoch": 0.5760835321121562,
      "grad_norm": 1.3913713693618774,
      "learning_rate": 9.423916467887845e-05,
      "loss": 1.0654,
      "step": 12800
    },
    {
      "epoch": 0.5765335973716189,
      "grad_norm": 1.1974929571151733,
      "learning_rate": 9.423466402628382e-05,
      "loss": 1.051,
      "step": 12810
    },
    {
      "epoch": 0.5769836626310815,
      "grad_norm": 1.6691967248916626,
      "learning_rate": 9.423016337368918e-05,
      "loss": 1.0538,
      "step": 12820
    },
    {
      "epoch": 0.5774337278905441,
      "grad_norm": 1.8202953338623047,
      "learning_rate": 9.422566272109457e-05,
      "loss": 1.075,
      "step": 12830
    },
    {
      "epoch": 0.5778837931500067,
      "grad_norm": 1.8299983739852905,
      "learning_rate": 9.422116206849994e-05,
      "loss": 1.0441,
      "step": 12840
    },
    {
      "epoch": 0.5783338584094694,
      "grad_norm": 1.7970905303955078,
      "learning_rate": 9.421666141590532e-05,
      "loss": 1.0568,
      "step": 12850
    },
    {
      "epoch": 0.5787839236689319,
      "grad_norm": 1.4996038675308228,
      "learning_rate": 9.421216076331069e-05,
      "loss": 1.089,
      "step": 12860
    },
    {
      "epoch": 0.5792339889283946,
      "grad_norm": 2.2890217304229736,
      "learning_rate": 9.420766011071606e-05,
      "loss": 1.159,
      "step": 12870
    },
    {
      "epoch": 0.5796840541878573,
      "grad_norm": 3.0725791454315186,
      "learning_rate": 9.420315945812144e-05,
      "loss": 1.0604,
      "step": 12880
    },
    {
      "epoch": 0.5801341194473199,
      "grad_norm": 1.703366756439209,
      "learning_rate": 9.419865880552681e-05,
      "loss": 1.1197,
      "step": 12890
    },
    {
      "epoch": 0.5805841847067825,
      "grad_norm": 1.884075403213501,
      "learning_rate": 9.419415815293218e-05,
      "loss": 1.1052,
      "step": 12900
    },
    {
      "epoch": 0.5810342499662451,
      "grad_norm": 1.398218035697937,
      "learning_rate": 9.418965750033756e-05,
      "loss": 1.0708,
      "step": 12910
    },
    {
      "epoch": 0.5814843152257078,
      "grad_norm": 1.1478676795959473,
      "learning_rate": 9.418515684774293e-05,
      "loss": 1.0193,
      "step": 12920
    },
    {
      "epoch": 0.5819343804851703,
      "grad_norm": 1.033958911895752,
      "learning_rate": 9.41806561951483e-05,
      "loss": 1.121,
      "step": 12930
    },
    {
      "epoch": 0.582384445744633,
      "grad_norm": 1.4026005268096924,
      "learning_rate": 9.417615554255368e-05,
      "loss": 1.1246,
      "step": 12940
    },
    {
      "epoch": 0.5828345110040956,
      "grad_norm": 1.2656413316726685,
      "learning_rate": 9.417165488995905e-05,
      "loss": 1.1986,
      "step": 12950
    },
    {
      "epoch": 0.5832845762635582,
      "grad_norm": 1.6349025964736938,
      "learning_rate": 9.416715423736443e-05,
      "loss": 1.0677,
      "step": 12960
    },
    {
      "epoch": 0.5837346415230208,
      "grad_norm": 1.41584312915802,
      "learning_rate": 9.41626535847698e-05,
      "loss": 1.0278,
      "step": 12970
    },
    {
      "epoch": 0.5841847067824835,
      "grad_norm": 1.7322617769241333,
      "learning_rate": 9.415815293217517e-05,
      "loss": 1.0023,
      "step": 12980
    },
    {
      "epoch": 0.584634772041946,
      "grad_norm": 1.807938575744629,
      "learning_rate": 9.415365227958055e-05,
      "loss": 1.0289,
      "step": 12990
    },
    {
      "epoch": 0.5850848373014087,
      "grad_norm": 1.6339986324310303,
      "learning_rate": 9.414915162698592e-05,
      "loss": 1.0327,
      "step": 13000
    },
    {
      "epoch": 0.5855349025608714,
      "grad_norm": 1.1554473638534546,
      "learning_rate": 9.414465097439129e-05,
      "loss": 1.0313,
      "step": 13010
    },
    {
      "epoch": 0.5859849678203339,
      "grad_norm": 1.5189682245254517,
      "learning_rate": 9.414015032179667e-05,
      "loss": 1.092,
      "step": 13020
    },
    {
      "epoch": 0.5864350330797966,
      "grad_norm": 1.3724805116653442,
      "learning_rate": 9.413564966920204e-05,
      "loss": 1.1292,
      "step": 13030
    },
    {
      "epoch": 0.5868850983392592,
      "grad_norm": 1.529184103012085,
      "learning_rate": 9.413114901660741e-05,
      "loss": 1.0755,
      "step": 13040
    },
    {
      "epoch": 0.5873351635987218,
      "grad_norm": 1.7641817331314087,
      "learning_rate": 9.412664836401279e-05,
      "loss": 1.1188,
      "step": 13050
    },
    {
      "epoch": 0.5877852288581844,
      "grad_norm": 1.7781472206115723,
      "learning_rate": 9.412214771141816e-05,
      "loss": 1.05,
      "step": 13060
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 2.7955539226531982,
      "learning_rate": 9.411764705882353e-05,
      "loss": 1.0981,
      "step": 13070
    },
    {
      "epoch": 0.5886853593771096,
      "grad_norm": 1.0181047916412354,
      "learning_rate": 9.411314640622891e-05,
      "loss": 1.1298,
      "step": 13080
    },
    {
      "epoch": 0.5891354246365723,
      "grad_norm": 1.734948754310608,
      "learning_rate": 9.410864575363428e-05,
      "loss": 1.0363,
      "step": 13090
    },
    {
      "epoch": 0.5895854898960349,
      "grad_norm": 1.1643974781036377,
      "learning_rate": 9.410414510103966e-05,
      "loss": 1.1019,
      "step": 13100
    },
    {
      "epoch": 0.5900355551554975,
      "grad_norm": 1.6523243188858032,
      "learning_rate": 9.409964444844503e-05,
      "loss": 1.0095,
      "step": 13110
    },
    {
      "epoch": 0.5904856204149602,
      "grad_norm": 1.125442624092102,
      "learning_rate": 9.40951437958504e-05,
      "loss": 1.0559,
      "step": 13120
    },
    {
      "epoch": 0.5909356856744228,
      "grad_norm": 1.5435187816619873,
      "learning_rate": 9.409064314325578e-05,
      "loss": 1.0402,
      "step": 13130
    },
    {
      "epoch": 0.5913857509338855,
      "grad_norm": 1.2780430316925049,
      "learning_rate": 9.408614249066115e-05,
      "loss": 1.1768,
      "step": 13140
    },
    {
      "epoch": 0.591835816193348,
      "grad_norm": 1.5460288524627686,
      "learning_rate": 9.408164183806652e-05,
      "loss": 1.1005,
      "step": 13150
    },
    {
      "epoch": 0.5922858814528107,
      "grad_norm": 2.5131843090057373,
      "learning_rate": 9.40771411854719e-05,
      "loss": 1.0809,
      "step": 13160
    },
    {
      "epoch": 0.5927359467122733,
      "grad_norm": 1.5407005548477173,
      "learning_rate": 9.407264053287727e-05,
      "loss": 1.0484,
      "step": 13170
    },
    {
      "epoch": 0.5931860119717359,
      "grad_norm": 1.7503924369812012,
      "learning_rate": 9.406813988028264e-05,
      "loss": 1.0478,
      "step": 13180
    },
    {
      "epoch": 0.5936360772311985,
      "grad_norm": 1.3572916984558105,
      "learning_rate": 9.406363922768802e-05,
      "loss": 1.0133,
      "step": 13190
    },
    {
      "epoch": 0.5940861424906612,
      "grad_norm": 2.0304906368255615,
      "learning_rate": 9.405913857509339e-05,
      "loss": 1.1216,
      "step": 13200
    },
    {
      "epoch": 0.5945362077501237,
      "grad_norm": 1.3414177894592285,
      "learning_rate": 9.405463792249877e-05,
      "loss": 1.1077,
      "step": 13210
    },
    {
      "epoch": 0.5949862730095864,
      "grad_norm": 1.4114153385162354,
      "learning_rate": 9.405013726990414e-05,
      "loss": 1.0783,
      "step": 13220
    },
    {
      "epoch": 0.595436338269049,
      "grad_norm": 1.7279053926467896,
      "learning_rate": 9.404563661730951e-05,
      "loss": 1.1138,
      "step": 13230
    },
    {
      "epoch": 0.5958864035285116,
      "grad_norm": 2.2783901691436768,
      "learning_rate": 9.404113596471489e-05,
      "loss": 1.0423,
      "step": 13240
    },
    {
      "epoch": 0.5963364687879743,
      "grad_norm": 1.2547471523284912,
      "learning_rate": 9.403663531212026e-05,
      "loss": 1.0793,
      "step": 13250
    },
    {
      "epoch": 0.5967865340474369,
      "grad_norm": 2.1964709758758545,
      "learning_rate": 9.403213465952563e-05,
      "loss": 1.084,
      "step": 13260
    },
    {
      "epoch": 0.5972365993068995,
      "grad_norm": 1.9312162399291992,
      "learning_rate": 9.402763400693101e-05,
      "loss": 1.1287,
      "step": 13270
    },
    {
      "epoch": 0.5976866645663621,
      "grad_norm": 1.1131901741027832,
      "learning_rate": 9.402313335433638e-05,
      "loss": 0.9963,
      "step": 13280
    },
    {
      "epoch": 0.5981367298258248,
      "grad_norm": 1.6004561185836792,
      "learning_rate": 9.401863270174175e-05,
      "loss": 1.1182,
      "step": 13290
    },
    {
      "epoch": 0.5985867950852873,
      "grad_norm": 1.3391177654266357,
      "learning_rate": 9.401413204914713e-05,
      "loss": 1.0703,
      "step": 13300
    },
    {
      "epoch": 0.59903686034475,
      "grad_norm": 1.970168948173523,
      "learning_rate": 9.40096313965525e-05,
      "loss": 1.067,
      "step": 13310
    },
    {
      "epoch": 0.5994869256042126,
      "grad_norm": 1.8721939325332642,
      "learning_rate": 9.400513074395787e-05,
      "loss": 1.1078,
      "step": 13320
    },
    {
      "epoch": 0.5999369908636752,
      "grad_norm": 1.4342271089553833,
      "learning_rate": 9.400063009136325e-05,
      "loss": 1.0667,
      "step": 13330
    },
    {
      "epoch": 0.6003870561231378,
      "grad_norm": 1.643790364265442,
      "learning_rate": 9.399612943876862e-05,
      "loss": 1.1331,
      "step": 13340
    },
    {
      "epoch": 0.6008371213826005,
      "grad_norm": 2.2225000858306885,
      "learning_rate": 9.3991628786174e-05,
      "loss": 1.1296,
      "step": 13350
    },
    {
      "epoch": 0.6012871866420632,
      "grad_norm": 2.5378921031951904,
      "learning_rate": 9.398712813357937e-05,
      "loss": 1.0863,
      "step": 13360
    },
    {
      "epoch": 0.6017372519015257,
      "grad_norm": 1.6148656606674194,
      "learning_rate": 9.398262748098474e-05,
      "loss": 1.1039,
      "step": 13370
    },
    {
      "epoch": 0.6021873171609884,
      "grad_norm": 1.6379393339157104,
      "learning_rate": 9.397812682839012e-05,
      "loss": 1.0074,
      "step": 13380
    },
    {
      "epoch": 0.602637382420451,
      "grad_norm": 1.9891095161437988,
      "learning_rate": 9.397362617579549e-05,
      "loss": 1.0433,
      "step": 13390
    },
    {
      "epoch": 0.6030874476799136,
      "grad_norm": 2.0085861682891846,
      "learning_rate": 9.396912552320088e-05,
      "loss": 1.1186,
      "step": 13400
    },
    {
      "epoch": 0.6035375129393762,
      "grad_norm": 1.488810658454895,
      "learning_rate": 9.396462487060624e-05,
      "loss": 1.0561,
      "step": 13410
    },
    {
      "epoch": 0.6039875781988389,
      "grad_norm": 1.6739966869354248,
      "learning_rate": 9.396012421801161e-05,
      "loss": 1.0395,
      "step": 13420
    },
    {
      "epoch": 0.6044376434583014,
      "grad_norm": 1.9621044397354126,
      "learning_rate": 9.3955623565417e-05,
      "loss": 1.102,
      "step": 13430
    },
    {
      "epoch": 0.6048877087177641,
      "grad_norm": 2.0385429859161377,
      "learning_rate": 9.395112291282236e-05,
      "loss": 1.0854,
      "step": 13440
    },
    {
      "epoch": 0.6053377739772267,
      "grad_norm": 1.4077363014221191,
      "learning_rate": 9.394662226022773e-05,
      "loss": 1.0497,
      "step": 13450
    },
    {
      "epoch": 0.6057878392366893,
      "grad_norm": 2.8590667247772217,
      "learning_rate": 9.394212160763312e-05,
      "loss": 1.0593,
      "step": 13460
    },
    {
      "epoch": 0.6062379044961519,
      "grad_norm": 1.7875150442123413,
      "learning_rate": 9.393762095503848e-05,
      "loss": 1.0477,
      "step": 13470
    },
    {
      "epoch": 0.6066879697556146,
      "grad_norm": 1.3019936084747314,
      "learning_rate": 9.393312030244385e-05,
      "loss": 1.0203,
      "step": 13480
    },
    {
      "epoch": 0.6071380350150772,
      "grad_norm": 1.2666338682174683,
      "learning_rate": 9.392861964984924e-05,
      "loss": 1.083,
      "step": 13490
    },
    {
      "epoch": 0.6075881002745398,
      "grad_norm": 1.9979020357131958,
      "learning_rate": 9.392411899725461e-05,
      "loss": 1.1295,
      "step": 13500
    },
    {
      "epoch": 0.6080381655340025,
      "grad_norm": 1.411763310432434,
      "learning_rate": 9.391961834465997e-05,
      "loss": 1.0138,
      "step": 13510
    },
    {
      "epoch": 0.608488230793465,
      "grad_norm": 1.733431339263916,
      "learning_rate": 9.391511769206536e-05,
      "loss": 1.0725,
      "step": 13520
    },
    {
      "epoch": 0.6089382960529277,
      "grad_norm": 2.0924296379089355,
      "learning_rate": 9.391061703947073e-05,
      "loss": 1.0966,
      "step": 13530
    },
    {
      "epoch": 0.6093883613123903,
      "grad_norm": 1.8933374881744385,
      "learning_rate": 9.39061163868761e-05,
      "loss": 1.0184,
      "step": 13540
    },
    {
      "epoch": 0.6098384265718529,
      "grad_norm": 2.0570154190063477,
      "learning_rate": 9.390161573428148e-05,
      "loss": 1.1182,
      "step": 13550
    },
    {
      "epoch": 0.6102884918313155,
      "grad_norm": 1.588012933731079,
      "learning_rate": 9.389711508168685e-05,
      "loss": 1.0967,
      "step": 13560
    },
    {
      "epoch": 0.6107385570907782,
      "grad_norm": 1.3299649953842163,
      "learning_rate": 9.389261442909221e-05,
      "loss": 1.0616,
      "step": 13570
    },
    {
      "epoch": 0.6111886223502407,
      "grad_norm": 1.1820366382598877,
      "learning_rate": 9.38881137764976e-05,
      "loss": 1.0104,
      "step": 13580
    },
    {
      "epoch": 0.6116386876097034,
      "grad_norm": 1.3966723680496216,
      "learning_rate": 9.388361312390298e-05,
      "loss": 1.0319,
      "step": 13590
    },
    {
      "epoch": 0.612088752869166,
      "grad_norm": 1.805127739906311,
      "learning_rate": 9.387911247130834e-05,
      "loss": 1.1578,
      "step": 13600
    },
    {
      "epoch": 0.6125388181286286,
      "grad_norm": 1.1849175691604614,
      "learning_rate": 9.387461181871372e-05,
      "loss": 1.0483,
      "step": 13610
    },
    {
      "epoch": 0.6129888833880913,
      "grad_norm": 1.8518537282943726,
      "learning_rate": 9.38701111661191e-05,
      "loss": 1.0363,
      "step": 13620
    },
    {
      "epoch": 0.6134389486475539,
      "grad_norm": 1.6099177598953247,
      "learning_rate": 9.386561051352446e-05,
      "loss": 1.0389,
      "step": 13630
    },
    {
      "epoch": 0.6138890139070166,
      "grad_norm": 1.2677030563354492,
      "learning_rate": 9.386110986092984e-05,
      "loss": 1.0534,
      "step": 13640
    },
    {
      "epoch": 0.6143390791664791,
      "grad_norm": 1.4024254083633423,
      "learning_rate": 9.385660920833522e-05,
      "loss": 1.0607,
      "step": 13650
    },
    {
      "epoch": 0.6147891444259418,
      "grad_norm": 1.284702181816101,
      "learning_rate": 9.385210855574059e-05,
      "loss": 1.087,
      "step": 13660
    },
    {
      "epoch": 0.6152392096854044,
      "grad_norm": 1.5475808382034302,
      "learning_rate": 9.384760790314596e-05,
      "loss": 1.0587,
      "step": 13670
    },
    {
      "epoch": 0.615689274944867,
      "grad_norm": 1.0465102195739746,
      "learning_rate": 9.384310725055134e-05,
      "loss": 0.9988,
      "step": 13680
    },
    {
      "epoch": 0.6161393402043296,
      "grad_norm": 1.3713691234588623,
      "learning_rate": 9.383860659795671e-05,
      "loss": 1.1077,
      "step": 13690
    },
    {
      "epoch": 0.6165894054637923,
      "grad_norm": 1.3531807661056519,
      "learning_rate": 9.383410594536209e-05,
      "loss": 0.9851,
      "step": 13700
    },
    {
      "epoch": 0.6170394707232548,
      "grad_norm": 1.293176531791687,
      "learning_rate": 9.382960529276746e-05,
      "loss": 1.0856,
      "step": 13710
    },
    {
      "epoch": 0.6174895359827175,
      "grad_norm": 1.6030031442642212,
      "learning_rate": 9.382510464017283e-05,
      "loss": 1.0271,
      "step": 13720
    },
    {
      "epoch": 0.6179396012421802,
      "grad_norm": 1.3617864847183228,
      "learning_rate": 9.38206039875782e-05,
      "loss": 1.0288,
      "step": 13730
    },
    {
      "epoch": 0.6183896665016427,
      "grad_norm": 1.1673208475112915,
      "learning_rate": 9.381610333498358e-05,
      "loss": 1.0978,
      "step": 13740
    },
    {
      "epoch": 0.6188397317611054,
      "grad_norm": 1.192000150680542,
      "learning_rate": 9.381160268238895e-05,
      "loss": 1.0369,
      "step": 13750
    },
    {
      "epoch": 0.619289797020568,
      "grad_norm": 1.2719273567199707,
      "learning_rate": 9.380710202979433e-05,
      "loss": 1.1124,
      "step": 13760
    },
    {
      "epoch": 0.6197398622800306,
      "grad_norm": 1.8988388776779175,
      "learning_rate": 9.38026013771997e-05,
      "loss": 1.0757,
      "step": 13770
    },
    {
      "epoch": 0.6201899275394932,
      "grad_norm": 1.8932526111602783,
      "learning_rate": 9.379810072460507e-05,
      "loss": 1.0598,
      "step": 13780
    },
    {
      "epoch": 0.6206399927989559,
      "grad_norm": 1.881334662437439,
      "learning_rate": 9.379360007201045e-05,
      "loss": 1.0544,
      "step": 13790
    },
    {
      "epoch": 0.6210900580584184,
      "grad_norm": 1.3234591484069824,
      "learning_rate": 9.378909941941582e-05,
      "loss": 1.0999,
      "step": 13800
    },
    {
      "epoch": 0.6215401233178811,
      "grad_norm": 1.1788026094436646,
      "learning_rate": 9.37845987668212e-05,
      "loss": 1.0052,
      "step": 13810
    },
    {
      "epoch": 0.6219901885773437,
      "grad_norm": 1.5365514755249023,
      "learning_rate": 9.378009811422657e-05,
      "loss": 1.0332,
      "step": 13820
    },
    {
      "epoch": 0.6224402538368063,
      "grad_norm": 1.3313018083572388,
      "learning_rate": 9.377559746163194e-05,
      "loss": 0.9997,
      "step": 13830
    },
    {
      "epoch": 0.6228903190962689,
      "grad_norm": 1.3792595863342285,
      "learning_rate": 9.377109680903732e-05,
      "loss": 1.0201,
      "step": 13840
    },
    {
      "epoch": 0.6233403843557316,
      "grad_norm": 1.8483805656433105,
      "learning_rate": 9.376659615644269e-05,
      "loss": 1.1167,
      "step": 13850
    },
    {
      "epoch": 0.6237904496151943,
      "grad_norm": 2.080033540725708,
      "learning_rate": 9.376209550384806e-05,
      "loss": 1.095,
      "step": 13860
    },
    {
      "epoch": 0.6242405148746568,
      "grad_norm": 1.7753220796585083,
      "learning_rate": 9.375759485125344e-05,
      "loss": 1.0167,
      "step": 13870
    },
    {
      "epoch": 0.6246905801341195,
      "grad_norm": 1.5548014640808105,
      "learning_rate": 9.375309419865881e-05,
      "loss": 1.0427,
      "step": 13880
    },
    {
      "epoch": 0.625140645393582,
      "grad_norm": 1.6722283363342285,
      "learning_rate": 9.374859354606418e-05,
      "loss": 1.0658,
      "step": 13890
    },
    {
      "epoch": 0.6255907106530447,
      "grad_norm": 1.3403215408325195,
      "learning_rate": 9.374409289346956e-05,
      "loss": 1.1146,
      "step": 13900
    },
    {
      "epoch": 0.6260407759125073,
      "grad_norm": 2.1689507961273193,
      "learning_rate": 9.373959224087493e-05,
      "loss": 1.0526,
      "step": 13910
    },
    {
      "epoch": 0.62649084117197,
      "grad_norm": 1.45577073097229,
      "learning_rate": 9.37350915882803e-05,
      "loss": 1.0165,
      "step": 13920
    },
    {
      "epoch": 0.6269409064314325,
      "grad_norm": 2.625793218612671,
      "learning_rate": 9.373059093568568e-05,
      "loss": 1.096,
      "step": 13930
    },
    {
      "epoch": 0.6273909716908952,
      "grad_norm": 1.3741683959960938,
      "learning_rate": 9.372609028309105e-05,
      "loss": 0.9749,
      "step": 13940
    },
    {
      "epoch": 0.6278410369503578,
      "grad_norm": 1.5695853233337402,
      "learning_rate": 9.372158963049643e-05,
      "loss": 1.1846,
      "step": 13950
    },
    {
      "epoch": 0.6282911022098204,
      "grad_norm": 2.2395167350769043,
      "learning_rate": 9.37170889779018e-05,
      "loss": 1.024,
      "step": 13960
    },
    {
      "epoch": 0.628741167469283,
      "grad_norm": 1.4759268760681152,
      "learning_rate": 9.371258832530717e-05,
      "loss": 1.0003,
      "step": 13970
    },
    {
      "epoch": 0.6291912327287457,
      "grad_norm": 1.4270296096801758,
      "learning_rate": 9.370808767271255e-05,
      "loss": 0.9709,
      "step": 13980
    },
    {
      "epoch": 0.6296412979882083,
      "grad_norm": 1.502938151359558,
      "learning_rate": 9.370358702011792e-05,
      "loss": 1.0657,
      "step": 13990
    },
    {
      "epoch": 0.6300913632476709,
      "grad_norm": 1.4382094144821167,
      "learning_rate": 9.36990863675233e-05,
      "loss": 1.1182,
      "step": 14000
    },
    {
      "epoch": 0.6305414285071336,
      "grad_norm": 1.5812127590179443,
      "learning_rate": 9.369458571492867e-05,
      "loss": 1.0036,
      "step": 14010
    },
    {
      "epoch": 0.6309914937665961,
      "grad_norm": 1.159730315208435,
      "learning_rate": 9.369008506233404e-05,
      "loss": 1.1024,
      "step": 14020
    },
    {
      "epoch": 0.6314415590260588,
      "grad_norm": 2.4298861026763916,
      "learning_rate": 9.368558440973941e-05,
      "loss": 1.0537,
      "step": 14030
    },
    {
      "epoch": 0.6318916242855214,
      "grad_norm": 1.5707108974456787,
      "learning_rate": 9.368108375714479e-05,
      "loss": 1.1187,
      "step": 14040
    },
    {
      "epoch": 0.632341689544984,
      "grad_norm": 1.0544365644454956,
      "learning_rate": 9.367658310455016e-05,
      "loss": 1.1267,
      "step": 14050
    },
    {
      "epoch": 0.6327917548044466,
      "grad_norm": 1.7407771348953247,
      "learning_rate": 9.367208245195554e-05,
      "loss": 1.0994,
      "step": 14060
    },
    {
      "epoch": 0.6332418200639093,
      "grad_norm": 2.5812721252441406,
      "learning_rate": 9.366758179936091e-05,
      "loss": 1.0959,
      "step": 14070
    },
    {
      "epoch": 0.6336918853233718,
      "grad_norm": 1.5686581134796143,
      "learning_rate": 9.366308114676628e-05,
      "loss": 0.9955,
      "step": 14080
    },
    {
      "epoch": 0.6341419505828345,
      "grad_norm": 2.3870437145233154,
      "learning_rate": 9.365858049417166e-05,
      "loss": 1.0096,
      "step": 14090
    },
    {
      "epoch": 0.6345920158422972,
      "grad_norm": 1.8997281789779663,
      "learning_rate": 9.365407984157703e-05,
      "loss": 1.0728,
      "step": 14100
    },
    {
      "epoch": 0.6350420811017597,
      "grad_norm": 1.2941317558288574,
      "learning_rate": 9.36495791889824e-05,
      "loss": 0.9709,
      "step": 14110
    },
    {
      "epoch": 0.6354921463612224,
      "grad_norm": 1.4921355247497559,
      "learning_rate": 9.364507853638778e-05,
      "loss": 1.1155,
      "step": 14120
    },
    {
      "epoch": 0.635942211620685,
      "grad_norm": 1.386348009109497,
      "learning_rate": 9.364057788379315e-05,
      "loss": 1.0668,
      "step": 14130
    },
    {
      "epoch": 0.6363922768801477,
      "grad_norm": 2.2418453693389893,
      "learning_rate": 9.363607723119852e-05,
      "loss": 1.0152,
      "step": 14140
    },
    {
      "epoch": 0.6368423421396102,
      "grad_norm": 1.9160343408584595,
      "learning_rate": 9.36315765786039e-05,
      "loss": 1.1273,
      "step": 14150
    },
    {
      "epoch": 0.6372924073990729,
      "grad_norm": 1.4032347202301025,
      "learning_rate": 9.362707592600927e-05,
      "loss": 1.1256,
      "step": 14160
    },
    {
      "epoch": 0.6377424726585355,
      "grad_norm": 1.493909239768982,
      "learning_rate": 9.362257527341464e-05,
      "loss": 1.1001,
      "step": 14170
    },
    {
      "epoch": 0.6381925379179981,
      "grad_norm": 1.7378933429718018,
      "learning_rate": 9.361807462082003e-05,
      "loss": 1.0971,
      "step": 14180
    },
    {
      "epoch": 0.6386426031774607,
      "grad_norm": 1.2581977844238281,
      "learning_rate": 9.36135739682254e-05,
      "loss": 1.0277,
      "step": 14190
    },
    {
      "epoch": 0.6390926684369234,
      "grad_norm": 1.313977599143982,
      "learning_rate": 9.360907331563077e-05,
      "loss": 1.1304,
      "step": 14200
    },
    {
      "epoch": 0.6395427336963859,
      "grad_norm": 1.3112835884094238,
      "learning_rate": 9.360457266303615e-05,
      "loss": 1.0955,
      "step": 14210
    },
    {
      "epoch": 0.6399927989558486,
      "grad_norm": 2.1811907291412354,
      "learning_rate": 9.360007201044153e-05,
      "loss": 1.1235,
      "step": 14220
    },
    {
      "epoch": 0.6404428642153113,
      "grad_norm": 1.7333365678787231,
      "learning_rate": 9.359557135784689e-05,
      "loss": 0.9648,
      "step": 14230
    },
    {
      "epoch": 0.6408929294747738,
      "grad_norm": 1.78192138671875,
      "learning_rate": 9.359107070525227e-05,
      "loss": 1.0401,
      "step": 14240
    },
    {
      "epoch": 0.6413429947342365,
      "grad_norm": 1.6917930841445923,
      "learning_rate": 9.358657005265765e-05,
      "loss": 1.0565,
      "step": 14250
    },
    {
      "epoch": 0.6417930599936991,
      "grad_norm": 1.1139034032821655,
      "learning_rate": 9.358206940006301e-05,
      "loss": 1.1254,
      "step": 14260
    },
    {
      "epoch": 0.6422431252531617,
      "grad_norm": 1.7361793518066406,
      "learning_rate": 9.35775687474684e-05,
      "loss": 1.0871,
      "step": 14270
    },
    {
      "epoch": 0.6426931905126243,
      "grad_norm": 1.444759726524353,
      "learning_rate": 9.357306809487377e-05,
      "loss": 1.0828,
      "step": 14280
    },
    {
      "epoch": 0.643143255772087,
      "grad_norm": 1.700484275817871,
      "learning_rate": 9.356856744227913e-05,
      "loss": 1.0553,
      "step": 14290
    },
    {
      "epoch": 0.6435933210315495,
      "grad_norm": 1.7265446186065674,
      "learning_rate": 9.356406678968452e-05,
      "loss": 1.0986,
      "step": 14300
    },
    {
      "epoch": 0.6440433862910122,
      "grad_norm": 1.4418503046035767,
      "learning_rate": 9.355956613708989e-05,
      "loss": 1.0481,
      "step": 14310
    },
    {
      "epoch": 0.6444934515504748,
      "grad_norm": 3.384269952774048,
      "learning_rate": 9.355506548449525e-05,
      "loss": 1.0354,
      "step": 14320
    },
    {
      "epoch": 0.6449435168099374,
      "grad_norm": 2.318563938140869,
      "learning_rate": 9.355056483190064e-05,
      "loss": 1.1077,
      "step": 14330
    },
    {
      "epoch": 0.6453935820694001,
      "grad_norm": 1.5615133047103882,
      "learning_rate": 9.354606417930601e-05,
      "loss": 1.0806,
      "step": 14340
    },
    {
      "epoch": 0.6458436473288627,
      "grad_norm": 1.8715033531188965,
      "learning_rate": 9.354156352671137e-05,
      "loss": 1.1738,
      "step": 14350
    },
    {
      "epoch": 0.6462937125883254,
      "grad_norm": 2.063499689102173,
      "learning_rate": 9.353706287411676e-05,
      "loss": 1.1689,
      "step": 14360
    },
    {
      "epoch": 0.6467437778477879,
      "grad_norm": 1.6759976148605347,
      "learning_rate": 9.353256222152213e-05,
      "loss": 1.0157,
      "step": 14370
    },
    {
      "epoch": 0.6471938431072506,
      "grad_norm": 1.2725552320480347,
      "learning_rate": 9.352806156892749e-05,
      "loss": 1.0505,
      "step": 14380
    },
    {
      "epoch": 0.6476439083667132,
      "grad_norm": 1.2568808794021606,
      "learning_rate": 9.352356091633288e-05,
      "loss": 1.0286,
      "step": 14390
    },
    {
      "epoch": 0.6480939736261758,
      "grad_norm": 1.436166763305664,
      "learning_rate": 9.351906026373825e-05,
      "loss": 1.1324,
      "step": 14400
    },
    {
      "epoch": 0.6485440388856384,
      "grad_norm": 1.2818273305892944,
      "learning_rate": 9.351455961114361e-05,
      "loss": 1.0098,
      "step": 14410
    },
    {
      "epoch": 0.6489941041451011,
      "grad_norm": 1.8680062294006348,
      "learning_rate": 9.3510058958549e-05,
      "loss": 1.0898,
      "step": 14420
    },
    {
      "epoch": 0.6494441694045636,
      "grad_norm": 1.6449717283248901,
      "learning_rate": 9.350555830595437e-05,
      "loss": 1.0941,
      "step": 14430
    },
    {
      "epoch": 0.6498942346640263,
      "grad_norm": 2.2646644115448,
      "learning_rate": 9.350105765335975e-05,
      "loss": 1.1142,
      "step": 14440
    },
    {
      "epoch": 0.6503442999234889,
      "grad_norm": 2.088463544845581,
      "learning_rate": 9.349655700076512e-05,
      "loss": 1.079,
      "step": 14450
    },
    {
      "epoch": 0.6507943651829515,
      "grad_norm": 2.3131320476531982,
      "learning_rate": 9.349205634817049e-05,
      "loss": 1.1753,
      "step": 14460
    },
    {
      "epoch": 0.6512444304424142,
      "grad_norm": 1.2175337076187134,
      "learning_rate": 9.348755569557587e-05,
      "loss": 1.0584,
      "step": 14470
    },
    {
      "epoch": 0.6516944957018768,
      "grad_norm": 1.3657796382904053,
      "learning_rate": 9.348305504298124e-05,
      "loss": 1.0279,
      "step": 14480
    },
    {
      "epoch": 0.6521445609613394,
      "grad_norm": 1.6908814907073975,
      "learning_rate": 9.347855439038661e-05,
      "loss": 1.1185,
      "step": 14490
    },
    {
      "epoch": 0.652594626220802,
      "grad_norm": 1.2459847927093506,
      "learning_rate": 9.347405373779199e-05,
      "loss": 1.0237,
      "step": 14500
    },
    {
      "epoch": 0.6530446914802647,
      "grad_norm": 1.712887167930603,
      "learning_rate": 9.346955308519736e-05,
      "loss": 1.0877,
      "step": 14510
    },
    {
      "epoch": 0.6534947567397272,
      "grad_norm": 1.433707594871521,
      "learning_rate": 9.346505243260273e-05,
      "loss": 1.0294,
      "step": 14520
    },
    {
      "epoch": 0.6539448219991899,
      "grad_norm": 1.5235506296157837,
      "learning_rate": 9.346055178000811e-05,
      "loss": 1.0738,
      "step": 14530
    },
    {
      "epoch": 0.6543948872586525,
      "grad_norm": 1.2756813764572144,
      "learning_rate": 9.345605112741348e-05,
      "loss": 1.0873,
      "step": 14540
    },
    {
      "epoch": 0.6548449525181151,
      "grad_norm": 1.5782054662704468,
      "learning_rate": 9.345155047481886e-05,
      "loss": 1.1058,
      "step": 14550
    },
    {
      "epoch": 0.6552950177775777,
      "grad_norm": 1.8599456548690796,
      "learning_rate": 9.344704982222423e-05,
      "loss": 1.1772,
      "step": 14560
    },
    {
      "epoch": 0.6557450830370404,
      "grad_norm": 1.3667994737625122,
      "learning_rate": 9.34425491696296e-05,
      "loss": 1.015,
      "step": 14570
    },
    {
      "epoch": 0.6561951482965029,
      "grad_norm": 2.229785680770874,
      "learning_rate": 9.343804851703498e-05,
      "loss": 1.148,
      "step": 14580
    },
    {
      "epoch": 0.6566452135559656,
      "grad_norm": 1.4484530687332153,
      "learning_rate": 9.343354786444035e-05,
      "loss": 1.0857,
      "step": 14590
    },
    {
      "epoch": 0.6570952788154283,
      "grad_norm": 1.0808701515197754,
      "learning_rate": 9.342904721184572e-05,
      "loss": 1.0599,
      "step": 14600
    },
    {
      "epoch": 0.6575453440748908,
      "grad_norm": 2.499807834625244,
      "learning_rate": 9.34245465592511e-05,
      "loss": 1.0625,
      "step": 14610
    },
    {
      "epoch": 0.6579954093343535,
      "grad_norm": 2.3002631664276123,
      "learning_rate": 9.342004590665647e-05,
      "loss": 1.0671,
      "step": 14620
    },
    {
      "epoch": 0.6584454745938161,
      "grad_norm": 1.3709313869476318,
      "learning_rate": 9.341554525406184e-05,
      "loss": 1.0525,
      "step": 14630
    },
    {
      "epoch": 0.6588955398532788,
      "grad_norm": 1.8471949100494385,
      "learning_rate": 9.341104460146722e-05,
      "loss": 1.0623,
      "step": 14640
    },
    {
      "epoch": 0.6593456051127413,
      "grad_norm": 1.3637237548828125,
      "learning_rate": 9.340654394887259e-05,
      "loss": 1.0982,
      "step": 14650
    },
    {
      "epoch": 0.659795670372204,
      "grad_norm": 1.0478254556655884,
      "learning_rate": 9.340204329627796e-05,
      "loss": 1.0771,
      "step": 14660
    },
    {
      "epoch": 0.6602457356316666,
      "grad_norm": 1.5896384716033936,
      "learning_rate": 9.339754264368334e-05,
      "loss": 1.0766,
      "step": 14670
    },
    {
      "epoch": 0.6606958008911292,
      "grad_norm": 1.7971203327178955,
      "learning_rate": 9.339304199108871e-05,
      "loss": 1.0473,
      "step": 14680
    },
    {
      "epoch": 0.6611458661505918,
      "grad_norm": 1.7733073234558105,
      "learning_rate": 9.338854133849409e-05,
      "loss": 1.0816,
      "step": 14690
    },
    {
      "epoch": 0.6615959314100545,
      "grad_norm": 1.210119605064392,
      "learning_rate": 9.338404068589946e-05,
      "loss": 1.0921,
      "step": 14700
    },
    {
      "epoch": 0.6620459966695171,
      "grad_norm": 1.3390588760375977,
      "learning_rate": 9.337954003330483e-05,
      "loss": 1.0869,
      "step": 14710
    },
    {
      "epoch": 0.6624960619289797,
      "grad_norm": 1.8568848371505737,
      "learning_rate": 9.33750393807102e-05,
      "loss": 1.1648,
      "step": 14720
    },
    {
      "epoch": 0.6629461271884424,
      "grad_norm": 1.4342119693756104,
      "learning_rate": 9.337053872811558e-05,
      "loss": 1.1215,
      "step": 14730
    },
    {
      "epoch": 0.6633961924479049,
      "grad_norm": 1.9840102195739746,
      "learning_rate": 9.336603807552095e-05,
      "loss": 1.0324,
      "step": 14740
    },
    {
      "epoch": 0.6638462577073676,
      "grad_norm": 1.8287087678909302,
      "learning_rate": 9.336153742292633e-05,
      "loss": 1.0694,
      "step": 14750
    },
    {
      "epoch": 0.6642963229668302,
      "grad_norm": 2.0469095706939697,
      "learning_rate": 9.33570367703317e-05,
      "loss": 1.0301,
      "step": 14760
    },
    {
      "epoch": 0.6647463882262928,
      "grad_norm": 1.5688481330871582,
      "learning_rate": 9.335253611773707e-05,
      "loss": 1.1146,
      "step": 14770
    },
    {
      "epoch": 0.6651964534857554,
      "grad_norm": 1.255409598350525,
      "learning_rate": 9.334803546514245e-05,
      "loss": 1.052,
      "step": 14780
    },
    {
      "epoch": 0.6656465187452181,
      "grad_norm": 1.644860863685608,
      "learning_rate": 9.334353481254782e-05,
      "loss": 1.1242,
      "step": 14790
    },
    {
      "epoch": 0.6660965840046806,
      "grad_norm": 2.1927919387817383,
      "learning_rate": 9.33390341599532e-05,
      "loss": 1.1207,
      "step": 14800
    },
    {
      "epoch": 0.6665466492641433,
      "grad_norm": 2.2547523975372314,
      "learning_rate": 9.333453350735857e-05,
      "loss": 1.0166,
      "step": 14810
    },
    {
      "epoch": 0.6669967145236059,
      "grad_norm": 1.9716848134994507,
      "learning_rate": 9.333003285476394e-05,
      "loss": 1.0263,
      "step": 14820
    },
    {
      "epoch": 0.6674467797830685,
      "grad_norm": 1.6546133756637573,
      "learning_rate": 9.332553220216932e-05,
      "loss": 1.0435,
      "step": 14830
    },
    {
      "epoch": 0.6678968450425312,
      "grad_norm": 1.7893788814544678,
      "learning_rate": 9.332103154957469e-05,
      "loss": 1.0723,
      "step": 14840
    },
    {
      "epoch": 0.6683469103019938,
      "grad_norm": 1.6213269233703613,
      "learning_rate": 9.331653089698008e-05,
      "loss": 1.0804,
      "step": 14850
    },
    {
      "epoch": 0.6687969755614565,
      "grad_norm": 1.752683401107788,
      "learning_rate": 9.331203024438544e-05,
      "loss": 1.0772,
      "step": 14860
    },
    {
      "epoch": 0.669247040820919,
      "grad_norm": 2.295785903930664,
      "learning_rate": 9.330752959179081e-05,
      "loss": 1.0461,
      "step": 14870
    },
    {
      "epoch": 0.6696971060803817,
      "grad_norm": 2.876801013946533,
      "learning_rate": 9.33030289391962e-05,
      "loss": 1.0548,
      "step": 14880
    },
    {
      "epoch": 0.6701471713398442,
      "grad_norm": 1.616206169128418,
      "learning_rate": 9.329852828660156e-05,
      "loss": 1.0887,
      "step": 14890
    },
    {
      "epoch": 0.6705972365993069,
      "grad_norm": 2.7018489837646484,
      "learning_rate": 9.329402763400693e-05,
      "loss": 1.0949,
      "step": 14900
    },
    {
      "epoch": 0.6710473018587695,
      "grad_norm": 1.3030058145523071,
      "learning_rate": 9.328952698141232e-05,
      "loss": 1.0763,
      "step": 14910
    },
    {
      "epoch": 0.6714973671182322,
      "grad_norm": 1.6352027654647827,
      "learning_rate": 9.328502632881768e-05,
      "loss": 1.0743,
      "step": 14920
    },
    {
      "epoch": 0.6719474323776947,
      "grad_norm": 1.641119360923767,
      "learning_rate": 9.328052567622305e-05,
      "loss": 1.0663,
      "step": 14930
    },
    {
      "epoch": 0.6723974976371574,
      "grad_norm": 1.3524678945541382,
      "learning_rate": 9.327602502362844e-05,
      "loss": 1.081,
      "step": 14940
    },
    {
      "epoch": 0.67284756289662,
      "grad_norm": 1.4558805227279663,
      "learning_rate": 9.32715243710338e-05,
      "loss": 1.0097,
      "step": 14950
    },
    {
      "epoch": 0.6732976281560826,
      "grad_norm": 1.2571266889572144,
      "learning_rate": 9.326702371843917e-05,
      "loss": 1.1078,
      "step": 14960
    },
    {
      "epoch": 0.6737476934155453,
      "grad_norm": 1.3784263134002686,
      "learning_rate": 9.326252306584456e-05,
      "loss": 1.0617,
      "step": 14970
    },
    {
      "epoch": 0.6741977586750079,
      "grad_norm": 2.686896800994873,
      "learning_rate": 9.325802241324992e-05,
      "loss": 1.092,
      "step": 14980
    },
    {
      "epoch": 0.6746478239344705,
      "grad_norm": 1.6780188083648682,
      "learning_rate": 9.325352176065531e-05,
      "loss": 1.0869,
      "step": 14990
    },
    {
      "epoch": 0.6750978891939331,
      "grad_norm": 1.7228566408157349,
      "learning_rate": 9.324902110806068e-05,
      "loss": 1.0274,
      "step": 15000
    },
    {
      "epoch": 0.6755479544533958,
      "grad_norm": 2.0302748680114746,
      "learning_rate": 9.324452045546604e-05,
      "loss": 1.1558,
      "step": 15010
    },
    {
      "epoch": 0.6759980197128583,
      "grad_norm": 2.0903213024139404,
      "learning_rate": 9.324001980287143e-05,
      "loss": 1.1071,
      "step": 15020
    },
    {
      "epoch": 0.676448084972321,
      "grad_norm": 1.8535678386688232,
      "learning_rate": 9.32355191502768e-05,
      "loss": 1.0859,
      "step": 15030
    },
    {
      "epoch": 0.6768981502317836,
      "grad_norm": 1.620538592338562,
      "learning_rate": 9.323101849768216e-05,
      "loss": 1.0174,
      "step": 15040
    },
    {
      "epoch": 0.6773482154912462,
      "grad_norm": 2.1926772594451904,
      "learning_rate": 9.322651784508755e-05,
      "loss": 1.1434,
      "step": 15050
    },
    {
      "epoch": 0.6777982807507088,
      "grad_norm": 1.4036675691604614,
      "learning_rate": 9.322201719249292e-05,
      "loss": 1.1435,
      "step": 15060
    },
    {
      "epoch": 0.6782483460101715,
      "grad_norm": 1.1854546070098877,
      "learning_rate": 9.321751653989828e-05,
      "loss": 1.1509,
      "step": 15070
    },
    {
      "epoch": 0.6786984112696341,
      "grad_norm": 1.267507791519165,
      "learning_rate": 9.321301588730367e-05,
      "loss": 0.9852,
      "step": 15080
    },
    {
      "epoch": 0.6791484765290967,
      "grad_norm": 2.0098378658294678,
      "learning_rate": 9.320851523470904e-05,
      "loss": 1.1379,
      "step": 15090
    },
    {
      "epoch": 0.6795985417885594,
      "grad_norm": 1.4431413412094116,
      "learning_rate": 9.32040145821144e-05,
      "loss": 1.0298,
      "step": 15100
    },
    {
      "epoch": 0.680048607048022,
      "grad_norm": 1.4390366077423096,
      "learning_rate": 9.319951392951979e-05,
      "loss": 1.0457,
      "step": 15110
    },
    {
      "epoch": 0.6804986723074846,
      "grad_norm": 1.5711034536361694,
      "learning_rate": 9.319501327692516e-05,
      "loss": 1.088,
      "step": 15120
    },
    {
      "epoch": 0.6809487375669472,
      "grad_norm": 2.0835037231445312,
      "learning_rate": 9.319051262433052e-05,
      "loss": 1.1322,
      "step": 15130
    },
    {
      "epoch": 0.6813988028264099,
      "grad_norm": 1.6051543951034546,
      "learning_rate": 9.318601197173591e-05,
      "loss": 1.0552,
      "step": 15140
    },
    {
      "epoch": 0.6818488680858724,
      "grad_norm": 1.4964762926101685,
      "learning_rate": 9.318151131914128e-05,
      "loss": 1.0451,
      "step": 15150
    },
    {
      "epoch": 0.6822989333453351,
      "grad_norm": 1.6204345226287842,
      "learning_rate": 9.317701066654664e-05,
      "loss": 1.0818,
      "step": 15160
    },
    {
      "epoch": 0.6827489986047977,
      "grad_norm": 1.4593924283981323,
      "learning_rate": 9.317251001395203e-05,
      "loss": 1.0957,
      "step": 15170
    },
    {
      "epoch": 0.6831990638642603,
      "grad_norm": 1.290746808052063,
      "learning_rate": 9.31680093613574e-05,
      "loss": 1.0941,
      "step": 15180
    },
    {
      "epoch": 0.6836491291237229,
      "grad_norm": 1.8699945211410522,
      "learning_rate": 9.316350870876277e-05,
      "loss": 1.0467,
      "step": 15190
    },
    {
      "epoch": 0.6840991943831856,
      "grad_norm": 1.8575847148895264,
      "learning_rate": 9.315900805616815e-05,
      "loss": 1.1128,
      "step": 15200
    },
    {
      "epoch": 0.6845492596426482,
      "grad_norm": 1.4104266166687012,
      "learning_rate": 9.315450740357353e-05,
      "loss": 1.0844,
      "step": 15210
    },
    {
      "epoch": 0.6849993249021108,
      "grad_norm": 1.8297033309936523,
      "learning_rate": 9.315000675097889e-05,
      "loss": 0.9218,
      "step": 15220
    },
    {
      "epoch": 0.6854493901615735,
      "grad_norm": 1.5623852014541626,
      "learning_rate": 9.314550609838427e-05,
      "loss": 1.1355,
      "step": 15230
    },
    {
      "epoch": 0.685899455421036,
      "grad_norm": 2.36899471282959,
      "learning_rate": 9.314100544578965e-05,
      "loss": 1.1236,
      "step": 15240
    },
    {
      "epoch": 0.6863495206804987,
      "grad_norm": 1.0659818649291992,
      "learning_rate": 9.313650479319502e-05,
      "loss": 1.082,
      "step": 15250
    },
    {
      "epoch": 0.6867995859399613,
      "grad_norm": 1.656278371810913,
      "learning_rate": 9.31320041406004e-05,
      "loss": 1.0993,
      "step": 15260
    },
    {
      "epoch": 0.6872496511994239,
      "grad_norm": 1.9199130535125732,
      "learning_rate": 9.312750348800577e-05,
      "loss": 1.0872,
      "step": 15270
    },
    {
      "epoch": 0.6876997164588865,
      "grad_norm": 1.0918972492218018,
      "learning_rate": 9.312300283541114e-05,
      "loss": 1.1154,
      "step": 15280
    },
    {
      "epoch": 0.6881497817183492,
      "grad_norm": 2.2392709255218506,
      "learning_rate": 9.311850218281652e-05,
      "loss": 1.0511,
      "step": 15290
    },
    {
      "epoch": 0.6885998469778117,
      "grad_norm": 1.3874963521957397,
      "learning_rate": 9.311400153022189e-05,
      "loss": 1.0685,
      "step": 15300
    },
    {
      "epoch": 0.6890499122372744,
      "grad_norm": 1.1231486797332764,
      "learning_rate": 9.310950087762726e-05,
      "loss": 1.0777,
      "step": 15310
    },
    {
      "epoch": 0.6894999774967371,
      "grad_norm": 1.245104432106018,
      "learning_rate": 9.310500022503264e-05,
      "loss": 1.0481,
      "step": 15320
    },
    {
      "epoch": 0.6899500427561996,
      "grad_norm": 1.6473338603973389,
      "learning_rate": 9.310049957243801e-05,
      "loss": 1.1013,
      "step": 15330
    },
    {
      "epoch": 0.6904001080156623,
      "grad_norm": 0.9294860363006592,
      "learning_rate": 9.309599891984338e-05,
      "loss": 1.0587,
      "step": 15340
    },
    {
      "epoch": 0.6908501732751249,
      "grad_norm": 1.4613752365112305,
      "learning_rate": 9.309149826724876e-05,
      "loss": 1.0169,
      "step": 15350
    },
    {
      "epoch": 0.6913002385345876,
      "grad_norm": 2.26706862449646,
      "learning_rate": 9.308699761465413e-05,
      "loss": 1.1612,
      "step": 15360
    },
    {
      "epoch": 0.6917503037940501,
      "grad_norm": 1.4214547872543335,
      "learning_rate": 9.30824969620595e-05,
      "loss": 1.0402,
      "step": 15370
    },
    {
      "epoch": 0.6922003690535128,
      "grad_norm": 1.3901344537734985,
      "learning_rate": 9.307799630946488e-05,
      "loss": 1.0452,
      "step": 15380
    },
    {
      "epoch": 0.6926504343129753,
      "grad_norm": 1.3024636507034302,
      "learning_rate": 9.307349565687025e-05,
      "loss": 1.058,
      "step": 15390
    },
    {
      "epoch": 0.693100499572438,
      "grad_norm": 1.905243158340454,
      "learning_rate": 9.306899500427562e-05,
      "loss": 1.013,
      "step": 15400
    },
    {
      "epoch": 0.6935505648319006,
      "grad_norm": 1.14602792263031,
      "learning_rate": 9.3064494351681e-05,
      "loss": 1.0092,
      "step": 15410
    },
    {
      "epoch": 0.6940006300913633,
      "grad_norm": 1.6321730613708496,
      "learning_rate": 9.305999369908637e-05,
      "loss": 1.0484,
      "step": 15420
    },
    {
      "epoch": 0.6944506953508258,
      "grad_norm": 1.311622142791748,
      "learning_rate": 9.305549304649175e-05,
      "loss": 1.1079,
      "step": 15430
    },
    {
      "epoch": 0.6949007606102885,
      "grad_norm": 1.4298462867736816,
      "learning_rate": 9.305099239389712e-05,
      "loss": 1.0539,
      "step": 15440
    },
    {
      "epoch": 0.6953508258697512,
      "grad_norm": 1.936737298965454,
      "learning_rate": 9.304649174130249e-05,
      "loss": 0.9694,
      "step": 15450
    },
    {
      "epoch": 0.6958008911292137,
      "grad_norm": 1.2048516273498535,
      "learning_rate": 9.304199108870787e-05,
      "loss": 1.0351,
      "step": 15460
    },
    {
      "epoch": 0.6962509563886764,
      "grad_norm": 2.302088499069214,
      "learning_rate": 9.303749043611324e-05,
      "loss": 1.0574,
      "step": 15470
    },
    {
      "epoch": 0.696701021648139,
      "grad_norm": 2.5618910789489746,
      "learning_rate": 9.303298978351861e-05,
      "loss": 1.0889,
      "step": 15480
    },
    {
      "epoch": 0.6971510869076016,
      "grad_norm": 1.8311628103256226,
      "learning_rate": 9.302848913092399e-05,
      "loss": 1.1148,
      "step": 15490
    },
    {
      "epoch": 0.6976011521670642,
      "grad_norm": 1.147803544998169,
      "learning_rate": 9.302398847832936e-05,
      "loss": 1.0955,
      "step": 15500
    },
    {
      "epoch": 0.6980512174265269,
      "grad_norm": 2.2924628257751465,
      "learning_rate": 9.301948782573473e-05,
      "loss": 1.0006,
      "step": 15510
    },
    {
      "epoch": 0.6985012826859894,
      "grad_norm": 1.328816294670105,
      "learning_rate": 9.301498717314011e-05,
      "loss": 1.0054,
      "step": 15520
    },
    {
      "epoch": 0.6989513479454521,
      "grad_norm": 1.9762507677078247,
      "learning_rate": 9.301048652054548e-05,
      "loss": 1.0188,
      "step": 15530
    },
    {
      "epoch": 0.6994014132049147,
      "grad_norm": 1.5380959510803223,
      "learning_rate": 9.300598586795087e-05,
      "loss": 1.1145,
      "step": 15540
    },
    {
      "epoch": 0.6998514784643773,
      "grad_norm": 1.0841624736785889,
      "learning_rate": 9.300148521535623e-05,
      "loss": 1.0465,
      "step": 15550
    },
    {
      "epoch": 0.7003015437238399,
      "grad_norm": 1.1380655765533447,
      "learning_rate": 9.29969845627616e-05,
      "loss": 1.1092,
      "step": 15560
    },
    {
      "epoch": 0.7007516089833026,
      "grad_norm": 1.6239525079727173,
      "learning_rate": 9.299248391016699e-05,
      "loss": 1.0199,
      "step": 15570
    },
    {
      "epoch": 0.7012016742427652,
      "grad_norm": 1.4714921712875366,
      "learning_rate": 9.298798325757235e-05,
      "loss": 1.0246,
      "step": 15580
    },
    {
      "epoch": 0.7016517395022278,
      "grad_norm": 1.5566717386245728,
      "learning_rate": 9.298348260497772e-05,
      "loss": 1.0462,
      "step": 15590
    },
    {
      "epoch": 0.7021018047616905,
      "grad_norm": 1.2665895223617554,
      "learning_rate": 9.297898195238311e-05,
      "loss": 1.0303,
      "step": 15600
    },
    {
      "epoch": 0.702551870021153,
      "grad_norm": 1.8799091577529907,
      "learning_rate": 9.297448129978847e-05,
      "loss": 1.1508,
      "step": 15610
    },
    {
      "epoch": 0.7030019352806157,
      "grad_norm": 1.393410325050354,
      "learning_rate": 9.296998064719384e-05,
      "loss": 1.0365,
      "step": 15620
    },
    {
      "epoch": 0.7034520005400783,
      "grad_norm": 1.8556208610534668,
      "learning_rate": 9.296547999459923e-05,
      "loss": 1.0548,
      "step": 15630
    },
    {
      "epoch": 0.703902065799541,
      "grad_norm": 1.232824444770813,
      "learning_rate": 9.296097934200459e-05,
      "loss": 1.0511,
      "step": 15640
    },
    {
      "epoch": 0.7043521310590035,
      "grad_norm": 1.5307620763778687,
      "learning_rate": 9.295647868940997e-05,
      "loss": 1.0063,
      "step": 15650
    },
    {
      "epoch": 0.7048021963184662,
      "grad_norm": 1.8107967376708984,
      "learning_rate": 9.295197803681535e-05,
      "loss": 1.0876,
      "step": 15660
    },
    {
      "epoch": 0.7052522615779288,
      "grad_norm": 1.7088699340820312,
      "learning_rate": 9.294747738422071e-05,
      "loss": 1.1036,
      "step": 15670
    },
    {
      "epoch": 0.7057023268373914,
      "grad_norm": 1.9294021129608154,
      "learning_rate": 9.294297673162609e-05,
      "loss": 1.0276,
      "step": 15680
    },
    {
      "epoch": 0.7061523920968541,
      "grad_norm": 2.314507246017456,
      "learning_rate": 9.293847607903147e-05,
      "loss": 1.0312,
      "step": 15690
    },
    {
      "epoch": 0.7066024573563167,
      "grad_norm": 2.017627239227295,
      "learning_rate": 9.293397542643683e-05,
      "loss": 1.0568,
      "step": 15700
    },
    {
      "epoch": 0.7070525226157793,
      "grad_norm": 1.4276297092437744,
      "learning_rate": 9.29294747738422e-05,
      "loss": 1.1273,
      "step": 15710
    },
    {
      "epoch": 0.7075025878752419,
      "grad_norm": 2.1025404930114746,
      "learning_rate": 9.29249741212476e-05,
      "loss": 1.0817,
      "step": 15720
    },
    {
      "epoch": 0.7079526531347046,
      "grad_norm": 1.4358478784561157,
      "learning_rate": 9.292047346865295e-05,
      "loss": 1.0985,
      "step": 15730
    },
    {
      "epoch": 0.7084027183941671,
      "grad_norm": 2.0500564575195312,
      "learning_rate": 9.291597281605833e-05,
      "loss": 1.1397,
      "step": 15740
    },
    {
      "epoch": 0.7088527836536298,
      "grad_norm": 1.5931297540664673,
      "learning_rate": 9.291147216346371e-05,
      "loss": 1.1277,
      "step": 15750
    },
    {
      "epoch": 0.7093028489130924,
      "grad_norm": 1.8712844848632812,
      "learning_rate": 9.290697151086907e-05,
      "loss": 1.071,
      "step": 15760
    },
    {
      "epoch": 0.709752914172555,
      "grad_norm": 1.5164765119552612,
      "learning_rate": 9.290247085827446e-05,
      "loss": 1.0113,
      "step": 15770
    },
    {
      "epoch": 0.7102029794320176,
      "grad_norm": 1.6999717950820923,
      "learning_rate": 9.289797020567984e-05,
      "loss": 1.0398,
      "step": 15780
    },
    {
      "epoch": 0.7106530446914803,
      "grad_norm": 1.2298568487167358,
      "learning_rate": 9.28934695530852e-05,
      "loss": 1.0723,
      "step": 15790
    },
    {
      "epoch": 0.7111031099509428,
      "grad_norm": 2.3353140354156494,
      "learning_rate": 9.288896890049058e-05,
      "loss": 1.0923,
      "step": 15800
    },
    {
      "epoch": 0.7115531752104055,
      "grad_norm": 1.282341718673706,
      "learning_rate": 9.288446824789596e-05,
      "loss": 1.0802,
      "step": 15810
    },
    {
      "epoch": 0.7120032404698682,
      "grad_norm": 1.3370256423950195,
      "learning_rate": 9.287996759530132e-05,
      "loss": 1.0978,
      "step": 15820
    },
    {
      "epoch": 0.7124533057293307,
      "grad_norm": 1.7411304712295532,
      "learning_rate": 9.28754669427067e-05,
      "loss": 1.0801,
      "step": 15830
    },
    {
      "epoch": 0.7129033709887934,
      "grad_norm": 1.7142143249511719,
      "learning_rate": 9.287096629011208e-05,
      "loss": 1.1121,
      "step": 15840
    },
    {
      "epoch": 0.713353436248256,
      "grad_norm": 1.6033540964126587,
      "learning_rate": 9.286646563751744e-05,
      "loss": 1.1042,
      "step": 15850
    },
    {
      "epoch": 0.7138035015077187,
      "grad_norm": 2.2275874614715576,
      "learning_rate": 9.286196498492282e-05,
      "loss": 1.1038,
      "step": 15860
    },
    {
      "epoch": 0.7142535667671812,
      "grad_norm": 1.6865582466125488,
      "learning_rate": 9.28574643323282e-05,
      "loss": 1.1092,
      "step": 15870
    },
    {
      "epoch": 0.7147036320266439,
      "grad_norm": 1.7328404188156128,
      "learning_rate": 9.285296367973356e-05,
      "loss": 1.0976,
      "step": 15880
    },
    {
      "epoch": 0.7151536972861064,
      "grad_norm": 1.4795942306518555,
      "learning_rate": 9.284846302713895e-05,
      "loss": 1.0296,
      "step": 15890
    },
    {
      "epoch": 0.7156037625455691,
      "grad_norm": 2.651705503463745,
      "learning_rate": 9.284396237454432e-05,
      "loss": 1.0419,
      "step": 15900
    },
    {
      "epoch": 0.7160538278050317,
      "grad_norm": 1.3182531595230103,
      "learning_rate": 9.283946172194968e-05,
      "loss": 1.0992,
      "step": 15910
    },
    {
      "epoch": 0.7165038930644944,
      "grad_norm": 1.2948009967803955,
      "learning_rate": 9.283496106935507e-05,
      "loss": 1.1493,
      "step": 15920
    },
    {
      "epoch": 0.7169539583239569,
      "grad_norm": 1.9500268697738647,
      "learning_rate": 9.283046041676044e-05,
      "loss": 1.021,
      "step": 15930
    },
    {
      "epoch": 0.7174040235834196,
      "grad_norm": 2.2090768814086914,
      "learning_rate": 9.28259597641658e-05,
      "loss": 1.1167,
      "step": 15940
    },
    {
      "epoch": 0.7178540888428823,
      "grad_norm": 1.8397183418273926,
      "learning_rate": 9.282145911157119e-05,
      "loss": 1.0396,
      "step": 15950
    },
    {
      "epoch": 0.7183041541023448,
      "grad_norm": 1.6107778549194336,
      "learning_rate": 9.281695845897656e-05,
      "loss": 1.0438,
      "step": 15960
    },
    {
      "epoch": 0.7187542193618075,
      "grad_norm": 2.037651538848877,
      "learning_rate": 9.281245780638192e-05,
      "loss": 1.073,
      "step": 15970
    },
    {
      "epoch": 0.7192042846212701,
      "grad_norm": 1.4254789352416992,
      "learning_rate": 9.280795715378731e-05,
      "loss": 1.0056,
      "step": 15980
    },
    {
      "epoch": 0.7196543498807327,
      "grad_norm": 1.0447889566421509,
      "learning_rate": 9.280345650119268e-05,
      "loss": 1.141,
      "step": 15990
    },
    {
      "epoch": 0.7201044151401953,
      "grad_norm": 1.4902311563491821,
      "learning_rate": 9.279895584859804e-05,
      "loss": 1.0282,
      "step": 16000
    },
    {
      "epoch": 0.720554480399658,
      "grad_norm": 2.2716073989868164,
      "learning_rate": 9.279445519600343e-05,
      "loss": 1.1569,
      "step": 16010
    },
    {
      "epoch": 0.7210045456591205,
      "grad_norm": 1.873741865158081,
      "learning_rate": 9.27899545434088e-05,
      "loss": 1.0664,
      "step": 16020
    },
    {
      "epoch": 0.7214546109185832,
      "grad_norm": 1.9795114994049072,
      "learning_rate": 9.278545389081418e-05,
      "loss": 1.0358,
      "step": 16030
    },
    {
      "epoch": 0.7219046761780458,
      "grad_norm": 2.093806743621826,
      "learning_rate": 9.278095323821955e-05,
      "loss": 1.0056,
      "step": 16040
    },
    {
      "epoch": 0.7223547414375084,
      "grad_norm": 1.6606720685958862,
      "learning_rate": 9.277645258562492e-05,
      "loss": 1.041,
      "step": 16050
    },
    {
      "epoch": 0.7228048066969711,
      "grad_norm": 1.9817358255386353,
      "learning_rate": 9.27719519330303e-05,
      "loss": 1.0392,
      "step": 16060
    },
    {
      "epoch": 0.7232548719564337,
      "grad_norm": 1.2917697429656982,
      "learning_rate": 9.276745128043567e-05,
      "loss": 1.0498,
      "step": 16070
    },
    {
      "epoch": 0.7237049372158963,
      "grad_norm": 1.7564027309417725,
      "learning_rate": 9.276295062784104e-05,
      "loss": 1.0454,
      "step": 16080
    },
    {
      "epoch": 0.7241550024753589,
      "grad_norm": 1.3266323804855347,
      "learning_rate": 9.275844997524642e-05,
      "loss": 1.0478,
      "step": 16090
    },
    {
      "epoch": 0.7246050677348216,
      "grad_norm": 2.5122733116149902,
      "learning_rate": 9.275394932265179e-05,
      "loss": 1.0088,
      "step": 16100
    },
    {
      "epoch": 0.7250551329942841,
      "grad_norm": 2.5046591758728027,
      "learning_rate": 9.274944867005716e-05,
      "loss": 1.1368,
      "step": 16110
    },
    {
      "epoch": 0.7255051982537468,
      "grad_norm": 1.7896326780319214,
      "learning_rate": 9.274494801746254e-05,
      "loss": 1.0605,
      "step": 16120
    },
    {
      "epoch": 0.7259552635132094,
      "grad_norm": 1.583762764930725,
      "learning_rate": 9.274044736486791e-05,
      "loss": 1.0288,
      "step": 16130
    },
    {
      "epoch": 0.726405328772672,
      "grad_norm": 1.5520637035369873,
      "learning_rate": 9.273594671227329e-05,
      "loss": 1.0571,
      "step": 16140
    },
    {
      "epoch": 0.7268553940321346,
      "grad_norm": 1.9922512769699097,
      "learning_rate": 9.273144605967866e-05,
      "loss": 1.0145,
      "step": 16150
    },
    {
      "epoch": 0.7273054592915973,
      "grad_norm": 1.8545204401016235,
      "learning_rate": 9.272694540708403e-05,
      "loss": 1.054,
      "step": 16160
    },
    {
      "epoch": 0.7277555245510599,
      "grad_norm": 2.2315187454223633,
      "learning_rate": 9.27224447544894e-05,
      "loss": 1.0919,
      "step": 16170
    },
    {
      "epoch": 0.7282055898105225,
      "grad_norm": 1.4481183290481567,
      "learning_rate": 9.271794410189478e-05,
      "loss": 1.0968,
      "step": 16180
    },
    {
      "epoch": 0.7286556550699852,
      "grad_norm": 1.6567012071609497,
      "learning_rate": 9.271344344930015e-05,
      "loss": 1.0496,
      "step": 16190
    },
    {
      "epoch": 0.7291057203294478,
      "grad_norm": 1.3913395404815674,
      "learning_rate": 9.270894279670553e-05,
      "loss": 1.0924,
      "step": 16200
    },
    {
      "epoch": 0.7295557855889104,
      "grad_norm": 1.2105000019073486,
      "learning_rate": 9.27044421441109e-05,
      "loss": 1.0967,
      "step": 16210
    },
    {
      "epoch": 0.730005850848373,
      "grad_norm": 1.4880642890930176,
      "learning_rate": 9.269994149151627e-05,
      "loss": 1.0108,
      "step": 16220
    },
    {
      "epoch": 0.7304559161078357,
      "grad_norm": 1.7060154676437378,
      "learning_rate": 9.269544083892165e-05,
      "loss": 1.0444,
      "step": 16230
    },
    {
      "epoch": 0.7309059813672982,
      "grad_norm": 1.5978727340698242,
      "learning_rate": 9.269094018632702e-05,
      "loss": 1.0291,
      "step": 16240
    },
    {
      "epoch": 0.7313560466267609,
      "grad_norm": 1.8794801235198975,
      "learning_rate": 9.26864395337324e-05,
      "loss": 1.0354,
      "step": 16250
    },
    {
      "epoch": 0.7318061118862235,
      "grad_norm": 1.2050896883010864,
      "learning_rate": 9.268193888113777e-05,
      "loss": 1.0199,
      "step": 16260
    },
    {
      "epoch": 0.7322561771456861,
      "grad_norm": 2.157193899154663,
      "learning_rate": 9.267743822854314e-05,
      "loss": 1.0558,
      "step": 16270
    },
    {
      "epoch": 0.7327062424051487,
      "grad_norm": 2.0673489570617676,
      "learning_rate": 9.267293757594852e-05,
      "loss": 1.0366,
      "step": 16280
    },
    {
      "epoch": 0.7331563076646114,
      "grad_norm": 2.175748109817505,
      "learning_rate": 9.26684369233539e-05,
      "loss": 1.0512,
      "step": 16290
    },
    {
      "epoch": 0.733606372924074,
      "grad_norm": 2.8035502433776855,
      "learning_rate": 9.266393627075926e-05,
      "loss": 1.1051,
      "step": 16300
    },
    {
      "epoch": 0.7340564381835366,
      "grad_norm": 1.3706423044204712,
      "learning_rate": 9.265943561816464e-05,
      "loss": 1.0371,
      "step": 16310
    },
    {
      "epoch": 0.7345065034429993,
      "grad_norm": 1.40028715133667,
      "learning_rate": 9.265493496557002e-05,
      "loss": 0.9672,
      "step": 16320
    },
    {
      "epoch": 0.7349565687024618,
      "grad_norm": 1.4569004774093628,
      "learning_rate": 9.265043431297538e-05,
      "loss": 1.1078,
      "step": 16330
    },
    {
      "epoch": 0.7354066339619245,
      "grad_norm": 1.7748311758041382,
      "learning_rate": 9.264593366038076e-05,
      "loss": 1.0685,
      "step": 16340
    },
    {
      "epoch": 0.7358566992213871,
      "grad_norm": 1.4527928829193115,
      "learning_rate": 9.264143300778614e-05,
      "loss": 1.0503,
      "step": 16350
    },
    {
      "epoch": 0.7363067644808498,
      "grad_norm": 1.6470764875411987,
      "learning_rate": 9.26369323551915e-05,
      "loss": 1.0315,
      "step": 16360
    },
    {
      "epoch": 0.7367568297403123,
      "grad_norm": 1.277632474899292,
      "learning_rate": 9.263243170259688e-05,
      "loss": 1.0663,
      "step": 16370
    },
    {
      "epoch": 0.737206894999775,
      "grad_norm": 1.7978652715682983,
      "learning_rate": 9.262793105000227e-05,
      "loss": 1.0181,
      "step": 16380
    },
    {
      "epoch": 0.7376569602592375,
      "grad_norm": 2.4441235065460205,
      "learning_rate": 9.262343039740763e-05,
      "loss": 1.174,
      "step": 16390
    },
    {
      "epoch": 0.7381070255187002,
      "grad_norm": 1.716491937637329,
      "learning_rate": 9.2618929744813e-05,
      "loss": 1.0909,
      "step": 16400
    },
    {
      "epoch": 0.7385570907781628,
      "grad_norm": 2.404231309890747,
      "learning_rate": 9.261442909221839e-05,
      "loss": 1.0258,
      "step": 16410
    },
    {
      "epoch": 0.7390071560376255,
      "grad_norm": 1.6819106340408325,
      "learning_rate": 9.260992843962375e-05,
      "loss": 1.1027,
      "step": 16420
    },
    {
      "epoch": 0.7394572212970881,
      "grad_norm": 1.182315468788147,
      "learning_rate": 9.260542778702912e-05,
      "loss": 1.0796,
      "step": 16430
    },
    {
      "epoch": 0.7399072865565507,
      "grad_norm": 1.7089855670928955,
      "learning_rate": 9.260092713443451e-05,
      "loss": 1.0353,
      "step": 16440
    },
    {
      "epoch": 0.7403573518160134,
      "grad_norm": 1.1800446510314941,
      "learning_rate": 9.259642648183987e-05,
      "loss": 1.055,
      "step": 16450
    },
    {
      "epoch": 0.7408074170754759,
      "grad_norm": 1.7125293016433716,
      "learning_rate": 9.259192582924524e-05,
      "loss": 1.0303,
      "step": 16460
    },
    {
      "epoch": 0.7412574823349386,
      "grad_norm": 2.418217182159424,
      "learning_rate": 9.258742517665063e-05,
      "loss": 0.997,
      "step": 16470
    },
    {
      "epoch": 0.7417075475944012,
      "grad_norm": 1.4938747882843018,
      "learning_rate": 9.258292452405599e-05,
      "loss": 1.0668,
      "step": 16480
    },
    {
      "epoch": 0.7421576128538638,
      "grad_norm": 1.2808955907821655,
      "learning_rate": 9.257842387146136e-05,
      "loss": 1.05,
      "step": 16490
    },
    {
      "epoch": 0.7426076781133264,
      "grad_norm": 2.567798137664795,
      "learning_rate": 9.257392321886675e-05,
      "loss": 1.1592,
      "step": 16500
    },
    {
      "epoch": 0.7430577433727891,
      "grad_norm": 2.840003490447998,
      "learning_rate": 9.256942256627211e-05,
      "loss": 1.0514,
      "step": 16510
    },
    {
      "epoch": 0.7435078086322516,
      "grad_norm": 1.8541761636734009,
      "learning_rate": 9.256492191367748e-05,
      "loss": 1.03,
      "step": 16520
    },
    {
      "epoch": 0.7439578738917143,
      "grad_norm": 1.2341049909591675,
      "learning_rate": 9.256042126108287e-05,
      "loss": 1.0702,
      "step": 16530
    },
    {
      "epoch": 0.7444079391511769,
      "grad_norm": 1.435804009437561,
      "learning_rate": 9.255592060848823e-05,
      "loss": 1.1595,
      "step": 16540
    },
    {
      "epoch": 0.7448580044106395,
      "grad_norm": 2.2604947090148926,
      "learning_rate": 9.25514199558936e-05,
      "loss": 1.0388,
      "step": 16550
    },
    {
      "epoch": 0.7453080696701022,
      "grad_norm": 1.7908294200897217,
      "learning_rate": 9.254691930329899e-05,
      "loss": 1.0765,
      "step": 16560
    },
    {
      "epoch": 0.7457581349295648,
      "grad_norm": 1.534353494644165,
      "learning_rate": 9.254241865070435e-05,
      "loss": 1.1051,
      "step": 16570
    },
    {
      "epoch": 0.7462082001890274,
      "grad_norm": 1.9109753370285034,
      "learning_rate": 9.253791799810974e-05,
      "loss": 1.0222,
      "step": 16580
    },
    {
      "epoch": 0.74665826544849,
      "grad_norm": 1.4702657461166382,
      "learning_rate": 9.253341734551511e-05,
      "loss": 1.0903,
      "step": 16590
    },
    {
      "epoch": 0.7471083307079527,
      "grad_norm": 3.0041558742523193,
      "learning_rate": 9.252891669292047e-05,
      "loss": 1.0226,
      "step": 16600
    },
    {
      "epoch": 0.7475583959674152,
      "grad_norm": 1.2268261909484863,
      "learning_rate": 9.252441604032586e-05,
      "loss": 1.0319,
      "step": 16610
    },
    {
      "epoch": 0.7480084612268779,
      "grad_norm": 1.6528644561767578,
      "learning_rate": 9.251991538773123e-05,
      "loss": 1.0956,
      "step": 16620
    },
    {
      "epoch": 0.7484585264863405,
      "grad_norm": 2.693690538406372,
      "learning_rate": 9.251541473513659e-05,
      "loss": 1.0834,
      "step": 16630
    },
    {
      "epoch": 0.7489085917458032,
      "grad_norm": 1.8616780042648315,
      "learning_rate": 9.251091408254198e-05,
      "loss": 1.1178,
      "step": 16640
    },
    {
      "epoch": 0.7493586570052657,
      "grad_norm": 1.7423033714294434,
      "learning_rate": 9.250641342994735e-05,
      "loss": 1.1073,
      "step": 16650
    },
    {
      "epoch": 0.7498087222647284,
      "grad_norm": 2.228341817855835,
      "learning_rate": 9.250191277735271e-05,
      "loss": 1.0297,
      "step": 16660
    },
    {
      "epoch": 0.7502587875241911,
      "grad_norm": 1.7563716173171997,
      "learning_rate": 9.24974121247581e-05,
      "loss": 1.0535,
      "step": 16670
    },
    {
      "epoch": 0.7507088527836536,
      "grad_norm": 1.9493128061294556,
      "learning_rate": 9.249291147216347e-05,
      "loss": 1.0215,
      "step": 16680
    },
    {
      "epoch": 0.7511589180431163,
      "grad_norm": 1.2662653923034668,
      "learning_rate": 9.248841081956883e-05,
      "loss": 1.0186,
      "step": 16690
    },
    {
      "epoch": 0.7516089833025789,
      "grad_norm": 1.8101706504821777,
      "learning_rate": 9.248391016697422e-05,
      "loss": 1.0425,
      "step": 16700
    },
    {
      "epoch": 0.7520590485620415,
      "grad_norm": 1.5597565174102783,
      "learning_rate": 9.24794095143796e-05,
      "loss": 1.069,
      "step": 16710
    },
    {
      "epoch": 0.7525091138215041,
      "grad_norm": 1.6581838130950928,
      "learning_rate": 9.247490886178495e-05,
      "loss": 1.031,
      "step": 16720
    },
    {
      "epoch": 0.7529591790809668,
      "grad_norm": 2.078545570373535,
      "learning_rate": 9.247040820919034e-05,
      "loss": 1.0454,
      "step": 16730
    },
    {
      "epoch": 0.7534092443404293,
      "grad_norm": 1.627471685409546,
      "learning_rate": 9.246590755659571e-05,
      "loss": 1.0583,
      "step": 16740
    },
    {
      "epoch": 0.753859309599892,
      "grad_norm": 1.1498857736587524,
      "learning_rate": 9.246140690400107e-05,
      "loss": 1.1337,
      "step": 16750
    },
    {
      "epoch": 0.7543093748593546,
      "grad_norm": 1.7567064762115479,
      "learning_rate": 9.245690625140646e-05,
      "loss": 1.0012,
      "step": 16760
    },
    {
      "epoch": 0.7547594401188172,
      "grad_norm": 1.6023685932159424,
      "learning_rate": 9.245240559881184e-05,
      "loss": 1.1421,
      "step": 16770
    },
    {
      "epoch": 0.7552095053782798,
      "grad_norm": 2.698585271835327,
      "learning_rate": 9.24479049462172e-05,
      "loss": 1.0327,
      "step": 16780
    },
    {
      "epoch": 0.7556595706377425,
      "grad_norm": 1.8717526197433472,
      "learning_rate": 9.244340429362258e-05,
      "loss": 1.0301,
      "step": 16790
    },
    {
      "epoch": 0.7561096358972051,
      "grad_norm": 1.5785101652145386,
      "learning_rate": 9.243890364102796e-05,
      "loss": 1.139,
      "step": 16800
    },
    {
      "epoch": 0.7565597011566677,
      "grad_norm": 1.827929973602295,
      "learning_rate": 9.243440298843332e-05,
      "loss": 1.1176,
      "step": 16810
    },
    {
      "epoch": 0.7570097664161304,
      "grad_norm": 1.3023440837860107,
      "learning_rate": 9.24299023358387e-05,
      "loss": 1.0741,
      "step": 16820
    },
    {
      "epoch": 0.7574598316755929,
      "grad_norm": 1.6077378988265991,
      "learning_rate": 9.242540168324408e-05,
      "loss": 1.0016,
      "step": 16830
    },
    {
      "epoch": 0.7579098969350556,
      "grad_norm": 1.7540837526321411,
      "learning_rate": 9.242090103064945e-05,
      "loss": 1.0557,
      "step": 16840
    },
    {
      "epoch": 0.7583599621945182,
      "grad_norm": 2.167966365814209,
      "learning_rate": 9.241640037805482e-05,
      "loss": 1.0927,
      "step": 16850
    },
    {
      "epoch": 0.7588100274539809,
      "grad_norm": 1.4644019603729248,
      "learning_rate": 9.24118997254602e-05,
      "loss": 1.071,
      "step": 16860
    },
    {
      "epoch": 0.7592600927134434,
      "grad_norm": 1.995187520980835,
      "learning_rate": 9.240739907286557e-05,
      "loss": 1.0387,
      "step": 16870
    },
    {
      "epoch": 0.7597101579729061,
      "grad_norm": 2.406888961791992,
      "learning_rate": 9.240289842027095e-05,
      "loss": 1.0554,
      "step": 16880
    },
    {
      "epoch": 0.7601602232323686,
      "grad_norm": 1.594296932220459,
      "learning_rate": 9.239839776767632e-05,
      "loss": 1.048,
      "step": 16890
    },
    {
      "epoch": 0.7606102884918313,
      "grad_norm": 1.610365867614746,
      "learning_rate": 9.239389711508169e-05,
      "loss": 1.0426,
      "step": 16900
    },
    {
      "epoch": 0.7610603537512939,
      "grad_norm": 2.331561326980591,
      "learning_rate": 9.238939646248707e-05,
      "loss": 1.1117,
      "step": 16910
    },
    {
      "epoch": 0.7615104190107566,
      "grad_norm": 1.0234788656234741,
      "learning_rate": 9.238489580989244e-05,
      "loss": 1.0456,
      "step": 16920
    },
    {
      "epoch": 0.7619604842702192,
      "grad_norm": 1.3615387678146362,
      "learning_rate": 9.238039515729781e-05,
      "loss": 1.1026,
      "step": 16930
    },
    {
      "epoch": 0.7624105495296818,
      "grad_norm": 1.5186920166015625,
      "learning_rate": 9.237589450470319e-05,
      "loss": 1.126,
      "step": 16940
    },
    {
      "epoch": 0.7628606147891445,
      "grad_norm": 1.5037126541137695,
      "learning_rate": 9.237139385210856e-05,
      "loss": 1.0291,
      "step": 16950
    },
    {
      "epoch": 0.763310680048607,
      "grad_norm": 1.4022867679595947,
      "learning_rate": 9.236689319951393e-05,
      "loss": 1.0056,
      "step": 16960
    },
    {
      "epoch": 0.7637607453080697,
      "grad_norm": 1.5641107559204102,
      "learning_rate": 9.236239254691931e-05,
      "loss": 1.0864,
      "step": 16970
    },
    {
      "epoch": 0.7642108105675323,
      "grad_norm": 1.2767266035079956,
      "learning_rate": 9.235789189432468e-05,
      "loss": 1.1037,
      "step": 16980
    },
    {
      "epoch": 0.7646608758269949,
      "grad_norm": 1.657155156135559,
      "learning_rate": 9.235339124173005e-05,
      "loss": 1.031,
      "step": 16990
    },
    {
      "epoch": 0.7651109410864575,
      "grad_norm": 1.5562143325805664,
      "learning_rate": 9.234889058913543e-05,
      "loss": 0.9968,
      "step": 17000
    },
    {
      "epoch": 0.7655610063459202,
      "grad_norm": 1.1089210510253906,
      "learning_rate": 9.23443899365408e-05,
      "loss": 1.1256,
      "step": 17010
    },
    {
      "epoch": 0.7660110716053827,
      "grad_norm": 1.4612209796905518,
      "learning_rate": 9.233988928394618e-05,
      "loss": 0.9379,
      "step": 17020
    },
    {
      "epoch": 0.7664611368648454,
      "grad_norm": 1.5195248126983643,
      "learning_rate": 9.233538863135155e-05,
      "loss": 1.1083,
      "step": 17030
    },
    {
      "epoch": 0.7669112021243081,
      "grad_norm": 1.6195827722549438,
      "learning_rate": 9.233088797875692e-05,
      "loss": 1.0832,
      "step": 17040
    },
    {
      "epoch": 0.7673612673837706,
      "grad_norm": 1.7087819576263428,
      "learning_rate": 9.23263873261623e-05,
      "loss": 1.0921,
      "step": 17050
    },
    {
      "epoch": 0.7678113326432333,
      "grad_norm": 1.618591547012329,
      "learning_rate": 9.232188667356767e-05,
      "loss": 0.932,
      "step": 17060
    },
    {
      "epoch": 0.7682613979026959,
      "grad_norm": 1.72773015499115,
      "learning_rate": 9.231738602097304e-05,
      "loss": 0.9716,
      "step": 17070
    },
    {
      "epoch": 0.7687114631621585,
      "grad_norm": 1.806644082069397,
      "learning_rate": 9.231288536837842e-05,
      "loss": 1.0122,
      "step": 17080
    },
    {
      "epoch": 0.7691615284216211,
      "grad_norm": 1.288801670074463,
      "learning_rate": 9.230838471578379e-05,
      "loss": 1.1139,
      "step": 17090
    },
    {
      "epoch": 0.7696115936810838,
      "grad_norm": 1.4331928491592407,
      "learning_rate": 9.230388406318918e-05,
      "loss": 1.0135,
      "step": 17100
    },
    {
      "epoch": 0.7700616589405463,
      "grad_norm": 2.9993319511413574,
      "learning_rate": 9.229938341059454e-05,
      "loss": 1.0781,
      "step": 17110
    },
    {
      "epoch": 0.770511724200009,
      "grad_norm": 1.5552645921707153,
      "learning_rate": 9.229488275799991e-05,
      "loss": 1.0521,
      "step": 17120
    },
    {
      "epoch": 0.7709617894594716,
      "grad_norm": 1.3844774961471558,
      "learning_rate": 9.22903821054053e-05,
      "loss": 1.011,
      "step": 17130
    },
    {
      "epoch": 0.7714118547189343,
      "grad_norm": 2.1450157165527344,
      "learning_rate": 9.228588145281066e-05,
      "loss": 1.0844,
      "step": 17140
    },
    {
      "epoch": 0.7718619199783968,
      "grad_norm": 2.1022143363952637,
      "learning_rate": 9.228138080021603e-05,
      "loss": 1.1603,
      "step": 17150
    },
    {
      "epoch": 0.7723119852378595,
      "grad_norm": 1.609042763710022,
      "learning_rate": 9.227688014762142e-05,
      "loss": 1.1087,
      "step": 17160
    },
    {
      "epoch": 0.7727620504973222,
      "grad_norm": 1.4962031841278076,
      "learning_rate": 9.227237949502678e-05,
      "loss": 1.0502,
      "step": 17170
    },
    {
      "epoch": 0.7732121157567847,
      "grad_norm": 1.796594262123108,
      "learning_rate": 9.226787884243215e-05,
      "loss": 1.0352,
      "step": 17180
    },
    {
      "epoch": 0.7736621810162474,
      "grad_norm": 1.3762366771697998,
      "learning_rate": 9.226337818983754e-05,
      "loss": 1.015,
      "step": 17190
    },
    {
      "epoch": 0.77411224627571,
      "grad_norm": 2.8370299339294434,
      "learning_rate": 9.22588775372429e-05,
      "loss": 1.0955,
      "step": 17200
    },
    {
      "epoch": 0.7745623115351726,
      "grad_norm": 2.170318841934204,
      "learning_rate": 9.225437688464827e-05,
      "loss": 1.0448,
      "step": 17210
    },
    {
      "epoch": 0.7750123767946352,
      "grad_norm": 1.4305906295776367,
      "learning_rate": 9.224987623205366e-05,
      "loss": 1.0428,
      "step": 17220
    },
    {
      "epoch": 0.7754624420540979,
      "grad_norm": 2.6449849605560303,
      "learning_rate": 9.224537557945902e-05,
      "loss": 1.094,
      "step": 17230
    },
    {
      "epoch": 0.7759125073135604,
      "grad_norm": 1.229074478149414,
      "learning_rate": 9.22408749268644e-05,
      "loss": 1.0557,
      "step": 17240
    },
    {
      "epoch": 0.7763625725730231,
      "grad_norm": 2.494235038757324,
      "learning_rate": 9.223637427426978e-05,
      "loss": 1.071,
      "step": 17250
    },
    {
      "epoch": 0.7768126378324857,
      "grad_norm": 1.7873499393463135,
      "learning_rate": 9.223187362167514e-05,
      "loss": 1.0236,
      "step": 17260
    },
    {
      "epoch": 0.7772627030919483,
      "grad_norm": 1.4070100784301758,
      "learning_rate": 9.222737296908052e-05,
      "loss": 1.0532,
      "step": 17270
    },
    {
      "epoch": 0.7777127683514109,
      "grad_norm": 2.877349615097046,
      "learning_rate": 9.22228723164859e-05,
      "loss": 1.0579,
      "step": 17280
    },
    {
      "epoch": 0.7781628336108736,
      "grad_norm": 1.9246740341186523,
      "learning_rate": 9.221837166389126e-05,
      "loss": 1.0554,
      "step": 17290
    },
    {
      "epoch": 0.7786128988703362,
      "grad_norm": 1.983513355255127,
      "learning_rate": 9.221387101129664e-05,
      "loss": 1.0297,
      "step": 17300
    },
    {
      "epoch": 0.7790629641297988,
      "grad_norm": 1.6486679315567017,
      "learning_rate": 9.220937035870202e-05,
      "loss": 1.091,
      "step": 17310
    },
    {
      "epoch": 0.7795130293892615,
      "grad_norm": 0.9935719966888428,
      "learning_rate": 9.220486970610738e-05,
      "loss": 1.078,
      "step": 17320
    },
    {
      "epoch": 0.779963094648724,
      "grad_norm": 1.582912802696228,
      "learning_rate": 9.220036905351276e-05,
      "loss": 1.1035,
      "step": 17330
    },
    {
      "epoch": 0.7804131599081867,
      "grad_norm": 1.1091997623443604,
      "learning_rate": 9.219586840091814e-05,
      "loss": 1.1377,
      "step": 17340
    },
    {
      "epoch": 0.7808632251676493,
      "grad_norm": 1.6102194786071777,
      "learning_rate": 9.21913677483235e-05,
      "loss": 1.0879,
      "step": 17350
    },
    {
      "epoch": 0.781313290427112,
      "grad_norm": 1.2351305484771729,
      "learning_rate": 9.218686709572889e-05,
      "loss": 1.0466,
      "step": 17360
    },
    {
      "epoch": 0.7817633556865745,
      "grad_norm": 1.8537875413894653,
      "learning_rate": 9.218236644313427e-05,
      "loss": 1.0402,
      "step": 17370
    },
    {
      "epoch": 0.7822134209460372,
      "grad_norm": 1.2491257190704346,
      "learning_rate": 9.217786579053963e-05,
      "loss": 1.0436,
      "step": 17380
    },
    {
      "epoch": 0.7826634862054997,
      "grad_norm": 1.5793901681900024,
      "learning_rate": 9.217336513794501e-05,
      "loss": 0.9545,
      "step": 17390
    },
    {
      "epoch": 0.7831135514649624,
      "grad_norm": 2.2614850997924805,
      "learning_rate": 9.216886448535039e-05,
      "loss": 1.0387,
      "step": 17400
    },
    {
      "epoch": 0.7835636167244251,
      "grad_norm": 1.8088815212249756,
      "learning_rate": 9.216436383275575e-05,
      "loss": 1.0843,
      "step": 17410
    },
    {
      "epoch": 0.7840136819838877,
      "grad_norm": 1.6126606464385986,
      "learning_rate": 9.215986318016113e-05,
      "loss": 1.0681,
      "step": 17420
    },
    {
      "epoch": 0.7844637472433503,
      "grad_norm": 1.592913031578064,
      "learning_rate": 9.215536252756651e-05,
      "loss": 1.0659,
      "step": 17430
    },
    {
      "epoch": 0.7849138125028129,
      "grad_norm": 1.5719131231307983,
      "learning_rate": 9.215086187497187e-05,
      "loss": 1.0248,
      "step": 17440
    },
    {
      "epoch": 0.7853638777622756,
      "grad_norm": 1.309360384941101,
      "learning_rate": 9.214636122237725e-05,
      "loss": 1.053,
      "step": 17450
    },
    {
      "epoch": 0.7858139430217381,
      "grad_norm": 1.5299875736236572,
      "learning_rate": 9.214186056978263e-05,
      "loss": 1.0006,
      "step": 17460
    },
    {
      "epoch": 0.7862640082812008,
      "grad_norm": 1.5725083351135254,
      "learning_rate": 9.213735991718799e-05,
      "loss": 1.0968,
      "step": 17470
    },
    {
      "epoch": 0.7867140735406634,
      "grad_norm": 2.265056610107422,
      "learning_rate": 9.213285926459338e-05,
      "loss": 1.1119,
      "step": 17480
    },
    {
      "epoch": 0.787164138800126,
      "grad_norm": 1.2257806062698364,
      "learning_rate": 9.212835861199875e-05,
      "loss": 1.0775,
      "step": 17490
    },
    {
      "epoch": 0.7876142040595886,
      "grad_norm": 2.0717029571533203,
      "learning_rate": 9.212385795940411e-05,
      "loss": 1.1339,
      "step": 17500
    },
    {
      "epoch": 0.7880642693190513,
      "grad_norm": 2.940369129180908,
      "learning_rate": 9.21193573068095e-05,
      "loss": 1.0429,
      "step": 17510
    },
    {
      "epoch": 0.7885143345785138,
      "grad_norm": 2.053288698196411,
      "learning_rate": 9.211485665421487e-05,
      "loss": 1.0987,
      "step": 17520
    },
    {
      "epoch": 0.7889643998379765,
      "grad_norm": 1.8859676122665405,
      "learning_rate": 9.211035600162023e-05,
      "loss": 0.9727,
      "step": 17530
    },
    {
      "epoch": 0.7894144650974392,
      "grad_norm": 1.384037971496582,
      "learning_rate": 9.210585534902562e-05,
      "loss": 1.0843,
      "step": 17540
    },
    {
      "epoch": 0.7898645303569017,
      "grad_norm": 1.57583749294281,
      "learning_rate": 9.210135469643099e-05,
      "loss": 1.0316,
      "step": 17550
    },
    {
      "epoch": 0.7903145956163644,
      "grad_norm": 1.156944751739502,
      "learning_rate": 9.209685404383635e-05,
      "loss": 1.008,
      "step": 17560
    },
    {
      "epoch": 0.790764660875827,
      "grad_norm": 1.6891663074493408,
      "learning_rate": 9.209235339124174e-05,
      "loss": 1.0947,
      "step": 17570
    },
    {
      "epoch": 0.7912147261352896,
      "grad_norm": 1.541115641593933,
      "learning_rate": 9.208785273864711e-05,
      "loss": 1.0644,
      "step": 17580
    },
    {
      "epoch": 0.7916647913947522,
      "grad_norm": 1.9370043277740479,
      "learning_rate": 9.208335208605247e-05,
      "loss": 0.9867,
      "step": 17590
    },
    {
      "epoch": 0.7921148566542149,
      "grad_norm": 1.1123878955841064,
      "learning_rate": 9.207885143345786e-05,
      "loss": 1.0825,
      "step": 17600
    },
    {
      "epoch": 0.7925649219136774,
      "grad_norm": 1.3019603490829468,
      "learning_rate": 9.207435078086323e-05,
      "loss": 1.0021,
      "step": 17610
    },
    {
      "epoch": 0.7930149871731401,
      "grad_norm": 1.8567500114440918,
      "learning_rate": 9.20698501282686e-05,
      "loss": 1.1332,
      "step": 17620
    },
    {
      "epoch": 0.7934650524326027,
      "grad_norm": 2.1427197456359863,
      "learning_rate": 9.206534947567398e-05,
      "loss": 1.0711,
      "step": 17630
    },
    {
      "epoch": 0.7939151176920654,
      "grad_norm": 1.265076756477356,
      "learning_rate": 9.206084882307935e-05,
      "loss": 1.0395,
      "step": 17640
    },
    {
      "epoch": 0.794365182951528,
      "grad_norm": 1.625062346458435,
      "learning_rate": 9.205634817048473e-05,
      "loss": 1.1381,
      "step": 17650
    },
    {
      "epoch": 0.7948152482109906,
      "grad_norm": 1.9900411367416382,
      "learning_rate": 9.20518475178901e-05,
      "loss": 1.0127,
      "step": 17660
    },
    {
      "epoch": 0.7952653134704533,
      "grad_norm": 1.5127763748168945,
      "learning_rate": 9.204734686529547e-05,
      "loss": 0.9495,
      "step": 17670
    },
    {
      "epoch": 0.7957153787299158,
      "grad_norm": 1.5294673442840576,
      "learning_rate": 9.204284621270085e-05,
      "loss": 1.0243,
      "step": 17680
    },
    {
      "epoch": 0.7961654439893785,
      "grad_norm": 3.188087224960327,
      "learning_rate": 9.203834556010622e-05,
      "loss": 1.0613,
      "step": 17690
    },
    {
      "epoch": 0.7966155092488411,
      "grad_norm": 1.2826813459396362,
      "learning_rate": 9.20338449075116e-05,
      "loss": 1.0606,
      "step": 17700
    },
    {
      "epoch": 0.7970655745083037,
      "grad_norm": 1.208742618560791,
      "learning_rate": 9.202934425491697e-05,
      "loss": 1.0225,
      "step": 17710
    },
    {
      "epoch": 0.7975156397677663,
      "grad_norm": 1.4982446432113647,
      "learning_rate": 9.202484360232234e-05,
      "loss": 1.039,
      "step": 17720
    },
    {
      "epoch": 0.797965705027229,
      "grad_norm": 1.6224380731582642,
      "learning_rate": 9.202034294972772e-05,
      "loss": 1.0488,
      "step": 17730
    },
    {
      "epoch": 0.7984157702866915,
      "grad_norm": 3.0334725379943848,
      "learning_rate": 9.201584229713309e-05,
      "loss": 1.0985,
      "step": 17740
    },
    {
      "epoch": 0.7988658355461542,
      "grad_norm": 1.2681642770767212,
      "learning_rate": 9.201134164453846e-05,
      "loss": 1.0659,
      "step": 17750
    },
    {
      "epoch": 0.7993159008056168,
      "grad_norm": 1.2621554136276245,
      "learning_rate": 9.200684099194384e-05,
      "loss": 1.1074,
      "step": 17760
    },
    {
      "epoch": 0.7997659660650794,
      "grad_norm": 2.000713586807251,
      "learning_rate": 9.200234033934921e-05,
      "loss": 1.0729,
      "step": 17770
    },
    {
      "epoch": 0.8002160313245421,
      "grad_norm": 1.277457356452942,
      "learning_rate": 9.199783968675458e-05,
      "loss": 1.0717,
      "step": 17780
    },
    {
      "epoch": 0.8006660965840047,
      "grad_norm": 2.057589292526245,
      "learning_rate": 9.199333903415996e-05,
      "loss": 1.0486,
      "step": 17790
    },
    {
      "epoch": 0.8011161618434673,
      "grad_norm": 2.5673446655273438,
      "learning_rate": 9.198883838156533e-05,
      "loss": 1.0843,
      "step": 17800
    },
    {
      "epoch": 0.8015662271029299,
      "grad_norm": 1.2543495893478394,
      "learning_rate": 9.19843377289707e-05,
      "loss": 1.0689,
      "step": 17810
    },
    {
      "epoch": 0.8020162923623926,
      "grad_norm": 1.6487541198730469,
      "learning_rate": 9.197983707637608e-05,
      "loss": 1.113,
      "step": 17820
    },
    {
      "epoch": 0.8024663576218551,
      "grad_norm": 1.798149824142456,
      "learning_rate": 9.197533642378145e-05,
      "loss": 1.0116,
      "step": 17830
    },
    {
      "epoch": 0.8029164228813178,
      "grad_norm": 1.373197317123413,
      "learning_rate": 9.197083577118682e-05,
      "loss": 1.1336,
      "step": 17840
    },
    {
      "epoch": 0.8033664881407804,
      "grad_norm": 1.5613315105438232,
      "learning_rate": 9.19663351185922e-05,
      "loss": 1.0293,
      "step": 17850
    },
    {
      "epoch": 0.803816553400243,
      "grad_norm": 1.7961554527282715,
      "learning_rate": 9.196183446599757e-05,
      "loss": 1.0866,
      "step": 17860
    },
    {
      "epoch": 0.8042666186597056,
      "grad_norm": 1.6637426614761353,
      "learning_rate": 9.195733381340295e-05,
      "loss": 1.0973,
      "step": 17870
    },
    {
      "epoch": 0.8047166839191683,
      "grad_norm": 1.5568732023239136,
      "learning_rate": 9.195283316080833e-05,
      "loss": 1.0473,
      "step": 17880
    },
    {
      "epoch": 0.8051667491786308,
      "grad_norm": 2.1604018211364746,
      "learning_rate": 9.194833250821369e-05,
      "loss": 1.1057,
      "step": 17890
    },
    {
      "epoch": 0.8056168144380935,
      "grad_norm": 1.4895445108413696,
      "learning_rate": 9.194383185561907e-05,
      "loss": 0.9966,
      "step": 17900
    },
    {
      "epoch": 0.8060668796975562,
      "grad_norm": 1.912253975868225,
      "learning_rate": 9.193933120302445e-05,
      "loss": 1.0607,
      "step": 17910
    },
    {
      "epoch": 0.8065169449570188,
      "grad_norm": 1.6306430101394653,
      "learning_rate": 9.193483055042981e-05,
      "loss": 1.0753,
      "step": 17920
    },
    {
      "epoch": 0.8069670102164814,
      "grad_norm": 2.9159345626831055,
      "learning_rate": 9.193032989783519e-05,
      "loss": 1.1075,
      "step": 17930
    },
    {
      "epoch": 0.807417075475944,
      "grad_norm": 1.6736226081848145,
      "learning_rate": 9.192582924524057e-05,
      "loss": 1.1119,
      "step": 17940
    },
    {
      "epoch": 0.8078671407354067,
      "grad_norm": 1.6528676748275757,
      "learning_rate": 9.192132859264593e-05,
      "loss": 1.031,
      "step": 17950
    },
    {
      "epoch": 0.8083172059948692,
      "grad_norm": 2.217154026031494,
      "learning_rate": 9.191682794005131e-05,
      "loss": 1.0081,
      "step": 17960
    },
    {
      "epoch": 0.8087672712543319,
      "grad_norm": 1.8586980104446411,
      "learning_rate": 9.19123272874567e-05,
      "loss": 1.0431,
      "step": 17970
    },
    {
      "epoch": 0.8092173365137945,
      "grad_norm": 2.1473662853240967,
      "learning_rate": 9.190782663486206e-05,
      "loss": 1.1062,
      "step": 17980
    },
    {
      "epoch": 0.8096674017732571,
      "grad_norm": 1.2697702646255493,
      "learning_rate": 9.190332598226743e-05,
      "loss": 1.0529,
      "step": 17990
    },
    {
      "epoch": 0.8101174670327197,
      "grad_norm": 2.457155466079712,
      "learning_rate": 9.189882532967282e-05,
      "loss": 1.1104,
      "step": 18000
    },
    {
      "epoch": 0.8105675322921824,
      "grad_norm": 1.2697561979293823,
      "learning_rate": 9.189432467707818e-05,
      "loss": 1.0815,
      "step": 18010
    },
    {
      "epoch": 0.811017597551645,
      "grad_norm": 1.455389142036438,
      "learning_rate": 9.188982402448355e-05,
      "loss": 1.0827,
      "step": 18020
    },
    {
      "epoch": 0.8114676628111076,
      "grad_norm": 1.3124796152114868,
      "learning_rate": 9.188532337188894e-05,
      "loss": 0.9948,
      "step": 18030
    },
    {
      "epoch": 0.8119177280705703,
      "grad_norm": 1.2157304286956787,
      "learning_rate": 9.18808227192943e-05,
      "loss": 1.0386,
      "step": 18040
    },
    {
      "epoch": 0.8123677933300328,
      "grad_norm": 1.1896610260009766,
      "learning_rate": 9.187632206669967e-05,
      "loss": 0.9992,
      "step": 18050
    },
    {
      "epoch": 0.8128178585894955,
      "grad_norm": 1.1401764154434204,
      "learning_rate": 9.187182141410506e-05,
      "loss": 1.0313,
      "step": 18060
    },
    {
      "epoch": 0.8132679238489581,
      "grad_norm": 1.291348934173584,
      "learning_rate": 9.186732076151042e-05,
      "loss": 1.0591,
      "step": 18070
    },
    {
      "epoch": 0.8137179891084207,
      "grad_norm": 1.5794461965560913,
      "learning_rate": 9.186282010891579e-05,
      "loss": 1.1296,
      "step": 18080
    },
    {
      "epoch": 0.8141680543678833,
      "grad_norm": 2.170773983001709,
      "learning_rate": 9.185831945632118e-05,
      "loss": 1.1356,
      "step": 18090
    },
    {
      "epoch": 0.814618119627346,
      "grad_norm": 1.8789148330688477,
      "learning_rate": 9.185381880372654e-05,
      "loss": 1.1239,
      "step": 18100
    },
    {
      "epoch": 0.8150681848868085,
      "grad_norm": 1.6090905666351318,
      "learning_rate": 9.184931815113191e-05,
      "loss": 0.9746,
      "step": 18110
    },
    {
      "epoch": 0.8155182501462712,
      "grad_norm": 1.9826483726501465,
      "learning_rate": 9.18448174985373e-05,
      "loss": 1.0228,
      "step": 18120
    },
    {
      "epoch": 0.8159683154057338,
      "grad_norm": 2.2609219551086426,
      "learning_rate": 9.184031684594266e-05,
      "loss": 1.0212,
      "step": 18130
    },
    {
      "epoch": 0.8164183806651965,
      "grad_norm": 2.28511118888855,
      "learning_rate": 9.183581619334803e-05,
      "loss": 1.1158,
      "step": 18140
    },
    {
      "epoch": 0.8168684459246591,
      "grad_norm": 1.3743146657943726,
      "learning_rate": 9.183131554075342e-05,
      "loss": 1.1177,
      "step": 18150
    },
    {
      "epoch": 0.8173185111841217,
      "grad_norm": 2.516444444656372,
      "learning_rate": 9.182681488815878e-05,
      "loss": 1.054,
      "step": 18160
    },
    {
      "epoch": 0.8177685764435844,
      "grad_norm": 1.9667718410491943,
      "learning_rate": 9.182231423556417e-05,
      "loss": 1.0631,
      "step": 18170
    },
    {
      "epoch": 0.8182186417030469,
      "grad_norm": 1.8315939903259277,
      "learning_rate": 9.181781358296954e-05,
      "loss": 1.1248,
      "step": 18180
    },
    {
      "epoch": 0.8186687069625096,
      "grad_norm": 1.879372239112854,
      "learning_rate": 9.18133129303749e-05,
      "loss": 1.0044,
      "step": 18190
    },
    {
      "epoch": 0.8191187722219722,
      "grad_norm": 1.356493592262268,
      "learning_rate": 9.180881227778029e-05,
      "loss": 1.0477,
      "step": 18200
    },
    {
      "epoch": 0.8195688374814348,
      "grad_norm": 2.415522813796997,
      "learning_rate": 9.180431162518566e-05,
      "loss": 1.0924,
      "step": 18210
    },
    {
      "epoch": 0.8200189027408974,
      "grad_norm": 1.3609470129013062,
      "learning_rate": 9.179981097259102e-05,
      "loss": 1.0599,
      "step": 18220
    },
    {
      "epoch": 0.8204689680003601,
      "grad_norm": 1.4957048892974854,
      "learning_rate": 9.179531031999641e-05,
      "loss": 1.0512,
      "step": 18230
    },
    {
      "epoch": 0.8209190332598226,
      "grad_norm": 1.5584558248519897,
      "learning_rate": 9.179080966740178e-05,
      "loss": 1.0645,
      "step": 18240
    },
    {
      "epoch": 0.8213690985192853,
      "grad_norm": 1.3284200429916382,
      "learning_rate": 9.178630901480714e-05,
      "loss": 1.0331,
      "step": 18250
    },
    {
      "epoch": 0.8218191637787479,
      "grad_norm": 1.5215480327606201,
      "learning_rate": 9.178180836221253e-05,
      "loss": 0.9942,
      "step": 18260
    },
    {
      "epoch": 0.8222692290382105,
      "grad_norm": 1.7558531761169434,
      "learning_rate": 9.17773077096179e-05,
      "loss": 1.011,
      "step": 18270
    },
    {
      "epoch": 0.8227192942976732,
      "grad_norm": 1.3357348442077637,
      "learning_rate": 9.177280705702326e-05,
      "loss": 1.1398,
      "step": 18280
    },
    {
      "epoch": 0.8231693595571358,
      "grad_norm": 1.423658847808838,
      "learning_rate": 9.176830640442865e-05,
      "loss": 1.1369,
      "step": 18290
    },
    {
      "epoch": 0.8236194248165984,
      "grad_norm": 2.4451725482940674,
      "learning_rate": 9.176380575183402e-05,
      "loss": 1.0191,
      "step": 18300
    },
    {
      "epoch": 0.824069490076061,
      "grad_norm": 2.298889398574829,
      "learning_rate": 9.175930509923938e-05,
      "loss": 1.0145,
      "step": 18310
    },
    {
      "epoch": 0.8245195553355237,
      "grad_norm": 1.2853180170059204,
      "learning_rate": 9.175480444664477e-05,
      "loss": 1.0102,
      "step": 18320
    },
    {
      "epoch": 0.8249696205949862,
      "grad_norm": 1.4246853590011597,
      "learning_rate": 9.175030379405014e-05,
      "loss": 1.0415,
      "step": 18330
    },
    {
      "epoch": 0.8254196858544489,
      "grad_norm": 1.5646723508834839,
      "learning_rate": 9.17458031414555e-05,
      "loss": 1.0596,
      "step": 18340
    },
    {
      "epoch": 0.8258697511139115,
      "grad_norm": 1.4648892879486084,
      "learning_rate": 9.174130248886089e-05,
      "loss": 1.0261,
      "step": 18350
    },
    {
      "epoch": 0.8263198163733741,
      "grad_norm": 1.644770860671997,
      "learning_rate": 9.173680183626627e-05,
      "loss": 1.0538,
      "step": 18360
    },
    {
      "epoch": 0.8267698816328367,
      "grad_norm": 1.6040325164794922,
      "learning_rate": 9.173230118367163e-05,
      "loss": 1.0833,
      "step": 18370
    },
    {
      "epoch": 0.8272199468922994,
      "grad_norm": 1.7377842664718628,
      "learning_rate": 9.172780053107701e-05,
      "loss": 1.1114,
      "step": 18380
    },
    {
      "epoch": 0.8276700121517621,
      "grad_norm": 1.5622271299362183,
      "learning_rate": 9.172329987848239e-05,
      "loss": 1.0167,
      "step": 18390
    },
    {
      "epoch": 0.8281200774112246,
      "grad_norm": 1.200854778289795,
      "learning_rate": 9.171879922588775e-05,
      "loss": 1.0711,
      "step": 18400
    },
    {
      "epoch": 0.8285701426706873,
      "grad_norm": 2.957777500152588,
      "learning_rate": 9.171429857329313e-05,
      "loss": 0.9895,
      "step": 18410
    },
    {
      "epoch": 0.8290202079301499,
      "grad_norm": 1.346205472946167,
      "learning_rate": 9.170979792069851e-05,
      "loss": 1.0986,
      "step": 18420
    },
    {
      "epoch": 0.8294702731896125,
      "grad_norm": 2.852877140045166,
      "learning_rate": 9.170529726810388e-05,
      "loss": 1.0718,
      "step": 18430
    },
    {
      "epoch": 0.8299203384490751,
      "grad_norm": 1.2672417163848877,
      "learning_rate": 9.170079661550925e-05,
      "loss": 1.0215,
      "step": 18440
    },
    {
      "epoch": 0.8303704037085378,
      "grad_norm": 3.0820019245147705,
      "learning_rate": 9.169629596291463e-05,
      "loss": 1.155,
      "step": 18450
    },
    {
      "epoch": 0.8308204689680003,
      "grad_norm": 2.1661672592163086,
      "learning_rate": 9.169179531032e-05,
      "loss": 1.0069,
      "step": 18460
    },
    {
      "epoch": 0.831270534227463,
      "grad_norm": 1.8529391288757324,
      "learning_rate": 9.168729465772538e-05,
      "loss": 1.0267,
      "step": 18470
    },
    {
      "epoch": 0.8317205994869256,
      "grad_norm": 1.9457056522369385,
      "learning_rate": 9.168279400513075e-05,
      "loss": 1.0332,
      "step": 18480
    },
    {
      "epoch": 0.8321706647463882,
      "grad_norm": 1.554168939590454,
      "learning_rate": 9.167829335253612e-05,
      "loss": 1.0369,
      "step": 18490
    },
    {
      "epoch": 0.8326207300058508,
      "grad_norm": 1.353276252746582,
      "learning_rate": 9.16737926999415e-05,
      "loss": 1.0709,
      "step": 18500
    },
    {
      "epoch": 0.8330707952653135,
      "grad_norm": 1.1017887592315674,
      "learning_rate": 9.166929204734687e-05,
      "loss": 1.0907,
      "step": 18510
    },
    {
      "epoch": 0.8335208605247761,
      "grad_norm": 1.5639684200286865,
      "learning_rate": 9.166479139475224e-05,
      "loss": 1.0792,
      "step": 18520
    },
    {
      "epoch": 0.8339709257842387,
      "grad_norm": 1.5227149724960327,
      "learning_rate": 9.166029074215762e-05,
      "loss": 1.0123,
      "step": 18530
    },
    {
      "epoch": 0.8344209910437014,
      "grad_norm": 1.4645711183547974,
      "learning_rate": 9.165579008956299e-05,
      "loss": 1.0773,
      "step": 18540
    },
    {
      "epoch": 0.8348710563031639,
      "grad_norm": 1.8539446592330933,
      "learning_rate": 9.165128943696836e-05,
      "loss": 1.0534,
      "step": 18550
    },
    {
      "epoch": 0.8353211215626266,
      "grad_norm": 1.646801233291626,
      "learning_rate": 9.164678878437374e-05,
      "loss": 1.0398,
      "step": 18560
    },
    {
      "epoch": 0.8357711868220892,
      "grad_norm": 1.6282997131347656,
      "learning_rate": 9.164228813177911e-05,
      "loss": 1.0707,
      "step": 18570
    },
    {
      "epoch": 0.8362212520815518,
      "grad_norm": 2.113568067550659,
      "learning_rate": 9.163778747918449e-05,
      "loss": 1.0701,
      "step": 18580
    },
    {
      "epoch": 0.8366713173410144,
      "grad_norm": 1.4767162799835205,
      "learning_rate": 9.163328682658986e-05,
      "loss": 1.063,
      "step": 18590
    },
    {
      "epoch": 0.8371213826004771,
      "grad_norm": 2.163450002670288,
      "learning_rate": 9.162878617399523e-05,
      "loss": 0.9911,
      "step": 18600
    },
    {
      "epoch": 0.8375714478599396,
      "grad_norm": 1.78705632686615,
      "learning_rate": 9.16242855214006e-05,
      "loss": 1.0901,
      "step": 18610
    },
    {
      "epoch": 0.8380215131194023,
      "grad_norm": 1.3725417852401733,
      "learning_rate": 9.161978486880598e-05,
      "loss": 1.0012,
      "step": 18620
    },
    {
      "epoch": 0.838471578378865,
      "grad_norm": 1.8250789642333984,
      "learning_rate": 9.161528421621135e-05,
      "loss": 1.0992,
      "step": 18630
    },
    {
      "epoch": 0.8389216436383276,
      "grad_norm": 1.1157008409500122,
      "learning_rate": 9.161078356361673e-05,
      "loss": 1.0334,
      "step": 18640
    },
    {
      "epoch": 0.8393717088977902,
      "grad_norm": 1.1221582889556885,
      "learning_rate": 9.16062829110221e-05,
      "loss": 1.0216,
      "step": 18650
    },
    {
      "epoch": 0.8398217741572528,
      "grad_norm": 1.5678414106369019,
      "learning_rate": 9.160178225842747e-05,
      "loss": 1.0387,
      "step": 18660
    },
    {
      "epoch": 0.8402718394167155,
      "grad_norm": 1.1805710792541504,
      "learning_rate": 9.159728160583285e-05,
      "loss": 1.0585,
      "step": 18670
    },
    {
      "epoch": 0.840721904676178,
      "grad_norm": 1.5491586923599243,
      "learning_rate": 9.159278095323822e-05,
      "loss": 1.0661,
      "step": 18680
    },
    {
      "epoch": 0.8411719699356407,
      "grad_norm": 1.7975964546203613,
      "learning_rate": 9.158828030064361e-05,
      "loss": 1.0421,
      "step": 18690
    },
    {
      "epoch": 0.8416220351951033,
      "grad_norm": 2.0822861194610596,
      "learning_rate": 9.158377964804897e-05,
      "loss": 1.0527,
      "step": 18700
    },
    {
      "epoch": 0.8420721004545659,
      "grad_norm": 2.09281325340271,
      "learning_rate": 9.157927899545434e-05,
      "loss": 1.0712,
      "step": 18710
    },
    {
      "epoch": 0.8425221657140285,
      "grad_norm": 1.4107091426849365,
      "learning_rate": 9.157477834285973e-05,
      "loss": 1.0975,
      "step": 18720
    },
    {
      "epoch": 0.8429722309734912,
      "grad_norm": 1.974277138710022,
      "learning_rate": 9.157027769026509e-05,
      "loss": 1.0525,
      "step": 18730
    },
    {
      "epoch": 0.8434222962329537,
      "grad_norm": 1.4601943492889404,
      "learning_rate": 9.156577703767046e-05,
      "loss": 1.0722,
      "step": 18740
    },
    {
      "epoch": 0.8438723614924164,
      "grad_norm": 1.9197051525115967,
      "learning_rate": 9.156127638507585e-05,
      "loss": 1.0978,
      "step": 18750
    },
    {
      "epoch": 0.8443224267518791,
      "grad_norm": 1.2861618995666504,
      "learning_rate": 9.155677573248121e-05,
      "loss": 1.1089,
      "step": 18760
    },
    {
      "epoch": 0.8447724920113416,
      "grad_norm": 1.597823977470398,
      "learning_rate": 9.155227507988658e-05,
      "loss": 1.0113,
      "step": 18770
    },
    {
      "epoch": 0.8452225572708043,
      "grad_norm": 1.600428819656372,
      "learning_rate": 9.154777442729197e-05,
      "loss": 1.0719,
      "step": 18780
    },
    {
      "epoch": 0.8456726225302669,
      "grad_norm": 1.4415456056594849,
      "learning_rate": 9.154327377469733e-05,
      "loss": 1.0833,
      "step": 18790
    },
    {
      "epoch": 0.8461226877897295,
      "grad_norm": 3.1591808795928955,
      "learning_rate": 9.15387731221027e-05,
      "loss": 1.0112,
      "step": 18800
    },
    {
      "epoch": 0.8465727530491921,
      "grad_norm": 1.1712723970413208,
      "learning_rate": 9.153427246950809e-05,
      "loss": 1.0678,
      "step": 18810
    },
    {
      "epoch": 0.8470228183086548,
      "grad_norm": 2.0434646606445312,
      "learning_rate": 9.152977181691345e-05,
      "loss": 1.0735,
      "step": 18820
    },
    {
      "epoch": 0.8474728835681173,
      "grad_norm": 1.5035570859909058,
      "learning_rate": 9.152527116431883e-05,
      "loss": 1.1213,
      "step": 18830
    },
    {
      "epoch": 0.84792294882758,
      "grad_norm": 2.105663537979126,
      "learning_rate": 9.152077051172421e-05,
      "loss": 1.1549,
      "step": 18840
    },
    {
      "epoch": 0.8483730140870426,
      "grad_norm": 1.8644739389419556,
      "learning_rate": 9.151626985912957e-05,
      "loss": 1.0224,
      "step": 18850
    },
    {
      "epoch": 0.8488230793465052,
      "grad_norm": 1.5160419940948486,
      "learning_rate": 9.151176920653495e-05,
      "loss": 1.0197,
      "step": 18860
    },
    {
      "epoch": 0.8492731446059678,
      "grad_norm": 1.3848224878311157,
      "learning_rate": 9.150726855394033e-05,
      "loss": 1.1088,
      "step": 18870
    },
    {
      "epoch": 0.8497232098654305,
      "grad_norm": 1.3124569654464722,
      "learning_rate": 9.150276790134569e-05,
      "loss": 1.0471,
      "step": 18880
    },
    {
      "epoch": 0.8501732751248932,
      "grad_norm": 1.8419564962387085,
      "learning_rate": 9.149826724875107e-05,
      "loss": 1.0888,
      "step": 18890
    },
    {
      "epoch": 0.8506233403843557,
      "grad_norm": 1.979800820350647,
      "learning_rate": 9.149376659615645e-05,
      "loss": 1.0881,
      "step": 18900
    },
    {
      "epoch": 0.8510734056438184,
      "grad_norm": 1.677323579788208,
      "learning_rate": 9.148926594356181e-05,
      "loss": 1.0994,
      "step": 18910
    },
    {
      "epoch": 0.851523470903281,
      "grad_norm": 2.51446795463562,
      "learning_rate": 9.148476529096719e-05,
      "loss": 1.0027,
      "step": 18920
    },
    {
      "epoch": 0.8519735361627436,
      "grad_norm": 1.0734180212020874,
      "learning_rate": 9.148026463837257e-05,
      "loss": 1.0204,
      "step": 18930
    },
    {
      "epoch": 0.8524236014222062,
      "grad_norm": 1.8158451318740845,
      "learning_rate": 9.147576398577793e-05,
      "loss": 1.051,
      "step": 18940
    },
    {
      "epoch": 0.8528736666816689,
      "grad_norm": 2.252068519592285,
      "learning_rate": 9.147126333318332e-05,
      "loss": 1.062,
      "step": 18950
    },
    {
      "epoch": 0.8533237319411314,
      "grad_norm": 1.5428425073623657,
      "learning_rate": 9.14667626805887e-05,
      "loss": 1.0676,
      "step": 18960
    },
    {
      "epoch": 0.8537737972005941,
      "grad_norm": 1.5195064544677734,
      "learning_rate": 9.146226202799406e-05,
      "loss": 1.0353,
      "step": 18970
    },
    {
      "epoch": 0.8542238624600567,
      "grad_norm": 1.66457200050354,
      "learning_rate": 9.145776137539944e-05,
      "loss": 1.0242,
      "step": 18980
    },
    {
      "epoch": 0.8546739277195193,
      "grad_norm": 1.9423506259918213,
      "learning_rate": 9.145326072280482e-05,
      "loss": 1.1116,
      "step": 18990
    },
    {
      "epoch": 0.855123992978982,
      "grad_norm": 2.3121297359466553,
      "learning_rate": 9.144876007021018e-05,
      "loss": 1.0797,
      "step": 19000
    },
    {
      "epoch": 0.8555740582384446,
      "grad_norm": 2.428179979324341,
      "learning_rate": 9.144425941761556e-05,
      "loss": 1.0837,
      "step": 19010
    },
    {
      "epoch": 0.8560241234979072,
      "grad_norm": 1.5447797775268555,
      "learning_rate": 9.143975876502094e-05,
      "loss": 1.1009,
      "step": 19020
    },
    {
      "epoch": 0.8564741887573698,
      "grad_norm": 1.5078959465026855,
      "learning_rate": 9.14352581124263e-05,
      "loss": 1.1165,
      "step": 19030
    },
    {
      "epoch": 0.8569242540168325,
      "grad_norm": 1.8280538320541382,
      "learning_rate": 9.143075745983168e-05,
      "loss": 1.1,
      "step": 19040
    },
    {
      "epoch": 0.857374319276295,
      "grad_norm": 1.6023149490356445,
      "learning_rate": 9.142625680723706e-05,
      "loss": 1.0579,
      "step": 19050
    },
    {
      "epoch": 0.8578243845357577,
      "grad_norm": 1.7508265972137451,
      "learning_rate": 9.142175615464242e-05,
      "loss": 1.0444,
      "step": 19060
    },
    {
      "epoch": 0.8582744497952203,
      "grad_norm": 2.010207176208496,
      "learning_rate": 9.14172555020478e-05,
      "loss": 1.0682,
      "step": 19070
    },
    {
      "epoch": 0.858724515054683,
      "grad_norm": 2.4962406158447266,
      "learning_rate": 9.141275484945318e-05,
      "loss": 1.037,
      "step": 19080
    },
    {
      "epoch": 0.8591745803141455,
      "grad_norm": 1.4821488857269287,
      "learning_rate": 9.140825419685854e-05,
      "loss": 1.0689,
      "step": 19090
    },
    {
      "epoch": 0.8596246455736082,
      "grad_norm": 1.6460996866226196,
      "learning_rate": 9.140375354426393e-05,
      "loss": 1.1161,
      "step": 19100
    },
    {
      "epoch": 0.8600747108330707,
      "grad_norm": 1.9698542356491089,
      "learning_rate": 9.13992528916693e-05,
      "loss": 1.0483,
      "step": 19110
    },
    {
      "epoch": 0.8605247760925334,
      "grad_norm": 1.1426762342453003,
      "learning_rate": 9.139475223907466e-05,
      "loss": 1.0731,
      "step": 19120
    },
    {
      "epoch": 0.8609748413519961,
      "grad_norm": 2.0715298652648926,
      "learning_rate": 9.139025158648005e-05,
      "loss": 1.0579,
      "step": 19130
    },
    {
      "epoch": 0.8614249066114587,
      "grad_norm": 1.9239649772644043,
      "learning_rate": 9.138575093388542e-05,
      "loss": 1.0592,
      "step": 19140
    },
    {
      "epoch": 0.8618749718709213,
      "grad_norm": 1.8174502849578857,
      "learning_rate": 9.138125028129078e-05,
      "loss": 1.0642,
      "step": 19150
    },
    {
      "epoch": 0.8623250371303839,
      "grad_norm": 2.2041397094726562,
      "learning_rate": 9.137674962869617e-05,
      "loss": 1.0137,
      "step": 19160
    },
    {
      "epoch": 0.8627751023898466,
      "grad_norm": 1.5126588344573975,
      "learning_rate": 9.137224897610154e-05,
      "loss": 1.0837,
      "step": 19170
    },
    {
      "epoch": 0.8632251676493091,
      "grad_norm": 2.07831072807312,
      "learning_rate": 9.13677483235069e-05,
      "loss": 1.0685,
      "step": 19180
    },
    {
      "epoch": 0.8636752329087718,
      "grad_norm": 2.2269861698150635,
      "learning_rate": 9.136324767091229e-05,
      "loss": 1.0598,
      "step": 19190
    },
    {
      "epoch": 0.8641252981682344,
      "grad_norm": 1.7019709348678589,
      "learning_rate": 9.135874701831766e-05,
      "loss": 1.0624,
      "step": 19200
    },
    {
      "epoch": 0.864575363427697,
      "grad_norm": 1.637366771697998,
      "learning_rate": 9.135424636572304e-05,
      "loss": 1.0958,
      "step": 19210
    },
    {
      "epoch": 0.8650254286871596,
      "grad_norm": 2.6042866706848145,
      "learning_rate": 9.134974571312841e-05,
      "loss": 1.0253,
      "step": 19220
    },
    {
      "epoch": 0.8654754939466223,
      "grad_norm": 1.3846280574798584,
      "learning_rate": 9.134524506053378e-05,
      "loss": 1.017,
      "step": 19230
    },
    {
      "epoch": 0.8659255592060848,
      "grad_norm": 1.6189630031585693,
      "learning_rate": 9.134074440793916e-05,
      "loss": 1.0524,
      "step": 19240
    },
    {
      "epoch": 0.8663756244655475,
      "grad_norm": 1.6955229043960571,
      "learning_rate": 9.133624375534453e-05,
      "loss": 1.0867,
      "step": 19250
    },
    {
      "epoch": 0.8668256897250102,
      "grad_norm": 2.563250780105591,
      "learning_rate": 9.13317431027499e-05,
      "loss": 1.0145,
      "step": 19260
    },
    {
      "epoch": 0.8672757549844727,
      "grad_norm": 1.7079646587371826,
      "learning_rate": 9.132724245015528e-05,
      "loss": 1.0391,
      "step": 19270
    },
    {
      "epoch": 0.8677258202439354,
      "grad_norm": 2.1673195362091064,
      "learning_rate": 9.132274179756065e-05,
      "loss": 0.9964,
      "step": 19280
    },
    {
      "epoch": 0.868175885503398,
      "grad_norm": 1.9322559833526611,
      "learning_rate": 9.131824114496602e-05,
      "loss": 1.0048,
      "step": 19290
    },
    {
      "epoch": 0.8686259507628606,
      "grad_norm": 1.5426220893859863,
      "learning_rate": 9.13137404923714e-05,
      "loss": 1.0534,
      "step": 19300
    },
    {
      "epoch": 0.8690760160223232,
      "grad_norm": 1.6408054828643799,
      "learning_rate": 9.130923983977677e-05,
      "loss": 1.0807,
      "step": 19310
    },
    {
      "epoch": 0.8695260812817859,
      "grad_norm": 2.0222175121307373,
      "learning_rate": 9.130473918718215e-05,
      "loss": 1.0788,
      "step": 19320
    },
    {
      "epoch": 0.8699761465412484,
      "grad_norm": 2.173292875289917,
      "learning_rate": 9.130023853458752e-05,
      "loss": 1.0053,
      "step": 19330
    },
    {
      "epoch": 0.8704262118007111,
      "grad_norm": 1.5524832010269165,
      "learning_rate": 9.129573788199289e-05,
      "loss": 1.054,
      "step": 19340
    },
    {
      "epoch": 0.8708762770601737,
      "grad_norm": 1.9200599193572998,
      "learning_rate": 9.129123722939827e-05,
      "loss": 1.0737,
      "step": 19350
    },
    {
      "epoch": 0.8713263423196363,
      "grad_norm": 2.544309377670288,
      "learning_rate": 9.128673657680364e-05,
      "loss": 1.072,
      "step": 19360
    },
    {
      "epoch": 0.871776407579099,
      "grad_norm": 1.9030474424362183,
      "learning_rate": 9.128223592420901e-05,
      "loss": 1.0691,
      "step": 19370
    },
    {
      "epoch": 0.8722264728385616,
      "grad_norm": 1.981318473815918,
      "learning_rate": 9.127773527161439e-05,
      "loss": 1.0453,
      "step": 19380
    },
    {
      "epoch": 0.8726765380980243,
      "grad_norm": 1.6358752250671387,
      "learning_rate": 9.127323461901976e-05,
      "loss": 1.1376,
      "step": 19390
    },
    {
      "epoch": 0.8731266033574868,
      "grad_norm": 1.541395664215088,
      "learning_rate": 9.126873396642513e-05,
      "loss": 1.2,
      "step": 19400
    },
    {
      "epoch": 0.8735766686169495,
      "grad_norm": 1.7001943588256836,
      "learning_rate": 9.126423331383051e-05,
      "loss": 1.025,
      "step": 19410
    },
    {
      "epoch": 0.874026733876412,
      "grad_norm": 1.9897011518478394,
      "learning_rate": 9.125973266123588e-05,
      "loss": 1.095,
      "step": 19420
    },
    {
      "epoch": 0.8744767991358747,
      "grad_norm": 1.8610124588012695,
      "learning_rate": 9.125523200864125e-05,
      "loss": 1.0075,
      "step": 19430
    },
    {
      "epoch": 0.8749268643953373,
      "grad_norm": 2.1929352283477783,
      "learning_rate": 9.125073135604663e-05,
      "loss": 1.0176,
      "step": 19440
    },
    {
      "epoch": 0.8753769296548,
      "grad_norm": 1.1804320812225342,
      "learning_rate": 9.1246230703452e-05,
      "loss": 1.059,
      "step": 19450
    },
    {
      "epoch": 0.8758269949142625,
      "grad_norm": 1.4476723670959473,
      "learning_rate": 9.124173005085738e-05,
      "loss": 1.0492,
      "step": 19460
    },
    {
      "epoch": 0.8762770601737252,
      "grad_norm": 1.4936046600341797,
      "learning_rate": 9.123722939826276e-05,
      "loss": 1.1163,
      "step": 19470
    },
    {
      "epoch": 0.8767271254331878,
      "grad_norm": 1.328946828842163,
      "learning_rate": 9.123272874566812e-05,
      "loss": 1.0092,
      "step": 19480
    },
    {
      "epoch": 0.8771771906926504,
      "grad_norm": 2.052910804748535,
      "learning_rate": 9.12282280930735e-05,
      "loss": 1.0224,
      "step": 19490
    },
    {
      "epoch": 0.8776272559521131,
      "grad_norm": 1.8149363994598389,
      "learning_rate": 9.122372744047888e-05,
      "loss": 1.121,
      "step": 19500
    },
    {
      "epoch": 0.8780773212115757,
      "grad_norm": 1.6463525295257568,
      "learning_rate": 9.121922678788424e-05,
      "loss": 1.1168,
      "step": 19510
    },
    {
      "epoch": 0.8785273864710383,
      "grad_norm": 2.5806033611297607,
      "learning_rate": 9.121472613528962e-05,
      "loss": 1.1264,
      "step": 19520
    },
    {
      "epoch": 0.8789774517305009,
      "grad_norm": 1.5216068029403687,
      "learning_rate": 9.1210225482695e-05,
      "loss": 1.0805,
      "step": 19530
    },
    {
      "epoch": 0.8794275169899636,
      "grad_norm": 1.987491250038147,
      "learning_rate": 9.120572483010036e-05,
      "loss": 1.0305,
      "step": 19540
    },
    {
      "epoch": 0.8798775822494261,
      "grad_norm": 1.8251241445541382,
      "learning_rate": 9.120122417750574e-05,
      "loss": 1.0668,
      "step": 19550
    },
    {
      "epoch": 0.8803276475088888,
      "grad_norm": 1.4320204257965088,
      "learning_rate": 9.119672352491113e-05,
      "loss": 1.0361,
      "step": 19560
    },
    {
      "epoch": 0.8807777127683514,
      "grad_norm": 1.5332543849945068,
      "learning_rate": 9.119222287231649e-05,
      "loss": 1.0949,
      "step": 19570
    },
    {
      "epoch": 0.881227778027814,
      "grad_norm": 2.045258045196533,
      "learning_rate": 9.118772221972186e-05,
      "loss": 0.9939,
      "step": 19580
    },
    {
      "epoch": 0.8816778432872766,
      "grad_norm": 2.394517183303833,
      "learning_rate": 9.118322156712725e-05,
      "loss": 1.0187,
      "step": 19590
    },
    {
      "epoch": 0.8821279085467393,
      "grad_norm": 1.378005027770996,
      "learning_rate": 9.11787209145326e-05,
      "loss": 1.0687,
      "step": 19600
    },
    {
      "epoch": 0.882577973806202,
      "grad_norm": 1.4289847612380981,
      "learning_rate": 9.117422026193798e-05,
      "loss": 1.0544,
      "step": 19610
    },
    {
      "epoch": 0.8830280390656645,
      "grad_norm": 1.0435150861740112,
      "learning_rate": 9.116971960934337e-05,
      "loss": 0.9914,
      "step": 19620
    },
    {
      "epoch": 0.8834781043251272,
      "grad_norm": 1.3923532962799072,
      "learning_rate": 9.116521895674873e-05,
      "loss": 1.0145,
      "step": 19630
    },
    {
      "epoch": 0.8839281695845898,
      "grad_norm": 1.7653474807739258,
      "learning_rate": 9.11607183041541e-05,
      "loss": 1.0852,
      "step": 19640
    },
    {
      "epoch": 0.8843782348440524,
      "grad_norm": 2.001459836959839,
      "learning_rate": 9.115621765155949e-05,
      "loss": 0.988,
      "step": 19650
    },
    {
      "epoch": 0.884828300103515,
      "grad_norm": 1.6593526601791382,
      "learning_rate": 9.115171699896485e-05,
      "loss": 1.0311,
      "step": 19660
    },
    {
      "epoch": 0.8852783653629777,
      "grad_norm": 2.5888609886169434,
      "learning_rate": 9.114721634637022e-05,
      "loss": 1.0323,
      "step": 19670
    },
    {
      "epoch": 0.8857284306224402,
      "grad_norm": 1.39340078830719,
      "learning_rate": 9.114271569377561e-05,
      "loss": 0.9122,
      "step": 19680
    },
    {
      "epoch": 0.8861784958819029,
      "grad_norm": 2.7631592750549316,
      "learning_rate": 9.113821504118097e-05,
      "loss": 1.045,
      "step": 19690
    },
    {
      "epoch": 0.8866285611413655,
      "grad_norm": 1.6615060567855835,
      "learning_rate": 9.113371438858634e-05,
      "loss": 1.1143,
      "step": 19700
    },
    {
      "epoch": 0.8870786264008281,
      "grad_norm": 1.3842970132827759,
      "learning_rate": 9.112921373599173e-05,
      "loss": 0.9978,
      "step": 19710
    },
    {
      "epoch": 0.8875286916602907,
      "grad_norm": 0.9976546764373779,
      "learning_rate": 9.112471308339709e-05,
      "loss": 1.0726,
      "step": 19720
    },
    {
      "epoch": 0.8879787569197534,
      "grad_norm": 1.761220097541809,
      "learning_rate": 9.112021243080248e-05,
      "loss": 1.1252,
      "step": 19730
    },
    {
      "epoch": 0.888428822179216,
      "grad_norm": 1.5245921611785889,
      "learning_rate": 9.111571177820785e-05,
      "loss": 0.9763,
      "step": 19740
    },
    {
      "epoch": 0.8888788874386786,
      "grad_norm": 1.629105567932129,
      "learning_rate": 9.111121112561321e-05,
      "loss": 1.0347,
      "step": 19750
    },
    {
      "epoch": 0.8893289526981413,
      "grad_norm": 1.3739590644836426,
      "learning_rate": 9.11067104730186e-05,
      "loss": 1.0383,
      "step": 19760
    },
    {
      "epoch": 0.8897790179576038,
      "grad_norm": 1.2662639617919922,
      "learning_rate": 9.110220982042397e-05,
      "loss": 1.0728,
      "step": 19770
    },
    {
      "epoch": 0.8902290832170665,
      "grad_norm": 1.7855851650238037,
      "learning_rate": 9.109770916782933e-05,
      "loss": 1.0771,
      "step": 19780
    },
    {
      "epoch": 0.8906791484765291,
      "grad_norm": 1.9657959938049316,
      "learning_rate": 9.109320851523472e-05,
      "loss": 0.9833,
      "step": 19790
    },
    {
      "epoch": 0.8911292137359917,
      "grad_norm": 1.966894268989563,
      "learning_rate": 9.108870786264009e-05,
      "loss": 0.9976,
      "step": 19800
    },
    {
      "epoch": 0.8915792789954543,
      "grad_norm": 1.6616013050079346,
      "learning_rate": 9.108420721004545e-05,
      "loss": 1.1803,
      "step": 19810
    },
    {
      "epoch": 0.892029344254917,
      "grad_norm": 1.5042799711227417,
      "learning_rate": 9.107970655745084e-05,
      "loss": 0.9966,
      "step": 19820
    },
    {
      "epoch": 0.8924794095143795,
      "grad_norm": 1.8502836227416992,
      "learning_rate": 9.107520590485621e-05,
      "loss": 1.0796,
      "step": 19830
    },
    {
      "epoch": 0.8929294747738422,
      "grad_norm": 1.8043385744094849,
      "learning_rate": 9.107070525226157e-05,
      "loss": 1.0356,
      "step": 19840
    },
    {
      "epoch": 0.8933795400333048,
      "grad_norm": 1.8978239297866821,
      "learning_rate": 9.106620459966696e-05,
      "loss": 0.9983,
      "step": 19850
    },
    {
      "epoch": 0.8938296052927674,
      "grad_norm": 1.0849920511245728,
      "learning_rate": 9.106170394707233e-05,
      "loss": 0.9879,
      "step": 19860
    },
    {
      "epoch": 0.8942796705522301,
      "grad_norm": 1.5813463926315308,
      "learning_rate": 9.10572032944777e-05,
      "loss": 0.9971,
      "step": 19870
    },
    {
      "epoch": 0.8947297358116927,
      "grad_norm": 1.7852543592453003,
      "learning_rate": 9.105270264188308e-05,
      "loss": 1.1071,
      "step": 19880
    },
    {
      "epoch": 0.8951798010711554,
      "grad_norm": 1.5875380039215088,
      "learning_rate": 9.104820198928845e-05,
      "loss": 1.0508,
      "step": 19890
    },
    {
      "epoch": 0.8956298663306179,
      "grad_norm": 2.6379778385162354,
      "learning_rate": 9.104370133669381e-05,
      "loss": 1.1044,
      "step": 19900
    },
    {
      "epoch": 0.8960799315900806,
      "grad_norm": 2.184671401977539,
      "learning_rate": 9.10392006840992e-05,
      "loss": 1.1157,
      "step": 19910
    },
    {
      "epoch": 0.8965299968495432,
      "grad_norm": 1.5291006565093994,
      "learning_rate": 9.103470003150457e-05,
      "loss": 0.9904,
      "step": 19920
    },
    {
      "epoch": 0.8969800621090058,
      "grad_norm": 2.015031099319458,
      "learning_rate": 9.103019937890994e-05,
      "loss": 1.0339,
      "step": 19930
    },
    {
      "epoch": 0.8974301273684684,
      "grad_norm": 1.2175989151000977,
      "learning_rate": 9.102569872631532e-05,
      "loss": 1.0202,
      "step": 19940
    },
    {
      "epoch": 0.8978801926279311,
      "grad_norm": 1.8941988945007324,
      "learning_rate": 9.10211980737207e-05,
      "loss": 1.0669,
      "step": 19950
    },
    {
      "epoch": 0.8983302578873936,
      "grad_norm": 2.4449033737182617,
      "learning_rate": 9.101669742112606e-05,
      "loss": 1.0904,
      "step": 19960
    },
    {
      "epoch": 0.8987803231468563,
      "grad_norm": 3.0526533126831055,
      "learning_rate": 9.101219676853144e-05,
      "loss": 0.9782,
      "step": 19970
    },
    {
      "epoch": 0.899230388406319,
      "grad_norm": 1.4854670763015747,
      "learning_rate": 9.100769611593682e-05,
      "loss": 1.0598,
      "step": 19980
    },
    {
      "epoch": 0.8996804536657815,
      "grad_norm": 1.6857761144638062,
      "learning_rate": 9.100319546334219e-05,
      "loss": 1.1156,
      "step": 19990
    },
    {
      "epoch": 0.9001305189252442,
      "grad_norm": 1.7661076784133911,
      "learning_rate": 9.099869481074756e-05,
      "loss": 1.0161,
      "step": 20000
    },
    {
      "epoch": 0.9005805841847068,
      "grad_norm": 1.9874556064605713,
      "learning_rate": 9.099419415815294e-05,
      "loss": 1.0952,
      "step": 20010
    },
    {
      "epoch": 0.9010306494441694,
      "grad_norm": 1.6687767505645752,
      "learning_rate": 9.098969350555831e-05,
      "loss": 1.0114,
      "step": 20020
    },
    {
      "epoch": 0.901480714703632,
      "grad_norm": 1.8938499689102173,
      "learning_rate": 9.098519285296368e-05,
      "loss": 1.0595,
      "step": 20030
    },
    {
      "epoch": 0.9019307799630947,
      "grad_norm": 1.5763534307479858,
      "learning_rate": 9.098069220036906e-05,
      "loss": 1.0274,
      "step": 20040
    },
    {
      "epoch": 0.9023808452225572,
      "grad_norm": 2.243269205093384,
      "learning_rate": 9.097619154777443e-05,
      "loss": 0.9976,
      "step": 20050
    },
    {
      "epoch": 0.9028309104820199,
      "grad_norm": 2.360457420349121,
      "learning_rate": 9.09716908951798e-05,
      "loss": 1.0256,
      "step": 20060
    },
    {
      "epoch": 0.9032809757414825,
      "grad_norm": 1.663071632385254,
      "learning_rate": 9.096719024258518e-05,
      "loss": 0.9856,
      "step": 20070
    },
    {
      "epoch": 0.9037310410009451,
      "grad_norm": 1.5613455772399902,
      "learning_rate": 9.096268958999055e-05,
      "loss": 0.9902,
      "step": 20080
    },
    {
      "epoch": 0.9041811062604077,
      "grad_norm": 1.860826849937439,
      "learning_rate": 9.095818893739593e-05,
      "loss": 1.0622,
      "step": 20090
    },
    {
      "epoch": 0.9046311715198704,
      "grad_norm": 1.9154059886932373,
      "learning_rate": 9.09536882848013e-05,
      "loss": 1.0378,
      "step": 20100
    },
    {
      "epoch": 0.905081236779333,
      "grad_norm": 1.7107744216918945,
      "learning_rate": 9.094918763220667e-05,
      "loss": 0.9925,
      "step": 20110
    },
    {
      "epoch": 0.9055313020387956,
      "grad_norm": 1.5437499284744263,
      "learning_rate": 9.094468697961205e-05,
      "loss": 1.1053,
      "step": 20120
    },
    {
      "epoch": 0.9059813672982583,
      "grad_norm": 1.9424011707305908,
      "learning_rate": 9.094018632701742e-05,
      "loss": 1.0806,
      "step": 20130
    },
    {
      "epoch": 0.9064314325577209,
      "grad_norm": 1.643545389175415,
      "learning_rate": 9.09356856744228e-05,
      "loss": 0.9889,
      "step": 20140
    },
    {
      "epoch": 0.9068814978171835,
      "grad_norm": 1.2183033227920532,
      "learning_rate": 9.093118502182817e-05,
      "loss": 1.1267,
      "step": 20150
    },
    {
      "epoch": 0.9073315630766461,
      "grad_norm": 1.5517213344573975,
      "learning_rate": 9.092668436923354e-05,
      "loss": 1.0778,
      "step": 20160
    },
    {
      "epoch": 0.9077816283361088,
      "grad_norm": 1.9136033058166504,
      "learning_rate": 9.092218371663892e-05,
      "loss": 1.1184,
      "step": 20170
    },
    {
      "epoch": 0.9082316935955713,
      "grad_norm": 1.9367839097976685,
      "learning_rate": 9.091768306404429e-05,
      "loss": 1.1419,
      "step": 20180
    },
    {
      "epoch": 0.908681758855034,
      "grad_norm": 2.5018177032470703,
      "learning_rate": 9.091318241144966e-05,
      "loss": 1.0813,
      "step": 20190
    },
    {
      "epoch": 0.9091318241144966,
      "grad_norm": 1.4521721601486206,
      "learning_rate": 9.090868175885504e-05,
      "loss": 1.0495,
      "step": 20200
    },
    {
      "epoch": 0.9095818893739592,
      "grad_norm": 1.5532124042510986,
      "learning_rate": 9.090418110626041e-05,
      "loss": 0.9427,
      "step": 20210
    },
    {
      "epoch": 0.9100319546334218,
      "grad_norm": 2.846764326095581,
      "learning_rate": 9.089968045366578e-05,
      "loss": 1.0681,
      "step": 20220
    },
    {
      "epoch": 0.9104820198928845,
      "grad_norm": 2.4777941703796387,
      "learning_rate": 9.089517980107116e-05,
      "loss": 1.1089,
      "step": 20230
    },
    {
      "epoch": 0.9109320851523471,
      "grad_norm": 1.2238833904266357,
      "learning_rate": 9.089067914847653e-05,
      "loss": 0.9976,
      "step": 20240
    },
    {
      "epoch": 0.9113821504118097,
      "grad_norm": 1.1865975856781006,
      "learning_rate": 9.08861784958819e-05,
      "loss": 1.0065,
      "step": 20250
    },
    {
      "epoch": 0.9118322156712724,
      "grad_norm": 1.4781761169433594,
      "learning_rate": 9.088167784328728e-05,
      "loss": 0.9466,
      "step": 20260
    },
    {
      "epoch": 0.9122822809307349,
      "grad_norm": 2.8662633895874023,
      "learning_rate": 9.087717719069265e-05,
      "loss": 1.0566,
      "step": 20270
    },
    {
      "epoch": 0.9127323461901976,
      "grad_norm": 2.465616464614868,
      "learning_rate": 9.087267653809804e-05,
      "loss": 1.1754,
      "step": 20280
    },
    {
      "epoch": 0.9131824114496602,
      "grad_norm": 1.7475106716156006,
      "learning_rate": 9.08681758855034e-05,
      "loss": 1.0507,
      "step": 20290
    },
    {
      "epoch": 0.9136324767091228,
      "grad_norm": 1.9277433156967163,
      "learning_rate": 9.086367523290877e-05,
      "loss": 1.0716,
      "step": 20300
    },
    {
      "epoch": 0.9140825419685854,
      "grad_norm": 1.9367395639419556,
      "learning_rate": 9.085917458031416e-05,
      "loss": 0.9948,
      "step": 20310
    },
    {
      "epoch": 0.9145326072280481,
      "grad_norm": 1.6748020648956299,
      "learning_rate": 9.085467392771952e-05,
      "loss": 1.0708,
      "step": 20320
    },
    {
      "epoch": 0.9149826724875106,
      "grad_norm": 1.6939880847930908,
      "learning_rate": 9.085017327512489e-05,
      "loss": 1.0321,
      "step": 20330
    },
    {
      "epoch": 0.9154327377469733,
      "grad_norm": 1.7680162191390991,
      "learning_rate": 9.084567262253028e-05,
      "loss": 0.9867,
      "step": 20340
    },
    {
      "epoch": 0.915882803006436,
      "grad_norm": 1.3986964225769043,
      "learning_rate": 9.084117196993564e-05,
      "loss": 1.0403,
      "step": 20350
    },
    {
      "epoch": 0.9163328682658985,
      "grad_norm": 2.5274152755737305,
      "learning_rate": 9.083667131734101e-05,
      "loss": 1.0784,
      "step": 20360
    },
    {
      "epoch": 0.9167829335253612,
      "grad_norm": 2.453073740005493,
      "learning_rate": 9.08321706647464e-05,
      "loss": 1.1023,
      "step": 20370
    },
    {
      "epoch": 0.9172329987848238,
      "grad_norm": 1.3405280113220215,
      "learning_rate": 9.082767001215176e-05,
      "loss": 1.0636,
      "step": 20380
    },
    {
      "epoch": 0.9176830640442865,
      "grad_norm": 2.9148366451263428,
      "learning_rate": 9.082316935955713e-05,
      "loss": 1.0543,
      "step": 20390
    },
    {
      "epoch": 0.918133129303749,
      "grad_norm": 1.1758766174316406,
      "learning_rate": 9.081866870696252e-05,
      "loss": 1.0868,
      "step": 20400
    },
    {
      "epoch": 0.9185831945632117,
      "grad_norm": 1.174572467803955,
      "learning_rate": 9.081416805436788e-05,
      "loss": 1.013,
      "step": 20410
    },
    {
      "epoch": 0.9190332598226743,
      "grad_norm": 1.5214167833328247,
      "learning_rate": 9.080966740177326e-05,
      "loss": 1.0373,
      "step": 20420
    },
    {
      "epoch": 0.9194833250821369,
      "grad_norm": 1.0545042753219604,
      "learning_rate": 9.080516674917864e-05,
      "loss": 1.0269,
      "step": 20430
    },
    {
      "epoch": 0.9199333903415995,
      "grad_norm": 1.3858543634414673,
      "learning_rate": 9.0800666096584e-05,
      "loss": 1.0514,
      "step": 20440
    },
    {
      "epoch": 0.9203834556010622,
      "grad_norm": 1.8613669872283936,
      "learning_rate": 9.079616544398938e-05,
      "loss": 1.1235,
      "step": 20450
    },
    {
      "epoch": 0.9208335208605247,
      "grad_norm": 1.909008502960205,
      "learning_rate": 9.079166479139476e-05,
      "loss": 1.0014,
      "step": 20460
    },
    {
      "epoch": 0.9212835861199874,
      "grad_norm": 2.129842519760132,
      "learning_rate": 9.078716413880012e-05,
      "loss": 1.0954,
      "step": 20470
    },
    {
      "epoch": 0.9217336513794501,
      "grad_norm": 1.7719430923461914,
      "learning_rate": 9.07826634862055e-05,
      "loss": 1.0342,
      "step": 20480
    },
    {
      "epoch": 0.9221837166389126,
      "grad_norm": 1.3862600326538086,
      "learning_rate": 9.077816283361088e-05,
      "loss": 1.0269,
      "step": 20490
    },
    {
      "epoch": 0.9226337818983753,
      "grad_norm": 1.7184858322143555,
      "learning_rate": 9.077366218101624e-05,
      "loss": 1.1157,
      "step": 20500
    },
    {
      "epoch": 0.9230838471578379,
      "grad_norm": 2.0840039253234863,
      "learning_rate": 9.076916152842162e-05,
      "loss": 1.0011,
      "step": 20510
    },
    {
      "epoch": 0.9235339124173005,
      "grad_norm": 1.6630632877349854,
      "learning_rate": 9.0764660875827e-05,
      "loss": 1.0459,
      "step": 20520
    },
    {
      "epoch": 0.9239839776767631,
      "grad_norm": 1.9844380617141724,
      "learning_rate": 9.076016022323236e-05,
      "loss": 1.0365,
      "step": 20530
    },
    {
      "epoch": 0.9244340429362258,
      "grad_norm": 1.6726189851760864,
      "learning_rate": 9.075565957063775e-05,
      "loss": 1.1202,
      "step": 20540
    },
    {
      "epoch": 0.9248841081956883,
      "grad_norm": 1.7283755540847778,
      "learning_rate": 9.075115891804313e-05,
      "loss": 1.0875,
      "step": 20550
    },
    {
      "epoch": 0.925334173455151,
      "grad_norm": 1.4760680198669434,
      "learning_rate": 9.074665826544849e-05,
      "loss": 1.0184,
      "step": 20560
    },
    {
      "epoch": 0.9257842387146136,
      "grad_norm": 1.6909427642822266,
      "learning_rate": 9.074215761285387e-05,
      "loss": 1.0446,
      "step": 20570
    },
    {
      "epoch": 0.9262343039740762,
      "grad_norm": 1.768707275390625,
      "learning_rate": 9.073765696025925e-05,
      "loss": 1.0256,
      "step": 20580
    },
    {
      "epoch": 0.9266843692335389,
      "grad_norm": 1.9290395975112915,
      "learning_rate": 9.07331563076646e-05,
      "loss": 1.1156,
      "step": 20590
    },
    {
      "epoch": 0.9271344344930015,
      "grad_norm": 2.1351845264434814,
      "learning_rate": 9.072865565507e-05,
      "loss": 0.9729,
      "step": 20600
    },
    {
      "epoch": 0.9275844997524642,
      "grad_norm": 1.3129802942276,
      "learning_rate": 9.072415500247537e-05,
      "loss": 0.9523,
      "step": 20610
    },
    {
      "epoch": 0.9280345650119267,
      "grad_norm": 2.1187477111816406,
      "learning_rate": 9.071965434988073e-05,
      "loss": 0.9982,
      "step": 20620
    },
    {
      "epoch": 0.9284846302713894,
      "grad_norm": 2.387392282485962,
      "learning_rate": 9.071515369728611e-05,
      "loss": 1.0304,
      "step": 20630
    },
    {
      "epoch": 0.928934695530852,
      "grad_norm": 1.854791283607483,
      "learning_rate": 9.071065304469149e-05,
      "loss": 1.1231,
      "step": 20640
    },
    {
      "epoch": 0.9293847607903146,
      "grad_norm": 1.8942914009094238,
      "learning_rate": 9.070615239209685e-05,
      "loss": 1.0671,
      "step": 20650
    },
    {
      "epoch": 0.9298348260497772,
      "grad_norm": 1.8296699523925781,
      "learning_rate": 9.070165173950224e-05,
      "loss": 1.0379,
      "step": 20660
    },
    {
      "epoch": 0.9302848913092399,
      "grad_norm": 1.4863488674163818,
      "learning_rate": 9.069715108690761e-05,
      "loss": 1.0155,
      "step": 20670
    },
    {
      "epoch": 0.9307349565687024,
      "grad_norm": 2.3760266304016113,
      "learning_rate": 9.069265043431298e-05,
      "loss": 1.0869,
      "step": 20680
    },
    {
      "epoch": 0.9311850218281651,
      "grad_norm": 1.5892819166183472,
      "learning_rate": 9.068814978171836e-05,
      "loss": 1.0201,
      "step": 20690
    },
    {
      "epoch": 0.9316350870876277,
      "grad_norm": 1.392527461051941,
      "learning_rate": 9.068364912912373e-05,
      "loss": 1.057,
      "step": 20700
    },
    {
      "epoch": 0.9320851523470903,
      "grad_norm": 1.015069603919983,
      "learning_rate": 9.06791484765291e-05,
      "loss": 1.0451,
      "step": 20710
    },
    {
      "epoch": 0.932535217606553,
      "grad_norm": 2.6435580253601074,
      "learning_rate": 9.067464782393448e-05,
      "loss": 1.0906,
      "step": 20720
    },
    {
      "epoch": 0.9329852828660156,
      "grad_norm": 1.5819892883300781,
      "learning_rate": 9.067014717133985e-05,
      "loss": 1.0592,
      "step": 20730
    },
    {
      "epoch": 0.9334353481254782,
      "grad_norm": 1.6608270406723022,
      "learning_rate": 9.066564651874522e-05,
      "loss": 1.0457,
      "step": 20740
    },
    {
      "epoch": 0.9338854133849408,
      "grad_norm": 1.5269767045974731,
      "learning_rate": 9.06611458661506e-05,
      "loss": 1.0548,
      "step": 20750
    },
    {
      "epoch": 0.9343354786444035,
      "grad_norm": 2.640456199645996,
      "learning_rate": 9.065664521355597e-05,
      "loss": 1.0493,
      "step": 20760
    },
    {
      "epoch": 0.934785543903866,
      "grad_norm": 1.3747187852859497,
      "learning_rate": 9.065214456096134e-05,
      "loss": 1.0133,
      "step": 20770
    },
    {
      "epoch": 0.9352356091633287,
      "grad_norm": 1.4846481084823608,
      "learning_rate": 9.064764390836672e-05,
      "loss": 1.0191,
      "step": 20780
    },
    {
      "epoch": 0.9356856744227913,
      "grad_norm": 2.3017940521240234,
      "learning_rate": 9.064314325577209e-05,
      "loss": 1.0049,
      "step": 20790
    },
    {
      "epoch": 0.9361357396822539,
      "grad_norm": 1.5976418256759644,
      "learning_rate": 9.063864260317747e-05,
      "loss": 1.0621,
      "step": 20800
    },
    {
      "epoch": 0.9365858049417165,
      "grad_norm": 1.7668009996414185,
      "learning_rate": 9.063414195058284e-05,
      "loss": 1.0524,
      "step": 20810
    },
    {
      "epoch": 0.9370358702011792,
      "grad_norm": 1.9995553493499756,
      "learning_rate": 9.062964129798821e-05,
      "loss": 1.0009,
      "step": 20820
    },
    {
      "epoch": 0.9374859354606417,
      "grad_norm": 2.4228999614715576,
      "learning_rate": 9.062514064539359e-05,
      "loss": 1.1221,
      "step": 20830
    },
    {
      "epoch": 0.9379360007201044,
      "grad_norm": 1.5887223482131958,
      "learning_rate": 9.062063999279896e-05,
      "loss": 1.0868,
      "step": 20840
    },
    {
      "epoch": 0.9383860659795671,
      "grad_norm": 2.4742233753204346,
      "learning_rate": 9.061613934020433e-05,
      "loss": 1.0096,
      "step": 20850
    },
    {
      "epoch": 0.9388361312390296,
      "grad_norm": 1.296974778175354,
      "learning_rate": 9.061163868760971e-05,
      "loss": 1.0828,
      "step": 20860
    },
    {
      "epoch": 0.9392861964984923,
      "grad_norm": 2.5104193687438965,
      "learning_rate": 9.060713803501508e-05,
      "loss": 1.0872,
      "step": 20870
    },
    {
      "epoch": 0.9397362617579549,
      "grad_norm": 1.8550478219985962,
      "learning_rate": 9.060263738242045e-05,
      "loss": 1.0647,
      "step": 20880
    },
    {
      "epoch": 0.9401863270174176,
      "grad_norm": 1.2974196672439575,
      "learning_rate": 9.059813672982583e-05,
      "loss": 1.0249,
      "step": 20890
    },
    {
      "epoch": 0.9406363922768801,
      "grad_norm": 1.8932139873504639,
      "learning_rate": 9.05936360772312e-05,
      "loss": 1.1046,
      "step": 20900
    },
    {
      "epoch": 0.9410864575363428,
      "grad_norm": 2.0811309814453125,
      "learning_rate": 9.058913542463658e-05,
      "loss": 1.0011,
      "step": 20910
    },
    {
      "epoch": 0.9415365227958054,
      "grad_norm": 1.5665189027786255,
      "learning_rate": 9.058463477204195e-05,
      "loss": 0.9669,
      "step": 20920
    },
    {
      "epoch": 0.941986588055268,
      "grad_norm": 2.3538594245910645,
      "learning_rate": 9.058013411944732e-05,
      "loss": 1.0363,
      "step": 20930
    },
    {
      "epoch": 0.9424366533147306,
      "grad_norm": 1.771934151649475,
      "learning_rate": 9.05756334668527e-05,
      "loss": 1.0402,
      "step": 20940
    },
    {
      "epoch": 0.9428867185741933,
      "grad_norm": 1.4172160625457764,
      "learning_rate": 9.057113281425807e-05,
      "loss": 0.9931,
      "step": 20950
    },
    {
      "epoch": 0.9433367838336559,
      "grad_norm": 2.4224157333374023,
      "learning_rate": 9.056663216166344e-05,
      "loss": 1.0221,
      "step": 20960
    },
    {
      "epoch": 0.9437868490931185,
      "grad_norm": 2.028670072555542,
      "learning_rate": 9.056213150906882e-05,
      "loss": 1.0465,
      "step": 20970
    },
    {
      "epoch": 0.9442369143525812,
      "grad_norm": 1.217293381690979,
      "learning_rate": 9.055763085647419e-05,
      "loss": 1.0247,
      "step": 20980
    },
    {
      "epoch": 0.9446869796120437,
      "grad_norm": 4.077978134155273,
      "learning_rate": 9.055313020387956e-05,
      "loss": 1.0438,
      "step": 20990
    },
    {
      "epoch": 0.9451370448715064,
      "grad_norm": 1.9327079057693481,
      "learning_rate": 9.054862955128494e-05,
      "loss": 1.0755,
      "step": 21000
    },
    {
      "epoch": 0.945587110130969,
      "grad_norm": 1.8700807094573975,
      "learning_rate": 9.054412889869031e-05,
      "loss": 0.9975,
      "step": 21010
    },
    {
      "epoch": 0.9460371753904316,
      "grad_norm": 1.271315336227417,
      "learning_rate": 9.053962824609568e-05,
      "loss": 1.0479,
      "step": 21020
    },
    {
      "epoch": 0.9464872406498942,
      "grad_norm": 1.4532661437988281,
      "learning_rate": 9.053512759350106e-05,
      "loss": 1.0174,
      "step": 21030
    },
    {
      "epoch": 0.9469373059093569,
      "grad_norm": 2.3752243518829346,
      "learning_rate": 9.053062694090643e-05,
      "loss": 1.0698,
      "step": 21040
    },
    {
      "epoch": 0.9473873711688194,
      "grad_norm": 1.6871700286865234,
      "learning_rate": 9.05261262883118e-05,
      "loss": 1.0165,
      "step": 21050
    },
    {
      "epoch": 0.9478374364282821,
      "grad_norm": 1.597163200378418,
      "learning_rate": 9.052162563571719e-05,
      "loss": 1.0135,
      "step": 21060
    },
    {
      "epoch": 0.9482875016877447,
      "grad_norm": 1.3989698886871338,
      "learning_rate": 9.051712498312255e-05,
      "loss": 1.0833,
      "step": 21070
    },
    {
      "epoch": 0.9487375669472073,
      "grad_norm": 2.0881595611572266,
      "learning_rate": 9.051262433052793e-05,
      "loss": 1.0133,
      "step": 21080
    },
    {
      "epoch": 0.94918763220667,
      "grad_norm": 1.7824763059616089,
      "learning_rate": 9.050812367793331e-05,
      "loss": 1.0612,
      "step": 21090
    },
    {
      "epoch": 0.9496376974661326,
      "grad_norm": 1.788097620010376,
      "learning_rate": 9.050362302533867e-05,
      "loss": 1.0382,
      "step": 21100
    },
    {
      "epoch": 0.9500877627255953,
      "grad_norm": 1.6127965450286865,
      "learning_rate": 9.049912237274405e-05,
      "loss": 1.0295,
      "step": 21110
    },
    {
      "epoch": 0.9505378279850578,
      "grad_norm": 1.562410831451416,
      "learning_rate": 9.049462172014943e-05,
      "loss": 1.0521,
      "step": 21120
    },
    {
      "epoch": 0.9509878932445205,
      "grad_norm": 1.4391862154006958,
      "learning_rate": 9.04901210675548e-05,
      "loss": 0.9961,
      "step": 21130
    },
    {
      "epoch": 0.951437958503983,
      "grad_norm": 1.5571492910385132,
      "learning_rate": 9.048562041496017e-05,
      "loss": 1.0856,
      "step": 21140
    },
    {
      "epoch": 0.9518880237634457,
      "grad_norm": 1.6164902448654175,
      "learning_rate": 9.048111976236556e-05,
      "loss": 1.0212,
      "step": 21150
    },
    {
      "epoch": 0.9523380890229083,
      "grad_norm": 1.7338874340057373,
      "learning_rate": 9.047661910977092e-05,
      "loss": 1.0145,
      "step": 21160
    },
    {
      "epoch": 0.952788154282371,
      "grad_norm": 1.863503336906433,
      "learning_rate": 9.047211845717629e-05,
      "loss": 1.0541,
      "step": 21170
    },
    {
      "epoch": 0.9532382195418335,
      "grad_norm": 1.3820440769195557,
      "learning_rate": 9.046761780458168e-05,
      "loss": 1.0738,
      "step": 21180
    },
    {
      "epoch": 0.9536882848012962,
      "grad_norm": 1.415560007095337,
      "learning_rate": 9.046311715198704e-05,
      "loss": 1.0763,
      "step": 21190
    },
    {
      "epoch": 0.9541383500607588,
      "grad_norm": 1.8990472555160522,
      "learning_rate": 9.045861649939241e-05,
      "loss": 1.0541,
      "step": 21200
    },
    {
      "epoch": 0.9545884153202214,
      "grad_norm": 2.6324002742767334,
      "learning_rate": 9.04541158467978e-05,
      "loss": 1.0618,
      "step": 21210
    },
    {
      "epoch": 0.9550384805796841,
      "grad_norm": 2.846062660217285,
      "learning_rate": 9.044961519420316e-05,
      "loss": 1.0675,
      "step": 21220
    },
    {
      "epoch": 0.9554885458391467,
      "grad_norm": 1.1833068132400513,
      "learning_rate": 9.044511454160853e-05,
      "loss": 1.0307,
      "step": 21230
    },
    {
      "epoch": 0.9559386110986093,
      "grad_norm": 1.8369446992874146,
      "learning_rate": 9.044061388901392e-05,
      "loss": 1.0887,
      "step": 21240
    },
    {
      "epoch": 0.9563886763580719,
      "grad_norm": 1.6711311340332031,
      "learning_rate": 9.043611323641928e-05,
      "loss": 1.0383,
      "step": 21250
    },
    {
      "epoch": 0.9568387416175346,
      "grad_norm": 1.9252997636795044,
      "learning_rate": 9.043161258382465e-05,
      "loss": 0.9896,
      "step": 21260
    },
    {
      "epoch": 0.9572888068769971,
      "grad_norm": 2.2441930770874023,
      "learning_rate": 9.042711193123004e-05,
      "loss": 1.066,
      "step": 21270
    },
    {
      "epoch": 0.9577388721364598,
      "grad_norm": 1.5767427682876587,
      "learning_rate": 9.04226112786354e-05,
      "loss": 1.0373,
      "step": 21280
    },
    {
      "epoch": 0.9581889373959224,
      "grad_norm": 2.0141735076904297,
      "learning_rate": 9.041811062604077e-05,
      "loss": 1.1106,
      "step": 21290
    },
    {
      "epoch": 0.958639002655385,
      "grad_norm": 1.7238391637802124,
      "learning_rate": 9.041360997344616e-05,
      "loss": 0.9968,
      "step": 21300
    },
    {
      "epoch": 0.9590890679148476,
      "grad_norm": 1.8998645544052124,
      "learning_rate": 9.040910932085152e-05,
      "loss": 1.0632,
      "step": 21310
    },
    {
      "epoch": 0.9595391331743103,
      "grad_norm": 1.4033526182174683,
      "learning_rate": 9.04046086682569e-05,
      "loss": 1.0783,
      "step": 21320
    },
    {
      "epoch": 0.959989198433773,
      "grad_norm": 1.5138274431228638,
      "learning_rate": 9.040010801566228e-05,
      "loss": 0.9946,
      "step": 21330
    },
    {
      "epoch": 0.9604392636932355,
      "grad_norm": 2.6966590881347656,
      "learning_rate": 9.039560736306765e-05,
      "loss": 0.8988,
      "step": 21340
    },
    {
      "epoch": 0.9608893289526982,
      "grad_norm": 1.958956241607666,
      "learning_rate": 9.039110671047303e-05,
      "loss": 1.0951,
      "step": 21350
    },
    {
      "epoch": 0.9613393942121607,
      "grad_norm": 1.1825274229049683,
      "learning_rate": 9.03866060578784e-05,
      "loss": 1.0864,
      "step": 21360
    },
    {
      "epoch": 0.9617894594716234,
      "grad_norm": 1.667040228843689,
      "learning_rate": 9.038210540528377e-05,
      "loss": 1.0509,
      "step": 21370
    },
    {
      "epoch": 0.962239524731086,
      "grad_norm": 1.3771674633026123,
      "learning_rate": 9.037760475268915e-05,
      "loss": 1.0791,
      "step": 21380
    },
    {
      "epoch": 0.9626895899905487,
      "grad_norm": 3.3229622840881348,
      "learning_rate": 9.037310410009452e-05,
      "loss": 1.0573,
      "step": 21390
    },
    {
      "epoch": 0.9631396552500112,
      "grad_norm": 1.5578118562698364,
      "learning_rate": 9.03686034474999e-05,
      "loss": 1.0823,
      "step": 21400
    },
    {
      "epoch": 0.9635897205094739,
      "grad_norm": 2.2792677879333496,
      "learning_rate": 9.036410279490527e-05,
      "loss": 1.1054,
      "step": 21410
    },
    {
      "epoch": 0.9640397857689365,
      "grad_norm": 1.7647091150283813,
      "learning_rate": 9.035960214231064e-05,
      "loss": 1.1238,
      "step": 21420
    },
    {
      "epoch": 0.9644898510283991,
      "grad_norm": 1.1797469854354858,
      "learning_rate": 9.035510148971602e-05,
      "loss": 1.0022,
      "step": 21430
    },
    {
      "epoch": 0.9649399162878617,
      "grad_norm": 1.8104475736618042,
      "learning_rate": 9.035060083712139e-05,
      "loss": 1.0055,
      "step": 21440
    },
    {
      "epoch": 0.9653899815473244,
      "grad_norm": 2.263497829437256,
      "learning_rate": 9.034610018452676e-05,
      "loss": 1.0574,
      "step": 21450
    },
    {
      "epoch": 0.965840046806787,
      "grad_norm": 1.5714941024780273,
      "learning_rate": 9.034159953193214e-05,
      "loss": 1.052,
      "step": 21460
    },
    {
      "epoch": 0.9662901120662496,
      "grad_norm": 1.4309002161026,
      "learning_rate": 9.033709887933751e-05,
      "loss": 1.0289,
      "step": 21470
    },
    {
      "epoch": 0.9667401773257123,
      "grad_norm": 1.3842469453811646,
      "learning_rate": 9.033259822674288e-05,
      "loss": 1.0356,
      "step": 21480
    },
    {
      "epoch": 0.9671902425851748,
      "grad_norm": 1.3225044012069702,
      "learning_rate": 9.032809757414826e-05,
      "loss": 1.0035,
      "step": 21490
    },
    {
      "epoch": 0.9676403078446375,
      "grad_norm": 2.1215932369232178,
      "learning_rate": 9.032359692155363e-05,
      "loss": 1.0319,
      "step": 21500
    },
    {
      "epoch": 0.9680903731041001,
      "grad_norm": 3.2316529750823975,
      "learning_rate": 9.0319096268959e-05,
      "loss": 0.9747,
      "step": 21510
    },
    {
      "epoch": 0.9685404383635627,
      "grad_norm": 1.8097527027130127,
      "learning_rate": 9.031459561636438e-05,
      "loss": 1.0434,
      "step": 21520
    },
    {
      "epoch": 0.9689905036230253,
      "grad_norm": 1.8194339275360107,
      "learning_rate": 9.031009496376975e-05,
      "loss": 1.0762,
      "step": 21530
    },
    {
      "epoch": 0.969440568882488,
      "grad_norm": 1.6773678064346313,
      "learning_rate": 9.030559431117513e-05,
      "loss": 1.0609,
      "step": 21540
    },
    {
      "epoch": 0.9698906341419505,
      "grad_norm": 1.8528900146484375,
      "learning_rate": 9.03010936585805e-05,
      "loss": 1.0625,
      "step": 21550
    },
    {
      "epoch": 0.9703406994014132,
      "grad_norm": 1.9662410020828247,
      "learning_rate": 9.029659300598587e-05,
      "loss": 1.0127,
      "step": 21560
    },
    {
      "epoch": 0.9707907646608759,
      "grad_norm": 1.7520586252212524,
      "learning_rate": 9.029209235339125e-05,
      "loss": 0.9857,
      "step": 21570
    },
    {
      "epoch": 0.9712408299203384,
      "grad_norm": 2.140916109085083,
      "learning_rate": 9.028759170079662e-05,
      "loss": 0.9586,
      "step": 21580
    },
    {
      "epoch": 0.9716908951798011,
      "grad_norm": 1.6255854368209839,
      "learning_rate": 9.0283091048202e-05,
      "loss": 1.0329,
      "step": 21590
    },
    {
      "epoch": 0.9721409604392637,
      "grad_norm": 2.9741485118865967,
      "learning_rate": 9.027859039560737e-05,
      "loss": 1.0685,
      "step": 21600
    },
    {
      "epoch": 0.9725910256987264,
      "grad_norm": 2.3807430267333984,
      "learning_rate": 9.027408974301274e-05,
      "loss": 1.0066,
      "step": 21610
    },
    {
      "epoch": 0.9730410909581889,
      "grad_norm": 1.2469648122787476,
      "learning_rate": 9.026958909041811e-05,
      "loss": 1.0186,
      "step": 21620
    },
    {
      "epoch": 0.9734911562176516,
      "grad_norm": 2.2933340072631836,
      "learning_rate": 9.026508843782349e-05,
      "loss": 1.0731,
      "step": 21630
    },
    {
      "epoch": 0.9739412214771141,
      "grad_norm": 1.9311468601226807,
      "learning_rate": 9.026058778522886e-05,
      "loss": 1.0393,
      "step": 21640
    },
    {
      "epoch": 0.9743912867365768,
      "grad_norm": 2.03590989112854,
      "learning_rate": 9.025608713263424e-05,
      "loss": 1.005,
      "step": 21650
    },
    {
      "epoch": 0.9748413519960394,
      "grad_norm": 2.14262056350708,
      "learning_rate": 9.025158648003961e-05,
      "loss": 1.04,
      "step": 21660
    },
    {
      "epoch": 0.9752914172555021,
      "grad_norm": 1.6505470275878906,
      "learning_rate": 9.024708582744498e-05,
      "loss": 1.0854,
      "step": 21670
    },
    {
      "epoch": 0.9757414825149646,
      "grad_norm": 1.983748197555542,
      "learning_rate": 9.024258517485036e-05,
      "loss": 1.0594,
      "step": 21680
    },
    {
      "epoch": 0.9761915477744273,
      "grad_norm": 2.8043951988220215,
      "learning_rate": 9.023808452225573e-05,
      "loss": 1.0479,
      "step": 21690
    },
    {
      "epoch": 0.97664161303389,
      "grad_norm": 1.817813515663147,
      "learning_rate": 9.02335838696611e-05,
      "loss": 1.0243,
      "step": 21700
    },
    {
      "epoch": 0.9770916782933525,
      "grad_norm": 1.927123785018921,
      "learning_rate": 9.022908321706648e-05,
      "loss": 0.9799,
      "step": 21710
    },
    {
      "epoch": 0.9775417435528152,
      "grad_norm": 1.754367470741272,
      "learning_rate": 9.022458256447185e-05,
      "loss": 1.0488,
      "step": 21720
    },
    {
      "epoch": 0.9779918088122778,
      "grad_norm": 1.5389471054077148,
      "learning_rate": 9.022008191187722e-05,
      "loss": 0.9585,
      "step": 21730
    },
    {
      "epoch": 0.9784418740717404,
      "grad_norm": 1.2853193283081055,
      "learning_rate": 9.02155812592826e-05,
      "loss": 0.9984,
      "step": 21740
    },
    {
      "epoch": 0.978891939331203,
      "grad_norm": 1.805079698562622,
      "learning_rate": 9.021108060668797e-05,
      "loss": 1.0036,
      "step": 21750
    },
    {
      "epoch": 0.9793420045906657,
      "grad_norm": 2.703435182571411,
      "learning_rate": 9.020657995409335e-05,
      "loss": 1.0902,
      "step": 21760
    },
    {
      "epoch": 0.9797920698501282,
      "grad_norm": 1.6349354982376099,
      "learning_rate": 9.020207930149872e-05,
      "loss": 1.0733,
      "step": 21770
    },
    {
      "epoch": 0.9802421351095909,
      "grad_norm": 2.4502689838409424,
      "learning_rate": 9.019757864890409e-05,
      "loss": 1.0323,
      "step": 21780
    },
    {
      "epoch": 0.9806922003690535,
      "grad_norm": 1.2767235040664673,
      "learning_rate": 9.019307799630947e-05,
      "loss": 1.1177,
      "step": 21790
    },
    {
      "epoch": 0.9811422656285161,
      "grad_norm": 2.2629435062408447,
      "learning_rate": 9.018857734371484e-05,
      "loss": 0.9882,
      "step": 21800
    },
    {
      "epoch": 0.9815923308879787,
      "grad_norm": 1.5363070964813232,
      "learning_rate": 9.018407669112021e-05,
      "loss": 1.1238,
      "step": 21810
    },
    {
      "epoch": 0.9820423961474414,
      "grad_norm": 1.507394552230835,
      "learning_rate": 9.017957603852559e-05,
      "loss": 0.9871,
      "step": 21820
    },
    {
      "epoch": 0.982492461406904,
      "grad_norm": 1.8764384984970093,
      "learning_rate": 9.017507538593096e-05,
      "loss": 1.0601,
      "step": 21830
    },
    {
      "epoch": 0.9829425266663666,
      "grad_norm": 2.3326921463012695,
      "learning_rate": 9.017057473333633e-05,
      "loss": 1.1264,
      "step": 21840
    },
    {
      "epoch": 0.9833925919258293,
      "grad_norm": 1.6762034893035889,
      "learning_rate": 9.016607408074171e-05,
      "loss": 1.0514,
      "step": 21850
    },
    {
      "epoch": 0.9838426571852918,
      "grad_norm": 2.204207420349121,
      "learning_rate": 9.016157342814708e-05,
      "loss": 1.1196,
      "step": 21860
    },
    {
      "epoch": 0.9842927224447545,
      "grad_norm": 2.02451753616333,
      "learning_rate": 9.015707277555247e-05,
      "loss": 1.0156,
      "step": 21870
    },
    {
      "epoch": 0.9847427877042171,
      "grad_norm": 2.6012022495269775,
      "learning_rate": 9.015257212295783e-05,
      "loss": 1.1151,
      "step": 21880
    },
    {
      "epoch": 0.9851928529636798,
      "grad_norm": 1.415099859237671,
      "learning_rate": 9.01480714703632e-05,
      "loss": 1.078,
      "step": 21890
    },
    {
      "epoch": 0.9856429182231423,
      "grad_norm": 1.6723613739013672,
      "learning_rate": 9.014357081776859e-05,
      "loss": 1.0002,
      "step": 21900
    },
    {
      "epoch": 0.986092983482605,
      "grad_norm": 1.999829888343811,
      "learning_rate": 9.013907016517395e-05,
      "loss": 1.0453,
      "step": 21910
    },
    {
      "epoch": 0.9865430487420676,
      "grad_norm": 1.4139338731765747,
      "learning_rate": 9.013456951257932e-05,
      "loss": 1.0298,
      "step": 21920
    },
    {
      "epoch": 0.9869931140015302,
      "grad_norm": 1.8387587070465088,
      "learning_rate": 9.013006885998471e-05,
      "loss": 1.0265,
      "step": 21930
    },
    {
      "epoch": 0.9874431792609929,
      "grad_norm": 1.5779651403427124,
      "learning_rate": 9.012556820739007e-05,
      "loss": 1.099,
      "step": 21940
    },
    {
      "epoch": 0.9878932445204555,
      "grad_norm": 1.4427751302719116,
      "learning_rate": 9.012106755479544e-05,
      "loss": 0.9939,
      "step": 21950
    },
    {
      "epoch": 0.9883433097799181,
      "grad_norm": 1.6011179685592651,
      "learning_rate": 9.011656690220083e-05,
      "loss": 1.0887,
      "step": 21960
    },
    {
      "epoch": 0.9887933750393807,
      "grad_norm": 2.7041382789611816,
      "learning_rate": 9.011206624960619e-05,
      "loss": 1.0583,
      "step": 21970
    },
    {
      "epoch": 0.9892434402988434,
      "grad_norm": 1.7746518850326538,
      "learning_rate": 9.010756559701156e-05,
      "loss": 1.063,
      "step": 21980
    },
    {
      "epoch": 0.9896935055583059,
      "grad_norm": 2.632963180541992,
      "learning_rate": 9.010306494441695e-05,
      "loss": 1.0268,
      "step": 21990
    },
    {
      "epoch": 0.9901435708177686,
      "grad_norm": 1.6784294843673706,
      "learning_rate": 9.009856429182231e-05,
      "loss": 0.9569,
      "step": 22000
    },
    {
      "epoch": 0.9905936360772312,
      "grad_norm": 2.3573272228240967,
      "learning_rate": 9.009406363922769e-05,
      "loss": 1.0419,
      "step": 22010
    },
    {
      "epoch": 0.9910437013366938,
      "grad_norm": 2.459251642227173,
      "learning_rate": 9.008956298663307e-05,
      "loss": 0.964,
      "step": 22020
    },
    {
      "epoch": 0.9914937665961564,
      "grad_norm": 1.968258023262024,
      "learning_rate": 9.008506233403845e-05,
      "loss": 1.1125,
      "step": 22030
    },
    {
      "epoch": 0.9919438318556191,
      "grad_norm": 2.6634254455566406,
      "learning_rate": 9.00805616814438e-05,
      "loss": 1.0471,
      "step": 22040
    },
    {
      "epoch": 0.9923938971150816,
      "grad_norm": 2.3023054599761963,
      "learning_rate": 9.007606102884919e-05,
      "loss": 1.0638,
      "step": 22050
    },
    {
      "epoch": 0.9928439623745443,
      "grad_norm": 1.772181510925293,
      "learning_rate": 9.007156037625457e-05,
      "loss": 1.0877,
      "step": 22060
    },
    {
      "epoch": 0.993294027634007,
      "grad_norm": 2.0536272525787354,
      "learning_rate": 9.006705972365993e-05,
      "loss": 1.0802,
      "step": 22070
    },
    {
      "epoch": 0.9937440928934695,
      "grad_norm": 3.180239200592041,
      "learning_rate": 9.006255907106531e-05,
      "loss": 1.0665,
      "step": 22080
    },
    {
      "epoch": 0.9941941581529322,
      "grad_norm": 1.14231276512146,
      "learning_rate": 9.005805841847069e-05,
      "loss": 1.0739,
      "step": 22090
    },
    {
      "epoch": 0.9946442234123948,
      "grad_norm": 1.4526314735412598,
      "learning_rate": 9.005355776587605e-05,
      "loss": 1.043,
      "step": 22100
    },
    {
      "epoch": 0.9950942886718575,
      "grad_norm": 1.478144884109497,
      "learning_rate": 9.004905711328143e-05,
      "loss": 1.0954,
      "step": 22110
    },
    {
      "epoch": 0.99554435393132,
      "grad_norm": 1.9016106128692627,
      "learning_rate": 9.004455646068681e-05,
      "loss": 0.9888,
      "step": 22120
    },
    {
      "epoch": 0.9959944191907827,
      "grad_norm": 1.9565153121948242,
      "learning_rate": 9.004005580809218e-05,
      "loss": 1.0587,
      "step": 22130
    },
    {
      "epoch": 0.9964444844502452,
      "grad_norm": 1.7488435506820679,
      "learning_rate": 9.003555515549756e-05,
      "loss": 1.0186,
      "step": 22140
    },
    {
      "epoch": 0.9968945497097079,
      "grad_norm": 1.731656551361084,
      "learning_rate": 9.003105450290293e-05,
      "loss": 1.0483,
      "step": 22150
    },
    {
      "epoch": 0.9973446149691705,
      "grad_norm": 1.620197057723999,
      "learning_rate": 9.00265538503083e-05,
      "loss": 1.099,
      "step": 22160
    },
    {
      "epoch": 0.9977946802286332,
      "grad_norm": 1.4059921503067017,
      "learning_rate": 9.002205319771368e-05,
      "loss": 1.0775,
      "step": 22170
    },
    {
      "epoch": 0.9982447454880957,
      "grad_norm": 1.7390053272247314,
      "learning_rate": 9.001755254511905e-05,
      "loss": 1.099,
      "step": 22180
    },
    {
      "epoch": 0.9986948107475584,
      "grad_norm": 1.5614663362503052,
      "learning_rate": 9.001305189252442e-05,
      "loss": 1.0086,
      "step": 22190
    },
    {
      "epoch": 0.9991448760070211,
      "grad_norm": 2.072496175765991,
      "learning_rate": 9.00085512399298e-05,
      "loss": 1.0385,
      "step": 22200
    },
    {
      "epoch": 0.9995949412664836,
      "grad_norm": 1.3187836408615112,
      "learning_rate": 9.000405058733517e-05,
      "loss": 0.9915,
      "step": 22210
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.5566219781827183,
      "eval_loss": 1.0501248836517334,
      "eval_runtime": 18.0929,
      "eval_samples_per_second": 9824.254,
      "eval_steps_per_second": 307.027,
      "step": 22219
    }
  ],
  "logging_steps": 10,
  "max_steps": 222190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3695348925360000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
