{
  "best_metric": 0.9474146127404374,
  "best_model_checkpoint": "./results\\checkpoint-22219",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 22219,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0004500652594626221,
      "grad_norm": 3.2008986473083496,
      "learning_rate": 9.999549934740538e-05,
      "loss": 1.3188,
      "step": 10
    },
    {
      "epoch": 0.0009001305189252442,
      "grad_norm": 1.607740044593811,
      "learning_rate": 9.999099869481075e-05,
      "loss": 0.935,
      "step": 20
    },
    {
      "epoch": 0.0013501957783878663,
      "grad_norm": 1.4434700012207031,
      "learning_rate": 9.998649804221613e-05,
      "loss": 0.9002,
      "step": 30
    },
    {
      "epoch": 0.0018002610378504884,
      "grad_norm": 1.6147968769073486,
      "learning_rate": 9.99819973896215e-05,
      "loss": 0.8019,
      "step": 40
    },
    {
      "epoch": 0.0022503262973131103,
      "grad_norm": 1.70392906665802,
      "learning_rate": 9.997749673702687e-05,
      "loss": 0.7483,
      "step": 50
    },
    {
      "epoch": 0.0027003915567757326,
      "grad_norm": 2.065603494644165,
      "learning_rate": 9.997299608443225e-05,
      "loss": 0.7517,
      "step": 60
    },
    {
      "epoch": 0.0031504568162383545,
      "grad_norm": 1.919008493423462,
      "learning_rate": 9.996849543183762e-05,
      "loss": 0.7983,
      "step": 70
    },
    {
      "epoch": 0.003600522075700977,
      "grad_norm": 1.552905559539795,
      "learning_rate": 9.9963994779243e-05,
      "loss": 0.6426,
      "step": 80
    },
    {
      "epoch": 0.004050587335163599,
      "grad_norm": 1.3930459022521973,
      "learning_rate": 9.995949412664837e-05,
      "loss": 0.731,
      "step": 90
    },
    {
      "epoch": 0.004500652594626221,
      "grad_norm": 1.5244683027267456,
      "learning_rate": 9.995499347405374e-05,
      "loss": 0.7301,
      "step": 100
    },
    {
      "epoch": 0.0049507178540888425,
      "grad_norm": 2.358532190322876,
      "learning_rate": 9.995049282145911e-05,
      "loss": 0.7743,
      "step": 110
    },
    {
      "epoch": 0.005400783113551465,
      "grad_norm": 2.477370500564575,
      "learning_rate": 9.994599216886449e-05,
      "loss": 0.6656,
      "step": 120
    },
    {
      "epoch": 0.005850848373014087,
      "grad_norm": 2.512604236602783,
      "learning_rate": 9.994149151626986e-05,
      "loss": 0.6515,
      "step": 130
    },
    {
      "epoch": 0.006300913632476709,
      "grad_norm": 1.7991188764572144,
      "learning_rate": 9.993699086367524e-05,
      "loss": 0.6952,
      "step": 140
    },
    {
      "epoch": 0.006750978891939331,
      "grad_norm": 2.4224917888641357,
      "learning_rate": 9.993249021108061e-05,
      "loss": 0.6194,
      "step": 150
    },
    {
      "epoch": 0.007201044151401954,
      "grad_norm": 1.9820255041122437,
      "learning_rate": 9.9927989558486e-05,
      "loss": 0.7003,
      "step": 160
    },
    {
      "epoch": 0.0076511094108645756,
      "grad_norm": 2.503058433532715,
      "learning_rate": 9.992348890589136e-05,
      "loss": 0.654,
      "step": 170
    },
    {
      "epoch": 0.008101174670327197,
      "grad_norm": 1.5171198844909668,
      "learning_rate": 9.991898825329673e-05,
      "loss": 0.6495,
      "step": 180
    },
    {
      "epoch": 0.00855123992978982,
      "grad_norm": 1.5931955575942993,
      "learning_rate": 9.991448760070212e-05,
      "loss": 0.6671,
      "step": 190
    },
    {
      "epoch": 0.009001305189252441,
      "grad_norm": 2.3481881618499756,
      "learning_rate": 9.990998694810748e-05,
      "loss": 0.7095,
      "step": 200
    },
    {
      "epoch": 0.009451370448715064,
      "grad_norm": 2.2459359169006348,
      "learning_rate": 9.990548629551285e-05,
      "loss": 0.6173,
      "step": 210
    },
    {
      "epoch": 0.009901435708177685,
      "grad_norm": 1.7117760181427002,
      "learning_rate": 9.990098564291824e-05,
      "loss": 0.5994,
      "step": 220
    },
    {
      "epoch": 0.010351500967640308,
      "grad_norm": 1.6256940364837646,
      "learning_rate": 9.98964849903236e-05,
      "loss": 0.5624,
      "step": 230
    },
    {
      "epoch": 0.01080156622710293,
      "grad_norm": 1.143288254737854,
      "learning_rate": 9.989198433772897e-05,
      "loss": 0.582,
      "step": 240
    },
    {
      "epoch": 0.011251631486565552,
      "grad_norm": 1.8007808923721313,
      "learning_rate": 9.988748368513436e-05,
      "loss": 0.5681,
      "step": 250
    },
    {
      "epoch": 0.011701696746028174,
      "grad_norm": 1.8823939561843872,
      "learning_rate": 9.988298303253972e-05,
      "loss": 0.5428,
      "step": 260
    },
    {
      "epoch": 0.012151762005490795,
      "grad_norm": 1.7564098834991455,
      "learning_rate": 9.987848237994509e-05,
      "loss": 0.5773,
      "step": 270
    },
    {
      "epoch": 0.012601827264953418,
      "grad_norm": 2.1491119861602783,
      "learning_rate": 9.987398172735048e-05,
      "loss": 0.5525,
      "step": 280
    },
    {
      "epoch": 0.01305189252441604,
      "grad_norm": 1.827496886253357,
      "learning_rate": 9.986948107475584e-05,
      "loss": 0.542,
      "step": 290
    },
    {
      "epoch": 0.013501957783878662,
      "grad_norm": 1.7367912530899048,
      "learning_rate": 9.986498042216121e-05,
      "loss": 0.6357,
      "step": 300
    },
    {
      "epoch": 0.013952023043341285,
      "grad_norm": 1.6035258769989014,
      "learning_rate": 9.98604797695666e-05,
      "loss": 0.5368,
      "step": 310
    },
    {
      "epoch": 0.014402088302803907,
      "grad_norm": 1.55293869972229,
      "learning_rate": 9.985597911697196e-05,
      "loss": 0.6091,
      "step": 320
    },
    {
      "epoch": 0.014852153562266528,
      "grad_norm": 1.8793542385101318,
      "learning_rate": 9.985147846437733e-05,
      "loss": 0.5296,
      "step": 330
    },
    {
      "epoch": 0.015302218821729151,
      "grad_norm": 2.3496177196502686,
      "learning_rate": 9.984697781178272e-05,
      "loss": 0.5305,
      "step": 340
    },
    {
      "epoch": 0.015752284081191774,
      "grad_norm": 1.500579833984375,
      "learning_rate": 9.984247715918808e-05,
      "loss": 0.5326,
      "step": 350
    },
    {
      "epoch": 0.016202349340654395,
      "grad_norm": 2.1330313682556152,
      "learning_rate": 9.983797650659345e-05,
      "loss": 0.5163,
      "step": 360
    },
    {
      "epoch": 0.016652414600117016,
      "grad_norm": 1.5187065601348877,
      "learning_rate": 9.983347585399884e-05,
      "loss": 0.4872,
      "step": 370
    },
    {
      "epoch": 0.01710247985957964,
      "grad_norm": 1.5453484058380127,
      "learning_rate": 9.98289752014042e-05,
      "loss": 0.4931,
      "step": 380
    },
    {
      "epoch": 0.01755254511904226,
      "grad_norm": 1.815280795097351,
      "learning_rate": 9.982447454880958e-05,
      "loss": 0.4711,
      "step": 390
    },
    {
      "epoch": 0.018002610378504882,
      "grad_norm": 1.8611726760864258,
      "learning_rate": 9.981997389621496e-05,
      "loss": 0.5302,
      "step": 400
    },
    {
      "epoch": 0.018452675637967507,
      "grad_norm": 2.2059218883514404,
      "learning_rate": 9.981547324362032e-05,
      "loss": 0.4968,
      "step": 410
    },
    {
      "epoch": 0.018902740897430128,
      "grad_norm": 1.6594140529632568,
      "learning_rate": 9.981097259102571e-05,
      "loss": 0.472,
      "step": 420
    },
    {
      "epoch": 0.01935280615689275,
      "grad_norm": 1.5799427032470703,
      "learning_rate": 9.980647193843108e-05,
      "loss": 0.4541,
      "step": 430
    },
    {
      "epoch": 0.01980287141635537,
      "grad_norm": 1.7668323516845703,
      "learning_rate": 9.980197128583644e-05,
      "loss": 0.4775,
      "step": 440
    },
    {
      "epoch": 0.020252936675817994,
      "grad_norm": 1.4154741764068604,
      "learning_rate": 9.979747063324183e-05,
      "loss": 0.4875,
      "step": 450
    },
    {
      "epoch": 0.020703001935280615,
      "grad_norm": 2.1402344703674316,
      "learning_rate": 9.97929699806472e-05,
      "loss": 0.4232,
      "step": 460
    },
    {
      "epoch": 0.021153067194743237,
      "grad_norm": 0.9581387639045715,
      "learning_rate": 9.978846932805256e-05,
      "loss": 0.4229,
      "step": 470
    },
    {
      "epoch": 0.02160313245420586,
      "grad_norm": 1.5850260257720947,
      "learning_rate": 9.978396867545795e-05,
      "loss": 0.4998,
      "step": 480
    },
    {
      "epoch": 0.022053197713668482,
      "grad_norm": 1.8188196420669556,
      "learning_rate": 9.977946802286332e-05,
      "loss": 0.4398,
      "step": 490
    },
    {
      "epoch": 0.022503262973131103,
      "grad_norm": 1.6984996795654297,
      "learning_rate": 9.977496737026868e-05,
      "loss": 0.4422,
      "step": 500
    },
    {
      "epoch": 0.022953328232593728,
      "grad_norm": 1.6573878526687622,
      "learning_rate": 9.977046671767407e-05,
      "loss": 0.4738,
      "step": 510
    },
    {
      "epoch": 0.02340339349205635,
      "grad_norm": 1.578774333000183,
      "learning_rate": 9.976596606507945e-05,
      "loss": 0.4405,
      "step": 520
    },
    {
      "epoch": 0.02385345875151897,
      "grad_norm": 1.4838157892227173,
      "learning_rate": 9.97614654124848e-05,
      "loss": 0.4433,
      "step": 530
    },
    {
      "epoch": 0.02430352401098159,
      "grad_norm": 2.190925121307373,
      "learning_rate": 9.975696475989019e-05,
      "loss": 0.4494,
      "step": 540
    },
    {
      "epoch": 0.024753589270444215,
      "grad_norm": 1.092760443687439,
      "learning_rate": 9.975246410729557e-05,
      "loss": 0.4839,
      "step": 550
    },
    {
      "epoch": 0.025203654529906836,
      "grad_norm": 1.0484411716461182,
      "learning_rate": 9.974796345470093e-05,
      "loss": 0.4021,
      "step": 560
    },
    {
      "epoch": 0.025653719789369457,
      "grad_norm": 2.038402557373047,
      "learning_rate": 9.974346280210631e-05,
      "loss": 0.4808,
      "step": 570
    },
    {
      "epoch": 0.02610378504883208,
      "grad_norm": 1.7665207386016846,
      "learning_rate": 9.973896214951169e-05,
      "loss": 0.4399,
      "step": 580
    },
    {
      "epoch": 0.026553850308294703,
      "grad_norm": 2.0450387001037598,
      "learning_rate": 9.973446149691705e-05,
      "loss": 0.4278,
      "step": 590
    },
    {
      "epoch": 0.027003915567757324,
      "grad_norm": 2.431368112564087,
      "learning_rate": 9.972996084432243e-05,
      "loss": 0.3358,
      "step": 600
    },
    {
      "epoch": 0.027453980827219948,
      "grad_norm": 2.4472734928131104,
      "learning_rate": 9.972546019172781e-05,
      "loss": 0.4674,
      "step": 610
    },
    {
      "epoch": 0.02790404608668257,
      "grad_norm": 1.059885025024414,
      "learning_rate": 9.972095953913317e-05,
      "loss": 0.4059,
      "step": 620
    },
    {
      "epoch": 0.02835411134614519,
      "grad_norm": 1.282366156578064,
      "learning_rate": 9.971645888653856e-05,
      "loss": 0.445,
      "step": 630
    },
    {
      "epoch": 0.028804176605607815,
      "grad_norm": 1.2389931678771973,
      "learning_rate": 9.971195823394393e-05,
      "loss": 0.4789,
      "step": 640
    },
    {
      "epoch": 0.029254241865070436,
      "grad_norm": 2.8236312866210938,
      "learning_rate": 9.970745758134929e-05,
      "loss": 0.4046,
      "step": 650
    },
    {
      "epoch": 0.029704307124533057,
      "grad_norm": 1.6482279300689697,
      "learning_rate": 9.970295692875468e-05,
      "loss": 0.3824,
      "step": 660
    },
    {
      "epoch": 0.030154372383995678,
      "grad_norm": 1.7919111251831055,
      "learning_rate": 9.969845627616005e-05,
      "loss": 0.387,
      "step": 670
    },
    {
      "epoch": 0.030604437643458302,
      "grad_norm": 4.270113945007324,
      "learning_rate": 9.969395562356542e-05,
      "loss": 0.4939,
      "step": 680
    },
    {
      "epoch": 0.031054502902920923,
      "grad_norm": 1.9383877515792847,
      "learning_rate": 9.96894549709708e-05,
      "loss": 0.4252,
      "step": 690
    },
    {
      "epoch": 0.03150456816238355,
      "grad_norm": 1.164613127708435,
      "learning_rate": 9.968495431837617e-05,
      "loss": 0.3658,
      "step": 700
    },
    {
      "epoch": 0.031954633421846165,
      "grad_norm": 2.897250175476074,
      "learning_rate": 9.968045366578154e-05,
      "loss": 0.4559,
      "step": 710
    },
    {
      "epoch": 0.03240469868130879,
      "grad_norm": 1.7557175159454346,
      "learning_rate": 9.967595301318692e-05,
      "loss": 0.4221,
      "step": 720
    },
    {
      "epoch": 0.032854763940771414,
      "grad_norm": 1.1338427066802979,
      "learning_rate": 9.967145236059229e-05,
      "loss": 0.394,
      "step": 730
    },
    {
      "epoch": 0.03330482920023403,
      "grad_norm": 2.038001298904419,
      "learning_rate": 9.966695170799766e-05,
      "loss": 0.4062,
      "step": 740
    },
    {
      "epoch": 0.033754894459696656,
      "grad_norm": 1.5053030252456665,
      "learning_rate": 9.966245105540304e-05,
      "loss": 0.3596,
      "step": 750
    },
    {
      "epoch": 0.03420495971915928,
      "grad_norm": 1.1295905113220215,
      "learning_rate": 9.965795040280841e-05,
      "loss": 0.437,
      "step": 760
    },
    {
      "epoch": 0.0346550249786219,
      "grad_norm": 1.73250412940979,
      "learning_rate": 9.965344975021379e-05,
      "loss": 0.3807,
      "step": 770
    },
    {
      "epoch": 0.03510509023808452,
      "grad_norm": 0.9030531644821167,
      "learning_rate": 9.964894909761916e-05,
      "loss": 0.3583,
      "step": 780
    },
    {
      "epoch": 0.03555515549754715,
      "grad_norm": 1.8677053451538086,
      "learning_rate": 9.964444844502453e-05,
      "loss": 0.3655,
      "step": 790
    },
    {
      "epoch": 0.036005220757009765,
      "grad_norm": 2.3043007850646973,
      "learning_rate": 9.96399477924299e-05,
      "loss": 0.3966,
      "step": 800
    },
    {
      "epoch": 0.03645528601647239,
      "grad_norm": 1.8934836387634277,
      "learning_rate": 9.963544713983528e-05,
      "loss": 0.4345,
      "step": 810
    },
    {
      "epoch": 0.036905351275935014,
      "grad_norm": 2.8068690299987793,
      "learning_rate": 9.963094648724065e-05,
      "loss": 0.4521,
      "step": 820
    },
    {
      "epoch": 0.03735541653539763,
      "grad_norm": 1.4404404163360596,
      "learning_rate": 9.962644583464603e-05,
      "loss": 0.3929,
      "step": 830
    },
    {
      "epoch": 0.037805481794860256,
      "grad_norm": 1.6695400476455688,
      "learning_rate": 9.96219451820514e-05,
      "loss": 0.3578,
      "step": 840
    },
    {
      "epoch": 0.03825554705432287,
      "grad_norm": 2.9772932529449463,
      "learning_rate": 9.961744452945677e-05,
      "loss": 0.4214,
      "step": 850
    },
    {
      "epoch": 0.0387056123137855,
      "grad_norm": 1.5978904962539673,
      "learning_rate": 9.961294387686215e-05,
      "loss": 0.4182,
      "step": 860
    },
    {
      "epoch": 0.03915567757324812,
      "grad_norm": 1.8057676553726196,
      "learning_rate": 9.960844322426752e-05,
      "loss": 0.404,
      "step": 870
    },
    {
      "epoch": 0.03960574283271074,
      "grad_norm": 0.950404167175293,
      "learning_rate": 9.96039425716729e-05,
      "loss": 0.4097,
      "step": 880
    },
    {
      "epoch": 0.040055808092173364,
      "grad_norm": 1.3332550525665283,
      "learning_rate": 9.959944191907827e-05,
      "loss": 0.388,
      "step": 890
    },
    {
      "epoch": 0.04050587335163599,
      "grad_norm": 1.2630492448806763,
      "learning_rate": 9.959494126648364e-05,
      "loss": 0.4487,
      "step": 900
    },
    {
      "epoch": 0.040955938611098607,
      "grad_norm": 1.6290687322616577,
      "learning_rate": 9.959044061388902e-05,
      "loss": 0.394,
      "step": 910
    },
    {
      "epoch": 0.04140600387056123,
      "grad_norm": 1.4934288263320923,
      "learning_rate": 9.958593996129439e-05,
      "loss": 0.3636,
      "step": 920
    },
    {
      "epoch": 0.041856069130023855,
      "grad_norm": 2.2116920948028564,
      "learning_rate": 9.958143930869976e-05,
      "loss": 0.3971,
      "step": 930
    },
    {
      "epoch": 0.04230613438948647,
      "grad_norm": 2.707315683364868,
      "learning_rate": 9.957693865610515e-05,
      "loss": 0.3142,
      "step": 940
    },
    {
      "epoch": 0.0427561996489491,
      "grad_norm": 0.9857003092765808,
      "learning_rate": 9.957243800351051e-05,
      "loss": 0.3174,
      "step": 950
    },
    {
      "epoch": 0.04320626490841172,
      "grad_norm": 1.3159905672073364,
      "learning_rate": 9.956793735091588e-05,
      "loss": 0.4217,
      "step": 960
    },
    {
      "epoch": 0.04365633016787434,
      "grad_norm": 1.9823602437973022,
      "learning_rate": 9.956343669832127e-05,
      "loss": 0.3592,
      "step": 970
    },
    {
      "epoch": 0.044106395427336964,
      "grad_norm": 2.043914794921875,
      "learning_rate": 9.955893604572663e-05,
      "loss": 0.3675,
      "step": 980
    },
    {
      "epoch": 0.04455646068679959,
      "grad_norm": 1.4249063730239868,
      "learning_rate": 9.9554435393132e-05,
      "loss": 0.4045,
      "step": 990
    },
    {
      "epoch": 0.045006525946262206,
      "grad_norm": 2.406796455383301,
      "learning_rate": 9.954993474053739e-05,
      "loss": 0.3251,
      "step": 1000
    },
    {
      "epoch": 0.04545659120572483,
      "grad_norm": 2.6882364749908447,
      "learning_rate": 9.954543408794275e-05,
      "loss": 0.3273,
      "step": 1010
    },
    {
      "epoch": 0.045906656465187455,
      "grad_norm": 1.3997191190719604,
      "learning_rate": 9.954093343534813e-05,
      "loss": 0.3511,
      "step": 1020
    },
    {
      "epoch": 0.04635672172465007,
      "grad_norm": 2.4559454917907715,
      "learning_rate": 9.953643278275351e-05,
      "loss": 0.3722,
      "step": 1030
    },
    {
      "epoch": 0.0468067869841127,
      "grad_norm": 2.0164566040039062,
      "learning_rate": 9.953193213015887e-05,
      "loss": 0.3316,
      "step": 1040
    },
    {
      "epoch": 0.04725685224357532,
      "grad_norm": 2.0743567943573,
      "learning_rate": 9.952743147756425e-05,
      "loss": 0.3661,
      "step": 1050
    },
    {
      "epoch": 0.04770691750303794,
      "grad_norm": 2.8334951400756836,
      "learning_rate": 9.952293082496963e-05,
      "loss": 0.345,
      "step": 1060
    },
    {
      "epoch": 0.048156982762500564,
      "grad_norm": 2.364745855331421,
      "learning_rate": 9.9518430172375e-05,
      "loss": 0.3829,
      "step": 1070
    },
    {
      "epoch": 0.04860704802196318,
      "grad_norm": 1.3879530429840088,
      "learning_rate": 9.951392951978037e-05,
      "loss": 0.3267,
      "step": 1080
    },
    {
      "epoch": 0.049057113281425806,
      "grad_norm": 1.9968526363372803,
      "learning_rate": 9.950942886718575e-05,
      "loss": 0.3472,
      "step": 1090
    },
    {
      "epoch": 0.04950717854088843,
      "grad_norm": 1.5273358821868896,
      "learning_rate": 9.950492821459111e-05,
      "loss": 0.3032,
      "step": 1100
    },
    {
      "epoch": 0.04995724380035105,
      "grad_norm": 1.4684782028198242,
      "learning_rate": 9.950042756199649e-05,
      "loss": 0.3453,
      "step": 1110
    },
    {
      "epoch": 0.05040730905981367,
      "grad_norm": 2.8333449363708496,
      "learning_rate": 9.949592690940188e-05,
      "loss": 0.3511,
      "step": 1120
    },
    {
      "epoch": 0.0508573743192763,
      "grad_norm": 1.9825130701065063,
      "learning_rate": 9.949142625680724e-05,
      "loss": 0.2973,
      "step": 1130
    },
    {
      "epoch": 0.051307439578738914,
      "grad_norm": 1.241758108139038,
      "learning_rate": 9.948692560421261e-05,
      "loss": 0.272,
      "step": 1140
    },
    {
      "epoch": 0.05175750483820154,
      "grad_norm": 2.717698574066162,
      "learning_rate": 9.9482424951618e-05,
      "loss": 0.3004,
      "step": 1150
    },
    {
      "epoch": 0.05220757009766416,
      "grad_norm": 1.8071576356887817,
      "learning_rate": 9.947792429902336e-05,
      "loss": 0.3242,
      "step": 1160
    },
    {
      "epoch": 0.05265763535712678,
      "grad_norm": 1.8681243658065796,
      "learning_rate": 9.947342364642873e-05,
      "loss": 0.3999,
      "step": 1170
    },
    {
      "epoch": 0.053107700616589405,
      "grad_norm": 1.8808467388153076,
      "learning_rate": 9.946892299383412e-05,
      "loss": 0.3294,
      "step": 1180
    },
    {
      "epoch": 0.05355776587605203,
      "grad_norm": 1.379313349723816,
      "learning_rate": 9.946442234123948e-05,
      "loss": 0.3094,
      "step": 1190
    },
    {
      "epoch": 0.05400783113551465,
      "grad_norm": 1.4253212213516235,
      "learning_rate": 9.945992168864486e-05,
      "loss": 0.3528,
      "step": 1200
    },
    {
      "epoch": 0.05445789639497727,
      "grad_norm": 1.6248784065246582,
      "learning_rate": 9.945542103605024e-05,
      "loss": 0.2809,
      "step": 1210
    },
    {
      "epoch": 0.054907961654439896,
      "grad_norm": 1.0029579401016235,
      "learning_rate": 9.94509203834556e-05,
      "loss": 0.3666,
      "step": 1220
    },
    {
      "epoch": 0.055358026913902514,
      "grad_norm": 2.04823899269104,
      "learning_rate": 9.944641973086099e-05,
      "loss": 0.2965,
      "step": 1230
    },
    {
      "epoch": 0.05580809217336514,
      "grad_norm": 2.2935373783111572,
      "learning_rate": 9.944191907826636e-05,
      "loss": 0.3401,
      "step": 1240
    },
    {
      "epoch": 0.05625815743282776,
      "grad_norm": 0.9849081039428711,
      "learning_rate": 9.943741842567172e-05,
      "loss": 0.3532,
      "step": 1250
    },
    {
      "epoch": 0.05670822269229038,
      "grad_norm": 1.6272659301757812,
      "learning_rate": 9.94329177730771e-05,
      "loss": 0.3086,
      "step": 1260
    },
    {
      "epoch": 0.057158287951753005,
      "grad_norm": 1.4441910982131958,
      "learning_rate": 9.942841712048248e-05,
      "loss": 0.3859,
      "step": 1270
    },
    {
      "epoch": 0.05760835321121563,
      "grad_norm": 2.16697096824646,
      "learning_rate": 9.942391646788784e-05,
      "loss": 0.3432,
      "step": 1280
    },
    {
      "epoch": 0.05805841847067825,
      "grad_norm": 1.5546411275863647,
      "learning_rate": 9.941941581529323e-05,
      "loss": 0.3545,
      "step": 1290
    },
    {
      "epoch": 0.05850848373014087,
      "grad_norm": 2.2736501693725586,
      "learning_rate": 9.94149151626986e-05,
      "loss": 0.3428,
      "step": 1300
    },
    {
      "epoch": 0.058958548989603496,
      "grad_norm": 1.4821693897247314,
      "learning_rate": 9.941041451010396e-05,
      "loss": 0.3092,
      "step": 1310
    },
    {
      "epoch": 0.05940861424906611,
      "grad_norm": 2.69075870513916,
      "learning_rate": 9.940591385750935e-05,
      "loss": 0.3312,
      "step": 1320
    },
    {
      "epoch": 0.05985867950852874,
      "grad_norm": 1.441357970237732,
      "learning_rate": 9.940141320491472e-05,
      "loss": 0.3396,
      "step": 1330
    },
    {
      "epoch": 0.060308744767991355,
      "grad_norm": 2.6243515014648438,
      "learning_rate": 9.939691255232008e-05,
      "loss": 0.3914,
      "step": 1340
    },
    {
      "epoch": 0.06075881002745398,
      "grad_norm": 1.482005000114441,
      "learning_rate": 9.939241189972547e-05,
      "loss": 0.2922,
      "step": 1350
    },
    {
      "epoch": 0.061208875286916604,
      "grad_norm": 1.1742312908172607,
      "learning_rate": 9.938791124713084e-05,
      "loss": 0.3635,
      "step": 1360
    },
    {
      "epoch": 0.06165894054637922,
      "grad_norm": 1.981799602508545,
      "learning_rate": 9.93834105945362e-05,
      "loss": 0.2854,
      "step": 1370
    },
    {
      "epoch": 0.062109005805841846,
      "grad_norm": 1.2757567167282104,
      "learning_rate": 9.937890994194159e-05,
      "loss": 0.3377,
      "step": 1380
    },
    {
      "epoch": 0.06255907106530446,
      "grad_norm": 1.9558953046798706,
      "learning_rate": 9.937440928934696e-05,
      "loss": 0.3457,
      "step": 1390
    },
    {
      "epoch": 0.0630091363247671,
      "grad_norm": 1.745740532875061,
      "learning_rate": 9.936990863675232e-05,
      "loss": 0.2529,
      "step": 1400
    },
    {
      "epoch": 0.06345920158422971,
      "grad_norm": 3.5838606357574463,
      "learning_rate": 9.936540798415771e-05,
      "loss": 0.3281,
      "step": 1410
    },
    {
      "epoch": 0.06390926684369233,
      "grad_norm": 1.0429439544677734,
      "learning_rate": 9.936090733156308e-05,
      "loss": 0.2469,
      "step": 1420
    },
    {
      "epoch": 0.06435933210315496,
      "grad_norm": 1.475380778312683,
      "learning_rate": 9.935640667896844e-05,
      "loss": 0.3336,
      "step": 1430
    },
    {
      "epoch": 0.06480939736261758,
      "grad_norm": 2.3834869861602783,
      "learning_rate": 9.935190602637383e-05,
      "loss": 0.3472,
      "step": 1440
    },
    {
      "epoch": 0.0652594626220802,
      "grad_norm": 2.004476547241211,
      "learning_rate": 9.93474053737792e-05,
      "loss": 0.2685,
      "step": 1450
    },
    {
      "epoch": 0.06570952788154283,
      "grad_norm": 3.948333263397217,
      "learning_rate": 9.934290472118458e-05,
      "loss": 0.4233,
      "step": 1460
    },
    {
      "epoch": 0.06615959314100545,
      "grad_norm": 1.7178839445114136,
      "learning_rate": 9.933840406858995e-05,
      "loss": 0.2567,
      "step": 1470
    },
    {
      "epoch": 0.06660965840046806,
      "grad_norm": 1.8043041229248047,
      "learning_rate": 9.933390341599533e-05,
      "loss": 0.3193,
      "step": 1480
    },
    {
      "epoch": 0.0670597236599307,
      "grad_norm": 2.014103889465332,
      "learning_rate": 9.93294027634007e-05,
      "loss": 0.3661,
      "step": 1490
    },
    {
      "epoch": 0.06750978891939331,
      "grad_norm": 1.6025826930999756,
      "learning_rate": 9.932490211080607e-05,
      "loss": 0.3018,
      "step": 1500
    },
    {
      "epoch": 0.06795985417885593,
      "grad_norm": 1.8439611196517944,
      "learning_rate": 9.932040145821145e-05,
      "loss": 0.3553,
      "step": 1510
    },
    {
      "epoch": 0.06840991943831856,
      "grad_norm": 1.3592740297317505,
      "learning_rate": 9.931590080561682e-05,
      "loss": 0.3617,
      "step": 1520
    },
    {
      "epoch": 0.06885998469778118,
      "grad_norm": 2.1150612831115723,
      "learning_rate": 9.931140015302219e-05,
      "loss": 0.2885,
      "step": 1530
    },
    {
      "epoch": 0.0693100499572438,
      "grad_norm": 1.9386016130447388,
      "learning_rate": 9.930689950042757e-05,
      "loss": 0.3202,
      "step": 1540
    },
    {
      "epoch": 0.06976011521670643,
      "grad_norm": 2.8672542572021484,
      "learning_rate": 9.930239884783294e-05,
      "loss": 0.3417,
      "step": 1550
    },
    {
      "epoch": 0.07021018047616905,
      "grad_norm": 0.7570956945419312,
      "learning_rate": 9.929789819523831e-05,
      "loss": 0.3228,
      "step": 1560
    },
    {
      "epoch": 0.07066024573563166,
      "grad_norm": 1.9319933652877808,
      "learning_rate": 9.929339754264369e-05,
      "loss": 0.2945,
      "step": 1570
    },
    {
      "epoch": 0.0711103109950943,
      "grad_norm": 2.1348371505737305,
      "learning_rate": 9.928889689004906e-05,
      "loss": 0.2659,
      "step": 1580
    },
    {
      "epoch": 0.07156037625455691,
      "grad_norm": 2.6499171257019043,
      "learning_rate": 9.928439623745443e-05,
      "loss": 0.3235,
      "step": 1590
    },
    {
      "epoch": 0.07201044151401953,
      "grad_norm": 1.8936222791671753,
      "learning_rate": 9.927989558485981e-05,
      "loss": 0.2826,
      "step": 1600
    },
    {
      "epoch": 0.07246050677348216,
      "grad_norm": 2.004601001739502,
      "learning_rate": 9.927539493226518e-05,
      "loss": 0.3175,
      "step": 1610
    },
    {
      "epoch": 0.07291057203294478,
      "grad_norm": 1.2214806079864502,
      "learning_rate": 9.927089427967056e-05,
      "loss": 0.3025,
      "step": 1620
    },
    {
      "epoch": 0.0733606372924074,
      "grad_norm": 2.5207951068878174,
      "learning_rate": 9.926639362707593e-05,
      "loss": 0.3338,
      "step": 1630
    },
    {
      "epoch": 0.07381070255187003,
      "grad_norm": 1.6998810768127441,
      "learning_rate": 9.92618929744813e-05,
      "loss": 0.3365,
      "step": 1640
    },
    {
      "epoch": 0.07426076781133265,
      "grad_norm": 2.3801748752593994,
      "learning_rate": 9.925739232188668e-05,
      "loss": 0.3296,
      "step": 1650
    },
    {
      "epoch": 0.07471083307079526,
      "grad_norm": 1.5860275030136108,
      "learning_rate": 9.925289166929205e-05,
      "loss": 0.2735,
      "step": 1660
    },
    {
      "epoch": 0.0751608983302579,
      "grad_norm": 3.4944186210632324,
      "learning_rate": 9.924839101669742e-05,
      "loss": 0.3172,
      "step": 1670
    },
    {
      "epoch": 0.07561096358972051,
      "grad_norm": 2.0828588008880615,
      "learning_rate": 9.92438903641028e-05,
      "loss": 0.3213,
      "step": 1680
    },
    {
      "epoch": 0.07606102884918313,
      "grad_norm": 2.526313304901123,
      "learning_rate": 9.923938971150817e-05,
      "loss": 0.3124,
      "step": 1690
    },
    {
      "epoch": 0.07651109410864575,
      "grad_norm": 2.15551495552063,
      "learning_rate": 9.923488905891354e-05,
      "loss": 0.289,
      "step": 1700
    },
    {
      "epoch": 0.07696115936810838,
      "grad_norm": 1.6584439277648926,
      "learning_rate": 9.923038840631892e-05,
      "loss": 0.3437,
      "step": 1710
    },
    {
      "epoch": 0.077411224627571,
      "grad_norm": 2.153942584991455,
      "learning_rate": 9.922588775372429e-05,
      "loss": 0.2987,
      "step": 1720
    },
    {
      "epoch": 0.07786128988703361,
      "grad_norm": 2.319882392883301,
      "learning_rate": 9.922138710112967e-05,
      "loss": 0.2238,
      "step": 1730
    },
    {
      "epoch": 0.07831135514649624,
      "grad_norm": 1.042568564414978,
      "learning_rate": 9.921688644853504e-05,
      "loss": 0.3388,
      "step": 1740
    },
    {
      "epoch": 0.07876142040595886,
      "grad_norm": 1.7932289838790894,
      "learning_rate": 9.921238579594043e-05,
      "loss": 0.3718,
      "step": 1750
    },
    {
      "epoch": 0.07921148566542148,
      "grad_norm": 1.6718029975891113,
      "learning_rate": 9.920788514334579e-05,
      "loss": 0.3289,
      "step": 1760
    },
    {
      "epoch": 0.07966155092488411,
      "grad_norm": 2.7390363216400146,
      "learning_rate": 9.920338449075116e-05,
      "loss": 0.2905,
      "step": 1770
    },
    {
      "epoch": 0.08011161618434673,
      "grad_norm": 2.1234641075134277,
      "learning_rate": 9.919888383815655e-05,
      "loss": 0.2999,
      "step": 1780
    },
    {
      "epoch": 0.08056168144380935,
      "grad_norm": 1.5359939336776733,
      "learning_rate": 9.919438318556191e-05,
      "loss": 0.2561,
      "step": 1790
    },
    {
      "epoch": 0.08101174670327198,
      "grad_norm": 1.8756294250488281,
      "learning_rate": 9.918988253296728e-05,
      "loss": 0.2832,
      "step": 1800
    },
    {
      "epoch": 0.0814618119627346,
      "grad_norm": 1.4425431489944458,
      "learning_rate": 9.918538188037267e-05,
      "loss": 0.2403,
      "step": 1810
    },
    {
      "epoch": 0.08191187722219721,
      "grad_norm": 1.7091740369796753,
      "learning_rate": 9.918088122777803e-05,
      "loss": 0.2544,
      "step": 1820
    },
    {
      "epoch": 0.08236194248165984,
      "grad_norm": 2.9457781314849854,
      "learning_rate": 9.91763805751834e-05,
      "loss": 0.2742,
      "step": 1830
    },
    {
      "epoch": 0.08281200774112246,
      "grad_norm": 1.6388550996780396,
      "learning_rate": 9.917187992258879e-05,
      "loss": 0.2196,
      "step": 1840
    },
    {
      "epoch": 0.08326207300058508,
      "grad_norm": 1.2158658504486084,
      "learning_rate": 9.916737926999415e-05,
      "loss": 0.2446,
      "step": 1850
    },
    {
      "epoch": 0.08371213826004771,
      "grad_norm": 2.2625346183776855,
      "learning_rate": 9.916287861739952e-05,
      "loss": 0.3195,
      "step": 1860
    },
    {
      "epoch": 0.08416220351951033,
      "grad_norm": 2.2235498428344727,
      "learning_rate": 9.915837796480491e-05,
      "loss": 0.2435,
      "step": 1870
    },
    {
      "epoch": 0.08461226877897295,
      "grad_norm": 2.199087142944336,
      "learning_rate": 9.915387731221027e-05,
      "loss": 0.2472,
      "step": 1880
    },
    {
      "epoch": 0.08506233403843558,
      "grad_norm": 2.0462827682495117,
      "learning_rate": 9.914937665961564e-05,
      "loss": 0.2932,
      "step": 1890
    },
    {
      "epoch": 0.0855123992978982,
      "grad_norm": 1.157240390777588,
      "learning_rate": 9.914487600702103e-05,
      "loss": 0.2314,
      "step": 1900
    },
    {
      "epoch": 0.08596246455736081,
      "grad_norm": 1.687347650527954,
      "learning_rate": 9.914037535442639e-05,
      "loss": 0.2049,
      "step": 1910
    },
    {
      "epoch": 0.08641252981682344,
      "grad_norm": 3.5019168853759766,
      "learning_rate": 9.913587470183176e-05,
      "loss": 0.2784,
      "step": 1920
    },
    {
      "epoch": 0.08686259507628606,
      "grad_norm": 2.2777318954467773,
      "learning_rate": 9.913137404923715e-05,
      "loss": 0.2097,
      "step": 1930
    },
    {
      "epoch": 0.08731266033574868,
      "grad_norm": 2.5591580867767334,
      "learning_rate": 9.912687339664251e-05,
      "loss": 0.3291,
      "step": 1940
    },
    {
      "epoch": 0.08776272559521131,
      "grad_norm": 2.4231948852539062,
      "learning_rate": 9.912237274404788e-05,
      "loss": 0.3345,
      "step": 1950
    },
    {
      "epoch": 0.08821279085467393,
      "grad_norm": 2.0947394371032715,
      "learning_rate": 9.911787209145327e-05,
      "loss": 0.2509,
      "step": 1960
    },
    {
      "epoch": 0.08866285611413655,
      "grad_norm": 1.245121717453003,
      "learning_rate": 9.911337143885863e-05,
      "loss": 0.3008,
      "step": 1970
    },
    {
      "epoch": 0.08911292137359918,
      "grad_norm": 1.5868473052978516,
      "learning_rate": 9.9108870786264e-05,
      "loss": 0.2926,
      "step": 1980
    },
    {
      "epoch": 0.0895629866330618,
      "grad_norm": 1.9943240880966187,
      "learning_rate": 9.910437013366939e-05,
      "loss": 0.252,
      "step": 1990
    },
    {
      "epoch": 0.09001305189252441,
      "grad_norm": 1.6439656019210815,
      "learning_rate": 9.909986948107475e-05,
      "loss": 0.2545,
      "step": 2000
    },
    {
      "epoch": 0.09046311715198704,
      "grad_norm": 2.645476818084717,
      "learning_rate": 9.909536882848014e-05,
      "loss": 0.274,
      "step": 2010
    },
    {
      "epoch": 0.09091318241144966,
      "grad_norm": 1.5595598220825195,
      "learning_rate": 9.909086817588551e-05,
      "loss": 0.2271,
      "step": 2020
    },
    {
      "epoch": 0.09136324767091228,
      "grad_norm": 3.0517776012420654,
      "learning_rate": 9.908636752329087e-05,
      "loss": 0.323,
      "step": 2030
    },
    {
      "epoch": 0.09181331293037491,
      "grad_norm": 1.8137562274932861,
      "learning_rate": 9.908186687069626e-05,
      "loss": 0.2923,
      "step": 2040
    },
    {
      "epoch": 0.09226337818983753,
      "grad_norm": 2.232895612716675,
      "learning_rate": 9.907736621810163e-05,
      "loss": 0.336,
      "step": 2050
    },
    {
      "epoch": 0.09271344344930015,
      "grad_norm": 1.9651083946228027,
      "learning_rate": 9.9072865565507e-05,
      "loss": 0.2372,
      "step": 2060
    },
    {
      "epoch": 0.09316350870876278,
      "grad_norm": 1.3082290887832642,
      "learning_rate": 9.906836491291238e-05,
      "loss": 0.2362,
      "step": 2070
    },
    {
      "epoch": 0.0936135739682254,
      "grad_norm": 1.4861605167388916,
      "learning_rate": 9.906386426031775e-05,
      "loss": 0.2402,
      "step": 2080
    },
    {
      "epoch": 0.09406363922768801,
      "grad_norm": 1.3077504634857178,
      "learning_rate": 9.905936360772311e-05,
      "loss": 0.2479,
      "step": 2090
    },
    {
      "epoch": 0.09451370448715064,
      "grad_norm": 0.9019849300384521,
      "learning_rate": 9.90548629551285e-05,
      "loss": 0.3437,
      "step": 2100
    },
    {
      "epoch": 0.09496376974661326,
      "grad_norm": 2.5288665294647217,
      "learning_rate": 9.905036230253388e-05,
      "loss": 0.2812,
      "step": 2110
    },
    {
      "epoch": 0.09541383500607588,
      "grad_norm": 2.7807185649871826,
      "learning_rate": 9.904586164993924e-05,
      "loss": 0.2954,
      "step": 2120
    },
    {
      "epoch": 0.09586390026553851,
      "grad_norm": 2.2363686561584473,
      "learning_rate": 9.904136099734462e-05,
      "loss": 0.2612,
      "step": 2130
    },
    {
      "epoch": 0.09631396552500113,
      "grad_norm": 2.366929531097412,
      "learning_rate": 9.903686034475e-05,
      "loss": 0.2144,
      "step": 2140
    },
    {
      "epoch": 0.09676403078446374,
      "grad_norm": 3.3724043369293213,
      "learning_rate": 9.903235969215536e-05,
      "loss": 0.2742,
      "step": 2150
    },
    {
      "epoch": 0.09721409604392636,
      "grad_norm": 2.914091110229492,
      "learning_rate": 9.902785903956074e-05,
      "loss": 0.2222,
      "step": 2160
    },
    {
      "epoch": 0.097664161303389,
      "grad_norm": 0.8587416410446167,
      "learning_rate": 9.902335838696612e-05,
      "loss": 0.2264,
      "step": 2170
    },
    {
      "epoch": 0.09811422656285161,
      "grad_norm": 2.149946928024292,
      "learning_rate": 9.901885773437148e-05,
      "loss": 0.2874,
      "step": 2180
    },
    {
      "epoch": 0.09856429182231423,
      "grad_norm": 2.2416045665740967,
      "learning_rate": 9.901435708177686e-05,
      "loss": 0.2482,
      "step": 2190
    },
    {
      "epoch": 0.09901435708177686,
      "grad_norm": 2.166171073913574,
      "learning_rate": 9.900985642918224e-05,
      "loss": 0.2552,
      "step": 2200
    },
    {
      "epoch": 0.09946442234123948,
      "grad_norm": 2.8879170417785645,
      "learning_rate": 9.90053557765876e-05,
      "loss": 0.2699,
      "step": 2210
    },
    {
      "epoch": 0.0999144876007021,
      "grad_norm": 2.0691111087799072,
      "learning_rate": 9.900085512399299e-05,
      "loss": 0.232,
      "step": 2220
    },
    {
      "epoch": 0.10036455286016473,
      "grad_norm": 3.5248260498046875,
      "learning_rate": 9.899635447139836e-05,
      "loss": 0.3057,
      "step": 2230
    },
    {
      "epoch": 0.10081461811962734,
      "grad_norm": 1.604433536529541,
      "learning_rate": 9.899185381880373e-05,
      "loss": 0.2629,
      "step": 2240
    },
    {
      "epoch": 0.10126468337908996,
      "grad_norm": 1.6868009567260742,
      "learning_rate": 9.89873531662091e-05,
      "loss": 0.2884,
      "step": 2250
    },
    {
      "epoch": 0.1017147486385526,
      "grad_norm": 1.3146926164627075,
      "learning_rate": 9.898285251361448e-05,
      "loss": 0.2847,
      "step": 2260
    },
    {
      "epoch": 0.10216481389801521,
      "grad_norm": 1.1196284294128418,
      "learning_rate": 9.897835186101985e-05,
      "loss": 0.192,
      "step": 2270
    },
    {
      "epoch": 0.10261487915747783,
      "grad_norm": 1.6295007467269897,
      "learning_rate": 9.897385120842523e-05,
      "loss": 0.2654,
      "step": 2280
    },
    {
      "epoch": 0.10306494441694046,
      "grad_norm": 1.18349289894104,
      "learning_rate": 9.89693505558306e-05,
      "loss": 0.2547,
      "step": 2290
    },
    {
      "epoch": 0.10351500967640308,
      "grad_norm": 1.2875900268554688,
      "learning_rate": 9.896484990323597e-05,
      "loss": 0.3047,
      "step": 2300
    },
    {
      "epoch": 0.1039650749358657,
      "grad_norm": 2.3882977962493896,
      "learning_rate": 9.896034925064135e-05,
      "loss": 0.2543,
      "step": 2310
    },
    {
      "epoch": 0.10441514019532833,
      "grad_norm": 0.9197096824645996,
      "learning_rate": 9.895584859804672e-05,
      "loss": 0.262,
      "step": 2320
    },
    {
      "epoch": 0.10486520545479094,
      "grad_norm": 2.622471570968628,
      "learning_rate": 9.89513479454521e-05,
      "loss": 0.2053,
      "step": 2330
    },
    {
      "epoch": 0.10531527071425356,
      "grad_norm": 1.6267666816711426,
      "learning_rate": 9.894684729285747e-05,
      "loss": 0.2608,
      "step": 2340
    },
    {
      "epoch": 0.10576533597371619,
      "grad_norm": 2.1234896183013916,
      "learning_rate": 9.894234664026284e-05,
      "loss": 0.25,
      "step": 2350
    },
    {
      "epoch": 0.10621540123317881,
      "grad_norm": 2.9281692504882812,
      "learning_rate": 9.893784598766822e-05,
      "loss": 0.2291,
      "step": 2360
    },
    {
      "epoch": 0.10666546649264143,
      "grad_norm": 3.6289279460906982,
      "learning_rate": 9.893334533507359e-05,
      "loss": 0.2201,
      "step": 2370
    },
    {
      "epoch": 0.10711553175210406,
      "grad_norm": 1.0565366744995117,
      "learning_rate": 9.892884468247896e-05,
      "loss": 0.2553,
      "step": 2380
    },
    {
      "epoch": 0.10756559701156668,
      "grad_norm": 0.8406755924224854,
      "learning_rate": 9.892434402988434e-05,
      "loss": 0.2877,
      "step": 2390
    },
    {
      "epoch": 0.1080156622710293,
      "grad_norm": 1.6829209327697754,
      "learning_rate": 9.891984337728971e-05,
      "loss": 0.3384,
      "step": 2400
    },
    {
      "epoch": 0.10846572753049193,
      "grad_norm": 3.431751012802124,
      "learning_rate": 9.891534272469508e-05,
      "loss": 0.2564,
      "step": 2410
    },
    {
      "epoch": 0.10891579278995454,
      "grad_norm": 2.019864082336426,
      "learning_rate": 9.891084207210046e-05,
      "loss": 0.2864,
      "step": 2420
    },
    {
      "epoch": 0.10936585804941716,
      "grad_norm": 2.406244993209839,
      "learning_rate": 9.890634141950583e-05,
      "loss": 0.2985,
      "step": 2430
    },
    {
      "epoch": 0.10981592330887979,
      "grad_norm": 2.1122474670410156,
      "learning_rate": 9.89018407669112e-05,
      "loss": 0.2338,
      "step": 2440
    },
    {
      "epoch": 0.11026598856834241,
      "grad_norm": 0.3943389058113098,
      "learning_rate": 9.889734011431658e-05,
      "loss": 0.2255,
      "step": 2450
    },
    {
      "epoch": 0.11071605382780503,
      "grad_norm": 1.96915864944458,
      "learning_rate": 9.889283946172195e-05,
      "loss": 0.2565,
      "step": 2460
    },
    {
      "epoch": 0.11116611908726766,
      "grad_norm": 1.84942626953125,
      "learning_rate": 9.888833880912733e-05,
      "loss": 0.2531,
      "step": 2470
    },
    {
      "epoch": 0.11161618434673028,
      "grad_norm": 1.2757301330566406,
      "learning_rate": 9.88838381565327e-05,
      "loss": 0.2839,
      "step": 2480
    },
    {
      "epoch": 0.1120662496061929,
      "grad_norm": 1.6458173990249634,
      "learning_rate": 9.887933750393807e-05,
      "loss": 0.2567,
      "step": 2490
    },
    {
      "epoch": 0.11251631486565553,
      "grad_norm": 3.0941359996795654,
      "learning_rate": 9.887483685134345e-05,
      "loss": 0.2998,
      "step": 2500
    },
    {
      "epoch": 0.11296638012511814,
      "grad_norm": 1.9986670017242432,
      "learning_rate": 9.887033619874882e-05,
      "loss": 0.2651,
      "step": 2510
    },
    {
      "epoch": 0.11341644538458076,
      "grad_norm": 1.9549405574798584,
      "learning_rate": 9.88658355461542e-05,
      "loss": 0.2509,
      "step": 2520
    },
    {
      "epoch": 0.11386651064404339,
      "grad_norm": 1.705582618713379,
      "learning_rate": 9.886133489355958e-05,
      "loss": 0.2751,
      "step": 2530
    },
    {
      "epoch": 0.11431657590350601,
      "grad_norm": 2.5807275772094727,
      "learning_rate": 9.885683424096494e-05,
      "loss": 0.2323,
      "step": 2540
    },
    {
      "epoch": 0.11476664116296863,
      "grad_norm": 1.638375997543335,
      "learning_rate": 9.885233358837031e-05,
      "loss": 0.2526,
      "step": 2550
    },
    {
      "epoch": 0.11521670642243126,
      "grad_norm": 1.8350776433944702,
      "learning_rate": 9.88478329357757e-05,
      "loss": 0.267,
      "step": 2560
    },
    {
      "epoch": 0.11566677168189388,
      "grad_norm": 2.497352361679077,
      "learning_rate": 9.884333228318106e-05,
      "loss": 0.2654,
      "step": 2570
    },
    {
      "epoch": 0.1161168369413565,
      "grad_norm": 2.8320538997650146,
      "learning_rate": 9.883883163058644e-05,
      "loss": 0.2952,
      "step": 2580
    },
    {
      "epoch": 0.11656690220081913,
      "grad_norm": 1.3366354703903198,
      "learning_rate": 9.883433097799182e-05,
      "loss": 0.2676,
      "step": 2590
    },
    {
      "epoch": 0.11701696746028174,
      "grad_norm": 1.3182377815246582,
      "learning_rate": 9.882983032539718e-05,
      "loss": 0.2455,
      "step": 2600
    },
    {
      "epoch": 0.11746703271974436,
      "grad_norm": 1.8024955987930298,
      "learning_rate": 9.882532967280256e-05,
      "loss": 0.2458,
      "step": 2610
    },
    {
      "epoch": 0.11791709797920699,
      "grad_norm": 2.209792375564575,
      "learning_rate": 9.882082902020794e-05,
      "loss": 0.2451,
      "step": 2620
    },
    {
      "epoch": 0.11836716323866961,
      "grad_norm": 1.137870192527771,
      "learning_rate": 9.88163283676133e-05,
      "loss": 0.3024,
      "step": 2630
    },
    {
      "epoch": 0.11881722849813223,
      "grad_norm": 1.7425702810287476,
      "learning_rate": 9.881182771501868e-05,
      "loss": 0.2494,
      "step": 2640
    },
    {
      "epoch": 0.11926729375759484,
      "grad_norm": 2.340874195098877,
      "learning_rate": 9.880732706242406e-05,
      "loss": 0.2808,
      "step": 2650
    },
    {
      "epoch": 0.11971735901705748,
      "grad_norm": 3.293592929840088,
      "learning_rate": 9.880282640982942e-05,
      "loss": 0.2652,
      "step": 2660
    },
    {
      "epoch": 0.1201674242765201,
      "grad_norm": 2.48736834526062,
      "learning_rate": 9.87983257572348e-05,
      "loss": 0.2908,
      "step": 2670
    },
    {
      "epoch": 0.12061748953598271,
      "grad_norm": 3.041841745376587,
      "learning_rate": 9.879382510464018e-05,
      "loss": 0.303,
      "step": 2680
    },
    {
      "epoch": 0.12106755479544534,
      "grad_norm": 1.8282301425933838,
      "learning_rate": 9.878932445204554e-05,
      "loss": 0.2158,
      "step": 2690
    },
    {
      "epoch": 0.12151762005490796,
      "grad_norm": 1.6981545686721802,
      "learning_rate": 9.878482379945092e-05,
      "loss": 0.2107,
      "step": 2700
    },
    {
      "epoch": 0.12196768531437058,
      "grad_norm": 1.9146692752838135,
      "learning_rate": 9.87803231468563e-05,
      "loss": 0.2145,
      "step": 2710
    },
    {
      "epoch": 0.12241775057383321,
      "grad_norm": 2.2036216259002686,
      "learning_rate": 9.877582249426167e-05,
      "loss": 0.2651,
      "step": 2720
    },
    {
      "epoch": 0.12286781583329583,
      "grad_norm": 1.718312382698059,
      "learning_rate": 9.877132184166704e-05,
      "loss": 0.263,
      "step": 2730
    },
    {
      "epoch": 0.12331788109275844,
      "grad_norm": 1.0735316276550293,
      "learning_rate": 9.876682118907243e-05,
      "loss": 0.22,
      "step": 2740
    },
    {
      "epoch": 0.12376794635222108,
      "grad_norm": 0.720014750957489,
      "learning_rate": 9.876232053647779e-05,
      "loss": 0.2301,
      "step": 2750
    },
    {
      "epoch": 0.12421801161168369,
      "grad_norm": 2.5814647674560547,
      "learning_rate": 9.875781988388316e-05,
      "loss": 0.2996,
      "step": 2760
    },
    {
      "epoch": 0.12466807687114631,
      "grad_norm": 1.1579968929290771,
      "learning_rate": 9.875331923128855e-05,
      "loss": 0.2486,
      "step": 2770
    },
    {
      "epoch": 0.12511814213060893,
      "grad_norm": 1.4282183647155762,
      "learning_rate": 9.874881857869391e-05,
      "loss": 0.2694,
      "step": 2780
    },
    {
      "epoch": 0.12556820739007157,
      "grad_norm": 1.8759220838546753,
      "learning_rate": 9.87443179260993e-05,
      "loss": 0.2557,
      "step": 2790
    },
    {
      "epoch": 0.1260182726495342,
      "grad_norm": 3.2084357738494873,
      "learning_rate": 9.873981727350467e-05,
      "loss": 0.2175,
      "step": 2800
    },
    {
      "epoch": 0.1264683379089968,
      "grad_norm": 2.274759531021118,
      "learning_rate": 9.873531662091003e-05,
      "loss": 0.2243,
      "step": 2810
    },
    {
      "epoch": 0.12691840316845943,
      "grad_norm": 1.8413922786712646,
      "learning_rate": 9.873081596831542e-05,
      "loss": 0.1848,
      "step": 2820
    },
    {
      "epoch": 0.12736846842792204,
      "grad_norm": 3.029771327972412,
      "learning_rate": 9.872631531572079e-05,
      "loss": 0.191,
      "step": 2830
    },
    {
      "epoch": 0.12781853368738466,
      "grad_norm": 1.7088276147842407,
      "learning_rate": 9.872181466312615e-05,
      "loss": 0.1805,
      "step": 2840
    },
    {
      "epoch": 0.1282685989468473,
      "grad_norm": 2.84603214263916,
      "learning_rate": 9.871731401053154e-05,
      "loss": 0.3086,
      "step": 2850
    },
    {
      "epoch": 0.12871866420630992,
      "grad_norm": 4.414430618286133,
      "learning_rate": 9.871281335793691e-05,
      "loss": 0.2525,
      "step": 2860
    },
    {
      "epoch": 0.12916872946577254,
      "grad_norm": 2.569762945175171,
      "learning_rate": 9.870831270534227e-05,
      "loss": 0.2523,
      "step": 2870
    },
    {
      "epoch": 0.12961879472523516,
      "grad_norm": 1.193787932395935,
      "learning_rate": 9.870381205274766e-05,
      "loss": 0.2826,
      "step": 2880
    },
    {
      "epoch": 0.13006885998469778,
      "grad_norm": 1.5799747705459595,
      "learning_rate": 9.869931140015303e-05,
      "loss": 0.2742,
      "step": 2890
    },
    {
      "epoch": 0.1305189252441604,
      "grad_norm": 1.2302757501602173,
      "learning_rate": 9.869481074755839e-05,
      "loss": 0.237,
      "step": 2900
    },
    {
      "epoch": 0.130968990503623,
      "grad_norm": 1.3475900888442993,
      "learning_rate": 9.869031009496378e-05,
      "loss": 0.2358,
      "step": 2910
    },
    {
      "epoch": 0.13141905576308566,
      "grad_norm": 3.578817129135132,
      "learning_rate": 9.868580944236915e-05,
      "loss": 0.2235,
      "step": 2920
    },
    {
      "epoch": 0.13186912102254827,
      "grad_norm": 3.3022990226745605,
      "learning_rate": 9.868130878977452e-05,
      "loss": 0.264,
      "step": 2930
    },
    {
      "epoch": 0.1323191862820109,
      "grad_norm": 2.311746835708618,
      "learning_rate": 9.86768081371799e-05,
      "loss": 0.2589,
      "step": 2940
    },
    {
      "epoch": 0.1327692515414735,
      "grad_norm": 1.6963049173355103,
      "learning_rate": 9.867230748458527e-05,
      "loss": 0.2428,
      "step": 2950
    },
    {
      "epoch": 0.13321931680093613,
      "grad_norm": 1.330472469329834,
      "learning_rate": 9.866780683199065e-05,
      "loss": 0.2229,
      "step": 2960
    },
    {
      "epoch": 0.13366938206039874,
      "grad_norm": 1.5372670888900757,
      "learning_rate": 9.866330617939602e-05,
      "loss": 0.1907,
      "step": 2970
    },
    {
      "epoch": 0.1341194473198614,
      "grad_norm": 2.555300712585449,
      "learning_rate": 9.865880552680139e-05,
      "loss": 0.2799,
      "step": 2980
    },
    {
      "epoch": 0.134569512579324,
      "grad_norm": 3.208874225616455,
      "learning_rate": 9.865430487420677e-05,
      "loss": 0.2292,
      "step": 2990
    },
    {
      "epoch": 0.13501957783878663,
      "grad_norm": 2.3745241165161133,
      "learning_rate": 9.864980422161214e-05,
      "loss": 0.2206,
      "step": 3000
    },
    {
      "epoch": 0.13546964309824924,
      "grad_norm": 2.6992106437683105,
      "learning_rate": 9.864530356901751e-05,
      "loss": 0.2238,
      "step": 3010
    },
    {
      "epoch": 0.13591970835771186,
      "grad_norm": 2.0541512966156006,
      "learning_rate": 9.864080291642289e-05,
      "loss": 0.3128,
      "step": 3020
    },
    {
      "epoch": 0.13636977361717448,
      "grad_norm": 1.2467658519744873,
      "learning_rate": 9.863630226382826e-05,
      "loss": 0.2107,
      "step": 3030
    },
    {
      "epoch": 0.13681983887663712,
      "grad_norm": 1.468176007270813,
      "learning_rate": 9.863180161123363e-05,
      "loss": 0.2597,
      "step": 3040
    },
    {
      "epoch": 0.13726990413609974,
      "grad_norm": 0.95204097032547,
      "learning_rate": 9.862730095863901e-05,
      "loss": 0.2511,
      "step": 3050
    },
    {
      "epoch": 0.13771996939556236,
      "grad_norm": 2.9259912967681885,
      "learning_rate": 9.862280030604438e-05,
      "loss": 0.2829,
      "step": 3060
    },
    {
      "epoch": 0.13817003465502498,
      "grad_norm": 2.76355242729187,
      "learning_rate": 9.861829965344976e-05,
      "loss": 0.2492,
      "step": 3070
    },
    {
      "epoch": 0.1386200999144876,
      "grad_norm": 2.398379325866699,
      "learning_rate": 9.861379900085513e-05,
      "loss": 0.2717,
      "step": 3080
    },
    {
      "epoch": 0.1390701651739502,
      "grad_norm": 1.0483256578445435,
      "learning_rate": 9.86092983482605e-05,
      "loss": 0.1985,
      "step": 3090
    },
    {
      "epoch": 0.13952023043341286,
      "grad_norm": 1.8935142755508423,
      "learning_rate": 9.860479769566588e-05,
      "loss": 0.2463,
      "step": 3100
    },
    {
      "epoch": 0.13997029569287547,
      "grad_norm": 2.9745676517486572,
      "learning_rate": 9.860029704307125e-05,
      "loss": 0.3071,
      "step": 3110
    },
    {
      "epoch": 0.1404203609523381,
      "grad_norm": 1.6433465480804443,
      "learning_rate": 9.859579639047662e-05,
      "loss": 0.2473,
      "step": 3120
    },
    {
      "epoch": 0.1408704262118007,
      "grad_norm": 2.685553789138794,
      "learning_rate": 9.8591295737882e-05,
      "loss": 0.2304,
      "step": 3130
    },
    {
      "epoch": 0.14132049147126333,
      "grad_norm": 0.8381316065788269,
      "learning_rate": 9.858679508528737e-05,
      "loss": 0.1931,
      "step": 3140
    },
    {
      "epoch": 0.14177055673072594,
      "grad_norm": 2.9422922134399414,
      "learning_rate": 9.858229443269274e-05,
      "loss": 0.1838,
      "step": 3150
    },
    {
      "epoch": 0.1422206219901886,
      "grad_norm": 3.5879039764404297,
      "learning_rate": 9.857779378009812e-05,
      "loss": 0.1911,
      "step": 3160
    },
    {
      "epoch": 0.1426706872496512,
      "grad_norm": 2.4510841369628906,
      "learning_rate": 9.857329312750349e-05,
      "loss": 0.3335,
      "step": 3170
    },
    {
      "epoch": 0.14312075250911382,
      "grad_norm": 1.6694444417953491,
      "learning_rate": 9.856879247490886e-05,
      "loss": 0.2347,
      "step": 3180
    },
    {
      "epoch": 0.14357081776857644,
      "grad_norm": 2.1950230598449707,
      "learning_rate": 9.856429182231424e-05,
      "loss": 0.2745,
      "step": 3190
    },
    {
      "epoch": 0.14402088302803906,
      "grad_norm": 2.0220847129821777,
      "learning_rate": 9.855979116971961e-05,
      "loss": 0.2389,
      "step": 3200
    },
    {
      "epoch": 0.14447094828750168,
      "grad_norm": 4.501984119415283,
      "learning_rate": 9.855529051712499e-05,
      "loss": 0.2639,
      "step": 3210
    },
    {
      "epoch": 0.14492101354696432,
      "grad_norm": 1.927715539932251,
      "learning_rate": 9.855078986453036e-05,
      "loss": 0.2653,
      "step": 3220
    },
    {
      "epoch": 0.14537107880642694,
      "grad_norm": 1.2742408514022827,
      "learning_rate": 9.854628921193573e-05,
      "loss": 0.2954,
      "step": 3230
    },
    {
      "epoch": 0.14582114406588956,
      "grad_norm": 2.0591766834259033,
      "learning_rate": 9.85417885593411e-05,
      "loss": 0.2259,
      "step": 3240
    },
    {
      "epoch": 0.14627120932535218,
      "grad_norm": 3.348891019821167,
      "learning_rate": 9.853728790674648e-05,
      "loss": 0.3019,
      "step": 3250
    },
    {
      "epoch": 0.1467212745848148,
      "grad_norm": 1.1687586307525635,
      "learning_rate": 9.853278725415185e-05,
      "loss": 0.2161,
      "step": 3260
    },
    {
      "epoch": 0.1471713398442774,
      "grad_norm": 3.4211270809173584,
      "learning_rate": 9.852828660155723e-05,
      "loss": 0.2519,
      "step": 3270
    },
    {
      "epoch": 0.14762140510374006,
      "grad_norm": 2.4601261615753174,
      "learning_rate": 9.85237859489626e-05,
      "loss": 0.308,
      "step": 3280
    },
    {
      "epoch": 0.14807147036320267,
      "grad_norm": 3.2236757278442383,
      "learning_rate": 9.851928529636797e-05,
      "loss": 0.2309,
      "step": 3290
    },
    {
      "epoch": 0.1485215356226653,
      "grad_norm": 2.6965951919555664,
      "learning_rate": 9.851478464377335e-05,
      "loss": 0.2543,
      "step": 3300
    },
    {
      "epoch": 0.1489716008821279,
      "grad_norm": 1.0469801425933838,
      "learning_rate": 9.851028399117872e-05,
      "loss": 0.2056,
      "step": 3310
    },
    {
      "epoch": 0.14942166614159053,
      "grad_norm": 3.784299373626709,
      "learning_rate": 9.85057833385841e-05,
      "loss": 0.2613,
      "step": 3320
    },
    {
      "epoch": 0.14987173140105314,
      "grad_norm": 1.9813580513000488,
      "learning_rate": 9.850128268598947e-05,
      "loss": 0.2397,
      "step": 3330
    },
    {
      "epoch": 0.1503217966605158,
      "grad_norm": 1.4044989347457886,
      "learning_rate": 9.849678203339486e-05,
      "loss": 0.2135,
      "step": 3340
    },
    {
      "epoch": 0.1507718619199784,
      "grad_norm": 1.8552347421646118,
      "learning_rate": 9.849228138080022e-05,
      "loss": 0.2371,
      "step": 3350
    },
    {
      "epoch": 0.15122192717944102,
      "grad_norm": 1.1063255071640015,
      "learning_rate": 9.848778072820559e-05,
      "loss": 0.2419,
      "step": 3360
    },
    {
      "epoch": 0.15167199243890364,
      "grad_norm": 4.12015438079834,
      "learning_rate": 9.848328007561098e-05,
      "loss": 0.2321,
      "step": 3370
    },
    {
      "epoch": 0.15212205769836626,
      "grad_norm": 2.106027126312256,
      "learning_rate": 9.847877942301634e-05,
      "loss": 0.2291,
      "step": 3380
    },
    {
      "epoch": 0.15257212295782888,
      "grad_norm": 1.912044644355774,
      "learning_rate": 9.847427877042171e-05,
      "loss": 0.2294,
      "step": 3390
    },
    {
      "epoch": 0.1530221882172915,
      "grad_norm": 1.6210256814956665,
      "learning_rate": 9.84697781178271e-05,
      "loss": 0.251,
      "step": 3400
    },
    {
      "epoch": 0.15347225347675414,
      "grad_norm": 1.7217775583267212,
      "learning_rate": 9.846527746523246e-05,
      "loss": 0.265,
      "step": 3410
    },
    {
      "epoch": 0.15392231873621676,
      "grad_norm": 1.2627586126327515,
      "learning_rate": 9.846077681263783e-05,
      "loss": 0.2489,
      "step": 3420
    },
    {
      "epoch": 0.15437238399567937,
      "grad_norm": 3.527150869369507,
      "learning_rate": 9.845627616004322e-05,
      "loss": 0.2422,
      "step": 3430
    },
    {
      "epoch": 0.154822449255142,
      "grad_norm": 1.7379461526870728,
      "learning_rate": 9.845177550744858e-05,
      "loss": 0.2555,
      "step": 3440
    },
    {
      "epoch": 0.1552725145146046,
      "grad_norm": 2.587592601776123,
      "learning_rate": 9.844727485485395e-05,
      "loss": 0.2208,
      "step": 3450
    },
    {
      "epoch": 0.15572257977406723,
      "grad_norm": 1.1748491525650024,
      "learning_rate": 9.844277420225934e-05,
      "loss": 0.2348,
      "step": 3460
    },
    {
      "epoch": 0.15617264503352987,
      "grad_norm": 2.045746326446533,
      "learning_rate": 9.84382735496647e-05,
      "loss": 0.2857,
      "step": 3470
    },
    {
      "epoch": 0.1566227102929925,
      "grad_norm": 3.187018632888794,
      "learning_rate": 9.843377289707007e-05,
      "loss": 0.2289,
      "step": 3480
    },
    {
      "epoch": 0.1570727755524551,
      "grad_norm": 2.6291325092315674,
      "learning_rate": 9.842927224447546e-05,
      "loss": 0.2256,
      "step": 3490
    },
    {
      "epoch": 0.15752284081191772,
      "grad_norm": 1.9446700811386108,
      "learning_rate": 9.842477159188082e-05,
      "loss": 0.2655,
      "step": 3500
    },
    {
      "epoch": 0.15797290607138034,
      "grad_norm": 1.137391448020935,
      "learning_rate": 9.84202709392862e-05,
      "loss": 0.2173,
      "step": 3510
    },
    {
      "epoch": 0.15842297133084296,
      "grad_norm": 2.8333349227905273,
      "learning_rate": 9.841577028669158e-05,
      "loss": 0.1711,
      "step": 3520
    },
    {
      "epoch": 0.1588730365903056,
      "grad_norm": 2.1214849948883057,
      "learning_rate": 9.841126963409694e-05,
      "loss": 0.2787,
      "step": 3530
    },
    {
      "epoch": 0.15932310184976822,
      "grad_norm": 1.6727325916290283,
      "learning_rate": 9.840676898150231e-05,
      "loss": 0.196,
      "step": 3540
    },
    {
      "epoch": 0.15977316710923084,
      "grad_norm": 3.3201191425323486,
      "learning_rate": 9.84022683289077e-05,
      "loss": 0.2686,
      "step": 3550
    },
    {
      "epoch": 0.16022323236869346,
      "grad_norm": 3.2701621055603027,
      "learning_rate": 9.839776767631306e-05,
      "loss": 0.2371,
      "step": 3560
    },
    {
      "epoch": 0.16067329762815608,
      "grad_norm": 1.3216230869293213,
      "learning_rate": 9.839326702371844e-05,
      "loss": 0.234,
      "step": 3570
    },
    {
      "epoch": 0.1611233628876187,
      "grad_norm": 1.3267637491226196,
      "learning_rate": 9.838876637112382e-05,
      "loss": 0.2375,
      "step": 3580
    },
    {
      "epoch": 0.16157342814708134,
      "grad_norm": 2.4818532466888428,
      "learning_rate": 9.83842657185292e-05,
      "loss": 0.2495,
      "step": 3590
    },
    {
      "epoch": 0.16202349340654396,
      "grad_norm": 1.4576985836029053,
      "learning_rate": 9.837976506593457e-05,
      "loss": 0.2209,
      "step": 3600
    },
    {
      "epoch": 0.16247355866600657,
      "grad_norm": 1.9958117008209229,
      "learning_rate": 9.837526441333994e-05,
      "loss": 0.2397,
      "step": 3610
    },
    {
      "epoch": 0.1629236239254692,
      "grad_norm": 3.996229410171509,
      "learning_rate": 9.837076376074532e-05,
      "loss": 0.278,
      "step": 3620
    },
    {
      "epoch": 0.1633736891849318,
      "grad_norm": 0.6464511156082153,
      "learning_rate": 9.836626310815069e-05,
      "loss": 0.2725,
      "step": 3630
    },
    {
      "epoch": 0.16382375444439443,
      "grad_norm": 2.508404493331909,
      "learning_rate": 9.836176245555606e-05,
      "loss": 0.2459,
      "step": 3640
    },
    {
      "epoch": 0.16427381970385707,
      "grad_norm": 1.832805871963501,
      "learning_rate": 9.835726180296144e-05,
      "loss": 0.2254,
      "step": 3650
    },
    {
      "epoch": 0.1647238849633197,
      "grad_norm": 3.586134672164917,
      "learning_rate": 9.835276115036681e-05,
      "loss": 0.2229,
      "step": 3660
    },
    {
      "epoch": 0.1651739502227823,
      "grad_norm": 2.8870229721069336,
      "learning_rate": 9.834826049777218e-05,
      "loss": 0.2437,
      "step": 3670
    },
    {
      "epoch": 0.16562401548224492,
      "grad_norm": 1.9774664640426636,
      "learning_rate": 9.834375984517756e-05,
      "loss": 0.2046,
      "step": 3680
    },
    {
      "epoch": 0.16607408074170754,
      "grad_norm": 2.6275711059570312,
      "learning_rate": 9.833925919258293e-05,
      "loss": 0.3029,
      "step": 3690
    },
    {
      "epoch": 0.16652414600117016,
      "grad_norm": 1.4470149278640747,
      "learning_rate": 9.83347585399883e-05,
      "loss": 0.2155,
      "step": 3700
    },
    {
      "epoch": 0.1669742112606328,
      "grad_norm": 1.7485500574111938,
      "learning_rate": 9.833025788739368e-05,
      "loss": 0.2845,
      "step": 3710
    },
    {
      "epoch": 0.16742427652009542,
      "grad_norm": 2.8862862586975098,
      "learning_rate": 9.832575723479905e-05,
      "loss": 0.2278,
      "step": 3720
    },
    {
      "epoch": 0.16787434177955804,
      "grad_norm": 1.8550751209259033,
      "learning_rate": 9.832125658220443e-05,
      "loss": 0.2612,
      "step": 3730
    },
    {
      "epoch": 0.16832440703902066,
      "grad_norm": 2.342674732208252,
      "learning_rate": 9.83167559296098e-05,
      "loss": 0.2094,
      "step": 3740
    },
    {
      "epoch": 0.16877447229848327,
      "grad_norm": 1.5580793619155884,
      "learning_rate": 9.831225527701517e-05,
      "loss": 0.2402,
      "step": 3750
    },
    {
      "epoch": 0.1692245375579459,
      "grad_norm": 1.9157429933547974,
      "learning_rate": 9.830775462442055e-05,
      "loss": 0.2165,
      "step": 3760
    },
    {
      "epoch": 0.16967460281740854,
      "grad_norm": 4.3170552253723145,
      "learning_rate": 9.830325397182592e-05,
      "loss": 0.305,
      "step": 3770
    },
    {
      "epoch": 0.17012466807687115,
      "grad_norm": 1.994328260421753,
      "learning_rate": 9.82987533192313e-05,
      "loss": 0.2902,
      "step": 3780
    },
    {
      "epoch": 0.17057473333633377,
      "grad_norm": 1.9129209518432617,
      "learning_rate": 9.829425266663667e-05,
      "loss": 0.2237,
      "step": 3790
    },
    {
      "epoch": 0.1710247985957964,
      "grad_norm": 1.9876532554626465,
      "learning_rate": 9.828975201404204e-05,
      "loss": 0.2149,
      "step": 3800
    },
    {
      "epoch": 0.171474863855259,
      "grad_norm": 2.130934476852417,
      "learning_rate": 9.828525136144742e-05,
      "loss": 0.2605,
      "step": 3810
    },
    {
      "epoch": 0.17192492911472163,
      "grad_norm": 1.7367030382156372,
      "learning_rate": 9.828075070885279e-05,
      "loss": 0.229,
      "step": 3820
    },
    {
      "epoch": 0.17237499437418427,
      "grad_norm": 2.113182544708252,
      "learning_rate": 9.827625005625816e-05,
      "loss": 0.2816,
      "step": 3830
    },
    {
      "epoch": 0.1728250596336469,
      "grad_norm": 1.6326338052749634,
      "learning_rate": 9.827174940366354e-05,
      "loss": 0.2283,
      "step": 3840
    },
    {
      "epoch": 0.1732751248931095,
      "grad_norm": 2.20841908454895,
      "learning_rate": 9.826724875106891e-05,
      "loss": 0.2193,
      "step": 3850
    },
    {
      "epoch": 0.17372519015257212,
      "grad_norm": 1.7534239292144775,
      "learning_rate": 9.826274809847428e-05,
      "loss": 0.2195,
      "step": 3860
    },
    {
      "epoch": 0.17417525541203474,
      "grad_norm": 1.8515417575836182,
      "learning_rate": 9.825824744587966e-05,
      "loss": 0.1955,
      "step": 3870
    },
    {
      "epoch": 0.17462532067149736,
      "grad_norm": 2.7893004417419434,
      "learning_rate": 9.825374679328503e-05,
      "loss": 0.1872,
      "step": 3880
    },
    {
      "epoch": 0.17507538593095998,
      "grad_norm": 1.3082561492919922,
      "learning_rate": 9.82492461406904e-05,
      "loss": 0.1858,
      "step": 3890
    },
    {
      "epoch": 0.17552545119042262,
      "grad_norm": 1.9752904176712036,
      "learning_rate": 9.824474548809578e-05,
      "loss": 0.268,
      "step": 3900
    },
    {
      "epoch": 0.17597551644988524,
      "grad_norm": 2.444561243057251,
      "learning_rate": 9.824024483550115e-05,
      "loss": 0.2551,
      "step": 3910
    },
    {
      "epoch": 0.17642558170934786,
      "grad_norm": 2.692164182662964,
      "learning_rate": 9.823574418290653e-05,
      "loss": 0.2975,
      "step": 3920
    },
    {
      "epoch": 0.17687564696881047,
      "grad_norm": 2.1159613132476807,
      "learning_rate": 9.82312435303119e-05,
      "loss": 0.2159,
      "step": 3930
    },
    {
      "epoch": 0.1773257122282731,
      "grad_norm": 1.6889369487762451,
      "learning_rate": 9.822674287771727e-05,
      "loss": 0.2074,
      "step": 3940
    },
    {
      "epoch": 0.1777757774877357,
      "grad_norm": 1.780405044555664,
      "learning_rate": 9.822224222512265e-05,
      "loss": 0.1635,
      "step": 3950
    },
    {
      "epoch": 0.17822584274719835,
      "grad_norm": 2.5421435832977295,
      "learning_rate": 9.821774157252802e-05,
      "loss": 0.297,
      "step": 3960
    },
    {
      "epoch": 0.17867590800666097,
      "grad_norm": 2.6566381454467773,
      "learning_rate": 9.821324091993339e-05,
      "loss": 0.2772,
      "step": 3970
    },
    {
      "epoch": 0.1791259732661236,
      "grad_norm": 2.4882335662841797,
      "learning_rate": 9.820874026733877e-05,
      "loss": 0.1982,
      "step": 3980
    },
    {
      "epoch": 0.1795760385255862,
      "grad_norm": 2.623706579208374,
      "learning_rate": 9.820423961474414e-05,
      "loss": 0.1911,
      "step": 3990
    },
    {
      "epoch": 0.18002610378504882,
      "grad_norm": 3.6022303104400635,
      "learning_rate": 9.819973896214951e-05,
      "loss": 0.2571,
      "step": 4000
    },
    {
      "epoch": 0.18047616904451144,
      "grad_norm": 1.10262930393219,
      "learning_rate": 9.819523830955489e-05,
      "loss": 0.2007,
      "step": 4010
    },
    {
      "epoch": 0.1809262343039741,
      "grad_norm": 3.303030252456665,
      "learning_rate": 9.819073765696026e-05,
      "loss": 0.2139,
      "step": 4020
    },
    {
      "epoch": 0.1813762995634367,
      "grad_norm": 2.7303261756896973,
      "learning_rate": 9.818623700436563e-05,
      "loss": 0.2255,
      "step": 4030
    },
    {
      "epoch": 0.18182636482289932,
      "grad_norm": 1.2165225744247437,
      "learning_rate": 9.818173635177101e-05,
      "loss": 0.2537,
      "step": 4040
    },
    {
      "epoch": 0.18227643008236194,
      "grad_norm": 1.8530991077423096,
      "learning_rate": 9.817723569917638e-05,
      "loss": 0.2492,
      "step": 4050
    },
    {
      "epoch": 0.18272649534182456,
      "grad_norm": 2.3454742431640625,
      "learning_rate": 9.817273504658176e-05,
      "loss": 0.2823,
      "step": 4060
    },
    {
      "epoch": 0.18317656060128717,
      "grad_norm": 1.0978047847747803,
      "learning_rate": 9.816823439398713e-05,
      "loss": 0.2861,
      "step": 4070
    },
    {
      "epoch": 0.18362662586074982,
      "grad_norm": 2.1198604106903076,
      "learning_rate": 9.81637337413925e-05,
      "loss": 0.2274,
      "step": 4080
    },
    {
      "epoch": 0.18407669112021244,
      "grad_norm": 1.8064789772033691,
      "learning_rate": 9.815923308879788e-05,
      "loss": 0.214,
      "step": 4090
    },
    {
      "epoch": 0.18452675637967506,
      "grad_norm": 0.7823309898376465,
      "learning_rate": 9.815473243620325e-05,
      "loss": 0.175,
      "step": 4100
    },
    {
      "epoch": 0.18497682163913767,
      "grad_norm": 3.1262776851654053,
      "learning_rate": 9.815023178360862e-05,
      "loss": 0.2196,
      "step": 4110
    },
    {
      "epoch": 0.1854268868986003,
      "grad_norm": 2.128674268722534,
      "learning_rate": 9.814573113101401e-05,
      "loss": 0.2371,
      "step": 4120
    },
    {
      "epoch": 0.1858769521580629,
      "grad_norm": 3.2748892307281494,
      "learning_rate": 9.814123047841937e-05,
      "loss": 0.2813,
      "step": 4130
    },
    {
      "epoch": 0.18632701741752555,
      "grad_norm": 1.4816533327102661,
      "learning_rate": 9.813672982582474e-05,
      "loss": 0.2131,
      "step": 4140
    },
    {
      "epoch": 0.18677708267698817,
      "grad_norm": 3.0435590744018555,
      "learning_rate": 9.813222917323013e-05,
      "loss": 0.1947,
      "step": 4150
    },
    {
      "epoch": 0.1872271479364508,
      "grad_norm": 5.688252925872803,
      "learning_rate": 9.812772852063549e-05,
      "loss": 0.2555,
      "step": 4160
    },
    {
      "epoch": 0.1876772131959134,
      "grad_norm": 1.5283689498901367,
      "learning_rate": 9.812322786804087e-05,
      "loss": 0.2085,
      "step": 4170
    },
    {
      "epoch": 0.18812727845537602,
      "grad_norm": 1.6758065223693848,
      "learning_rate": 9.811872721544625e-05,
      "loss": 0.2159,
      "step": 4180
    },
    {
      "epoch": 0.18857734371483864,
      "grad_norm": 2.6264917850494385,
      "learning_rate": 9.811422656285161e-05,
      "loss": 0.251,
      "step": 4190
    },
    {
      "epoch": 0.1890274089743013,
      "grad_norm": 0.7526887655258179,
      "learning_rate": 9.810972591025699e-05,
      "loss": 0.2252,
      "step": 4200
    },
    {
      "epoch": 0.1894774742337639,
      "grad_norm": 1.631606101989746,
      "learning_rate": 9.810522525766237e-05,
      "loss": 0.211,
      "step": 4210
    },
    {
      "epoch": 0.18992753949322652,
      "grad_norm": 2.8961594104766846,
      "learning_rate": 9.810072460506773e-05,
      "loss": 0.2086,
      "step": 4220
    },
    {
      "epoch": 0.19037760475268914,
      "grad_norm": 3.841360569000244,
      "learning_rate": 9.80962239524731e-05,
      "loss": 0.2084,
      "step": 4230
    },
    {
      "epoch": 0.19082767001215176,
      "grad_norm": 1.799128770828247,
      "learning_rate": 9.80917232998785e-05,
      "loss": 0.2431,
      "step": 4240
    },
    {
      "epoch": 0.19127773527161437,
      "grad_norm": 0.9482505321502686,
      "learning_rate": 9.808722264728385e-05,
      "loss": 0.1855,
      "step": 4250
    },
    {
      "epoch": 0.19172780053107702,
      "grad_norm": 1.6791259050369263,
      "learning_rate": 9.808272199468923e-05,
      "loss": 0.2167,
      "step": 4260
    },
    {
      "epoch": 0.19217786579053964,
      "grad_norm": 2.406132459640503,
      "learning_rate": 9.807822134209461e-05,
      "loss": 0.1764,
      "step": 4270
    },
    {
      "epoch": 0.19262793105000225,
      "grad_norm": 1.8521754741668701,
      "learning_rate": 9.807372068949999e-05,
      "loss": 0.2283,
      "step": 4280
    },
    {
      "epoch": 0.19307799630946487,
      "grad_norm": 2.1827609539031982,
      "learning_rate": 9.806922003690535e-05,
      "loss": 0.2811,
      "step": 4290
    },
    {
      "epoch": 0.1935280615689275,
      "grad_norm": 1.2562358379364014,
      "learning_rate": 9.806471938431074e-05,
      "loss": 0.2628,
      "step": 4300
    },
    {
      "epoch": 0.1939781268283901,
      "grad_norm": 0.8403974771499634,
      "learning_rate": 9.806021873171611e-05,
      "loss": 0.2419,
      "step": 4310
    },
    {
      "epoch": 0.19442819208785272,
      "grad_norm": 1.525431513786316,
      "learning_rate": 9.805571807912147e-05,
      "loss": 0.2203,
      "step": 4320
    },
    {
      "epoch": 0.19487825734731537,
      "grad_norm": 3.4475812911987305,
      "learning_rate": 9.805121742652686e-05,
      "loss": 0.1896,
      "step": 4330
    },
    {
      "epoch": 0.195328322606778,
      "grad_norm": 2.0309507846832275,
      "learning_rate": 9.804671677393223e-05,
      "loss": 0.1824,
      "step": 4340
    },
    {
      "epoch": 0.1957783878662406,
      "grad_norm": 3.1934380531311035,
      "learning_rate": 9.804221612133759e-05,
      "loss": 0.2594,
      "step": 4350
    },
    {
      "epoch": 0.19622845312570322,
      "grad_norm": 2.3068125247955322,
      "learning_rate": 9.803771546874298e-05,
      "loss": 0.204,
      "step": 4360
    },
    {
      "epoch": 0.19667851838516584,
      "grad_norm": 2.474797487258911,
      "learning_rate": 9.803321481614835e-05,
      "loss": 0.2017,
      "step": 4370
    },
    {
      "epoch": 0.19712858364462846,
      "grad_norm": 2.2590200901031494,
      "learning_rate": 9.802871416355372e-05,
      "loss": 0.2398,
      "step": 4380
    },
    {
      "epoch": 0.1975786489040911,
      "grad_norm": 3.281238555908203,
      "learning_rate": 9.80242135109591e-05,
      "loss": 0.2404,
      "step": 4390
    },
    {
      "epoch": 0.19802871416355372,
      "grad_norm": 4.929545879364014,
      "learning_rate": 9.801971285836447e-05,
      "loss": 0.2776,
      "step": 4400
    },
    {
      "epoch": 0.19847877942301634,
      "grad_norm": 1.8692805767059326,
      "learning_rate": 9.801521220576985e-05,
      "loss": 0.236,
      "step": 4410
    },
    {
      "epoch": 0.19892884468247896,
      "grad_norm": 1.6944892406463623,
      "learning_rate": 9.801071155317522e-05,
      "loss": 0.2704,
      "step": 4420
    },
    {
      "epoch": 0.19937890994194157,
      "grad_norm": 2.728337049484253,
      "learning_rate": 9.800621090058059e-05,
      "loss": 0.2278,
      "step": 4430
    },
    {
      "epoch": 0.1998289752014042,
      "grad_norm": 1.6837021112442017,
      "learning_rate": 9.800171024798597e-05,
      "loss": 0.2137,
      "step": 4440
    },
    {
      "epoch": 0.20027904046086684,
      "grad_norm": 1.28476881980896,
      "learning_rate": 9.799720959539134e-05,
      "loss": 0.1654,
      "step": 4450
    },
    {
      "epoch": 0.20072910572032945,
      "grad_norm": 1.85479736328125,
      "learning_rate": 9.799270894279671e-05,
      "loss": 0.1905,
      "step": 4460
    },
    {
      "epoch": 0.20117917097979207,
      "grad_norm": 2.404487371444702,
      "learning_rate": 9.798820829020209e-05,
      "loss": 0.2233,
      "step": 4470
    },
    {
      "epoch": 0.2016292362392547,
      "grad_norm": 2.4354867935180664,
      "learning_rate": 9.798370763760746e-05,
      "loss": 0.2135,
      "step": 4480
    },
    {
      "epoch": 0.2020793014987173,
      "grad_norm": 2.012847423553467,
      "learning_rate": 9.797920698501283e-05,
      "loss": 0.1734,
      "step": 4490
    },
    {
      "epoch": 0.20252936675817992,
      "grad_norm": 2.293215274810791,
      "learning_rate": 9.797470633241821e-05,
      "loss": 0.1719,
      "step": 4500
    },
    {
      "epoch": 0.20297943201764257,
      "grad_norm": 1.8953813314437866,
      "learning_rate": 9.797020567982358e-05,
      "loss": 0.2186,
      "step": 4510
    },
    {
      "epoch": 0.2034294972771052,
      "grad_norm": 5.001928329467773,
      "learning_rate": 9.796570502722895e-05,
      "loss": 0.2662,
      "step": 4520
    },
    {
      "epoch": 0.2038795625365678,
      "grad_norm": 2.3996517658233643,
      "learning_rate": 9.796120437463433e-05,
      "loss": 0.1781,
      "step": 4530
    },
    {
      "epoch": 0.20432962779603042,
      "grad_norm": 1.8159641027450562,
      "learning_rate": 9.79567037220397e-05,
      "loss": 0.2503,
      "step": 4540
    },
    {
      "epoch": 0.20477969305549304,
      "grad_norm": 3.527318000793457,
      "learning_rate": 9.795220306944508e-05,
      "loss": 0.2227,
      "step": 4550
    },
    {
      "epoch": 0.20522975831495566,
      "grad_norm": 1.3897172212600708,
      "learning_rate": 9.794770241685045e-05,
      "loss": 0.1914,
      "step": 4560
    },
    {
      "epoch": 0.2056798235744183,
      "grad_norm": 1.2694830894470215,
      "learning_rate": 9.794320176425582e-05,
      "loss": 0.1596,
      "step": 4570
    },
    {
      "epoch": 0.20612988883388092,
      "grad_norm": 2.976060628890991,
      "learning_rate": 9.79387011116612e-05,
      "loss": 0.1785,
      "step": 4580
    },
    {
      "epoch": 0.20657995409334354,
      "grad_norm": 1.3702925443649292,
      "learning_rate": 9.793420045906657e-05,
      "loss": 0.2486,
      "step": 4590
    },
    {
      "epoch": 0.20703001935280615,
      "grad_norm": 1.1485059261322021,
      "learning_rate": 9.792969980647194e-05,
      "loss": 0.1843,
      "step": 4600
    },
    {
      "epoch": 0.20748008461226877,
      "grad_norm": 0.9331071376800537,
      "learning_rate": 9.792519915387732e-05,
      "loss": 0.2621,
      "step": 4610
    },
    {
      "epoch": 0.2079301498717314,
      "grad_norm": 1.0574991703033447,
      "learning_rate": 9.792069850128269e-05,
      "loss": 0.2074,
      "step": 4620
    },
    {
      "epoch": 0.20838021513119404,
      "grad_norm": 2.3140761852264404,
      "learning_rate": 9.791619784868806e-05,
      "loss": 0.3571,
      "step": 4630
    },
    {
      "epoch": 0.20883028039065665,
      "grad_norm": 1.7062342166900635,
      "learning_rate": 9.791169719609344e-05,
      "loss": 0.2999,
      "step": 4640
    },
    {
      "epoch": 0.20928034565011927,
      "grad_norm": 1.7078931331634521,
      "learning_rate": 9.790719654349881e-05,
      "loss": 0.2245,
      "step": 4650
    },
    {
      "epoch": 0.2097304109095819,
      "grad_norm": 2.0200226306915283,
      "learning_rate": 9.790269589090419e-05,
      "loss": 0.1896,
      "step": 4660
    },
    {
      "epoch": 0.2101804761690445,
      "grad_norm": 2.5900461673736572,
      "learning_rate": 9.789819523830956e-05,
      "loss": 0.177,
      "step": 4670
    },
    {
      "epoch": 0.21063054142850712,
      "grad_norm": 2.2883708477020264,
      "learning_rate": 9.789369458571493e-05,
      "loss": 0.2331,
      "step": 4680
    },
    {
      "epoch": 0.21108060668796977,
      "grad_norm": 2.753351926803589,
      "learning_rate": 9.78891939331203e-05,
      "loss": 0.173,
      "step": 4690
    },
    {
      "epoch": 0.21153067194743239,
      "grad_norm": 1.9076766967773438,
      "learning_rate": 9.788469328052568e-05,
      "loss": 0.2,
      "step": 4700
    },
    {
      "epoch": 0.211980737206895,
      "grad_norm": 1.611249327659607,
      "learning_rate": 9.788019262793105e-05,
      "loss": 0.1473,
      "step": 4710
    },
    {
      "epoch": 0.21243080246635762,
      "grad_norm": 3.150002956390381,
      "learning_rate": 9.787569197533643e-05,
      "loss": 0.2466,
      "step": 4720
    },
    {
      "epoch": 0.21288086772582024,
      "grad_norm": 1.2706571817398071,
      "learning_rate": 9.78711913227418e-05,
      "loss": 0.1531,
      "step": 4730
    },
    {
      "epoch": 0.21333093298528286,
      "grad_norm": 1.8725323677062988,
      "learning_rate": 9.786669067014717e-05,
      "loss": 0.1891,
      "step": 4740
    },
    {
      "epoch": 0.2137809982447455,
      "grad_norm": 1.8557981252670288,
      "learning_rate": 9.786219001755255e-05,
      "loss": 0.2426,
      "step": 4750
    },
    {
      "epoch": 0.21423106350420812,
      "grad_norm": 0.6779460906982422,
      "learning_rate": 9.785768936495792e-05,
      "loss": 0.167,
      "step": 4760
    },
    {
      "epoch": 0.21468112876367074,
      "grad_norm": 5.125866889953613,
      "learning_rate": 9.78531887123633e-05,
      "loss": 0.2165,
      "step": 4770
    },
    {
      "epoch": 0.21513119402313335,
      "grad_norm": 2.3780243396759033,
      "learning_rate": 9.784868805976867e-05,
      "loss": 0.1914,
      "step": 4780
    },
    {
      "epoch": 0.21558125928259597,
      "grad_norm": 1.6341617107391357,
      "learning_rate": 9.784418740717404e-05,
      "loss": 0.2719,
      "step": 4790
    },
    {
      "epoch": 0.2160313245420586,
      "grad_norm": 2.47956919670105,
      "learning_rate": 9.783968675457942e-05,
      "loss": 0.2407,
      "step": 4800
    },
    {
      "epoch": 0.2164813898015212,
      "grad_norm": 0.9444278478622437,
      "learning_rate": 9.783518610198479e-05,
      "loss": 0.1983,
      "step": 4810
    },
    {
      "epoch": 0.21693145506098385,
      "grad_norm": 1.5836503505706787,
      "learning_rate": 9.783068544939016e-05,
      "loss": 0.2785,
      "step": 4820
    },
    {
      "epoch": 0.21738152032044647,
      "grad_norm": 2.5436832904815674,
      "learning_rate": 9.782618479679554e-05,
      "loss": 0.191,
      "step": 4830
    },
    {
      "epoch": 0.2178315855799091,
      "grad_norm": 2.8949007987976074,
      "learning_rate": 9.782168414420091e-05,
      "loss": 0.2522,
      "step": 4840
    },
    {
      "epoch": 0.2182816508393717,
      "grad_norm": 2.8550045490264893,
      "learning_rate": 9.781718349160628e-05,
      "loss": 0.2209,
      "step": 4850
    },
    {
      "epoch": 0.21873171609883432,
      "grad_norm": 2.020174741744995,
      "learning_rate": 9.781268283901166e-05,
      "loss": 0.2268,
      "step": 4860
    },
    {
      "epoch": 0.21918178135829694,
      "grad_norm": 1.6514655351638794,
      "learning_rate": 9.780818218641703e-05,
      "loss": 0.2391,
      "step": 4870
    },
    {
      "epoch": 0.21963184661775959,
      "grad_norm": 1.7481324672698975,
      "learning_rate": 9.78036815338224e-05,
      "loss": 0.1934,
      "step": 4880
    },
    {
      "epoch": 0.2200819118772222,
      "grad_norm": 2.5905656814575195,
      "learning_rate": 9.779918088122778e-05,
      "loss": 0.2236,
      "step": 4890
    },
    {
      "epoch": 0.22053197713668482,
      "grad_norm": 1.1765118837356567,
      "learning_rate": 9.779468022863317e-05,
      "loss": 0.2084,
      "step": 4900
    },
    {
      "epoch": 0.22098204239614744,
      "grad_norm": 3.181114912033081,
      "learning_rate": 9.779017957603853e-05,
      "loss": 0.1584,
      "step": 4910
    },
    {
      "epoch": 0.22143210765561006,
      "grad_norm": 1.4569711685180664,
      "learning_rate": 9.77856789234439e-05,
      "loss": 0.1707,
      "step": 4920
    },
    {
      "epoch": 0.22188217291507267,
      "grad_norm": 2.521179437637329,
      "learning_rate": 9.778117827084929e-05,
      "loss": 0.1832,
      "step": 4930
    },
    {
      "epoch": 0.22233223817453532,
      "grad_norm": 1.0130900144577026,
      "learning_rate": 9.777667761825465e-05,
      "loss": 0.1487,
      "step": 4940
    },
    {
      "epoch": 0.22278230343399794,
      "grad_norm": 1.3733659982681274,
      "learning_rate": 9.777217696566002e-05,
      "loss": 0.1459,
      "step": 4950
    },
    {
      "epoch": 0.22323236869346055,
      "grad_norm": 1.6352680921554565,
      "learning_rate": 9.776767631306541e-05,
      "loss": 0.2633,
      "step": 4960
    },
    {
      "epoch": 0.22368243395292317,
      "grad_norm": 1.097326636314392,
      "learning_rate": 9.776317566047078e-05,
      "loss": 0.1653,
      "step": 4970
    },
    {
      "epoch": 0.2241324992123858,
      "grad_norm": 1.1874170303344727,
      "learning_rate": 9.775867500787614e-05,
      "loss": 0.1776,
      "step": 4980
    },
    {
      "epoch": 0.2245825644718484,
      "grad_norm": 1.407041311264038,
      "learning_rate": 9.775417435528153e-05,
      "loss": 0.2691,
      "step": 4990
    },
    {
      "epoch": 0.22503262973131105,
      "grad_norm": 1.9670933485031128,
      "learning_rate": 9.77496737026869e-05,
      "loss": 0.2523,
      "step": 5000
    },
    {
      "epoch": 0.22548269499077367,
      "grad_norm": 3.6963255405426025,
      "learning_rate": 9.774517305009226e-05,
      "loss": 0.1864,
      "step": 5010
    },
    {
      "epoch": 0.2259327602502363,
      "grad_norm": 2.6571836471557617,
      "learning_rate": 9.774067239749765e-05,
      "loss": 0.1869,
      "step": 5020
    },
    {
      "epoch": 0.2263828255096989,
      "grad_norm": 3.3643534183502197,
      "learning_rate": 9.773617174490302e-05,
      "loss": 0.1921,
      "step": 5030
    },
    {
      "epoch": 0.22683289076916152,
      "grad_norm": 2.3230884075164795,
      "learning_rate": 9.773167109230838e-05,
      "loss": 0.1403,
      "step": 5040
    },
    {
      "epoch": 0.22728295602862414,
      "grad_norm": 1.381006121635437,
      "learning_rate": 9.772717043971377e-05,
      "loss": 0.3164,
      "step": 5050
    },
    {
      "epoch": 0.22773302128808678,
      "grad_norm": 2.7289021015167236,
      "learning_rate": 9.772266978711914e-05,
      "loss": 0.217,
      "step": 5060
    },
    {
      "epoch": 0.2281830865475494,
      "grad_norm": 2.0424246788024902,
      "learning_rate": 9.77181691345245e-05,
      "loss": 0.2401,
      "step": 5070
    },
    {
      "epoch": 0.22863315180701202,
      "grad_norm": 1.5615899562835693,
      "learning_rate": 9.771366848192989e-05,
      "loss": 0.2058,
      "step": 5080
    },
    {
      "epoch": 0.22908321706647464,
      "grad_norm": 1.5294179916381836,
      "learning_rate": 9.770916782933526e-05,
      "loss": 0.178,
      "step": 5090
    },
    {
      "epoch": 0.22953328232593725,
      "grad_norm": 1.5611125230789185,
      "learning_rate": 9.770466717674062e-05,
      "loss": 0.1815,
      "step": 5100
    },
    {
      "epoch": 0.22998334758539987,
      "grad_norm": 1.5143976211547852,
      "learning_rate": 9.770016652414601e-05,
      "loss": 0.1846,
      "step": 5110
    },
    {
      "epoch": 0.23043341284486252,
      "grad_norm": 2.0854461193084717,
      "learning_rate": 9.769566587155138e-05,
      "loss": 0.1943,
      "step": 5120
    },
    {
      "epoch": 0.23088347810432513,
      "grad_norm": 3.0515658855438232,
      "learning_rate": 9.769116521895674e-05,
      "loss": 0.2384,
      "step": 5130
    },
    {
      "epoch": 0.23133354336378775,
      "grad_norm": 3.549206256866455,
      "learning_rate": 9.768666456636213e-05,
      "loss": 0.179,
      "step": 5140
    },
    {
      "epoch": 0.23178360862325037,
      "grad_norm": 1.8990119695663452,
      "learning_rate": 9.76821639137675e-05,
      "loss": 0.2479,
      "step": 5150
    },
    {
      "epoch": 0.232233673882713,
      "grad_norm": 3.1471545696258545,
      "learning_rate": 9.767766326117287e-05,
      "loss": 0.2571,
      "step": 5160
    },
    {
      "epoch": 0.2326837391421756,
      "grad_norm": 1.7614266872406006,
      "learning_rate": 9.767316260857825e-05,
      "loss": 0.1884,
      "step": 5170
    },
    {
      "epoch": 0.23313380440163825,
      "grad_norm": 2.7979698181152344,
      "learning_rate": 9.766866195598363e-05,
      "loss": 0.2706,
      "step": 5180
    },
    {
      "epoch": 0.23358386966110087,
      "grad_norm": 2.447366714477539,
      "learning_rate": 9.7664161303389e-05,
      "loss": 0.1862,
      "step": 5190
    },
    {
      "epoch": 0.23403393492056349,
      "grad_norm": 1.2908973693847656,
      "learning_rate": 9.765966065079437e-05,
      "loss": 0.1991,
      "step": 5200
    },
    {
      "epoch": 0.2344840001800261,
      "grad_norm": 1.0814507007598877,
      "learning_rate": 9.765515999819975e-05,
      "loss": 0.2052,
      "step": 5210
    },
    {
      "epoch": 0.23493406543948872,
      "grad_norm": 0.6417984366416931,
      "learning_rate": 9.765065934560512e-05,
      "loss": 0.2555,
      "step": 5220
    },
    {
      "epoch": 0.23538413069895134,
      "grad_norm": 1.897636890411377,
      "learning_rate": 9.76461586930105e-05,
      "loss": 0.1554,
      "step": 5230
    },
    {
      "epoch": 0.23583419595841398,
      "grad_norm": 2.472050428390503,
      "learning_rate": 9.764165804041587e-05,
      "loss": 0.1671,
      "step": 5240
    },
    {
      "epoch": 0.2362842612178766,
      "grad_norm": 2.256884813308716,
      "learning_rate": 9.763715738782124e-05,
      "loss": 0.2251,
      "step": 5250
    },
    {
      "epoch": 0.23673432647733922,
      "grad_norm": 2.7031402587890625,
      "learning_rate": 9.763265673522662e-05,
      "loss": 0.1973,
      "step": 5260
    },
    {
      "epoch": 0.23718439173680184,
      "grad_norm": 3.054722547531128,
      "learning_rate": 9.762815608263199e-05,
      "loss": 0.2456,
      "step": 5270
    },
    {
      "epoch": 0.23763445699626445,
      "grad_norm": 3.573976755142212,
      "learning_rate": 9.762365543003736e-05,
      "loss": 0.2042,
      "step": 5280
    },
    {
      "epoch": 0.23808452225572707,
      "grad_norm": 1.3518986701965332,
      "learning_rate": 9.761915477744274e-05,
      "loss": 0.1675,
      "step": 5290
    },
    {
      "epoch": 0.2385345875151897,
      "grad_norm": 1.5983929634094238,
      "learning_rate": 9.761465412484811e-05,
      "loss": 0.1802,
      "step": 5300
    },
    {
      "epoch": 0.23898465277465233,
      "grad_norm": 3.891238212585449,
      "learning_rate": 9.761015347225348e-05,
      "loss": 0.2349,
      "step": 5310
    },
    {
      "epoch": 0.23943471803411495,
      "grad_norm": 2.6766345500946045,
      "learning_rate": 9.760565281965886e-05,
      "loss": 0.1924,
      "step": 5320
    },
    {
      "epoch": 0.23988478329357757,
      "grad_norm": 2.331463098526001,
      "learning_rate": 9.760115216706423e-05,
      "loss": 0.2254,
      "step": 5330
    },
    {
      "epoch": 0.2403348485530402,
      "grad_norm": 2.252861261367798,
      "learning_rate": 9.75966515144696e-05,
      "loss": 0.2186,
      "step": 5340
    },
    {
      "epoch": 0.2407849138125028,
      "grad_norm": 2.4727115631103516,
      "learning_rate": 9.759215086187498e-05,
      "loss": 0.2344,
      "step": 5350
    },
    {
      "epoch": 0.24123497907196542,
      "grad_norm": 0.9438504576683044,
      "learning_rate": 9.758765020928035e-05,
      "loss": 0.242,
      "step": 5360
    },
    {
      "epoch": 0.24168504433142807,
      "grad_norm": 3.707156181335449,
      "learning_rate": 9.758314955668572e-05,
      "loss": 0.1914,
      "step": 5370
    },
    {
      "epoch": 0.24213510959089068,
      "grad_norm": 1.7369781732559204,
      "learning_rate": 9.75786489040911e-05,
      "loss": 0.2265,
      "step": 5380
    },
    {
      "epoch": 0.2425851748503533,
      "grad_norm": 3.3612987995147705,
      "learning_rate": 9.757414825149647e-05,
      "loss": 0.1767,
      "step": 5390
    },
    {
      "epoch": 0.24303524010981592,
      "grad_norm": 1.7788809537887573,
      "learning_rate": 9.756964759890185e-05,
      "loss": 0.2592,
      "step": 5400
    },
    {
      "epoch": 0.24348530536927854,
      "grad_norm": 1.7782682180404663,
      "learning_rate": 9.756514694630722e-05,
      "loss": 0.2183,
      "step": 5410
    },
    {
      "epoch": 0.24393537062874115,
      "grad_norm": 1.3981475830078125,
      "learning_rate": 9.756064629371259e-05,
      "loss": 0.1738,
      "step": 5420
    },
    {
      "epoch": 0.2443854358882038,
      "grad_norm": 1.2696510553359985,
      "learning_rate": 9.755614564111797e-05,
      "loss": 0.1704,
      "step": 5430
    },
    {
      "epoch": 0.24483550114766642,
      "grad_norm": 2.54636549949646,
      "learning_rate": 9.755164498852334e-05,
      "loss": 0.2454,
      "step": 5440
    },
    {
      "epoch": 0.24528556640712904,
      "grad_norm": 1.6385220289230347,
      "learning_rate": 9.754714433592871e-05,
      "loss": 0.1842,
      "step": 5450
    },
    {
      "epoch": 0.24573563166659165,
      "grad_norm": 1.688279390335083,
      "learning_rate": 9.754264368333409e-05,
      "loss": 0.2007,
      "step": 5460
    },
    {
      "epoch": 0.24618569692605427,
      "grad_norm": 5.034144878387451,
      "learning_rate": 9.753814303073946e-05,
      "loss": 0.199,
      "step": 5470
    },
    {
      "epoch": 0.2466357621855169,
      "grad_norm": 2.94679856300354,
      "learning_rate": 9.753364237814483e-05,
      "loss": 0.2205,
      "step": 5480
    },
    {
      "epoch": 0.24708582744497953,
      "grad_norm": 0.7908223867416382,
      "learning_rate": 9.752914172555021e-05,
      "loss": 0.2054,
      "step": 5490
    },
    {
      "epoch": 0.24753589270444215,
      "grad_norm": 1.3836833238601685,
      "learning_rate": 9.752464107295558e-05,
      "loss": 0.19,
      "step": 5500
    },
    {
      "epoch": 0.24798595796390477,
      "grad_norm": 1.460547685623169,
      "learning_rate": 9.752014042036096e-05,
      "loss": 0.2287,
      "step": 5510
    },
    {
      "epoch": 0.24843602322336739,
      "grad_norm": 1.515966773033142,
      "learning_rate": 9.751563976776633e-05,
      "loss": 0.1899,
      "step": 5520
    },
    {
      "epoch": 0.24888608848283,
      "grad_norm": 3.1408374309539795,
      "learning_rate": 9.75111391151717e-05,
      "loss": 0.2372,
      "step": 5530
    },
    {
      "epoch": 0.24933615374229262,
      "grad_norm": 1.7026522159576416,
      "learning_rate": 9.750663846257708e-05,
      "loss": 0.158,
      "step": 5540
    },
    {
      "epoch": 0.24978621900175527,
      "grad_norm": 1.8313708305358887,
      "learning_rate": 9.750213780998245e-05,
      "loss": 0.2398,
      "step": 5550
    },
    {
      "epoch": 0.25023628426121786,
      "grad_norm": 2.8861632347106934,
      "learning_rate": 9.749763715738782e-05,
      "loss": 0.1732,
      "step": 5560
    },
    {
      "epoch": 0.2506863495206805,
      "grad_norm": 1.8433481454849243,
      "learning_rate": 9.74931365047932e-05,
      "loss": 0.2194,
      "step": 5570
    },
    {
      "epoch": 0.25113641478014315,
      "grad_norm": 2.7412912845611572,
      "learning_rate": 9.748863585219857e-05,
      "loss": 0.2041,
      "step": 5580
    },
    {
      "epoch": 0.25158648003960576,
      "grad_norm": 3.108898162841797,
      "learning_rate": 9.748413519960394e-05,
      "loss": 0.198,
      "step": 5590
    },
    {
      "epoch": 0.2520365452990684,
      "grad_norm": 2.583095073699951,
      "learning_rate": 9.747963454700932e-05,
      "loss": 0.1558,
      "step": 5600
    },
    {
      "epoch": 0.252486610558531,
      "grad_norm": 2.0958614349365234,
      "learning_rate": 9.747513389441469e-05,
      "loss": 0.1777,
      "step": 5610
    },
    {
      "epoch": 0.2529366758179936,
      "grad_norm": 1.9555845260620117,
      "learning_rate": 9.747063324182006e-05,
      "loss": 0.2377,
      "step": 5620
    },
    {
      "epoch": 0.25338674107745623,
      "grad_norm": 3.7651853561401367,
      "learning_rate": 9.746613258922544e-05,
      "loss": 0.2061,
      "step": 5630
    },
    {
      "epoch": 0.25383680633691885,
      "grad_norm": 2.468319892883301,
      "learning_rate": 9.746163193663081e-05,
      "loss": 0.2159,
      "step": 5640
    },
    {
      "epoch": 0.25428687159638147,
      "grad_norm": 1.4490810632705688,
      "learning_rate": 9.745713128403619e-05,
      "loss": 0.2412,
      "step": 5650
    },
    {
      "epoch": 0.2547369368558441,
      "grad_norm": 1.2853602170944214,
      "learning_rate": 9.745263063144157e-05,
      "loss": 0.2031,
      "step": 5660
    },
    {
      "epoch": 0.2551870021153067,
      "grad_norm": 6.211825370788574,
      "learning_rate": 9.744812997884693e-05,
      "loss": 0.2257,
      "step": 5670
    },
    {
      "epoch": 0.2556370673747693,
      "grad_norm": 2.365079402923584,
      "learning_rate": 9.74436293262523e-05,
      "loss": 0.2249,
      "step": 5680
    },
    {
      "epoch": 0.25608713263423194,
      "grad_norm": 1.7753430604934692,
      "learning_rate": 9.74391286736577e-05,
      "loss": 0.1871,
      "step": 5690
    },
    {
      "epoch": 0.2565371978936946,
      "grad_norm": 3.4613943099975586,
      "learning_rate": 9.743462802106305e-05,
      "loss": 0.1985,
      "step": 5700
    },
    {
      "epoch": 0.25698726315315723,
      "grad_norm": 4.167544841766357,
      "learning_rate": 9.743012736846844e-05,
      "loss": 0.2001,
      "step": 5710
    },
    {
      "epoch": 0.25743732841261985,
      "grad_norm": 2.8627843856811523,
      "learning_rate": 9.742562671587381e-05,
      "loss": 0.1836,
      "step": 5720
    },
    {
      "epoch": 0.25788739367208247,
      "grad_norm": 0.9468194246292114,
      "learning_rate": 9.742112606327917e-05,
      "loss": 0.1815,
      "step": 5730
    },
    {
      "epoch": 0.2583374589315451,
      "grad_norm": 1.6158429384231567,
      "learning_rate": 9.741662541068456e-05,
      "loss": 0.2032,
      "step": 5740
    },
    {
      "epoch": 0.2587875241910077,
      "grad_norm": 2.0908315181732178,
      "learning_rate": 9.741212475808994e-05,
      "loss": 0.2359,
      "step": 5750
    },
    {
      "epoch": 0.2592375894504703,
      "grad_norm": 4.527562618255615,
      "learning_rate": 9.74076241054953e-05,
      "loss": 0.1793,
      "step": 5760
    },
    {
      "epoch": 0.25968765470993294,
      "grad_norm": 1.1676889657974243,
      "learning_rate": 9.740312345290068e-05,
      "loss": 0.1686,
      "step": 5770
    },
    {
      "epoch": 0.26013771996939555,
      "grad_norm": 2.7164058685302734,
      "learning_rate": 9.739862280030606e-05,
      "loss": 0.2113,
      "step": 5780
    },
    {
      "epoch": 0.26058778522885817,
      "grad_norm": 2.206880807876587,
      "learning_rate": 9.739412214771142e-05,
      "loss": 0.2693,
      "step": 5790
    },
    {
      "epoch": 0.2610378504883208,
      "grad_norm": 1.2905455827713013,
      "learning_rate": 9.73896214951168e-05,
      "loss": 0.2005,
      "step": 5800
    },
    {
      "epoch": 0.2614879157477834,
      "grad_norm": 0.8505688905715942,
      "learning_rate": 9.738512084252218e-05,
      "loss": 0.1544,
      "step": 5810
    },
    {
      "epoch": 0.261937981007246,
      "grad_norm": 1.554384469985962,
      "learning_rate": 9.738062018992754e-05,
      "loss": 0.1837,
      "step": 5820
    },
    {
      "epoch": 0.2623880462667087,
      "grad_norm": 2.8292298316955566,
      "learning_rate": 9.737611953733292e-05,
      "loss": 0.2069,
      "step": 5830
    },
    {
      "epoch": 0.2628381115261713,
      "grad_norm": 2.094287633895874,
      "learning_rate": 9.73716188847383e-05,
      "loss": 0.1976,
      "step": 5840
    },
    {
      "epoch": 0.26328817678563393,
      "grad_norm": 5.259358882904053,
      "learning_rate": 9.736711823214366e-05,
      "loss": 0.2058,
      "step": 5850
    },
    {
      "epoch": 0.26373824204509655,
      "grad_norm": 2.2918949127197266,
      "learning_rate": 9.736261757954904e-05,
      "loss": 0.2663,
      "step": 5860
    },
    {
      "epoch": 0.26418830730455917,
      "grad_norm": 1.2080541849136353,
      "learning_rate": 9.735811692695442e-05,
      "loss": 0.1921,
      "step": 5870
    },
    {
      "epoch": 0.2646383725640218,
      "grad_norm": 1.904810905456543,
      "learning_rate": 9.735361627435978e-05,
      "loss": 0.1859,
      "step": 5880
    },
    {
      "epoch": 0.2650884378234844,
      "grad_norm": 1.480760097503662,
      "learning_rate": 9.734911562176517e-05,
      "loss": 0.2262,
      "step": 5890
    },
    {
      "epoch": 0.265538503082947,
      "grad_norm": 1.3281222581863403,
      "learning_rate": 9.734461496917054e-05,
      "loss": 0.2346,
      "step": 5900
    },
    {
      "epoch": 0.26598856834240964,
      "grad_norm": 2.5785598754882812,
      "learning_rate": 9.73401143165759e-05,
      "loss": 0.2052,
      "step": 5910
    },
    {
      "epoch": 0.26643863360187225,
      "grad_norm": 2.307485342025757,
      "learning_rate": 9.733561366398129e-05,
      "loss": 0.2094,
      "step": 5920
    },
    {
      "epoch": 0.26688869886133487,
      "grad_norm": 2.358137607574463,
      "learning_rate": 9.733111301138666e-05,
      "loss": 0.2142,
      "step": 5930
    },
    {
      "epoch": 0.2673387641207975,
      "grad_norm": 4.142629146575928,
      "learning_rate": 9.732661235879202e-05,
      "loss": 0.1904,
      "step": 5940
    },
    {
      "epoch": 0.26778882938026016,
      "grad_norm": 2.343812942504883,
      "learning_rate": 9.732211170619741e-05,
      "loss": 0.261,
      "step": 5950
    },
    {
      "epoch": 0.2682388946397228,
      "grad_norm": 2.1514978408813477,
      "learning_rate": 9.731761105360278e-05,
      "loss": 0.2703,
      "step": 5960
    },
    {
      "epoch": 0.2686889598991854,
      "grad_norm": 1.7518885135650635,
      "learning_rate": 9.731311040100815e-05,
      "loss": 0.247,
      "step": 5970
    },
    {
      "epoch": 0.269139025158648,
      "grad_norm": 2.8958542346954346,
      "learning_rate": 9.730860974841353e-05,
      "loss": 0.2362,
      "step": 5980
    },
    {
      "epoch": 0.26958909041811063,
      "grad_norm": 1.7810602188110352,
      "learning_rate": 9.73041090958189e-05,
      "loss": 0.2232,
      "step": 5990
    },
    {
      "epoch": 0.27003915567757325,
      "grad_norm": 2.958095073699951,
      "learning_rate": 9.729960844322428e-05,
      "loss": 0.1582,
      "step": 6000
    },
    {
      "epoch": 0.27048922093703587,
      "grad_norm": 2.0147910118103027,
      "learning_rate": 9.729510779062965e-05,
      "loss": 0.2361,
      "step": 6010
    },
    {
      "epoch": 0.2709392861964985,
      "grad_norm": 3.2691080570220947,
      "learning_rate": 9.729060713803502e-05,
      "loss": 0.2491,
      "step": 6020
    },
    {
      "epoch": 0.2713893514559611,
      "grad_norm": 3.5405189990997314,
      "learning_rate": 9.72861064854404e-05,
      "loss": 0.2581,
      "step": 6030
    },
    {
      "epoch": 0.2718394167154237,
      "grad_norm": 3.3614397048950195,
      "learning_rate": 9.728160583284577e-05,
      "loss": 0.2084,
      "step": 6040
    },
    {
      "epoch": 0.27228948197488634,
      "grad_norm": 1.7380234003067017,
      "learning_rate": 9.727710518025114e-05,
      "loss": 0.1666,
      "step": 6050
    },
    {
      "epoch": 0.27273954723434896,
      "grad_norm": 2.592365026473999,
      "learning_rate": 9.727260452765652e-05,
      "loss": 0.1794,
      "step": 6060
    },
    {
      "epoch": 0.27318961249381163,
      "grad_norm": 1.3200839757919312,
      "learning_rate": 9.726810387506189e-05,
      "loss": 0.1948,
      "step": 6070
    },
    {
      "epoch": 0.27363967775327425,
      "grad_norm": 2.1536664962768555,
      "learning_rate": 9.726360322246726e-05,
      "loss": 0.2091,
      "step": 6080
    },
    {
      "epoch": 0.27408974301273686,
      "grad_norm": 1.4694581031799316,
      "learning_rate": 9.725910256987264e-05,
      "loss": 0.1537,
      "step": 6090
    },
    {
      "epoch": 0.2745398082721995,
      "grad_norm": 2.7802391052246094,
      "learning_rate": 9.725460191727801e-05,
      "loss": 0.2179,
      "step": 6100
    },
    {
      "epoch": 0.2749898735316621,
      "grad_norm": 2.2918758392333984,
      "learning_rate": 9.725010126468338e-05,
      "loss": 0.2272,
      "step": 6110
    },
    {
      "epoch": 0.2754399387911247,
      "grad_norm": 0.9697054624557495,
      "learning_rate": 9.724560061208876e-05,
      "loss": 0.1829,
      "step": 6120
    },
    {
      "epoch": 0.27589000405058733,
      "grad_norm": 2.2688393592834473,
      "learning_rate": 9.724109995949413e-05,
      "loss": 0.2171,
      "step": 6130
    },
    {
      "epoch": 0.27634006931004995,
      "grad_norm": 2.8919970989227295,
      "learning_rate": 9.72365993068995e-05,
      "loss": 0.2432,
      "step": 6140
    },
    {
      "epoch": 0.27679013456951257,
      "grad_norm": 1.3780266046524048,
      "learning_rate": 9.723209865430488e-05,
      "loss": 0.1917,
      "step": 6150
    },
    {
      "epoch": 0.2772401998289752,
      "grad_norm": 2.1736671924591064,
      "learning_rate": 9.722759800171025e-05,
      "loss": 0.2084,
      "step": 6160
    },
    {
      "epoch": 0.2776902650884378,
      "grad_norm": 3.3316752910614014,
      "learning_rate": 9.722309734911563e-05,
      "loss": 0.1942,
      "step": 6170
    },
    {
      "epoch": 0.2781403303479004,
      "grad_norm": 4.027109622955322,
      "learning_rate": 9.7218596696521e-05,
      "loss": 0.2363,
      "step": 6180
    },
    {
      "epoch": 0.2785903956073631,
      "grad_norm": 1.7375047206878662,
      "learning_rate": 9.721409604392637e-05,
      "loss": 0.1615,
      "step": 6190
    },
    {
      "epoch": 0.2790404608668257,
      "grad_norm": 2.2799904346466064,
      "learning_rate": 9.720959539133175e-05,
      "loss": 0.214,
      "step": 6200
    },
    {
      "epoch": 0.27949052612628833,
      "grad_norm": 3.703087329864502,
      "learning_rate": 9.720509473873712e-05,
      "loss": 0.1975,
      "step": 6210
    },
    {
      "epoch": 0.27994059138575095,
      "grad_norm": 1.1076922416687012,
      "learning_rate": 9.72005940861425e-05,
      "loss": 0.1694,
      "step": 6220
    },
    {
      "epoch": 0.28039065664521357,
      "grad_norm": 1.7983083724975586,
      "learning_rate": 9.719609343354787e-05,
      "loss": 0.195,
      "step": 6230
    },
    {
      "epoch": 0.2808407219046762,
      "grad_norm": 1.7791835069656372,
      "learning_rate": 9.719159278095324e-05,
      "loss": 0.2068,
      "step": 6240
    },
    {
      "epoch": 0.2812907871641388,
      "grad_norm": 2.887103319168091,
      "learning_rate": 9.718709212835862e-05,
      "loss": 0.1385,
      "step": 6250
    },
    {
      "epoch": 0.2817408524236014,
      "grad_norm": 1.802857756614685,
      "learning_rate": 9.718259147576399e-05,
      "loss": 0.1737,
      "step": 6260
    },
    {
      "epoch": 0.28219091768306404,
      "grad_norm": 1.7298067808151245,
      "learning_rate": 9.717809082316936e-05,
      "loss": 0.1849,
      "step": 6270
    },
    {
      "epoch": 0.28264098294252665,
      "grad_norm": 3.4033849239349365,
      "learning_rate": 9.717359017057474e-05,
      "loss": 0.1616,
      "step": 6280
    },
    {
      "epoch": 0.28309104820198927,
      "grad_norm": 1.9447027444839478,
      "learning_rate": 9.716908951798011e-05,
      "loss": 0.221,
      "step": 6290
    },
    {
      "epoch": 0.2835411134614519,
      "grad_norm": 4.321865081787109,
      "learning_rate": 9.716458886538548e-05,
      "loss": 0.1835,
      "step": 6300
    },
    {
      "epoch": 0.2839911787209145,
      "grad_norm": 3.952056407928467,
      "learning_rate": 9.716008821279086e-05,
      "loss": 0.2191,
      "step": 6310
    },
    {
      "epoch": 0.2844412439803772,
      "grad_norm": 6.288241386413574,
      "learning_rate": 9.715558756019624e-05,
      "loss": 0.194,
      "step": 6320
    },
    {
      "epoch": 0.2848913092398398,
      "grad_norm": 1.6500952243804932,
      "learning_rate": 9.71510869076016e-05,
      "loss": 0.1755,
      "step": 6330
    },
    {
      "epoch": 0.2853413744993024,
      "grad_norm": 3.0574393272399902,
      "learning_rate": 9.714658625500698e-05,
      "loss": 0.2234,
      "step": 6340
    },
    {
      "epoch": 0.28579143975876503,
      "grad_norm": 3.239626169204712,
      "learning_rate": 9.714208560241236e-05,
      "loss": 0.2319,
      "step": 6350
    },
    {
      "epoch": 0.28624150501822765,
      "grad_norm": 1.9808274507522583,
      "learning_rate": 9.713758494981772e-05,
      "loss": 0.1877,
      "step": 6360
    },
    {
      "epoch": 0.28669157027769027,
      "grad_norm": 1.8753879070281982,
      "learning_rate": 9.71330842972231e-05,
      "loss": 0.1961,
      "step": 6370
    },
    {
      "epoch": 0.2871416355371529,
      "grad_norm": 3.1633291244506836,
      "learning_rate": 9.712858364462849e-05,
      "loss": 0.1892,
      "step": 6380
    },
    {
      "epoch": 0.2875917007966155,
      "grad_norm": 1.2243402004241943,
      "learning_rate": 9.712408299203385e-05,
      "loss": 0.1712,
      "step": 6390
    },
    {
      "epoch": 0.2880417660560781,
      "grad_norm": 3.76519513130188,
      "learning_rate": 9.711958233943922e-05,
      "loss": 0.1944,
      "step": 6400
    },
    {
      "epoch": 0.28849183131554074,
      "grad_norm": 0.8189446926116943,
      "learning_rate": 9.71150816868446e-05,
      "loss": 0.1873,
      "step": 6410
    },
    {
      "epoch": 0.28894189657500335,
      "grad_norm": 1.8455268144607544,
      "learning_rate": 9.711058103424997e-05,
      "loss": 0.2155,
      "step": 6420
    },
    {
      "epoch": 0.28939196183446597,
      "grad_norm": 1.7748163938522339,
      "learning_rate": 9.710608038165534e-05,
      "loss": 0.1928,
      "step": 6430
    },
    {
      "epoch": 0.28984202709392864,
      "grad_norm": 1.836134433746338,
      "learning_rate": 9.710157972906073e-05,
      "loss": 0.1356,
      "step": 6440
    },
    {
      "epoch": 0.29029209235339126,
      "grad_norm": 3.0610780715942383,
      "learning_rate": 9.709707907646609e-05,
      "loss": 0.2219,
      "step": 6450
    },
    {
      "epoch": 0.2907421576128539,
      "grad_norm": 3.083829402923584,
      "learning_rate": 9.709257842387146e-05,
      "loss": 0.2098,
      "step": 6460
    },
    {
      "epoch": 0.2911922228723165,
      "grad_norm": 2.5943214893341064,
      "learning_rate": 9.708807777127685e-05,
      "loss": 0.1669,
      "step": 6470
    },
    {
      "epoch": 0.2916422881317791,
      "grad_norm": 2.0710537433624268,
      "learning_rate": 9.708357711868221e-05,
      "loss": 0.1678,
      "step": 6480
    },
    {
      "epoch": 0.29209235339124173,
      "grad_norm": 2.992670774459839,
      "learning_rate": 9.70790764660876e-05,
      "loss": 0.1714,
      "step": 6490
    },
    {
      "epoch": 0.29254241865070435,
      "grad_norm": 1.7017796039581299,
      "learning_rate": 9.707457581349297e-05,
      "loss": 0.1783,
      "step": 6500
    },
    {
      "epoch": 0.29299248391016697,
      "grad_norm": 4.639562606811523,
      "learning_rate": 9.707007516089833e-05,
      "loss": 0.2441,
      "step": 6510
    },
    {
      "epoch": 0.2934425491696296,
      "grad_norm": 3.5391838550567627,
      "learning_rate": 9.706557450830372e-05,
      "loss": 0.1806,
      "step": 6520
    },
    {
      "epoch": 0.2938926144290922,
      "grad_norm": 3.118739366531372,
      "learning_rate": 9.706107385570909e-05,
      "loss": 0.2257,
      "step": 6530
    },
    {
      "epoch": 0.2943426796885548,
      "grad_norm": 1.839965581893921,
      "learning_rate": 9.705657320311445e-05,
      "loss": 0.1676,
      "step": 6540
    },
    {
      "epoch": 0.29479274494801744,
      "grad_norm": 0.6030647158622742,
      "learning_rate": 9.705207255051984e-05,
      "loss": 0.1666,
      "step": 6550
    },
    {
      "epoch": 0.2952428102074801,
      "grad_norm": 3.6978654861450195,
      "learning_rate": 9.704757189792521e-05,
      "loss": 0.2302,
      "step": 6560
    },
    {
      "epoch": 0.29569287546694273,
      "grad_norm": 1.604921817779541,
      "learning_rate": 9.704307124533057e-05,
      "loss": 0.2003,
      "step": 6570
    },
    {
      "epoch": 0.29614294072640535,
      "grad_norm": 4.035091400146484,
      "learning_rate": 9.703857059273596e-05,
      "loss": 0.1895,
      "step": 6580
    },
    {
      "epoch": 0.29659300598586796,
      "grad_norm": 4.0302734375,
      "learning_rate": 9.703406994014133e-05,
      "loss": 0.1608,
      "step": 6590
    },
    {
      "epoch": 0.2970430712453306,
      "grad_norm": 1.839306116104126,
      "learning_rate": 9.702956928754669e-05,
      "loss": 0.137,
      "step": 6600
    },
    {
      "epoch": 0.2974931365047932,
      "grad_norm": 2.8762857913970947,
      "learning_rate": 9.702506863495208e-05,
      "loss": 0.1831,
      "step": 6610
    },
    {
      "epoch": 0.2979432017642558,
      "grad_norm": 2.4820570945739746,
      "learning_rate": 9.702056798235745e-05,
      "loss": 0.2237,
      "step": 6620
    },
    {
      "epoch": 0.29839326702371843,
      "grad_norm": 2.827785015106201,
      "learning_rate": 9.701606732976281e-05,
      "loss": 0.1955,
      "step": 6630
    },
    {
      "epoch": 0.29884333228318105,
      "grad_norm": 2.964606285095215,
      "learning_rate": 9.70115666771682e-05,
      "loss": 0.181,
      "step": 6640
    },
    {
      "epoch": 0.29929339754264367,
      "grad_norm": 1.5203077793121338,
      "learning_rate": 9.700706602457357e-05,
      "loss": 0.1788,
      "step": 6650
    },
    {
      "epoch": 0.2997434628021063,
      "grad_norm": 2.6857826709747314,
      "learning_rate": 9.700256537197893e-05,
      "loss": 0.1608,
      "step": 6660
    },
    {
      "epoch": 0.3001935280615689,
      "grad_norm": 1.6219947338104248,
      "learning_rate": 9.699806471938432e-05,
      "loss": 0.2401,
      "step": 6670
    },
    {
      "epoch": 0.3006435933210316,
      "grad_norm": 1.8369793891906738,
      "learning_rate": 9.69935640667897e-05,
      "loss": 0.1497,
      "step": 6680
    },
    {
      "epoch": 0.3010936585804942,
      "grad_norm": 1.7960951328277588,
      "learning_rate": 9.698906341419505e-05,
      "loss": 0.1852,
      "step": 6690
    },
    {
      "epoch": 0.3015437238399568,
      "grad_norm": 3.438427686691284,
      "learning_rate": 9.698456276160044e-05,
      "loss": 0.1817,
      "step": 6700
    },
    {
      "epoch": 0.30199378909941943,
      "grad_norm": 1.7768899202346802,
      "learning_rate": 9.698006210900581e-05,
      "loss": 0.2537,
      "step": 6710
    },
    {
      "epoch": 0.30244385435888205,
      "grad_norm": 2.223369836807251,
      "learning_rate": 9.697556145641117e-05,
      "loss": 0.2042,
      "step": 6720
    },
    {
      "epoch": 0.30289391961834466,
      "grad_norm": 1.4222865104675293,
      "learning_rate": 9.697106080381656e-05,
      "loss": 0.2109,
      "step": 6730
    },
    {
      "epoch": 0.3033439848778073,
      "grad_norm": 2.8681278228759766,
      "learning_rate": 9.696656015122194e-05,
      "loss": 0.2517,
      "step": 6740
    },
    {
      "epoch": 0.3037940501372699,
      "grad_norm": 1.23607337474823,
      "learning_rate": 9.69620594986273e-05,
      "loss": 0.1882,
      "step": 6750
    },
    {
      "epoch": 0.3042441153967325,
      "grad_norm": 1.6586445569992065,
      "learning_rate": 9.695755884603268e-05,
      "loss": 0.1689,
      "step": 6760
    },
    {
      "epoch": 0.30469418065619513,
      "grad_norm": 3.914425849914551,
      "learning_rate": 9.695305819343806e-05,
      "loss": 0.2398,
      "step": 6770
    },
    {
      "epoch": 0.30514424591565775,
      "grad_norm": 2.755826473236084,
      "learning_rate": 9.694855754084343e-05,
      "loss": 0.1556,
      "step": 6780
    },
    {
      "epoch": 0.30559431117512037,
      "grad_norm": 1.709104061126709,
      "learning_rate": 9.69440568882488e-05,
      "loss": 0.2042,
      "step": 6790
    },
    {
      "epoch": 0.306044376434583,
      "grad_norm": 2.133652687072754,
      "learning_rate": 9.693955623565418e-05,
      "loss": 0.1339,
      "step": 6800
    },
    {
      "epoch": 0.30649444169404566,
      "grad_norm": 4.587808132171631,
      "learning_rate": 9.693505558305955e-05,
      "loss": 0.229,
      "step": 6810
    },
    {
      "epoch": 0.3069445069535083,
      "grad_norm": 1.9138036966323853,
      "learning_rate": 9.693055493046492e-05,
      "loss": 0.1907,
      "step": 6820
    },
    {
      "epoch": 0.3073945722129709,
      "grad_norm": 2.9861934185028076,
      "learning_rate": 9.69260542778703e-05,
      "loss": 0.3207,
      "step": 6830
    },
    {
      "epoch": 0.3078446374724335,
      "grad_norm": 2.2400410175323486,
      "learning_rate": 9.692155362527567e-05,
      "loss": 0.2252,
      "step": 6840
    },
    {
      "epoch": 0.30829470273189613,
      "grad_norm": 2.4125194549560547,
      "learning_rate": 9.691705297268105e-05,
      "loss": 0.1802,
      "step": 6850
    },
    {
      "epoch": 0.30874476799135875,
      "grad_norm": 2.3428616523742676,
      "learning_rate": 9.691255232008642e-05,
      "loss": 0.2056,
      "step": 6860
    },
    {
      "epoch": 0.30919483325082137,
      "grad_norm": 4.054943084716797,
      "learning_rate": 9.690805166749179e-05,
      "loss": 0.1973,
      "step": 6870
    },
    {
      "epoch": 0.309644898510284,
      "grad_norm": 2.405245542526245,
      "learning_rate": 9.690355101489717e-05,
      "loss": 0.1546,
      "step": 6880
    },
    {
      "epoch": 0.3100949637697466,
      "grad_norm": 1.3738577365875244,
      "learning_rate": 9.689905036230254e-05,
      "loss": 0.1553,
      "step": 6890
    },
    {
      "epoch": 0.3105450290292092,
      "grad_norm": 2.3965096473693848,
      "learning_rate": 9.689454970970791e-05,
      "loss": 0.2346,
      "step": 6900
    },
    {
      "epoch": 0.31099509428867184,
      "grad_norm": 2.7859442234039307,
      "learning_rate": 9.689004905711329e-05,
      "loss": 0.1628,
      "step": 6910
    },
    {
      "epoch": 0.31144515954813445,
      "grad_norm": 1.8851830959320068,
      "learning_rate": 9.688554840451866e-05,
      "loss": 0.2259,
      "step": 6920
    },
    {
      "epoch": 0.3118952248075971,
      "grad_norm": 2.1547393798828125,
      "learning_rate": 9.688104775192403e-05,
      "loss": 0.2089,
      "step": 6930
    },
    {
      "epoch": 0.31234529006705974,
      "grad_norm": 1.165626049041748,
      "learning_rate": 9.687654709932941e-05,
      "loss": 0.1816,
      "step": 6940
    },
    {
      "epoch": 0.31279535532652236,
      "grad_norm": 1.6717160940170288,
      "learning_rate": 9.687204644673478e-05,
      "loss": 0.1827,
      "step": 6950
    },
    {
      "epoch": 0.313245420585985,
      "grad_norm": 1.5033870935440063,
      "learning_rate": 9.686754579414015e-05,
      "loss": 0.1935,
      "step": 6960
    },
    {
      "epoch": 0.3136954858454476,
      "grad_norm": 1.8360379934310913,
      "learning_rate": 9.686304514154553e-05,
      "loss": 0.1959,
      "step": 6970
    },
    {
      "epoch": 0.3141455511049102,
      "grad_norm": 1.05289888381958,
      "learning_rate": 9.68585444889509e-05,
      "loss": 0.1839,
      "step": 6980
    },
    {
      "epoch": 0.31459561636437283,
      "grad_norm": 2.182493209838867,
      "learning_rate": 9.685404383635628e-05,
      "loss": 0.2141,
      "step": 6990
    },
    {
      "epoch": 0.31504568162383545,
      "grad_norm": 2.68562912940979,
      "learning_rate": 9.684954318376165e-05,
      "loss": 0.1834,
      "step": 7000
    },
    {
      "epoch": 0.31549574688329807,
      "grad_norm": 2.1869382858276367,
      "learning_rate": 9.684504253116702e-05,
      "loss": 0.1573,
      "step": 7010
    },
    {
      "epoch": 0.3159458121427607,
      "grad_norm": 2.4522764682769775,
      "learning_rate": 9.68405418785724e-05,
      "loss": 0.1773,
      "step": 7020
    },
    {
      "epoch": 0.3163958774022233,
      "grad_norm": 2.2935690879821777,
      "learning_rate": 9.683604122597777e-05,
      "loss": 0.2247,
      "step": 7030
    },
    {
      "epoch": 0.3168459426616859,
      "grad_norm": 2.261957883834839,
      "learning_rate": 9.683154057338316e-05,
      "loss": 0.2142,
      "step": 7040
    },
    {
      "epoch": 0.3172960079211486,
      "grad_norm": 2.6177191734313965,
      "learning_rate": 9.682703992078852e-05,
      "loss": 0.2137,
      "step": 7050
    },
    {
      "epoch": 0.3177460731806112,
      "grad_norm": 1.771345853805542,
      "learning_rate": 9.682253926819389e-05,
      "loss": 0.2326,
      "step": 7060
    },
    {
      "epoch": 0.31819613844007383,
      "grad_norm": 3.9592950344085693,
      "learning_rate": 9.681803861559928e-05,
      "loss": 0.1825,
      "step": 7070
    },
    {
      "epoch": 0.31864620369953645,
      "grad_norm": 5.37076997756958,
      "learning_rate": 9.681353796300464e-05,
      "loss": 0.2173,
      "step": 7080
    },
    {
      "epoch": 0.31909626895899906,
      "grad_norm": 1.4179043769836426,
      "learning_rate": 9.680903731041001e-05,
      "loss": 0.2169,
      "step": 7090
    },
    {
      "epoch": 0.3195463342184617,
      "grad_norm": 2.527094841003418,
      "learning_rate": 9.68045366578154e-05,
      "loss": 0.2192,
      "step": 7100
    },
    {
      "epoch": 0.3199963994779243,
      "grad_norm": 3.513956308364868,
      "learning_rate": 9.680003600522076e-05,
      "loss": 0.1537,
      "step": 7110
    },
    {
      "epoch": 0.3204464647373869,
      "grad_norm": 2.37945294380188,
      "learning_rate": 9.679553535262613e-05,
      "loss": 0.1961,
      "step": 7120
    },
    {
      "epoch": 0.32089652999684953,
      "grad_norm": 1.665521502494812,
      "learning_rate": 9.679103470003152e-05,
      "loss": 0.1963,
      "step": 7130
    },
    {
      "epoch": 0.32134659525631215,
      "grad_norm": 2.724646806716919,
      "learning_rate": 9.678653404743688e-05,
      "loss": 0.2113,
      "step": 7140
    },
    {
      "epoch": 0.32179666051577477,
      "grad_norm": 3.1121201515197754,
      "learning_rate": 9.678203339484225e-05,
      "loss": 0.2042,
      "step": 7150
    },
    {
      "epoch": 0.3222467257752374,
      "grad_norm": 2.4437248706817627,
      "learning_rate": 9.677753274224764e-05,
      "loss": 0.1431,
      "step": 7160
    },
    {
      "epoch": 0.32269679103470006,
      "grad_norm": 1.4405581951141357,
      "learning_rate": 9.6773032089653e-05,
      "loss": 0.175,
      "step": 7170
    },
    {
      "epoch": 0.3231468562941627,
      "grad_norm": 1.4828463792800903,
      "learning_rate": 9.676853143705837e-05,
      "loss": 0.138,
      "step": 7180
    },
    {
      "epoch": 0.3235969215536253,
      "grad_norm": 3.7271082401275635,
      "learning_rate": 9.676403078446376e-05,
      "loss": 0.1978,
      "step": 7190
    },
    {
      "epoch": 0.3240469868130879,
      "grad_norm": 2.5355873107910156,
      "learning_rate": 9.675953013186912e-05,
      "loss": 0.1887,
      "step": 7200
    },
    {
      "epoch": 0.32449705207255053,
      "grad_norm": 3.3676915168762207,
      "learning_rate": 9.67550294792745e-05,
      "loss": 0.1837,
      "step": 7210
    },
    {
      "epoch": 0.32494711733201315,
      "grad_norm": 3.9794676303863525,
      "learning_rate": 9.675052882667988e-05,
      "loss": 0.1923,
      "step": 7220
    },
    {
      "epoch": 0.32539718259147576,
      "grad_norm": 2.4757564067840576,
      "learning_rate": 9.674602817408524e-05,
      "loss": 0.1756,
      "step": 7230
    },
    {
      "epoch": 0.3258472478509384,
      "grad_norm": 0.965526819229126,
      "learning_rate": 9.674152752149062e-05,
      "loss": 0.2084,
      "step": 7240
    },
    {
      "epoch": 0.326297313110401,
      "grad_norm": 2.4715769290924072,
      "learning_rate": 9.6737026868896e-05,
      "loss": 0.1288,
      "step": 7250
    },
    {
      "epoch": 0.3267473783698636,
      "grad_norm": 3.190075635910034,
      "learning_rate": 9.673252621630136e-05,
      "loss": 0.2063,
      "step": 7260
    },
    {
      "epoch": 0.32719744362932623,
      "grad_norm": 2.08376407623291,
      "learning_rate": 9.672802556370674e-05,
      "loss": 0.162,
      "step": 7270
    },
    {
      "epoch": 0.32764750888878885,
      "grad_norm": 1.648620843887329,
      "learning_rate": 9.672352491111212e-05,
      "loss": 0.1364,
      "step": 7280
    },
    {
      "epoch": 0.32809757414825147,
      "grad_norm": 4.876419544219971,
      "learning_rate": 9.671902425851748e-05,
      "loss": 0.187,
      "step": 7290
    },
    {
      "epoch": 0.32854763940771414,
      "grad_norm": 1.451759696006775,
      "learning_rate": 9.671452360592287e-05,
      "loss": 0.1612,
      "step": 7300
    },
    {
      "epoch": 0.32899770466717676,
      "grad_norm": 3.029876470565796,
      "learning_rate": 9.671002295332824e-05,
      "loss": 0.2577,
      "step": 7310
    },
    {
      "epoch": 0.3294477699266394,
      "grad_norm": 1.606722354888916,
      "learning_rate": 9.67055223007336e-05,
      "loss": 0.2498,
      "step": 7320
    },
    {
      "epoch": 0.329897835186102,
      "grad_norm": 1.818618893623352,
      "learning_rate": 9.670102164813899e-05,
      "loss": 0.184,
      "step": 7330
    },
    {
      "epoch": 0.3303479004455646,
      "grad_norm": 3.4029293060302734,
      "learning_rate": 9.669652099554437e-05,
      "loss": 0.1408,
      "step": 7340
    },
    {
      "epoch": 0.33079796570502723,
      "grad_norm": 2.898712158203125,
      "learning_rate": 9.669202034294973e-05,
      "loss": 0.2451,
      "step": 7350
    },
    {
      "epoch": 0.33124803096448985,
      "grad_norm": 2.1077051162719727,
      "learning_rate": 9.668751969035511e-05,
      "loss": 0.1663,
      "step": 7360
    },
    {
      "epoch": 0.33169809622395247,
      "grad_norm": 1.9140492677688599,
      "learning_rate": 9.668301903776049e-05,
      "loss": 0.1135,
      "step": 7370
    },
    {
      "epoch": 0.3321481614834151,
      "grad_norm": 3.4700207710266113,
      "learning_rate": 9.667851838516585e-05,
      "loss": 0.2021,
      "step": 7380
    },
    {
      "epoch": 0.3325982267428777,
      "grad_norm": 1.1318167448043823,
      "learning_rate": 9.667401773257123e-05,
      "loss": 0.1937,
      "step": 7390
    },
    {
      "epoch": 0.3330482920023403,
      "grad_norm": 2.4474432468414307,
      "learning_rate": 9.66695170799766e-05,
      "loss": 0.2461,
      "step": 7400
    },
    {
      "epoch": 0.33349835726180294,
      "grad_norm": 1.3826440572738647,
      "learning_rate": 9.666501642738197e-05,
      "loss": 0.1977,
      "step": 7410
    },
    {
      "epoch": 0.3339484225212656,
      "grad_norm": 4.500046253204346,
      "learning_rate": 9.666051577478735e-05,
      "loss": 0.2239,
      "step": 7420
    },
    {
      "epoch": 0.3343984877807282,
      "grad_norm": 5.122535705566406,
      "learning_rate": 9.665601512219273e-05,
      "loss": 0.1625,
      "step": 7430
    },
    {
      "epoch": 0.33484855304019084,
      "grad_norm": 4.768703937530518,
      "learning_rate": 9.665151446959809e-05,
      "loss": 0.1854,
      "step": 7440
    },
    {
      "epoch": 0.33529861829965346,
      "grad_norm": 2.299675941467285,
      "learning_rate": 9.664701381700347e-05,
      "loss": 0.2099,
      "step": 7450
    },
    {
      "epoch": 0.3357486835591161,
      "grad_norm": 3.001361608505249,
      "learning_rate": 9.664251316440885e-05,
      "loss": 0.1624,
      "step": 7460
    },
    {
      "epoch": 0.3361987488185787,
      "grad_norm": 4.557789325714111,
      "learning_rate": 9.663801251181421e-05,
      "loss": 0.2708,
      "step": 7470
    },
    {
      "epoch": 0.3366488140780413,
      "grad_norm": 1.6123337745666504,
      "learning_rate": 9.66335118592196e-05,
      "loss": 0.2106,
      "step": 7480
    },
    {
      "epoch": 0.33709887933750393,
      "grad_norm": 2.875011682510376,
      "learning_rate": 9.662901120662497e-05,
      "loss": 0.1949,
      "step": 7490
    },
    {
      "epoch": 0.33754894459696655,
      "grad_norm": 3.209800958633423,
      "learning_rate": 9.662451055403033e-05,
      "loss": 0.2004,
      "step": 7500
    },
    {
      "epoch": 0.33799900985642917,
      "grad_norm": 2.271562099456787,
      "learning_rate": 9.662000990143572e-05,
      "loss": 0.1577,
      "step": 7510
    },
    {
      "epoch": 0.3384490751158918,
      "grad_norm": 2.914522171020508,
      "learning_rate": 9.661550924884109e-05,
      "loss": 0.1703,
      "step": 7520
    },
    {
      "epoch": 0.3388991403753544,
      "grad_norm": 1.8740159273147583,
      "learning_rate": 9.661100859624645e-05,
      "loss": 0.1998,
      "step": 7530
    },
    {
      "epoch": 0.3393492056348171,
      "grad_norm": 1.0291101932525635,
      "learning_rate": 9.660650794365184e-05,
      "loss": 0.1642,
      "step": 7540
    },
    {
      "epoch": 0.3397992708942797,
      "grad_norm": 1.9650804996490479,
      "learning_rate": 9.660200729105721e-05,
      "loss": 0.1569,
      "step": 7550
    },
    {
      "epoch": 0.3402493361537423,
      "grad_norm": 3.1092989444732666,
      "learning_rate": 9.659750663846258e-05,
      "loss": 0.2201,
      "step": 7560
    },
    {
      "epoch": 0.3406994014132049,
      "grad_norm": 3.0587499141693115,
      "learning_rate": 9.659300598586796e-05,
      "loss": 0.18,
      "step": 7570
    },
    {
      "epoch": 0.34114946667266755,
      "grad_norm": 1.4525189399719238,
      "learning_rate": 9.658850533327333e-05,
      "loss": 0.189,
      "step": 7580
    },
    {
      "epoch": 0.34159953193213016,
      "grad_norm": 2.9100089073181152,
      "learning_rate": 9.65840046806787e-05,
      "loss": 0.198,
      "step": 7590
    },
    {
      "epoch": 0.3420495971915928,
      "grad_norm": 2.9121623039245605,
      "learning_rate": 9.657950402808408e-05,
      "loss": 0.1949,
      "step": 7600
    },
    {
      "epoch": 0.3424996624510554,
      "grad_norm": 6.123629570007324,
      "learning_rate": 9.657500337548945e-05,
      "loss": 0.2272,
      "step": 7610
    },
    {
      "epoch": 0.342949727710518,
      "grad_norm": 1.7195907831192017,
      "learning_rate": 9.657050272289483e-05,
      "loss": 0.1722,
      "step": 7620
    },
    {
      "epoch": 0.34339979296998063,
      "grad_norm": 3.190462112426758,
      "learning_rate": 9.65660020703002e-05,
      "loss": 0.2019,
      "step": 7630
    },
    {
      "epoch": 0.34384985822944325,
      "grad_norm": 2.53092098236084,
      "learning_rate": 9.656150141770557e-05,
      "loss": 0.1784,
      "step": 7640
    },
    {
      "epoch": 0.34429992348890587,
      "grad_norm": 0.7754976749420166,
      "learning_rate": 9.655700076511095e-05,
      "loss": 0.1574,
      "step": 7650
    },
    {
      "epoch": 0.34474998874836854,
      "grad_norm": 2.696795701980591,
      "learning_rate": 9.655250011251632e-05,
      "loss": 0.1901,
      "step": 7660
    },
    {
      "epoch": 0.34520005400783116,
      "grad_norm": 1.8528807163238525,
      "learning_rate": 9.65479994599217e-05,
      "loss": 0.188,
      "step": 7670
    },
    {
      "epoch": 0.3456501192672938,
      "grad_norm": 2.803379535675049,
      "learning_rate": 9.654349880732707e-05,
      "loss": 0.2172,
      "step": 7680
    },
    {
      "epoch": 0.3461001845267564,
      "grad_norm": 1.0717641115188599,
      "learning_rate": 9.653899815473244e-05,
      "loss": 0.1722,
      "step": 7690
    },
    {
      "epoch": 0.346550249786219,
      "grad_norm": 0.8031459450721741,
      "learning_rate": 9.653449750213781e-05,
      "loss": 0.1762,
      "step": 7700
    },
    {
      "epoch": 0.34700031504568163,
      "grad_norm": 1.3670713901519775,
      "learning_rate": 9.652999684954319e-05,
      "loss": 0.1579,
      "step": 7710
    },
    {
      "epoch": 0.34745038030514425,
      "grad_norm": 1.9188232421875,
      "learning_rate": 9.652549619694856e-05,
      "loss": 0.1702,
      "step": 7720
    },
    {
      "epoch": 0.34790044556460686,
      "grad_norm": 1.9593391418457031,
      "learning_rate": 9.652099554435394e-05,
      "loss": 0.19,
      "step": 7730
    },
    {
      "epoch": 0.3483505108240695,
      "grad_norm": 4.224700450897217,
      "learning_rate": 9.651649489175931e-05,
      "loss": 0.1837,
      "step": 7740
    },
    {
      "epoch": 0.3488005760835321,
      "grad_norm": 1.9159746170043945,
      "learning_rate": 9.651199423916468e-05,
      "loss": 0.2195,
      "step": 7750
    },
    {
      "epoch": 0.3492506413429947,
      "grad_norm": 2.170806884765625,
      "learning_rate": 9.650749358657006e-05,
      "loss": 0.2012,
      "step": 7760
    },
    {
      "epoch": 0.34970070660245733,
      "grad_norm": 3.547830820083618,
      "learning_rate": 9.650299293397543e-05,
      "loss": 0.1301,
      "step": 7770
    },
    {
      "epoch": 0.35015077186191995,
      "grad_norm": 1.8968380689620972,
      "learning_rate": 9.64984922813808e-05,
      "loss": 0.1442,
      "step": 7780
    },
    {
      "epoch": 0.3506008371213826,
      "grad_norm": 1.9225804805755615,
      "learning_rate": 9.649399162878618e-05,
      "loss": 0.2117,
      "step": 7790
    },
    {
      "epoch": 0.35105090238084524,
      "grad_norm": 3.037496566772461,
      "learning_rate": 9.648949097619155e-05,
      "loss": 0.1811,
      "step": 7800
    },
    {
      "epoch": 0.35150096764030786,
      "grad_norm": 4.746723175048828,
      "learning_rate": 9.648499032359692e-05,
      "loss": 0.1791,
      "step": 7810
    },
    {
      "epoch": 0.3519510328997705,
      "grad_norm": 1.2379989624023438,
      "learning_rate": 9.648048967100231e-05,
      "loss": 0.1872,
      "step": 7820
    },
    {
      "epoch": 0.3524010981592331,
      "grad_norm": 4.219525337219238,
      "learning_rate": 9.647598901840767e-05,
      "loss": 0.207,
      "step": 7830
    },
    {
      "epoch": 0.3528511634186957,
      "grad_norm": 1.2638663053512573,
      "learning_rate": 9.647148836581305e-05,
      "loss": 0.1759,
      "step": 7840
    },
    {
      "epoch": 0.35330122867815833,
      "grad_norm": 3.753777027130127,
      "learning_rate": 9.646698771321843e-05,
      "loss": 0.2597,
      "step": 7850
    },
    {
      "epoch": 0.35375129393762095,
      "grad_norm": 5.764793872833252,
      "learning_rate": 9.646248706062379e-05,
      "loss": 0.2519,
      "step": 7860
    },
    {
      "epoch": 0.35420135919708357,
      "grad_norm": 2.2384214401245117,
      "learning_rate": 9.645798640802917e-05,
      "loss": 0.1847,
      "step": 7870
    },
    {
      "epoch": 0.3546514244565462,
      "grad_norm": 1.084038496017456,
      "learning_rate": 9.645348575543455e-05,
      "loss": 0.1827,
      "step": 7880
    },
    {
      "epoch": 0.3551014897160088,
      "grad_norm": 2.8307178020477295,
      "learning_rate": 9.644898510283991e-05,
      "loss": 0.2127,
      "step": 7890
    },
    {
      "epoch": 0.3555515549754714,
      "grad_norm": 1.1055378913879395,
      "learning_rate": 9.644448445024529e-05,
      "loss": 0.1489,
      "step": 7900
    },
    {
      "epoch": 0.3560016202349341,
      "grad_norm": 3.3234546184539795,
      "learning_rate": 9.643998379765067e-05,
      "loss": 0.206,
      "step": 7910
    },
    {
      "epoch": 0.3564516854943967,
      "grad_norm": 1.937322735786438,
      "learning_rate": 9.643548314505603e-05,
      "loss": 0.2469,
      "step": 7920
    },
    {
      "epoch": 0.3569017507538593,
      "grad_norm": 0.6144739985466003,
      "learning_rate": 9.643098249246141e-05,
      "loss": 0.1333,
      "step": 7930
    },
    {
      "epoch": 0.35735181601332194,
      "grad_norm": 1.8123211860656738,
      "learning_rate": 9.64264818398668e-05,
      "loss": 0.1945,
      "step": 7940
    },
    {
      "epoch": 0.35780188127278456,
      "grad_norm": 4.51215934753418,
      "learning_rate": 9.642198118727215e-05,
      "loss": 0.1936,
      "step": 7950
    },
    {
      "epoch": 0.3582519465322472,
      "grad_norm": 1.8241742849349976,
      "learning_rate": 9.641748053467753e-05,
      "loss": 0.2453,
      "step": 7960
    },
    {
      "epoch": 0.3587020117917098,
      "grad_norm": 2.9073801040649414,
      "learning_rate": 9.641297988208292e-05,
      "loss": 0.1857,
      "step": 7970
    },
    {
      "epoch": 0.3591520770511724,
      "grad_norm": 2.389573097229004,
      "learning_rate": 9.640847922948828e-05,
      "loss": 0.2019,
      "step": 7980
    },
    {
      "epoch": 0.35960214231063503,
      "grad_norm": 2.1756279468536377,
      "learning_rate": 9.640397857689365e-05,
      "loss": 0.1902,
      "step": 7990
    },
    {
      "epoch": 0.36005220757009765,
      "grad_norm": 3.83136248588562,
      "learning_rate": 9.639947792429904e-05,
      "loss": 0.2325,
      "step": 8000
    },
    {
      "epoch": 0.36050227282956027,
      "grad_norm": 2.3681533336639404,
      "learning_rate": 9.63949772717044e-05,
      "loss": 0.1883,
      "step": 8010
    },
    {
      "epoch": 0.3609523380890229,
      "grad_norm": 0.9805013537406921,
      "learning_rate": 9.639047661910977e-05,
      "loss": 0.1938,
      "step": 8020
    },
    {
      "epoch": 0.36140240334848556,
      "grad_norm": 3.8716812133789062,
      "learning_rate": 9.638597596651516e-05,
      "loss": 0.2177,
      "step": 8030
    },
    {
      "epoch": 0.3618524686079482,
      "grad_norm": 0.8999245166778564,
      "learning_rate": 9.638147531392052e-05,
      "loss": 0.1215,
      "step": 8040
    },
    {
      "epoch": 0.3623025338674108,
      "grad_norm": 3.6385819911956787,
      "learning_rate": 9.637697466132589e-05,
      "loss": 0.1561,
      "step": 8050
    },
    {
      "epoch": 0.3627525991268734,
      "grad_norm": 1.1538771390914917,
      "learning_rate": 9.637247400873128e-05,
      "loss": 0.1784,
      "step": 8060
    },
    {
      "epoch": 0.363202664386336,
      "grad_norm": 2.726212501525879,
      "learning_rate": 9.636797335613664e-05,
      "loss": 0.1563,
      "step": 8070
    },
    {
      "epoch": 0.36365272964579864,
      "grad_norm": 2.534327983856201,
      "learning_rate": 9.636347270354203e-05,
      "loss": 0.1258,
      "step": 8080
    },
    {
      "epoch": 0.36410279490526126,
      "grad_norm": 2.7549118995666504,
      "learning_rate": 9.63589720509474e-05,
      "loss": 0.2258,
      "step": 8090
    },
    {
      "epoch": 0.3645528601647239,
      "grad_norm": 1.7742609977722168,
      "learning_rate": 9.635447139835276e-05,
      "loss": 0.1878,
      "step": 8100
    },
    {
      "epoch": 0.3650029254241865,
      "grad_norm": 4.11005163192749,
      "learning_rate": 9.634997074575815e-05,
      "loss": 0.1593,
      "step": 8110
    },
    {
      "epoch": 0.3654529906836491,
      "grad_norm": 2.502764940261841,
      "learning_rate": 9.634547009316352e-05,
      "loss": 0.151,
      "step": 8120
    },
    {
      "epoch": 0.36590305594311173,
      "grad_norm": 1.4208565950393677,
      "learning_rate": 9.634096944056888e-05,
      "loss": 0.1885,
      "step": 8130
    },
    {
      "epoch": 0.36635312120257435,
      "grad_norm": 2.415571451187134,
      "learning_rate": 9.633646878797427e-05,
      "loss": 0.1538,
      "step": 8140
    },
    {
      "epoch": 0.366803186462037,
      "grad_norm": 1.7796376943588257,
      "learning_rate": 9.633196813537964e-05,
      "loss": 0.1865,
      "step": 8150
    },
    {
      "epoch": 0.36725325172149964,
      "grad_norm": 1.9967097043991089,
      "learning_rate": 9.6327467482785e-05,
      "loss": 0.1642,
      "step": 8160
    },
    {
      "epoch": 0.36770331698096226,
      "grad_norm": 3.6359217166900635,
      "learning_rate": 9.632296683019039e-05,
      "loss": 0.164,
      "step": 8170
    },
    {
      "epoch": 0.3681533822404249,
      "grad_norm": 2.2251384258270264,
      "learning_rate": 9.631846617759576e-05,
      "loss": 0.1709,
      "step": 8180
    },
    {
      "epoch": 0.3686034474998875,
      "grad_norm": 4.491890907287598,
      "learning_rate": 9.631396552500112e-05,
      "loss": 0.2011,
      "step": 8190
    },
    {
      "epoch": 0.3690535127593501,
      "grad_norm": 0.6972659230232239,
      "learning_rate": 9.630946487240651e-05,
      "loss": 0.1624,
      "step": 8200
    },
    {
      "epoch": 0.36950357801881273,
      "grad_norm": 1.6794848442077637,
      "learning_rate": 9.630496421981188e-05,
      "loss": 0.1805,
      "step": 8210
    },
    {
      "epoch": 0.36995364327827535,
      "grad_norm": 2.877423048019409,
      "learning_rate": 9.630046356721724e-05,
      "loss": 0.2515,
      "step": 8220
    },
    {
      "epoch": 0.37040370853773796,
      "grad_norm": 3.5010132789611816,
      "learning_rate": 9.629596291462263e-05,
      "loss": 0.1901,
      "step": 8230
    },
    {
      "epoch": 0.3708537737972006,
      "grad_norm": 2.0423033237457275,
      "learning_rate": 9.6291462262028e-05,
      "loss": 0.18,
      "step": 8240
    },
    {
      "epoch": 0.3713038390566632,
      "grad_norm": 2.7770140171051025,
      "learning_rate": 9.628696160943336e-05,
      "loss": 0.1787,
      "step": 8250
    },
    {
      "epoch": 0.3717539043161258,
      "grad_norm": 1.0237337350845337,
      "learning_rate": 9.628246095683875e-05,
      "loss": 0.1341,
      "step": 8260
    },
    {
      "epoch": 0.37220396957558843,
      "grad_norm": 1.7155572175979614,
      "learning_rate": 9.627796030424412e-05,
      "loss": 0.1699,
      "step": 8270
    },
    {
      "epoch": 0.3726540348350511,
      "grad_norm": 2.9119632244110107,
      "learning_rate": 9.627345965164948e-05,
      "loss": 0.2113,
      "step": 8280
    },
    {
      "epoch": 0.3731041000945137,
      "grad_norm": 1.2065964937210083,
      "learning_rate": 9.626895899905487e-05,
      "loss": 0.1899,
      "step": 8290
    },
    {
      "epoch": 0.37355416535397634,
      "grad_norm": 1.4852890968322754,
      "learning_rate": 9.626445834646024e-05,
      "loss": 0.2084,
      "step": 8300
    },
    {
      "epoch": 0.37400423061343896,
      "grad_norm": 1.4222620725631714,
      "learning_rate": 9.62599576938656e-05,
      "loss": 0.1538,
      "step": 8310
    },
    {
      "epoch": 0.3744542958729016,
      "grad_norm": 1.2133876085281372,
      "learning_rate": 9.625545704127099e-05,
      "loss": 0.2035,
      "step": 8320
    },
    {
      "epoch": 0.3749043611323642,
      "grad_norm": 1.8762779235839844,
      "learning_rate": 9.625095638867637e-05,
      "loss": 0.1341,
      "step": 8330
    },
    {
      "epoch": 0.3753544263918268,
      "grad_norm": 2.2105681896209717,
      "learning_rate": 9.624645573608173e-05,
      "loss": 0.1847,
      "step": 8340
    },
    {
      "epoch": 0.37580449165128943,
      "grad_norm": 5.509660720825195,
      "learning_rate": 9.624195508348711e-05,
      "loss": 0.1625,
      "step": 8350
    },
    {
      "epoch": 0.37625455691075205,
      "grad_norm": 2.4174435138702393,
      "learning_rate": 9.623745443089249e-05,
      "loss": 0.1741,
      "step": 8360
    },
    {
      "epoch": 0.37670462217021466,
      "grad_norm": 5.467681407928467,
      "learning_rate": 9.623295377829786e-05,
      "loss": 0.1376,
      "step": 8370
    },
    {
      "epoch": 0.3771546874296773,
      "grad_norm": 4.701071739196777,
      "learning_rate": 9.622845312570323e-05,
      "loss": 0.1673,
      "step": 8380
    },
    {
      "epoch": 0.3776047526891399,
      "grad_norm": 2.556748628616333,
      "learning_rate": 9.622395247310861e-05,
      "loss": 0.1573,
      "step": 8390
    },
    {
      "epoch": 0.3780548179486026,
      "grad_norm": 7.024458885192871,
      "learning_rate": 9.621945182051398e-05,
      "loss": 0.1894,
      "step": 8400
    },
    {
      "epoch": 0.3785048832080652,
      "grad_norm": 2.714705467224121,
      "learning_rate": 9.621495116791935e-05,
      "loss": 0.1897,
      "step": 8410
    },
    {
      "epoch": 0.3789549484675278,
      "grad_norm": 2.034872055053711,
      "learning_rate": 9.621045051532473e-05,
      "loss": 0.2141,
      "step": 8420
    },
    {
      "epoch": 0.3794050137269904,
      "grad_norm": 2.216191530227661,
      "learning_rate": 9.62059498627301e-05,
      "loss": 0.232,
      "step": 8430
    },
    {
      "epoch": 0.37985507898645304,
      "grad_norm": 2.867858648300171,
      "learning_rate": 9.620144921013548e-05,
      "loss": 0.1996,
      "step": 8440
    },
    {
      "epoch": 0.38030514424591566,
      "grad_norm": 1.3001474142074585,
      "learning_rate": 9.619694855754085e-05,
      "loss": 0.1466,
      "step": 8450
    },
    {
      "epoch": 0.3807552095053783,
      "grad_norm": 2.2548999786376953,
      "learning_rate": 9.619244790494622e-05,
      "loss": 0.2434,
      "step": 8460
    },
    {
      "epoch": 0.3812052747648409,
      "grad_norm": 5.803530693054199,
      "learning_rate": 9.61879472523516e-05,
      "loss": 0.194,
      "step": 8470
    },
    {
      "epoch": 0.3816553400243035,
      "grad_norm": 2.8012607097625732,
      "learning_rate": 9.618344659975697e-05,
      "loss": 0.2038,
      "step": 8480
    },
    {
      "epoch": 0.38210540528376613,
      "grad_norm": 2.091834306716919,
      "learning_rate": 9.617894594716234e-05,
      "loss": 0.2063,
      "step": 8490
    },
    {
      "epoch": 0.38255547054322875,
      "grad_norm": 1.200043797492981,
      "learning_rate": 9.617444529456772e-05,
      "loss": 0.1958,
      "step": 8500
    },
    {
      "epoch": 0.38300553580269137,
      "grad_norm": 1.6755739450454712,
      "learning_rate": 9.616994464197309e-05,
      "loss": 0.1967,
      "step": 8510
    },
    {
      "epoch": 0.38345560106215404,
      "grad_norm": 3.2360875606536865,
      "learning_rate": 9.616544398937846e-05,
      "loss": 0.1759,
      "step": 8520
    },
    {
      "epoch": 0.38390566632161666,
      "grad_norm": 2.0009608268737793,
      "learning_rate": 9.616094333678384e-05,
      "loss": 0.1993,
      "step": 8530
    },
    {
      "epoch": 0.3843557315810793,
      "grad_norm": 5.142573356628418,
      "learning_rate": 9.615644268418921e-05,
      "loss": 0.2172,
      "step": 8540
    },
    {
      "epoch": 0.3848057968405419,
      "grad_norm": 1.1696512699127197,
      "learning_rate": 9.615194203159458e-05,
      "loss": 0.1604,
      "step": 8550
    },
    {
      "epoch": 0.3852558621000045,
      "grad_norm": 2.7414779663085938,
      "learning_rate": 9.614744137899996e-05,
      "loss": 0.1422,
      "step": 8560
    },
    {
      "epoch": 0.3857059273594671,
      "grad_norm": 1.8217819929122925,
      "learning_rate": 9.614294072640533e-05,
      "loss": 0.1691,
      "step": 8570
    },
    {
      "epoch": 0.38615599261892974,
      "grad_norm": 2.555908203125,
      "learning_rate": 9.61384400738107e-05,
      "loss": 0.1835,
      "step": 8580
    },
    {
      "epoch": 0.38660605787839236,
      "grad_norm": 2.9661736488342285,
      "learning_rate": 9.613393942121608e-05,
      "loss": 0.1782,
      "step": 8590
    },
    {
      "epoch": 0.387056123137855,
      "grad_norm": 1.8451746702194214,
      "learning_rate": 9.612943876862145e-05,
      "loss": 0.1644,
      "step": 8600
    },
    {
      "epoch": 0.3875061883973176,
      "grad_norm": 1.2108666896820068,
      "learning_rate": 9.612493811602683e-05,
      "loss": 0.1939,
      "step": 8610
    },
    {
      "epoch": 0.3879562536567802,
      "grad_norm": 2.5852766036987305,
      "learning_rate": 9.61204374634322e-05,
      "loss": 0.1192,
      "step": 8620
    },
    {
      "epoch": 0.38840631891624283,
      "grad_norm": 3.9354426860809326,
      "learning_rate": 9.611593681083759e-05,
      "loss": 0.1538,
      "step": 8630
    },
    {
      "epoch": 0.38885638417570545,
      "grad_norm": 1.152011513710022,
      "learning_rate": 9.611143615824295e-05,
      "loss": 0.1695,
      "step": 8640
    },
    {
      "epoch": 0.3893064494351681,
      "grad_norm": 2.48266339302063,
      "learning_rate": 9.610693550564832e-05,
      "loss": 0.1719,
      "step": 8650
    },
    {
      "epoch": 0.38975651469463074,
      "grad_norm": 4.457830905914307,
      "learning_rate": 9.610243485305371e-05,
      "loss": 0.1876,
      "step": 8660
    },
    {
      "epoch": 0.39020657995409336,
      "grad_norm": 3.0420424938201904,
      "learning_rate": 9.609793420045907e-05,
      "loss": 0.1847,
      "step": 8670
    },
    {
      "epoch": 0.390656645213556,
      "grad_norm": 2.545039415359497,
      "learning_rate": 9.609343354786444e-05,
      "loss": 0.1719,
      "step": 8680
    },
    {
      "epoch": 0.3911067104730186,
      "grad_norm": 2.363906145095825,
      "learning_rate": 9.608893289526983e-05,
      "loss": 0.2167,
      "step": 8690
    },
    {
      "epoch": 0.3915567757324812,
      "grad_norm": 1.9742549657821655,
      "learning_rate": 9.608443224267519e-05,
      "loss": 0.222,
      "step": 8700
    },
    {
      "epoch": 0.39200684099194383,
      "grad_norm": 0.8379781246185303,
      "learning_rate": 9.607993159008056e-05,
      "loss": 0.1711,
      "step": 8710
    },
    {
      "epoch": 0.39245690625140645,
      "grad_norm": 2.340679407119751,
      "learning_rate": 9.607543093748595e-05,
      "loss": 0.1528,
      "step": 8720
    },
    {
      "epoch": 0.39290697151086906,
      "grad_norm": 1.7498399019241333,
      "learning_rate": 9.607093028489131e-05,
      "loss": 0.1369,
      "step": 8730
    },
    {
      "epoch": 0.3933570367703317,
      "grad_norm": 0.8144925832748413,
      "learning_rate": 9.606642963229668e-05,
      "loss": 0.193,
      "step": 8740
    },
    {
      "epoch": 0.3938071020297943,
      "grad_norm": 3.217066764831543,
      "learning_rate": 9.606192897970207e-05,
      "loss": 0.1925,
      "step": 8750
    },
    {
      "epoch": 0.3942571672892569,
      "grad_norm": 1.8272037506103516,
      "learning_rate": 9.605742832710743e-05,
      "loss": 0.1426,
      "step": 8760
    },
    {
      "epoch": 0.3947072325487196,
      "grad_norm": 3.382444381713867,
      "learning_rate": 9.60529276745128e-05,
      "loss": 0.2215,
      "step": 8770
    },
    {
      "epoch": 0.3951572978081822,
      "grad_norm": 0.9006480574607849,
      "learning_rate": 9.604842702191819e-05,
      "loss": 0.1557,
      "step": 8780
    },
    {
      "epoch": 0.3956073630676448,
      "grad_norm": 1.293169379234314,
      "learning_rate": 9.604392636932355e-05,
      "loss": 0.2381,
      "step": 8790
    },
    {
      "epoch": 0.39605742832710744,
      "grad_norm": 3.404181480407715,
      "learning_rate": 9.603942571672892e-05,
      "loss": 0.196,
      "step": 8800
    },
    {
      "epoch": 0.39650749358657006,
      "grad_norm": 1.5705056190490723,
      "learning_rate": 9.603492506413431e-05,
      "loss": 0.1509,
      "step": 8810
    },
    {
      "epoch": 0.3969575588460327,
      "grad_norm": 2.323014974594116,
      "learning_rate": 9.603042441153967e-05,
      "loss": 0.1408,
      "step": 8820
    },
    {
      "epoch": 0.3974076241054953,
      "grad_norm": 4.391563415527344,
      "learning_rate": 9.602592375894505e-05,
      "loss": 0.1664,
      "step": 8830
    },
    {
      "epoch": 0.3978576893649579,
      "grad_norm": 3.1155192852020264,
      "learning_rate": 9.602142310635043e-05,
      "loss": 0.1631,
      "step": 8840
    },
    {
      "epoch": 0.39830775462442053,
      "grad_norm": 2.034200668334961,
      "learning_rate": 9.601692245375579e-05,
      "loss": 0.1678,
      "step": 8850
    },
    {
      "epoch": 0.39875781988388315,
      "grad_norm": 1.5710610151290894,
      "learning_rate": 9.601242180116117e-05,
      "loss": 0.1957,
      "step": 8860
    },
    {
      "epoch": 0.39920788514334576,
      "grad_norm": 1.6025307178497314,
      "learning_rate": 9.600792114856655e-05,
      "loss": 0.1559,
      "step": 8870
    },
    {
      "epoch": 0.3996579504028084,
      "grad_norm": 2.9890029430389404,
      "learning_rate": 9.600342049597191e-05,
      "loss": 0.1807,
      "step": 8880
    },
    {
      "epoch": 0.40010801566227105,
      "grad_norm": 1.3905128240585327,
      "learning_rate": 9.59989198433773e-05,
      "loss": 0.1727,
      "step": 8890
    },
    {
      "epoch": 0.4005580809217337,
      "grad_norm": 2.4606478214263916,
      "learning_rate": 9.599441919078267e-05,
      "loss": 0.1834,
      "step": 8900
    },
    {
      "epoch": 0.4010081461811963,
      "grad_norm": 2.6263387203216553,
      "learning_rate": 9.598991853818803e-05,
      "loss": 0.1427,
      "step": 8910
    },
    {
      "epoch": 0.4014582114406589,
      "grad_norm": 6.344547748565674,
      "learning_rate": 9.598541788559342e-05,
      "loss": 0.1914,
      "step": 8920
    },
    {
      "epoch": 0.4019082767001215,
      "grad_norm": 2.1765377521514893,
      "learning_rate": 9.59809172329988e-05,
      "loss": 0.1855,
      "step": 8930
    },
    {
      "epoch": 0.40235834195958414,
      "grad_norm": 2.6600208282470703,
      "learning_rate": 9.597641658040416e-05,
      "loss": 0.2209,
      "step": 8940
    },
    {
      "epoch": 0.40280840721904676,
      "grad_norm": 1.87826669216156,
      "learning_rate": 9.597191592780954e-05,
      "loss": 0.2456,
      "step": 8950
    },
    {
      "epoch": 0.4032584724785094,
      "grad_norm": 3.480747699737549,
      "learning_rate": 9.596741527521492e-05,
      "loss": 0.134,
      "step": 8960
    },
    {
      "epoch": 0.403708537737972,
      "grad_norm": 2.886916399002075,
      "learning_rate": 9.596291462262028e-05,
      "loss": 0.194,
      "step": 8970
    },
    {
      "epoch": 0.4041586029974346,
      "grad_norm": 1.782179355621338,
      "learning_rate": 9.595841397002566e-05,
      "loss": 0.1581,
      "step": 8980
    },
    {
      "epoch": 0.40460866825689723,
      "grad_norm": 2.829754114151001,
      "learning_rate": 9.595391331743104e-05,
      "loss": 0.2292,
      "step": 8990
    },
    {
      "epoch": 0.40505873351635985,
      "grad_norm": 2.230020523071289,
      "learning_rate": 9.59494126648364e-05,
      "loss": 0.2191,
      "step": 9000
    },
    {
      "epoch": 0.4055087987758225,
      "grad_norm": 1.5246391296386719,
      "learning_rate": 9.594491201224178e-05,
      "loss": 0.1506,
      "step": 9010
    },
    {
      "epoch": 0.40595886403528514,
      "grad_norm": 2.134748697280884,
      "learning_rate": 9.594041135964716e-05,
      "loss": 0.2445,
      "step": 9020
    },
    {
      "epoch": 0.40640892929474776,
      "grad_norm": 2.810487747192383,
      "learning_rate": 9.593591070705252e-05,
      "loss": 0.1809,
      "step": 9030
    },
    {
      "epoch": 0.4068589945542104,
      "grad_norm": 2.2549827098846436,
      "learning_rate": 9.59314100544579e-05,
      "loss": 0.192,
      "step": 9040
    },
    {
      "epoch": 0.407309059813673,
      "grad_norm": 1.6435070037841797,
      "learning_rate": 9.592690940186328e-05,
      "loss": 0.1771,
      "step": 9050
    },
    {
      "epoch": 0.4077591250731356,
      "grad_norm": 2.0366079807281494,
      "learning_rate": 9.592240874926864e-05,
      "loss": 0.2081,
      "step": 9060
    },
    {
      "epoch": 0.4082091903325982,
      "grad_norm": 0.9394903182983398,
      "learning_rate": 9.591790809667403e-05,
      "loss": 0.125,
      "step": 9070
    },
    {
      "epoch": 0.40865925559206084,
      "grad_norm": 2.682706832885742,
      "learning_rate": 9.59134074440794e-05,
      "loss": 0.1398,
      "step": 9080
    },
    {
      "epoch": 0.40910932085152346,
      "grad_norm": 3.313885450363159,
      "learning_rate": 9.590890679148476e-05,
      "loss": 0.2056,
      "step": 9090
    },
    {
      "epoch": 0.4095593861109861,
      "grad_norm": 3.855783462524414,
      "learning_rate": 9.590440613889015e-05,
      "loss": 0.1885,
      "step": 9100
    },
    {
      "epoch": 0.4100094513704487,
      "grad_norm": 3.214219808578491,
      "learning_rate": 9.589990548629552e-05,
      "loss": 0.1736,
      "step": 9110
    },
    {
      "epoch": 0.4104595166299113,
      "grad_norm": 1.7949849367141724,
      "learning_rate": 9.589540483370088e-05,
      "loss": 0.1692,
      "step": 9120
    },
    {
      "epoch": 0.41090958188937393,
      "grad_norm": 2.3988375663757324,
      "learning_rate": 9.589090418110627e-05,
      "loss": 0.1449,
      "step": 9130
    },
    {
      "epoch": 0.4113596471488366,
      "grad_norm": 1.3340791463851929,
      "learning_rate": 9.588640352851164e-05,
      "loss": 0.1639,
      "step": 9140
    },
    {
      "epoch": 0.4118097124082992,
      "grad_norm": 3.6859962940216064,
      "learning_rate": 9.588190287591701e-05,
      "loss": 0.1748,
      "step": 9150
    },
    {
      "epoch": 0.41225977766776184,
      "grad_norm": 3.2065141201019287,
      "learning_rate": 9.587740222332239e-05,
      "loss": 0.1501,
      "step": 9160
    },
    {
      "epoch": 0.41270984292722446,
      "grad_norm": 4.247177600860596,
      "learning_rate": 9.587290157072776e-05,
      "loss": 0.1788,
      "step": 9170
    },
    {
      "epoch": 0.4131599081866871,
      "grad_norm": 4.175334453582764,
      "learning_rate": 9.586840091813314e-05,
      "loss": 0.2201,
      "step": 9180
    },
    {
      "epoch": 0.4136099734461497,
      "grad_norm": 1.5948691368103027,
      "learning_rate": 9.586390026553851e-05,
      "loss": 0.1945,
      "step": 9190
    },
    {
      "epoch": 0.4140600387056123,
      "grad_norm": 1.561348795890808,
      "learning_rate": 9.585939961294388e-05,
      "loss": 0.178,
      "step": 9200
    },
    {
      "epoch": 0.4145101039650749,
      "grad_norm": 1.1605572700500488,
      "learning_rate": 9.585489896034926e-05,
      "loss": 0.1278,
      "step": 9210
    },
    {
      "epoch": 0.41496016922453755,
      "grad_norm": 2.332380771636963,
      "learning_rate": 9.585039830775463e-05,
      "loss": 0.1841,
      "step": 9220
    },
    {
      "epoch": 0.41541023448400016,
      "grad_norm": 0.7629491090774536,
      "learning_rate": 9.584589765516e-05,
      "loss": 0.1496,
      "step": 9230
    },
    {
      "epoch": 0.4158602997434628,
      "grad_norm": 2.7320072650909424,
      "learning_rate": 9.584139700256538e-05,
      "loss": 0.1487,
      "step": 9240
    },
    {
      "epoch": 0.4163103650029254,
      "grad_norm": 2.3091135025024414,
      "learning_rate": 9.583689634997075e-05,
      "loss": 0.1781,
      "step": 9250
    },
    {
      "epoch": 0.41676043026238807,
      "grad_norm": 5.197817325592041,
      "learning_rate": 9.583239569737612e-05,
      "loss": 0.1916,
      "step": 9260
    },
    {
      "epoch": 0.4172104955218507,
      "grad_norm": 1.8827859163284302,
      "learning_rate": 9.58278950447815e-05,
      "loss": 0.183,
      "step": 9270
    },
    {
      "epoch": 0.4176605607813133,
      "grad_norm": 2.449695110321045,
      "learning_rate": 9.582339439218687e-05,
      "loss": 0.1882,
      "step": 9280
    },
    {
      "epoch": 0.4181106260407759,
      "grad_norm": 2.8807098865509033,
      "learning_rate": 9.581889373959224e-05,
      "loss": 0.2072,
      "step": 9290
    },
    {
      "epoch": 0.41856069130023854,
      "grad_norm": 2.5755667686462402,
      "learning_rate": 9.581439308699762e-05,
      "loss": 0.2057,
      "step": 9300
    },
    {
      "epoch": 0.41901075655970116,
      "grad_norm": 3.422203302383423,
      "learning_rate": 9.580989243440299e-05,
      "loss": 0.1778,
      "step": 9310
    },
    {
      "epoch": 0.4194608218191638,
      "grad_norm": 3.0777881145477295,
      "learning_rate": 9.580539178180837e-05,
      "loss": 0.1405,
      "step": 9320
    },
    {
      "epoch": 0.4199108870786264,
      "grad_norm": 2.966187000274658,
      "learning_rate": 9.580089112921374e-05,
      "loss": 0.1739,
      "step": 9330
    },
    {
      "epoch": 0.420360952338089,
      "grad_norm": 1.0818132162094116,
      "learning_rate": 9.579639047661911e-05,
      "loss": 0.1449,
      "step": 9340
    },
    {
      "epoch": 0.42081101759755163,
      "grad_norm": 3.2017529010772705,
      "learning_rate": 9.579188982402449e-05,
      "loss": 0.1428,
      "step": 9350
    },
    {
      "epoch": 0.42126108285701425,
      "grad_norm": 2.6176586151123047,
      "learning_rate": 9.578738917142986e-05,
      "loss": 0.1868,
      "step": 9360
    },
    {
      "epoch": 0.42171114811647686,
      "grad_norm": 3.0368313789367676,
      "learning_rate": 9.578288851883523e-05,
      "loss": 0.1816,
      "step": 9370
    },
    {
      "epoch": 0.42216121337593954,
      "grad_norm": 6.392107963562012,
      "learning_rate": 9.577838786624061e-05,
      "loss": 0.2369,
      "step": 9380
    },
    {
      "epoch": 0.42261127863540215,
      "grad_norm": 3.908902883529663,
      "learning_rate": 9.577388721364598e-05,
      "loss": 0.1677,
      "step": 9390
    },
    {
      "epoch": 0.42306134389486477,
      "grad_norm": 1.7700042724609375,
      "learning_rate": 9.576938656105135e-05,
      "loss": 0.1577,
      "step": 9400
    },
    {
      "epoch": 0.4235114091543274,
      "grad_norm": 1.272289514541626,
      "learning_rate": 9.576488590845674e-05,
      "loss": 0.162,
      "step": 9410
    },
    {
      "epoch": 0.42396147441379,
      "grad_norm": 4.183132171630859,
      "learning_rate": 9.57603852558621e-05,
      "loss": 0.2427,
      "step": 9420
    },
    {
      "epoch": 0.4244115396732526,
      "grad_norm": 0.5178699493408203,
      "learning_rate": 9.575588460326748e-05,
      "loss": 0.1548,
      "step": 9430
    },
    {
      "epoch": 0.42486160493271524,
      "grad_norm": 1.8992637395858765,
      "learning_rate": 9.575138395067286e-05,
      "loss": 0.2124,
      "step": 9440
    },
    {
      "epoch": 0.42531167019217786,
      "grad_norm": 1.6669100522994995,
      "learning_rate": 9.574688329807822e-05,
      "loss": 0.167,
      "step": 9450
    },
    {
      "epoch": 0.4257617354516405,
      "grad_norm": 1.973319411277771,
      "learning_rate": 9.57423826454836e-05,
      "loss": 0.1795,
      "step": 9460
    },
    {
      "epoch": 0.4262118007111031,
      "grad_norm": 2.5965359210968018,
      "learning_rate": 9.573788199288898e-05,
      "loss": 0.1547,
      "step": 9470
    },
    {
      "epoch": 0.4266618659705657,
      "grad_norm": 1.7917869091033936,
      "learning_rate": 9.573338134029434e-05,
      "loss": 0.1763,
      "step": 9480
    },
    {
      "epoch": 0.42711193123002833,
      "grad_norm": 2.4331319332122803,
      "learning_rate": 9.572888068769972e-05,
      "loss": 0.1464,
      "step": 9490
    },
    {
      "epoch": 0.427561996489491,
      "grad_norm": 1.852083444595337,
      "learning_rate": 9.57243800351051e-05,
      "loss": 0.1483,
      "step": 9500
    },
    {
      "epoch": 0.4280120617489536,
      "grad_norm": 1.387563705444336,
      "learning_rate": 9.571987938251046e-05,
      "loss": 0.1496,
      "step": 9510
    },
    {
      "epoch": 0.42846212700841624,
      "grad_norm": 2.5819194316864014,
      "learning_rate": 9.571537872991584e-05,
      "loss": 0.1816,
      "step": 9520
    },
    {
      "epoch": 0.42891219226787886,
      "grad_norm": 3.4158191680908203,
      "learning_rate": 9.571087807732122e-05,
      "loss": 0.182,
      "step": 9530
    },
    {
      "epoch": 0.4293622575273415,
      "grad_norm": 3.2835967540740967,
      "learning_rate": 9.570637742472658e-05,
      "loss": 0.21,
      "step": 9540
    },
    {
      "epoch": 0.4298123227868041,
      "grad_norm": 3.2728488445281982,
      "learning_rate": 9.570187677213196e-05,
      "loss": 0.1559,
      "step": 9550
    },
    {
      "epoch": 0.4302623880462667,
      "grad_norm": 1.1707581281661987,
      "learning_rate": 9.569737611953735e-05,
      "loss": 0.1608,
      "step": 9560
    },
    {
      "epoch": 0.4307124533057293,
      "grad_norm": 2.033175468444824,
      "learning_rate": 9.56928754669427e-05,
      "loss": 0.1001,
      "step": 9570
    },
    {
      "epoch": 0.43116251856519194,
      "grad_norm": 3.041313886642456,
      "learning_rate": 9.568837481434808e-05,
      "loss": 0.1974,
      "step": 9580
    },
    {
      "epoch": 0.43161258382465456,
      "grad_norm": 3.684926748275757,
      "learning_rate": 9.568387416175347e-05,
      "loss": 0.135,
      "step": 9590
    },
    {
      "epoch": 0.4320626490841172,
      "grad_norm": 1.4870214462280273,
      "learning_rate": 9.567937350915883e-05,
      "loss": 0.1594,
      "step": 9600
    },
    {
      "epoch": 0.4325127143435798,
      "grad_norm": 5.111545562744141,
      "learning_rate": 9.56748728565642e-05,
      "loss": 0.1705,
      "step": 9610
    },
    {
      "epoch": 0.4329627796030424,
      "grad_norm": 2.1301774978637695,
      "learning_rate": 9.567037220396959e-05,
      "loss": 0.1562,
      "step": 9620
    },
    {
      "epoch": 0.4334128448625051,
      "grad_norm": 1.9312074184417725,
      "learning_rate": 9.566587155137495e-05,
      "loss": 0.1626,
      "step": 9630
    },
    {
      "epoch": 0.4338629101219677,
      "grad_norm": 2.0205435752868652,
      "learning_rate": 9.566137089878032e-05,
      "loss": 0.1755,
      "step": 9640
    },
    {
      "epoch": 0.4343129753814303,
      "grad_norm": 1.7042235136032104,
      "learning_rate": 9.565687024618571e-05,
      "loss": 0.1525,
      "step": 9650
    },
    {
      "epoch": 0.43476304064089294,
      "grad_norm": 1.6754614114761353,
      "learning_rate": 9.565236959359107e-05,
      "loss": 0.1494,
      "step": 9660
    },
    {
      "epoch": 0.43521310590035556,
      "grad_norm": 2.2819926738739014,
      "learning_rate": 9.564786894099646e-05,
      "loss": 0.1693,
      "step": 9670
    },
    {
      "epoch": 0.4356631711598182,
      "grad_norm": 1.1502184867858887,
      "learning_rate": 9.564336828840183e-05,
      "loss": 0.1933,
      "step": 9680
    },
    {
      "epoch": 0.4361132364192808,
      "grad_norm": 2.5433132648468018,
      "learning_rate": 9.563886763580719e-05,
      "loss": 0.1609,
      "step": 9690
    },
    {
      "epoch": 0.4365633016787434,
      "grad_norm": 0.9947956204414368,
      "learning_rate": 9.563436698321258e-05,
      "loss": 0.2154,
      "step": 9700
    },
    {
      "epoch": 0.437013366938206,
      "grad_norm": 3.249433994293213,
      "learning_rate": 9.562986633061795e-05,
      "loss": 0.1653,
      "step": 9710
    },
    {
      "epoch": 0.43746343219766864,
      "grad_norm": 6.003493309020996,
      "learning_rate": 9.562536567802331e-05,
      "loss": 0.151,
      "step": 9720
    },
    {
      "epoch": 0.43791349745713126,
      "grad_norm": 1.3849822282791138,
      "learning_rate": 9.56208650254287e-05,
      "loss": 0.1473,
      "step": 9730
    },
    {
      "epoch": 0.4383635627165939,
      "grad_norm": 3.637366771697998,
      "learning_rate": 9.561636437283407e-05,
      "loss": 0.1492,
      "step": 9740
    },
    {
      "epoch": 0.43881362797605655,
      "grad_norm": 4.139047145843506,
      "learning_rate": 9.561186372023943e-05,
      "loss": 0.2166,
      "step": 9750
    },
    {
      "epoch": 0.43926369323551917,
      "grad_norm": 2.92248797416687,
      "learning_rate": 9.560736306764482e-05,
      "loss": 0.1431,
      "step": 9760
    },
    {
      "epoch": 0.4397137584949818,
      "grad_norm": 2.377218008041382,
      "learning_rate": 9.560286241505019e-05,
      "loss": 0.166,
      "step": 9770
    },
    {
      "epoch": 0.4401638237544444,
      "grad_norm": 7.593936920166016,
      "learning_rate": 9.559836176245555e-05,
      "loss": 0.1565,
      "step": 9780
    },
    {
      "epoch": 0.440613889013907,
      "grad_norm": 2.752572774887085,
      "learning_rate": 9.559386110986094e-05,
      "loss": 0.1321,
      "step": 9790
    },
    {
      "epoch": 0.44106395427336964,
      "grad_norm": 1.2472429275512695,
      "learning_rate": 9.558936045726631e-05,
      "loss": 0.1922,
      "step": 9800
    },
    {
      "epoch": 0.44151401953283226,
      "grad_norm": 2.6114304065704346,
      "learning_rate": 9.558485980467167e-05,
      "loss": 0.1801,
      "step": 9810
    },
    {
      "epoch": 0.4419640847922949,
      "grad_norm": 1.319667935371399,
      "learning_rate": 9.558035915207706e-05,
      "loss": 0.1734,
      "step": 9820
    },
    {
      "epoch": 0.4424141500517575,
      "grad_norm": 2.984893321990967,
      "learning_rate": 9.557585849948243e-05,
      "loss": 0.1843,
      "step": 9830
    },
    {
      "epoch": 0.4428642153112201,
      "grad_norm": 1.7958275079727173,
      "learning_rate": 9.557135784688779e-05,
      "loss": 0.1804,
      "step": 9840
    },
    {
      "epoch": 0.44331428057068273,
      "grad_norm": 2.2418203353881836,
      "learning_rate": 9.556685719429318e-05,
      "loss": 0.1155,
      "step": 9850
    },
    {
      "epoch": 0.44376434583014535,
      "grad_norm": 1.334900975227356,
      "learning_rate": 9.556235654169855e-05,
      "loss": 0.118,
      "step": 9860
    },
    {
      "epoch": 0.444214411089608,
      "grad_norm": 3.200551748275757,
      "learning_rate": 9.555785588910391e-05,
      "loss": 0.2239,
      "step": 9870
    },
    {
      "epoch": 0.44466447634907064,
      "grad_norm": 0.936101496219635,
      "learning_rate": 9.55533552365093e-05,
      "loss": 0.191,
      "step": 9880
    },
    {
      "epoch": 0.44511454160853325,
      "grad_norm": 1.168062686920166,
      "learning_rate": 9.554885458391467e-05,
      "loss": 0.2302,
      "step": 9890
    },
    {
      "epoch": 0.44556460686799587,
      "grad_norm": 3.3235416412353516,
      "learning_rate": 9.554435393132003e-05,
      "loss": 0.1412,
      "step": 9900
    },
    {
      "epoch": 0.4460146721274585,
      "grad_norm": 4.090925216674805,
      "learning_rate": 9.553985327872542e-05,
      "loss": 0.1952,
      "step": 9910
    },
    {
      "epoch": 0.4464647373869211,
      "grad_norm": 1.0678293704986572,
      "learning_rate": 9.55353526261308e-05,
      "loss": 0.1485,
      "step": 9920
    },
    {
      "epoch": 0.4469148026463837,
      "grad_norm": 4.818993091583252,
      "learning_rate": 9.553085197353616e-05,
      "loss": 0.161,
      "step": 9930
    },
    {
      "epoch": 0.44736486790584634,
      "grad_norm": 1.9685451984405518,
      "learning_rate": 9.552635132094154e-05,
      "loss": 0.1547,
      "step": 9940
    },
    {
      "epoch": 0.44781493316530896,
      "grad_norm": 2.51468825340271,
      "learning_rate": 9.552185066834692e-05,
      "loss": 0.1696,
      "step": 9950
    },
    {
      "epoch": 0.4482649984247716,
      "grad_norm": 2.914412498474121,
      "learning_rate": 9.551735001575229e-05,
      "loss": 0.1285,
      "step": 9960
    },
    {
      "epoch": 0.4487150636842342,
      "grad_norm": 1.4029017686843872,
      "learning_rate": 9.551284936315766e-05,
      "loss": 0.1476,
      "step": 9970
    },
    {
      "epoch": 0.4491651289436968,
      "grad_norm": 1.3063658475875854,
      "learning_rate": 9.550834871056304e-05,
      "loss": 0.1358,
      "step": 9980
    },
    {
      "epoch": 0.4496151942031595,
      "grad_norm": 1.5091140270233154,
      "learning_rate": 9.550384805796841e-05,
      "loss": 0.1525,
      "step": 9990
    },
    {
      "epoch": 0.4500652594626221,
      "grad_norm": 1.4088153839111328,
      "learning_rate": 9.549934740537378e-05,
      "loss": 0.1749,
      "step": 10000
    },
    {
      "epoch": 0.4505153247220847,
      "grad_norm": 5.78167724609375,
      "learning_rate": 9.549484675277916e-05,
      "loss": 0.1803,
      "step": 10010
    },
    {
      "epoch": 0.45096538998154734,
      "grad_norm": 2.231858730316162,
      "learning_rate": 9.549034610018453e-05,
      "loss": 0.1641,
      "step": 10020
    },
    {
      "epoch": 0.45141545524100996,
      "grad_norm": 1.9737067222595215,
      "learning_rate": 9.54858454475899e-05,
      "loss": 0.1651,
      "step": 10030
    },
    {
      "epoch": 0.4518655205004726,
      "grad_norm": 2.0891611576080322,
      "learning_rate": 9.548134479499528e-05,
      "loss": 0.1657,
      "step": 10040
    },
    {
      "epoch": 0.4523155857599352,
      "grad_norm": 3.007392406463623,
      "learning_rate": 9.547684414240065e-05,
      "loss": 0.1222,
      "step": 10050
    },
    {
      "epoch": 0.4527656510193978,
      "grad_norm": 1.5876463651657104,
      "learning_rate": 9.547234348980603e-05,
      "loss": 0.1931,
      "step": 10060
    },
    {
      "epoch": 0.4532157162788604,
      "grad_norm": 2.339348554611206,
      "learning_rate": 9.54678428372114e-05,
      "loss": 0.1928,
      "step": 10070
    },
    {
      "epoch": 0.45366578153832304,
      "grad_norm": 0.7418772578239441,
      "learning_rate": 9.546334218461677e-05,
      "loss": 0.1382,
      "step": 10080
    },
    {
      "epoch": 0.45411584679778566,
      "grad_norm": 1.0576657056808472,
      "learning_rate": 9.545884153202215e-05,
      "loss": 0.1349,
      "step": 10090
    },
    {
      "epoch": 0.4545659120572483,
      "grad_norm": 1.270633578300476,
      "learning_rate": 9.545434087942752e-05,
      "loss": 0.1862,
      "step": 10100
    },
    {
      "epoch": 0.4550159773167109,
      "grad_norm": 3.119612693786621,
      "learning_rate": 9.54498402268329e-05,
      "loss": 0.1895,
      "step": 10110
    },
    {
      "epoch": 0.45546604257617357,
      "grad_norm": 1.17936372756958,
      "learning_rate": 9.544533957423827e-05,
      "loss": 0.158,
      "step": 10120
    },
    {
      "epoch": 0.4559161078356362,
      "grad_norm": 2.9542877674102783,
      "learning_rate": 9.544083892164364e-05,
      "loss": 0.192,
      "step": 10130
    },
    {
      "epoch": 0.4563661730950988,
      "grad_norm": 0.8723512291908264,
      "learning_rate": 9.543633826904901e-05,
      "loss": 0.1846,
      "step": 10140
    },
    {
      "epoch": 0.4568162383545614,
      "grad_norm": 1.6836251020431519,
      "learning_rate": 9.543183761645439e-05,
      "loss": 0.1689,
      "step": 10150
    },
    {
      "epoch": 0.45726630361402404,
      "grad_norm": 5.120866298675537,
      "learning_rate": 9.542733696385976e-05,
      "loss": 0.153,
      "step": 10160
    },
    {
      "epoch": 0.45771636887348666,
      "grad_norm": 1.7659215927124023,
      "learning_rate": 9.542283631126514e-05,
      "loss": 0.1499,
      "step": 10170
    },
    {
      "epoch": 0.4581664341329493,
      "grad_norm": 1.5326632261276245,
      "learning_rate": 9.541833565867051e-05,
      "loss": 0.1783,
      "step": 10180
    },
    {
      "epoch": 0.4586164993924119,
      "grad_norm": 2.6797754764556885,
      "learning_rate": 9.541383500607588e-05,
      "loss": 0.2131,
      "step": 10190
    },
    {
      "epoch": 0.4590665646518745,
      "grad_norm": 2.206859588623047,
      "learning_rate": 9.540933435348126e-05,
      "loss": 0.1546,
      "step": 10200
    },
    {
      "epoch": 0.4595166299113371,
      "grad_norm": 0.5553687214851379,
      "learning_rate": 9.540483370088663e-05,
      "loss": 0.1224,
      "step": 10210
    },
    {
      "epoch": 0.45996669517079974,
      "grad_norm": 2.005995512008667,
      "learning_rate": 9.540033304829202e-05,
      "loss": 0.1325,
      "step": 10220
    },
    {
      "epoch": 0.46041676043026236,
      "grad_norm": 2.5286483764648438,
      "learning_rate": 9.539583239569738e-05,
      "loss": 0.2018,
      "step": 10230
    },
    {
      "epoch": 0.46086682568972503,
      "grad_norm": 2.7431890964508057,
      "learning_rate": 9.539133174310275e-05,
      "loss": 0.1718,
      "step": 10240
    },
    {
      "epoch": 0.46131689094918765,
      "grad_norm": 2.0156495571136475,
      "learning_rate": 9.538683109050814e-05,
      "loss": 0.171,
      "step": 10250
    },
    {
      "epoch": 0.46176695620865027,
      "grad_norm": 2.7882614135742188,
      "learning_rate": 9.53823304379135e-05,
      "loss": 0.1646,
      "step": 10260
    },
    {
      "epoch": 0.4622170214681129,
      "grad_norm": 3.6997411251068115,
      "learning_rate": 9.537782978531887e-05,
      "loss": 0.1393,
      "step": 10270
    },
    {
      "epoch": 0.4626670867275755,
      "grad_norm": 2.9170989990234375,
      "learning_rate": 9.537332913272426e-05,
      "loss": 0.1716,
      "step": 10280
    },
    {
      "epoch": 0.4631171519870381,
      "grad_norm": 3.9879844188690186,
      "learning_rate": 9.536882848012962e-05,
      "loss": 0.1774,
      "step": 10290
    },
    {
      "epoch": 0.46356721724650074,
      "grad_norm": 1.5456123352050781,
      "learning_rate": 9.536432782753499e-05,
      "loss": 0.1283,
      "step": 10300
    },
    {
      "epoch": 0.46401728250596336,
      "grad_norm": 3.6308276653289795,
      "learning_rate": 9.535982717494038e-05,
      "loss": 0.1777,
      "step": 10310
    },
    {
      "epoch": 0.464467347765426,
      "grad_norm": 4.866432189941406,
      "learning_rate": 9.535532652234574e-05,
      "loss": 0.1999,
      "step": 10320
    },
    {
      "epoch": 0.4649174130248886,
      "grad_norm": 2.9467451572418213,
      "learning_rate": 9.535082586975111e-05,
      "loss": 0.1684,
      "step": 10330
    },
    {
      "epoch": 0.4653674782843512,
      "grad_norm": 2.204028844833374,
      "learning_rate": 9.53463252171565e-05,
      "loss": 0.2107,
      "step": 10340
    },
    {
      "epoch": 0.46581754354381383,
      "grad_norm": 3.5787343978881836,
      "learning_rate": 9.534182456456186e-05,
      "loss": 0.1834,
      "step": 10350
    },
    {
      "epoch": 0.4662676088032765,
      "grad_norm": 1.2443268299102783,
      "learning_rate": 9.533732391196723e-05,
      "loss": 0.2206,
      "step": 10360
    },
    {
      "epoch": 0.4667176740627391,
      "grad_norm": 1.0407801866531372,
      "learning_rate": 9.533282325937262e-05,
      "loss": 0.1335,
      "step": 10370
    },
    {
      "epoch": 0.46716773932220174,
      "grad_norm": 2.72389817237854,
      "learning_rate": 9.532832260677798e-05,
      "loss": 0.1461,
      "step": 10380
    },
    {
      "epoch": 0.46761780458166435,
      "grad_norm": 1.4886540174484253,
      "learning_rate": 9.532382195418335e-05,
      "loss": 0.1443,
      "step": 10390
    },
    {
      "epoch": 0.46806786984112697,
      "grad_norm": 0.19166962802410126,
      "learning_rate": 9.531932130158874e-05,
      "loss": 0.168,
      "step": 10400
    },
    {
      "epoch": 0.4685179351005896,
      "grad_norm": 0.6323928236961365,
      "learning_rate": 9.53148206489941e-05,
      "loss": 0.1524,
      "step": 10410
    },
    {
      "epoch": 0.4689680003600522,
      "grad_norm": 4.570793628692627,
      "learning_rate": 9.531031999639948e-05,
      "loss": 0.1622,
      "step": 10420
    },
    {
      "epoch": 0.4694180656195148,
      "grad_norm": 4.151322364807129,
      "learning_rate": 9.530581934380486e-05,
      "loss": 0.18,
      "step": 10430
    },
    {
      "epoch": 0.46986813087897744,
      "grad_norm": 2.340399742126465,
      "learning_rate": 9.530131869121022e-05,
      "loss": 0.1543,
      "step": 10440
    },
    {
      "epoch": 0.47031819613844006,
      "grad_norm": 2.0881237983703613,
      "learning_rate": 9.52968180386156e-05,
      "loss": 0.1398,
      "step": 10450
    },
    {
      "epoch": 0.4707682613979027,
      "grad_norm": 1.7094231843948364,
      "learning_rate": 9.529231738602098e-05,
      "loss": 0.174,
      "step": 10460
    },
    {
      "epoch": 0.4712183266573653,
      "grad_norm": 3.313271999359131,
      "learning_rate": 9.528781673342634e-05,
      "loss": 0.1903,
      "step": 10470
    },
    {
      "epoch": 0.47166839191682797,
      "grad_norm": 1.6602401733398438,
      "learning_rate": 9.528331608083173e-05,
      "loss": 0.1566,
      "step": 10480
    },
    {
      "epoch": 0.4721184571762906,
      "grad_norm": 3.2808997631073,
      "learning_rate": 9.52788154282371e-05,
      "loss": 0.1699,
      "step": 10490
    },
    {
      "epoch": 0.4725685224357532,
      "grad_norm": 3.9810023307800293,
      "learning_rate": 9.527431477564246e-05,
      "loss": 0.1575,
      "step": 10500
    },
    {
      "epoch": 0.4730185876952158,
      "grad_norm": 1.1769435405731201,
      "learning_rate": 9.526981412304785e-05,
      "loss": 0.162,
      "step": 10510
    },
    {
      "epoch": 0.47346865295467844,
      "grad_norm": 0.9099252223968506,
      "learning_rate": 9.526531347045323e-05,
      "loss": 0.1725,
      "step": 10520
    },
    {
      "epoch": 0.47391871821414105,
      "grad_norm": 0.9448354244232178,
      "learning_rate": 9.526081281785859e-05,
      "loss": 0.1401,
      "step": 10530
    },
    {
      "epoch": 0.4743687834736037,
      "grad_norm": 1.8799381256103516,
      "learning_rate": 9.525631216526397e-05,
      "loss": 0.2118,
      "step": 10540
    },
    {
      "epoch": 0.4748188487330663,
      "grad_norm": 2.7442879676818848,
      "learning_rate": 9.525181151266935e-05,
      "loss": 0.1582,
      "step": 10550
    },
    {
      "epoch": 0.4752689139925289,
      "grad_norm": 1.3776662349700928,
      "learning_rate": 9.52473108600747e-05,
      "loss": 0.2094,
      "step": 10560
    },
    {
      "epoch": 0.4757189792519915,
      "grad_norm": 3.991819143295288,
      "learning_rate": 9.52428102074801e-05,
      "loss": 0.1742,
      "step": 10570
    },
    {
      "epoch": 0.47616904451145414,
      "grad_norm": 1.4210878610610962,
      "learning_rate": 9.523830955488547e-05,
      "loss": 0.1663,
      "step": 10580
    },
    {
      "epoch": 0.47661910977091676,
      "grad_norm": 0.808638870716095,
      "learning_rate": 9.523380890229083e-05,
      "loss": 0.2295,
      "step": 10590
    },
    {
      "epoch": 0.4770691750303794,
      "grad_norm": 2.756578207015991,
      "learning_rate": 9.522930824969621e-05,
      "loss": 0.1876,
      "step": 10600
    },
    {
      "epoch": 0.47751924028984205,
      "grad_norm": 1.1856688261032104,
      "learning_rate": 9.522480759710159e-05,
      "loss": 0.1655,
      "step": 10610
    },
    {
      "epoch": 0.47796930554930467,
      "grad_norm": 2.796830415725708,
      "learning_rate": 9.522030694450695e-05,
      "loss": 0.2193,
      "step": 10620
    },
    {
      "epoch": 0.4784193708087673,
      "grad_norm": 2.5421712398529053,
      "learning_rate": 9.521580629191233e-05,
      "loss": 0.1379,
      "step": 10630
    },
    {
      "epoch": 0.4788694360682299,
      "grad_norm": 3.1309285163879395,
      "learning_rate": 9.521130563931771e-05,
      "loss": 0.1896,
      "step": 10640
    },
    {
      "epoch": 0.4793195013276925,
      "grad_norm": 1.7754067182540894,
      "learning_rate": 9.520680498672307e-05,
      "loss": 0.1413,
      "step": 10650
    },
    {
      "epoch": 0.47976956658715514,
      "grad_norm": 3.704599618911743,
      "learning_rate": 9.520230433412846e-05,
      "loss": 0.157,
      "step": 10660
    },
    {
      "epoch": 0.48021963184661776,
      "grad_norm": 4.005915641784668,
      "learning_rate": 9.519780368153383e-05,
      "loss": 0.1595,
      "step": 10670
    },
    {
      "epoch": 0.4806696971060804,
      "grad_norm": 2.6046693325042725,
      "learning_rate": 9.519330302893919e-05,
      "loss": 0.1585,
      "step": 10680
    },
    {
      "epoch": 0.481119762365543,
      "grad_norm": 2.8390491008758545,
      "learning_rate": 9.518880237634458e-05,
      "loss": 0.1984,
      "step": 10690
    },
    {
      "epoch": 0.4815698276250056,
      "grad_norm": 4.327860355377197,
      "learning_rate": 9.518430172374995e-05,
      "loss": 0.154,
      "step": 10700
    },
    {
      "epoch": 0.4820198928844682,
      "grad_norm": 1.4497557878494263,
      "learning_rate": 9.517980107115531e-05,
      "loss": 0.1508,
      "step": 10710
    },
    {
      "epoch": 0.48246995814393084,
      "grad_norm": 0.9413962364196777,
      "learning_rate": 9.51753004185607e-05,
      "loss": 0.1348,
      "step": 10720
    },
    {
      "epoch": 0.4829200234033935,
      "grad_norm": 1.2151259183883667,
      "learning_rate": 9.517079976596607e-05,
      "loss": 0.1597,
      "step": 10730
    },
    {
      "epoch": 0.48337008866285613,
      "grad_norm": 5.774806499481201,
      "learning_rate": 9.516629911337144e-05,
      "loss": 0.2112,
      "step": 10740
    },
    {
      "epoch": 0.48382015392231875,
      "grad_norm": 1.7156461477279663,
      "learning_rate": 9.516179846077682e-05,
      "loss": 0.1785,
      "step": 10750
    },
    {
      "epoch": 0.48427021918178137,
      "grad_norm": 1.6811800003051758,
      "learning_rate": 9.515729780818219e-05,
      "loss": 0.1407,
      "step": 10760
    },
    {
      "epoch": 0.484720284441244,
      "grad_norm": 1.7655160427093506,
      "learning_rate": 9.515279715558757e-05,
      "loss": 0.137,
      "step": 10770
    },
    {
      "epoch": 0.4851703497007066,
      "grad_norm": 1.7336416244506836,
      "learning_rate": 9.514829650299294e-05,
      "loss": 0.132,
      "step": 10780
    },
    {
      "epoch": 0.4856204149601692,
      "grad_norm": 2.398480176925659,
      "learning_rate": 9.514379585039831e-05,
      "loss": 0.1775,
      "step": 10790
    },
    {
      "epoch": 0.48607048021963184,
      "grad_norm": 4.346884727478027,
      "learning_rate": 9.513929519780369e-05,
      "loss": 0.2307,
      "step": 10800
    },
    {
      "epoch": 0.48652054547909446,
      "grad_norm": 2.7262768745422363,
      "learning_rate": 9.513479454520906e-05,
      "loss": 0.1774,
      "step": 10810
    },
    {
      "epoch": 0.4869706107385571,
      "grad_norm": 2.58969783782959,
      "learning_rate": 9.513029389261443e-05,
      "loss": 0.1531,
      "step": 10820
    },
    {
      "epoch": 0.4874206759980197,
      "grad_norm": 4.066455841064453,
      "learning_rate": 9.512579324001981e-05,
      "loss": 0.1304,
      "step": 10830
    },
    {
      "epoch": 0.4878707412574823,
      "grad_norm": 0.7796339392662048,
      "learning_rate": 9.512129258742518e-05,
      "loss": 0.1269,
      "step": 10840
    },
    {
      "epoch": 0.488320806516945,
      "grad_norm": 1.7284035682678223,
      "learning_rate": 9.511679193483055e-05,
      "loss": 0.1469,
      "step": 10850
    },
    {
      "epoch": 0.4887708717764076,
      "grad_norm": 5.019270420074463,
      "learning_rate": 9.511229128223593e-05,
      "loss": 0.189,
      "step": 10860
    },
    {
      "epoch": 0.4892209370358702,
      "grad_norm": 0.8274478912353516,
      "learning_rate": 9.51077906296413e-05,
      "loss": 0.1295,
      "step": 10870
    },
    {
      "epoch": 0.48967100229533284,
      "grad_norm": 0.4346902072429657,
      "learning_rate": 9.510328997704667e-05,
      "loss": 0.2103,
      "step": 10880
    },
    {
      "epoch": 0.49012106755479545,
      "grad_norm": 3.1777052879333496,
      "learning_rate": 9.509878932445205e-05,
      "loss": 0.2146,
      "step": 10890
    },
    {
      "epoch": 0.49057113281425807,
      "grad_norm": 1.3521901369094849,
      "learning_rate": 9.509428867185742e-05,
      "loss": 0.1706,
      "step": 10900
    },
    {
      "epoch": 0.4910211980737207,
      "grad_norm": 3.296457529067993,
      "learning_rate": 9.50897880192628e-05,
      "loss": 0.183,
      "step": 10910
    },
    {
      "epoch": 0.4914712633331833,
      "grad_norm": 3.002929210662842,
      "learning_rate": 9.508528736666817e-05,
      "loss": 0.1722,
      "step": 10920
    },
    {
      "epoch": 0.4919213285926459,
      "grad_norm": 1.5913004875183105,
      "learning_rate": 9.508078671407354e-05,
      "loss": 0.1178,
      "step": 10930
    },
    {
      "epoch": 0.49237139385210854,
      "grad_norm": 5.424952507019043,
      "learning_rate": 9.507628606147892e-05,
      "loss": 0.1873,
      "step": 10940
    },
    {
      "epoch": 0.49282145911157116,
      "grad_norm": 1.6600497961044312,
      "learning_rate": 9.507178540888429e-05,
      "loss": 0.1758,
      "step": 10950
    },
    {
      "epoch": 0.4932715243710338,
      "grad_norm": 3.3696022033691406,
      "learning_rate": 9.506728475628966e-05,
      "loss": 0.1602,
      "step": 10960
    },
    {
      "epoch": 0.49372158963049645,
      "grad_norm": 3.024996519088745,
      "learning_rate": 9.506278410369504e-05,
      "loss": 0.1709,
      "step": 10970
    },
    {
      "epoch": 0.49417165488995907,
      "grad_norm": 2.641871690750122,
      "learning_rate": 9.505828345110041e-05,
      "loss": 0.1721,
      "step": 10980
    },
    {
      "epoch": 0.4946217201494217,
      "grad_norm": 5.97866153717041,
      "learning_rate": 9.505378279850578e-05,
      "loss": 0.2026,
      "step": 10990
    },
    {
      "epoch": 0.4950717854088843,
      "grad_norm": 1.6816035509109497,
      "learning_rate": 9.504928214591117e-05,
      "loss": 0.1643,
      "step": 11000
    },
    {
      "epoch": 0.4955218506683469,
      "grad_norm": 1.5483254194259644,
      "learning_rate": 9.504478149331653e-05,
      "loss": 0.1332,
      "step": 11010
    },
    {
      "epoch": 0.49597191592780954,
      "grad_norm": 1.7914668321609497,
      "learning_rate": 9.50402808407219e-05,
      "loss": 0.1508,
      "step": 11020
    },
    {
      "epoch": 0.49642198118727215,
      "grad_norm": 2.278475522994995,
      "learning_rate": 9.503578018812729e-05,
      "loss": 0.2051,
      "step": 11030
    },
    {
      "epoch": 0.49687204644673477,
      "grad_norm": 2.853243827819824,
      "learning_rate": 9.503127953553265e-05,
      "loss": 0.1336,
      "step": 11040
    },
    {
      "epoch": 0.4973221117061974,
      "grad_norm": 2.6972010135650635,
      "learning_rate": 9.502677888293803e-05,
      "loss": 0.1779,
      "step": 11050
    },
    {
      "epoch": 0.49777217696566,
      "grad_norm": 2.0369482040405273,
      "learning_rate": 9.502227823034341e-05,
      "loss": 0.165,
      "step": 11060
    },
    {
      "epoch": 0.4982222422251226,
      "grad_norm": 2.2133281230926514,
      "learning_rate": 9.501777757774877e-05,
      "loss": 0.1876,
      "step": 11070
    },
    {
      "epoch": 0.49867230748458524,
      "grad_norm": 4.570408821105957,
      "learning_rate": 9.501327692515415e-05,
      "loss": 0.1853,
      "step": 11080
    },
    {
      "epoch": 0.49912237274404786,
      "grad_norm": 2.3343217372894287,
      "learning_rate": 9.500877627255953e-05,
      "loss": 0.1789,
      "step": 11090
    },
    {
      "epoch": 0.49957243800351053,
      "grad_norm": 1.7700756788253784,
      "learning_rate": 9.50042756199649e-05,
      "loss": 0.1643,
      "step": 11100
    },
    {
      "epoch": 0.5000225032629732,
      "grad_norm": 1.1270653009414673,
      "learning_rate": 9.499977496737027e-05,
      "loss": 0.1942,
      "step": 11110
    },
    {
      "epoch": 0.5004725685224357,
      "grad_norm": 1.130750060081482,
      "learning_rate": 9.499527431477565e-05,
      "loss": 0.1346,
      "step": 11120
    },
    {
      "epoch": 0.5009226337818984,
      "grad_norm": 1.9203495979309082,
      "learning_rate": 9.499077366218102e-05,
      "loss": 0.2533,
      "step": 11130
    },
    {
      "epoch": 0.501372699041361,
      "grad_norm": 2.875845432281494,
      "learning_rate": 9.498627300958639e-05,
      "loss": 0.1362,
      "step": 11140
    },
    {
      "epoch": 0.5018227643008236,
      "grad_norm": 3.818284749984741,
      "learning_rate": 9.498177235699178e-05,
      "loss": 0.184,
      "step": 11150
    },
    {
      "epoch": 0.5022728295602863,
      "grad_norm": 3.406665802001953,
      "learning_rate": 9.497727170439714e-05,
      "loss": 0.1482,
      "step": 11160
    },
    {
      "epoch": 0.5027228948197489,
      "grad_norm": 2.113346576690674,
      "learning_rate": 9.497277105180251e-05,
      "loss": 0.1257,
      "step": 11170
    },
    {
      "epoch": 0.5031729600792115,
      "grad_norm": 2.260824680328369,
      "learning_rate": 9.49682703992079e-05,
      "loss": 0.168,
      "step": 11180
    },
    {
      "epoch": 0.5036230253386741,
      "grad_norm": 1.2961877584457397,
      "learning_rate": 9.496376974661326e-05,
      "loss": 0.153,
      "step": 11190
    },
    {
      "epoch": 0.5040730905981368,
      "grad_norm": 2.0343708992004395,
      "learning_rate": 9.495926909401863e-05,
      "loss": 0.1143,
      "step": 11200
    },
    {
      "epoch": 0.5045231558575993,
      "grad_norm": 0.46321505308151245,
      "learning_rate": 9.495476844142402e-05,
      "loss": 0.1862,
      "step": 11210
    },
    {
      "epoch": 0.504973221117062,
      "grad_norm": 4.9545369148254395,
      "learning_rate": 9.495026778882938e-05,
      "loss": 0.1748,
      "step": 11220
    },
    {
      "epoch": 0.5054232863765246,
      "grad_norm": 1.5813575983047485,
      "learning_rate": 9.494576713623475e-05,
      "loss": 0.157,
      "step": 11230
    },
    {
      "epoch": 0.5058733516359872,
      "grad_norm": 5.835926532745361,
      "learning_rate": 9.494126648364014e-05,
      "loss": 0.1666,
      "step": 11240
    },
    {
      "epoch": 0.5063234168954498,
      "grad_norm": 1.039758324623108,
      "learning_rate": 9.49367658310455e-05,
      "loss": 0.1685,
      "step": 11250
    },
    {
      "epoch": 0.5067734821549125,
      "grad_norm": 1.2993381023406982,
      "learning_rate": 9.493226517845089e-05,
      "loss": 0.1644,
      "step": 11260
    },
    {
      "epoch": 0.507223547414375,
      "grad_norm": 2.7727725505828857,
      "learning_rate": 9.492776452585626e-05,
      "loss": 0.1324,
      "step": 11270
    },
    {
      "epoch": 0.5076736126738377,
      "grad_norm": 2.018223524093628,
      "learning_rate": 9.492326387326162e-05,
      "loss": 0.1679,
      "step": 11280
    },
    {
      "epoch": 0.5081236779333004,
      "grad_norm": 1.6754876375198364,
      "learning_rate": 9.4918763220667e-05,
      "loss": 0.1198,
      "step": 11290
    },
    {
      "epoch": 0.5085737431927629,
      "grad_norm": 3.8723599910736084,
      "learning_rate": 9.491426256807238e-05,
      "loss": 0.2066,
      "step": 11300
    },
    {
      "epoch": 0.5090238084522256,
      "grad_norm": 3.507387161254883,
      "learning_rate": 9.490976191547774e-05,
      "loss": 0.1455,
      "step": 11310
    },
    {
      "epoch": 0.5094738737116882,
      "grad_norm": 3.597611904144287,
      "learning_rate": 9.490526126288313e-05,
      "loss": 0.2319,
      "step": 11320
    },
    {
      "epoch": 0.5099239389711508,
      "grad_norm": 0.9384573698043823,
      "learning_rate": 9.49007606102885e-05,
      "loss": 0.1672,
      "step": 11330
    },
    {
      "epoch": 0.5103740042306134,
      "grad_norm": 2.3354508876800537,
      "learning_rate": 9.489625995769386e-05,
      "loss": 0.2027,
      "step": 11340
    },
    {
      "epoch": 0.5108240694900761,
      "grad_norm": 0.8649374842643738,
      "learning_rate": 9.489175930509925e-05,
      "loss": 0.2036,
      "step": 11350
    },
    {
      "epoch": 0.5112741347495386,
      "grad_norm": 1.8736817836761475,
      "learning_rate": 9.488725865250462e-05,
      "loss": 0.1588,
      "step": 11360
    },
    {
      "epoch": 0.5117242000090013,
      "grad_norm": 1.2724339962005615,
      "learning_rate": 9.488275799990998e-05,
      "loss": 0.1681,
      "step": 11370
    },
    {
      "epoch": 0.5121742652684639,
      "grad_norm": 0.8270999193191528,
      "learning_rate": 9.487825734731537e-05,
      "loss": 0.1794,
      "step": 11380
    },
    {
      "epoch": 0.5126243305279266,
      "grad_norm": 1.2921130657196045,
      "learning_rate": 9.487375669472074e-05,
      "loss": 0.2032,
      "step": 11390
    },
    {
      "epoch": 0.5130743957873892,
      "grad_norm": 1.5749558210372925,
      "learning_rate": 9.48692560421261e-05,
      "loss": 0.1455,
      "step": 11400
    },
    {
      "epoch": 0.5135244610468518,
      "grad_norm": 1.262267827987671,
      "learning_rate": 9.486475538953149e-05,
      "loss": 0.1851,
      "step": 11410
    },
    {
      "epoch": 0.5139745263063145,
      "grad_norm": 2.0712623596191406,
      "learning_rate": 9.486025473693686e-05,
      "loss": 0.1827,
      "step": 11420
    },
    {
      "epoch": 0.514424591565777,
      "grad_norm": 1.1109063625335693,
      "learning_rate": 9.485575408434222e-05,
      "loss": 0.1486,
      "step": 11430
    },
    {
      "epoch": 0.5148746568252397,
      "grad_norm": 4.125411510467529,
      "learning_rate": 9.485125343174761e-05,
      "loss": 0.1385,
      "step": 11440
    },
    {
      "epoch": 0.5153247220847023,
      "grad_norm": 3.7090141773223877,
      "learning_rate": 9.484675277915298e-05,
      "loss": 0.1842,
      "step": 11450
    },
    {
      "epoch": 0.5157747873441649,
      "grad_norm": 2.005347728729248,
      "learning_rate": 9.484225212655836e-05,
      "loss": 0.1442,
      "step": 11460
    },
    {
      "epoch": 0.5162248526036275,
      "grad_norm": 4.035765171051025,
      "learning_rate": 9.483775147396373e-05,
      "loss": 0.1586,
      "step": 11470
    },
    {
      "epoch": 0.5166749178630902,
      "grad_norm": 2.407899856567383,
      "learning_rate": 9.48332508213691e-05,
      "loss": 0.1516,
      "step": 11480
    },
    {
      "epoch": 0.5171249831225527,
      "grad_norm": 1.9646023511886597,
      "learning_rate": 9.482875016877448e-05,
      "loss": 0.126,
      "step": 11490
    },
    {
      "epoch": 0.5175750483820154,
      "grad_norm": 4.774216175079346,
      "learning_rate": 9.482424951617985e-05,
      "loss": 0.163,
      "step": 11500
    },
    {
      "epoch": 0.518025113641478,
      "grad_norm": 2.193861722946167,
      "learning_rate": 9.481974886358523e-05,
      "loss": 0.2118,
      "step": 11510
    },
    {
      "epoch": 0.5184751789009406,
      "grad_norm": 2.9589791297912598,
      "learning_rate": 9.48152482109906e-05,
      "loss": 0.1383,
      "step": 11520
    },
    {
      "epoch": 0.5189252441604033,
      "grad_norm": 2.134678602218628,
      "learning_rate": 9.481074755839597e-05,
      "loss": 0.1794,
      "step": 11530
    },
    {
      "epoch": 0.5193753094198659,
      "grad_norm": 3.1056854724884033,
      "learning_rate": 9.480624690580135e-05,
      "loss": 0.161,
      "step": 11540
    },
    {
      "epoch": 0.5198253746793285,
      "grad_norm": 2.216036558151245,
      "learning_rate": 9.480174625320672e-05,
      "loss": 0.1469,
      "step": 11550
    },
    {
      "epoch": 0.5202754399387911,
      "grad_norm": 1.6650663614273071,
      "learning_rate": 9.47972456006121e-05,
      "loss": 0.1918,
      "step": 11560
    },
    {
      "epoch": 0.5207255051982538,
      "grad_norm": 3.555598497390747,
      "learning_rate": 9.479274494801747e-05,
      "loss": 0.1856,
      "step": 11570
    },
    {
      "epoch": 0.5211755704577163,
      "grad_norm": 1.2075631618499756,
      "learning_rate": 9.478824429542284e-05,
      "loss": 0.128,
      "step": 11580
    },
    {
      "epoch": 0.521625635717179,
      "grad_norm": 1.0225579738616943,
      "learning_rate": 9.478374364282821e-05,
      "loss": 0.183,
      "step": 11590
    },
    {
      "epoch": 0.5220757009766416,
      "grad_norm": 2.600043773651123,
      "learning_rate": 9.477924299023359e-05,
      "loss": 0.1782,
      "step": 11600
    },
    {
      "epoch": 0.5225257662361042,
      "grad_norm": 1.8112112283706665,
      "learning_rate": 9.477474233763896e-05,
      "loss": 0.1388,
      "step": 11610
    },
    {
      "epoch": 0.5229758314955668,
      "grad_norm": 2.503742218017578,
      "learning_rate": 9.477024168504434e-05,
      "loss": 0.1445,
      "step": 11620
    },
    {
      "epoch": 0.5234258967550295,
      "grad_norm": 1.124685287475586,
      "learning_rate": 9.476574103244971e-05,
      "loss": 0.1378,
      "step": 11630
    },
    {
      "epoch": 0.523875962014492,
      "grad_norm": 1.1776316165924072,
      "learning_rate": 9.476124037985508e-05,
      "loss": 0.1787,
      "step": 11640
    },
    {
      "epoch": 0.5243260272739547,
      "grad_norm": 2.124619722366333,
      "learning_rate": 9.475673972726046e-05,
      "loss": 0.2003,
      "step": 11650
    },
    {
      "epoch": 0.5247760925334174,
      "grad_norm": 4.701563835144043,
      "learning_rate": 9.475223907466583e-05,
      "loss": 0.1623,
      "step": 11660
    },
    {
      "epoch": 0.52522615779288,
      "grad_norm": 1.8484362363815308,
      "learning_rate": 9.47477384220712e-05,
      "loss": 0.164,
      "step": 11670
    },
    {
      "epoch": 0.5256762230523426,
      "grad_norm": 2.4066720008850098,
      "learning_rate": 9.474323776947658e-05,
      "loss": 0.1426,
      "step": 11680
    },
    {
      "epoch": 0.5261262883118052,
      "grad_norm": 3.6963422298431396,
      "learning_rate": 9.473873711688195e-05,
      "loss": 0.171,
      "step": 11690
    },
    {
      "epoch": 0.5265763535712679,
      "grad_norm": 2.0974223613739014,
      "learning_rate": 9.473423646428732e-05,
      "loss": 0.1822,
      "step": 11700
    },
    {
      "epoch": 0.5270264188307304,
      "grad_norm": 1.9279180765151978,
      "learning_rate": 9.47297358116927e-05,
      "loss": 0.1799,
      "step": 11710
    },
    {
      "epoch": 0.5274764840901931,
      "grad_norm": 1.8450959920883179,
      "learning_rate": 9.472523515909807e-05,
      "loss": 0.1477,
      "step": 11720
    },
    {
      "epoch": 0.5279265493496557,
      "grad_norm": 2.5855441093444824,
      "learning_rate": 9.472073450650344e-05,
      "loss": 0.1796,
      "step": 11730
    },
    {
      "epoch": 0.5283766146091183,
      "grad_norm": 2.5131759643554688,
      "learning_rate": 9.471623385390882e-05,
      "loss": 0.1708,
      "step": 11740
    },
    {
      "epoch": 0.5288266798685809,
      "grad_norm": 2.3985300064086914,
      "learning_rate": 9.471173320131419e-05,
      "loss": 0.1312,
      "step": 11750
    },
    {
      "epoch": 0.5292767451280436,
      "grad_norm": 4.101053237915039,
      "learning_rate": 9.470723254871957e-05,
      "loss": 0.1363,
      "step": 11760
    },
    {
      "epoch": 0.5297268103875062,
      "grad_norm": 2.9022936820983887,
      "learning_rate": 9.470273189612494e-05,
      "loss": 0.1864,
      "step": 11770
    },
    {
      "epoch": 0.5301768756469688,
      "grad_norm": 1.6164135932922363,
      "learning_rate": 9.469823124353031e-05,
      "loss": 0.1243,
      "step": 11780
    },
    {
      "epoch": 0.5306269409064315,
      "grad_norm": 3.3579366207122803,
      "learning_rate": 9.469373059093569e-05,
      "loss": 0.135,
      "step": 11790
    },
    {
      "epoch": 0.531077006165894,
      "grad_norm": 1.1337600946426392,
      "learning_rate": 9.468922993834106e-05,
      "loss": 0.1315,
      "step": 11800
    },
    {
      "epoch": 0.5315270714253567,
      "grad_norm": 2.956695556640625,
      "learning_rate": 9.468472928574645e-05,
      "loss": 0.1767,
      "step": 11810
    },
    {
      "epoch": 0.5319771366848193,
      "grad_norm": 2.0001657009124756,
      "learning_rate": 9.468022863315181e-05,
      "loss": 0.1181,
      "step": 11820
    },
    {
      "epoch": 0.532427201944282,
      "grad_norm": 5.991374969482422,
      "learning_rate": 9.467572798055718e-05,
      "loss": 0.1312,
      "step": 11830
    },
    {
      "epoch": 0.5328772672037445,
      "grad_norm": 4.055104732513428,
      "learning_rate": 9.467122732796257e-05,
      "loss": 0.1864,
      "step": 11840
    },
    {
      "epoch": 0.5333273324632072,
      "grad_norm": 3.365454912185669,
      "learning_rate": 9.466672667536793e-05,
      "loss": 0.1629,
      "step": 11850
    },
    {
      "epoch": 0.5337773977226697,
      "grad_norm": 4.060975074768066,
      "learning_rate": 9.46622260227733e-05,
      "loss": 0.195,
      "step": 11860
    },
    {
      "epoch": 0.5342274629821324,
      "grad_norm": 3.395113945007324,
      "learning_rate": 9.465772537017869e-05,
      "loss": 0.1556,
      "step": 11870
    },
    {
      "epoch": 0.534677528241595,
      "grad_norm": 4.131906509399414,
      "learning_rate": 9.465322471758405e-05,
      "loss": 0.1449,
      "step": 11880
    },
    {
      "epoch": 0.5351275935010577,
      "grad_norm": 2.6406259536743164,
      "learning_rate": 9.464872406498942e-05,
      "loss": 0.1601,
      "step": 11890
    },
    {
      "epoch": 0.5355776587605203,
      "grad_norm": 1.5874614715576172,
      "learning_rate": 9.464422341239481e-05,
      "loss": 0.1541,
      "step": 11900
    },
    {
      "epoch": 0.5360277240199829,
      "grad_norm": 4.721315860748291,
      "learning_rate": 9.463972275980017e-05,
      "loss": 0.1564,
      "step": 11910
    },
    {
      "epoch": 0.5364777892794456,
      "grad_norm": 7.3887834548950195,
      "learning_rate": 9.463522210720554e-05,
      "loss": 0.1623,
      "step": 11920
    },
    {
      "epoch": 0.5369278545389081,
      "grad_norm": 2.2650306224823,
      "learning_rate": 9.463072145461093e-05,
      "loss": 0.1827,
      "step": 11930
    },
    {
      "epoch": 0.5373779197983708,
      "grad_norm": 2.1859188079833984,
      "learning_rate": 9.462622080201629e-05,
      "loss": 0.1545,
      "step": 11940
    },
    {
      "epoch": 0.5378279850578334,
      "grad_norm": 3.1621012687683105,
      "learning_rate": 9.462172014942166e-05,
      "loss": 0.2115,
      "step": 11950
    },
    {
      "epoch": 0.538278050317296,
      "grad_norm": 2.1815106868743896,
      "learning_rate": 9.461721949682705e-05,
      "loss": 0.1518,
      "step": 11960
    },
    {
      "epoch": 0.5387281155767586,
      "grad_norm": 2.6615514755249023,
      "learning_rate": 9.461271884423241e-05,
      "loss": 0.1701,
      "step": 11970
    },
    {
      "epoch": 0.5391781808362213,
      "grad_norm": 4.240612030029297,
      "learning_rate": 9.460821819163778e-05,
      "loss": 0.2066,
      "step": 11980
    },
    {
      "epoch": 0.5396282460956838,
      "grad_norm": 1.148601770401001,
      "learning_rate": 9.460371753904317e-05,
      "loss": 0.1851,
      "step": 11990
    },
    {
      "epoch": 0.5400783113551465,
      "grad_norm": 3.2889909744262695,
      "learning_rate": 9.459921688644853e-05,
      "loss": 0.2023,
      "step": 12000
    },
    {
      "epoch": 0.5405283766146091,
      "grad_norm": 0.9347102046012878,
      "learning_rate": 9.45947162338539e-05,
      "loss": 0.1195,
      "step": 12010
    },
    {
      "epoch": 0.5409784418740717,
      "grad_norm": 1.9997284412384033,
      "learning_rate": 9.459021558125929e-05,
      "loss": 0.1434,
      "step": 12020
    },
    {
      "epoch": 0.5414285071335344,
      "grad_norm": 1.7528897523880005,
      "learning_rate": 9.458571492866465e-05,
      "loss": 0.1545,
      "step": 12030
    },
    {
      "epoch": 0.541878572392997,
      "grad_norm": 3.359251022338867,
      "learning_rate": 9.458121427607003e-05,
      "loss": 0.1402,
      "step": 12040
    },
    {
      "epoch": 0.5423286376524596,
      "grad_norm": 3.935596466064453,
      "learning_rate": 9.457671362347541e-05,
      "loss": 0.1891,
      "step": 12050
    },
    {
      "epoch": 0.5427787029119222,
      "grad_norm": 3.4157490730285645,
      "learning_rate": 9.457221297088077e-05,
      "loss": 0.1671,
      "step": 12060
    },
    {
      "epoch": 0.5432287681713849,
      "grad_norm": 1.663504958152771,
      "learning_rate": 9.456771231828616e-05,
      "loss": 0.1325,
      "step": 12070
    },
    {
      "epoch": 0.5436788334308474,
      "grad_norm": 2.4278576374053955,
      "learning_rate": 9.456321166569153e-05,
      "loss": 0.1262,
      "step": 12080
    },
    {
      "epoch": 0.5441288986903101,
      "grad_norm": 2.5300445556640625,
      "learning_rate": 9.45587110130969e-05,
      "loss": 0.1594,
      "step": 12090
    },
    {
      "epoch": 0.5445789639497727,
      "grad_norm": 3.7994303703308105,
      "learning_rate": 9.455421036050228e-05,
      "loss": 0.1426,
      "step": 12100
    },
    {
      "epoch": 0.5450290292092353,
      "grad_norm": 2.8158538341522217,
      "learning_rate": 9.454970970790766e-05,
      "loss": 0.2222,
      "step": 12110
    },
    {
      "epoch": 0.5454790944686979,
      "grad_norm": 3.428913116455078,
      "learning_rate": 9.454520905531303e-05,
      "loss": 0.1649,
      "step": 12120
    },
    {
      "epoch": 0.5459291597281606,
      "grad_norm": 1.3223109245300293,
      "learning_rate": 9.45407084027184e-05,
      "loss": 0.1841,
      "step": 12130
    },
    {
      "epoch": 0.5463792249876233,
      "grad_norm": 1.3164855241775513,
      "learning_rate": 9.453620775012378e-05,
      "loss": 0.121,
      "step": 12140
    },
    {
      "epoch": 0.5468292902470858,
      "grad_norm": 4.240216255187988,
      "learning_rate": 9.453170709752915e-05,
      "loss": 0.1522,
      "step": 12150
    },
    {
      "epoch": 0.5472793555065485,
      "grad_norm": 8.696728706359863,
      "learning_rate": 9.452720644493452e-05,
      "loss": 0.1679,
      "step": 12160
    },
    {
      "epoch": 0.547729420766011,
      "grad_norm": 7.497962474822998,
      "learning_rate": 9.45227057923399e-05,
      "loss": 0.1781,
      "step": 12170
    },
    {
      "epoch": 0.5481794860254737,
      "grad_norm": 2.8189151287078857,
      "learning_rate": 9.451820513974527e-05,
      "loss": 0.1727,
      "step": 12180
    },
    {
      "epoch": 0.5486295512849363,
      "grad_norm": 1.910813331604004,
      "learning_rate": 9.451370448715064e-05,
      "loss": 0.1787,
      "step": 12190
    },
    {
      "epoch": 0.549079616544399,
      "grad_norm": 1.7041007280349731,
      "learning_rate": 9.450920383455602e-05,
      "loss": 0.1441,
      "step": 12200
    },
    {
      "epoch": 0.5495296818038615,
      "grad_norm": 0.8431209921836853,
      "learning_rate": 9.450470318196139e-05,
      "loss": 0.1699,
      "step": 12210
    },
    {
      "epoch": 0.5499797470633242,
      "grad_norm": 2.696030855178833,
      "learning_rate": 9.450020252936676e-05,
      "loss": 0.1533,
      "step": 12220
    },
    {
      "epoch": 0.5504298123227868,
      "grad_norm": 1.204880714416504,
      "learning_rate": 9.449570187677214e-05,
      "loss": 0.1266,
      "step": 12230
    },
    {
      "epoch": 0.5508798775822494,
      "grad_norm": 0.8590948581695557,
      "learning_rate": 9.449120122417751e-05,
      "loss": 0.1485,
      "step": 12240
    },
    {
      "epoch": 0.551329942841712,
      "grad_norm": 2.186424493789673,
      "learning_rate": 9.448670057158289e-05,
      "loss": 0.1262,
      "step": 12250
    },
    {
      "epoch": 0.5517800081011747,
      "grad_norm": 6.616240501403809,
      "learning_rate": 9.448219991898826e-05,
      "loss": 0.198,
      "step": 12260
    },
    {
      "epoch": 0.5522300733606373,
      "grad_norm": 1.84775710105896,
      "learning_rate": 9.447769926639363e-05,
      "loss": 0.1914,
      "step": 12270
    },
    {
      "epoch": 0.5526801386200999,
      "grad_norm": 7.304092884063721,
      "learning_rate": 9.4473198613799e-05,
      "loss": 0.1898,
      "step": 12280
    },
    {
      "epoch": 0.5531302038795626,
      "grad_norm": 2.5186331272125244,
      "learning_rate": 9.446869796120438e-05,
      "loss": 0.1422,
      "step": 12290
    },
    {
      "epoch": 0.5535802691390251,
      "grad_norm": 0.9837818145751953,
      "learning_rate": 9.446419730860975e-05,
      "loss": 0.1629,
      "step": 12300
    },
    {
      "epoch": 0.5540303343984878,
      "grad_norm": 1.6599808931350708,
      "learning_rate": 9.445969665601513e-05,
      "loss": 0.1596,
      "step": 12310
    },
    {
      "epoch": 0.5544803996579504,
      "grad_norm": 1.731374979019165,
      "learning_rate": 9.44551960034205e-05,
      "loss": 0.2079,
      "step": 12320
    },
    {
      "epoch": 0.554930464917413,
      "grad_norm": 3.7102246284484863,
      "learning_rate": 9.445069535082587e-05,
      "loss": 0.1883,
      "step": 12330
    },
    {
      "epoch": 0.5553805301768756,
      "grad_norm": 2.4178271293640137,
      "learning_rate": 9.444619469823125e-05,
      "loss": 0.1648,
      "step": 12340
    },
    {
      "epoch": 0.5558305954363383,
      "grad_norm": 0.8951161503791809,
      "learning_rate": 9.444169404563662e-05,
      "loss": 0.1218,
      "step": 12350
    },
    {
      "epoch": 0.5562806606958008,
      "grad_norm": 1.8813817501068115,
      "learning_rate": 9.4437193393042e-05,
      "loss": 0.1963,
      "step": 12360
    },
    {
      "epoch": 0.5567307259552635,
      "grad_norm": 2.715266227722168,
      "learning_rate": 9.443269274044737e-05,
      "loss": 0.1293,
      "step": 12370
    },
    {
      "epoch": 0.5571807912147262,
      "grad_norm": 6.495786190032959,
      "learning_rate": 9.442819208785274e-05,
      "loss": 0.2331,
      "step": 12380
    },
    {
      "epoch": 0.5576308564741888,
      "grad_norm": 1.3443419933319092,
      "learning_rate": 9.442369143525812e-05,
      "loss": 0.172,
      "step": 12390
    },
    {
      "epoch": 0.5580809217336514,
      "grad_norm": 3.363046884536743,
      "learning_rate": 9.441919078266349e-05,
      "loss": 0.196,
      "step": 12400
    },
    {
      "epoch": 0.558530986993114,
      "grad_norm": 1.3531670570373535,
      "learning_rate": 9.441469013006886e-05,
      "loss": 0.1499,
      "step": 12410
    },
    {
      "epoch": 0.5589810522525767,
      "grad_norm": 1.6070294380187988,
      "learning_rate": 9.441018947747424e-05,
      "loss": 0.1568,
      "step": 12420
    },
    {
      "epoch": 0.5594311175120392,
      "grad_norm": 3.4104392528533936,
      "learning_rate": 9.440568882487961e-05,
      "loss": 0.1509,
      "step": 12430
    },
    {
      "epoch": 0.5598811827715019,
      "grad_norm": 1.5345014333724976,
      "learning_rate": 9.440118817228498e-05,
      "loss": 0.1721,
      "step": 12440
    },
    {
      "epoch": 0.5603312480309645,
      "grad_norm": 2.8450076580047607,
      "learning_rate": 9.439668751969036e-05,
      "loss": 0.1308,
      "step": 12450
    },
    {
      "epoch": 0.5607813132904271,
      "grad_norm": 0.971728503704071,
      "learning_rate": 9.439218686709573e-05,
      "loss": 0.1266,
      "step": 12460
    },
    {
      "epoch": 0.5612313785498897,
      "grad_norm": 4.641345977783203,
      "learning_rate": 9.43876862145011e-05,
      "loss": 0.1628,
      "step": 12470
    },
    {
      "epoch": 0.5616814438093524,
      "grad_norm": 2.6789472103118896,
      "learning_rate": 9.438318556190648e-05,
      "loss": 0.1719,
      "step": 12480
    },
    {
      "epoch": 0.5621315090688149,
      "grad_norm": 3.3000776767730713,
      "learning_rate": 9.437868490931185e-05,
      "loss": 0.1242,
      "step": 12490
    },
    {
      "epoch": 0.5625815743282776,
      "grad_norm": 7.920855522155762,
      "learning_rate": 9.437418425671723e-05,
      "loss": 0.219,
      "step": 12500
    },
    {
      "epoch": 0.5630316395877403,
      "grad_norm": 1.4525409936904907,
      "learning_rate": 9.43696836041226e-05,
      "loss": 0.1513,
      "step": 12510
    },
    {
      "epoch": 0.5634817048472028,
      "grad_norm": 3.555384874343872,
      "learning_rate": 9.436518295152797e-05,
      "loss": 0.1719,
      "step": 12520
    },
    {
      "epoch": 0.5639317701066655,
      "grad_norm": 3.114119529724121,
      "learning_rate": 9.436068229893335e-05,
      "loss": 0.1554,
      "step": 12530
    },
    {
      "epoch": 0.5643818353661281,
      "grad_norm": 2.139504909515381,
      "learning_rate": 9.435618164633872e-05,
      "loss": 0.1743,
      "step": 12540
    },
    {
      "epoch": 0.5648319006255907,
      "grad_norm": 3.8266639709472656,
      "learning_rate": 9.43516809937441e-05,
      "loss": 0.1592,
      "step": 12550
    },
    {
      "epoch": 0.5652819658850533,
      "grad_norm": 1.274852991104126,
      "learning_rate": 9.434718034114947e-05,
      "loss": 0.148,
      "step": 12560
    },
    {
      "epoch": 0.565732031144516,
      "grad_norm": 3.6009929180145264,
      "learning_rate": 9.434267968855484e-05,
      "loss": 0.1422,
      "step": 12570
    },
    {
      "epoch": 0.5661820964039785,
      "grad_norm": 7.143376350402832,
      "learning_rate": 9.433817903596021e-05,
      "loss": 0.1334,
      "step": 12580
    },
    {
      "epoch": 0.5666321616634412,
      "grad_norm": 2.7022902965545654,
      "learning_rate": 9.43336783833656e-05,
      "loss": 0.1902,
      "step": 12590
    },
    {
      "epoch": 0.5670822269229038,
      "grad_norm": 1.657211184501648,
      "learning_rate": 9.432917773077096e-05,
      "loss": 0.1299,
      "step": 12600
    },
    {
      "epoch": 0.5675322921823664,
      "grad_norm": 3.97345232963562,
      "learning_rate": 9.432467707817634e-05,
      "loss": 0.1466,
      "step": 12610
    },
    {
      "epoch": 0.567982357441829,
      "grad_norm": 2.5262961387634277,
      "learning_rate": 9.432017642558172e-05,
      "loss": 0.1427,
      "step": 12620
    },
    {
      "epoch": 0.5684324227012917,
      "grad_norm": 2.288445472717285,
      "learning_rate": 9.431567577298708e-05,
      "loss": 0.1561,
      "step": 12630
    },
    {
      "epoch": 0.5688824879607544,
      "grad_norm": 2.2526278495788574,
      "learning_rate": 9.431117512039246e-05,
      "loss": 0.1084,
      "step": 12640
    },
    {
      "epoch": 0.5693325532202169,
      "grad_norm": 0.8852847814559937,
      "learning_rate": 9.430667446779784e-05,
      "loss": 0.1809,
      "step": 12650
    },
    {
      "epoch": 0.5697826184796796,
      "grad_norm": 4.7154717445373535,
      "learning_rate": 9.43021738152032e-05,
      "loss": 0.1807,
      "step": 12660
    },
    {
      "epoch": 0.5702326837391422,
      "grad_norm": 2.191331148147583,
      "learning_rate": 9.429767316260858e-05,
      "loss": 0.1578,
      "step": 12670
    },
    {
      "epoch": 0.5706827489986048,
      "grad_norm": 2.1204476356506348,
      "learning_rate": 9.429317251001396e-05,
      "loss": 0.1847,
      "step": 12680
    },
    {
      "epoch": 0.5711328142580674,
      "grad_norm": 3.3388419151306152,
      "learning_rate": 9.428867185741932e-05,
      "loss": 0.1139,
      "step": 12690
    },
    {
      "epoch": 0.5715828795175301,
      "grad_norm": 1.6615610122680664,
      "learning_rate": 9.42841712048247e-05,
      "loss": 0.1228,
      "step": 12700
    },
    {
      "epoch": 0.5720329447769926,
      "grad_norm": 2.1767945289611816,
      "learning_rate": 9.427967055223008e-05,
      "loss": 0.144,
      "step": 12710
    },
    {
      "epoch": 0.5724830100364553,
      "grad_norm": 3.5438435077667236,
      "learning_rate": 9.427516989963545e-05,
      "loss": 0.154,
      "step": 12720
    },
    {
      "epoch": 0.5729330752959179,
      "grad_norm": 0.5985785722732544,
      "learning_rate": 9.427066924704082e-05,
      "loss": 0.1591,
      "step": 12730
    },
    {
      "epoch": 0.5733831405553805,
      "grad_norm": 2.271414279937744,
      "learning_rate": 9.42661685944462e-05,
      "loss": 0.1746,
      "step": 12740
    },
    {
      "epoch": 0.5738332058148432,
      "grad_norm": 4.444301128387451,
      "learning_rate": 9.426166794185157e-05,
      "loss": 0.1828,
      "step": 12750
    },
    {
      "epoch": 0.5742832710743058,
      "grad_norm": 3.806173801422119,
      "learning_rate": 9.425716728925694e-05,
      "loss": 0.1331,
      "step": 12760
    },
    {
      "epoch": 0.5747333363337684,
      "grad_norm": 1.815933108329773,
      "learning_rate": 9.425266663666233e-05,
      "loss": 0.1154,
      "step": 12770
    },
    {
      "epoch": 0.575183401593231,
      "grad_norm": 2.096041679382324,
      "learning_rate": 9.424816598406769e-05,
      "loss": 0.1581,
      "step": 12780
    },
    {
      "epoch": 0.5756334668526937,
      "grad_norm": 2.081799268722534,
      "learning_rate": 9.424366533147306e-05,
      "loss": 0.1824,
      "step": 12790
    },
    {
      "epoch": 0.5760835321121562,
      "grad_norm": 1.5912703275680542,
      "learning_rate": 9.423916467887845e-05,
      "loss": 0.1421,
      "step": 12800
    },
    {
      "epoch": 0.5765335973716189,
      "grad_norm": 2.882647752761841,
      "learning_rate": 9.423466402628382e-05,
      "loss": 0.1523,
      "step": 12810
    },
    {
      "epoch": 0.5769836626310815,
      "grad_norm": 4.838492393493652,
      "learning_rate": 9.423016337368918e-05,
      "loss": 0.1771,
      "step": 12820
    },
    {
      "epoch": 0.5774337278905441,
      "grad_norm": 2.95538067817688,
      "learning_rate": 9.422566272109457e-05,
      "loss": 0.1629,
      "step": 12830
    },
    {
      "epoch": 0.5778837931500067,
      "grad_norm": 1.9338345527648926,
      "learning_rate": 9.422116206849994e-05,
      "loss": 0.1258,
      "step": 12840
    },
    {
      "epoch": 0.5783338584094694,
      "grad_norm": 2.562659740447998,
      "learning_rate": 9.421666141590532e-05,
      "loss": 0.1784,
      "step": 12850
    },
    {
      "epoch": 0.5787839236689319,
      "grad_norm": 1.5392920970916748,
      "learning_rate": 9.421216076331069e-05,
      "loss": 0.1847,
      "step": 12860
    },
    {
      "epoch": 0.5792339889283946,
      "grad_norm": 1.2348893880844116,
      "learning_rate": 9.420766011071606e-05,
      "loss": 0.1225,
      "step": 12870
    },
    {
      "epoch": 0.5796840541878573,
      "grad_norm": 3.472341775894165,
      "learning_rate": 9.420315945812144e-05,
      "loss": 0.2214,
      "step": 12880
    },
    {
      "epoch": 0.5801341194473199,
      "grad_norm": 2.049044370651245,
      "learning_rate": 9.419865880552681e-05,
      "loss": 0.1151,
      "step": 12890
    },
    {
      "epoch": 0.5805841847067825,
      "grad_norm": 2.1078598499298096,
      "learning_rate": 9.419415815293218e-05,
      "loss": 0.1825,
      "step": 12900
    },
    {
      "epoch": 0.5810342499662451,
      "grad_norm": 2.776411533355713,
      "learning_rate": 9.418965750033756e-05,
      "loss": 0.1124,
      "step": 12910
    },
    {
      "epoch": 0.5814843152257078,
      "grad_norm": 0.6146038174629211,
      "learning_rate": 9.418515684774293e-05,
      "loss": 0.1598,
      "step": 12920
    },
    {
      "epoch": 0.5819343804851703,
      "grad_norm": 1.6145834922790527,
      "learning_rate": 9.41806561951483e-05,
      "loss": 0.1867,
      "step": 12930
    },
    {
      "epoch": 0.582384445744633,
      "grad_norm": 1.5911223888397217,
      "learning_rate": 9.417615554255368e-05,
      "loss": 0.1352,
      "step": 12940
    },
    {
      "epoch": 0.5828345110040956,
      "grad_norm": 5.2280073165893555,
      "learning_rate": 9.417165488995905e-05,
      "loss": 0.144,
      "step": 12950
    },
    {
      "epoch": 0.5832845762635582,
      "grad_norm": 1.1636525392532349,
      "learning_rate": 9.416715423736443e-05,
      "loss": 0.13,
      "step": 12960
    },
    {
      "epoch": 0.5837346415230208,
      "grad_norm": 1.2961376905441284,
      "learning_rate": 9.41626535847698e-05,
      "loss": 0.1106,
      "step": 12970
    },
    {
      "epoch": 0.5841847067824835,
      "grad_norm": 1.8722796440124512,
      "learning_rate": 9.415815293217517e-05,
      "loss": 0.1271,
      "step": 12980
    },
    {
      "epoch": 0.584634772041946,
      "grad_norm": 3.0571136474609375,
      "learning_rate": 9.415365227958055e-05,
      "loss": 0.1756,
      "step": 12990
    },
    {
      "epoch": 0.5850848373014087,
      "grad_norm": 3.4721851348876953,
      "learning_rate": 9.414915162698592e-05,
      "loss": 0.1401,
      "step": 13000
    },
    {
      "epoch": 0.5855349025608714,
      "grad_norm": 1.4255729913711548,
      "learning_rate": 9.414465097439129e-05,
      "loss": 0.1533,
      "step": 13010
    },
    {
      "epoch": 0.5859849678203339,
      "grad_norm": 2.956634044647217,
      "learning_rate": 9.414015032179667e-05,
      "loss": 0.1462,
      "step": 13020
    },
    {
      "epoch": 0.5864350330797966,
      "grad_norm": 1.2053918838500977,
      "learning_rate": 9.413564966920204e-05,
      "loss": 0.1548,
      "step": 13030
    },
    {
      "epoch": 0.5868850983392592,
      "grad_norm": 1.814379334449768,
      "learning_rate": 9.413114901660741e-05,
      "loss": 0.1331,
      "step": 13040
    },
    {
      "epoch": 0.5873351635987218,
      "grad_norm": 1.0190449953079224,
      "learning_rate": 9.412664836401279e-05,
      "loss": 0.1533,
      "step": 13050
    },
    {
      "epoch": 0.5877852288581844,
      "grad_norm": 1.9006520509719849,
      "learning_rate": 9.412214771141816e-05,
      "loss": 0.1245,
      "step": 13060
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 4.775850296020508,
      "learning_rate": 9.411764705882353e-05,
      "loss": 0.1429,
      "step": 13070
    },
    {
      "epoch": 0.5886853593771096,
      "grad_norm": 2.310080051422119,
      "learning_rate": 9.411314640622891e-05,
      "loss": 0.1226,
      "step": 13080
    },
    {
      "epoch": 0.5891354246365723,
      "grad_norm": 1.1284857988357544,
      "learning_rate": 9.410864575363428e-05,
      "loss": 0.1231,
      "step": 13090
    },
    {
      "epoch": 0.5895854898960349,
      "grad_norm": 1.9681345224380493,
      "learning_rate": 9.410414510103966e-05,
      "loss": 0.1801,
      "step": 13100
    },
    {
      "epoch": 0.5900355551554975,
      "grad_norm": 1.9902576208114624,
      "learning_rate": 9.409964444844503e-05,
      "loss": 0.1352,
      "step": 13110
    },
    {
      "epoch": 0.5904856204149602,
      "grad_norm": 2.878232955932617,
      "learning_rate": 9.40951437958504e-05,
      "loss": 0.2431,
      "step": 13120
    },
    {
      "epoch": 0.5909356856744228,
      "grad_norm": 1.8146315813064575,
      "learning_rate": 9.409064314325578e-05,
      "loss": 0.1402,
      "step": 13130
    },
    {
      "epoch": 0.5913857509338855,
      "grad_norm": 2.169497013092041,
      "learning_rate": 9.408614249066115e-05,
      "loss": 0.1867,
      "step": 13140
    },
    {
      "epoch": 0.591835816193348,
      "grad_norm": 2.42197847366333,
      "learning_rate": 9.408164183806652e-05,
      "loss": 0.1693,
      "step": 13150
    },
    {
      "epoch": 0.5922858814528107,
      "grad_norm": 3.527893304824829,
      "learning_rate": 9.40771411854719e-05,
      "loss": 0.18,
      "step": 13160
    },
    {
      "epoch": 0.5927359467122733,
      "grad_norm": 1.7997760772705078,
      "learning_rate": 9.407264053287727e-05,
      "loss": 0.0991,
      "step": 13170
    },
    {
      "epoch": 0.5931860119717359,
      "grad_norm": 3.0512328147888184,
      "learning_rate": 9.406813988028264e-05,
      "loss": 0.2011,
      "step": 13180
    },
    {
      "epoch": 0.5936360772311985,
      "grad_norm": 1.3534114360809326,
      "learning_rate": 9.406363922768802e-05,
      "loss": 0.1598,
      "step": 13190
    },
    {
      "epoch": 0.5940861424906612,
      "grad_norm": 3.066908597946167,
      "learning_rate": 9.405913857509339e-05,
      "loss": 0.2275,
      "step": 13200
    },
    {
      "epoch": 0.5945362077501237,
      "grad_norm": 1.4665526151657104,
      "learning_rate": 9.405463792249877e-05,
      "loss": 0.1201,
      "step": 13210
    },
    {
      "epoch": 0.5949862730095864,
      "grad_norm": 1.1119112968444824,
      "learning_rate": 9.405013726990414e-05,
      "loss": 0.1466,
      "step": 13220
    },
    {
      "epoch": 0.595436338269049,
      "grad_norm": 1.9410942792892456,
      "learning_rate": 9.404563661730951e-05,
      "loss": 0.1771,
      "step": 13230
    },
    {
      "epoch": 0.5958864035285116,
      "grad_norm": 2.9405648708343506,
      "learning_rate": 9.404113596471489e-05,
      "loss": 0.1423,
      "step": 13240
    },
    {
      "epoch": 0.5963364687879743,
      "grad_norm": 2.1170787811279297,
      "learning_rate": 9.403663531212026e-05,
      "loss": 0.1049,
      "step": 13250
    },
    {
      "epoch": 0.5967865340474369,
      "grad_norm": 0.9635854363441467,
      "learning_rate": 9.403213465952563e-05,
      "loss": 0.1256,
      "step": 13260
    },
    {
      "epoch": 0.5972365993068995,
      "grad_norm": 1.7271486520767212,
      "learning_rate": 9.402763400693101e-05,
      "loss": 0.1546,
      "step": 13270
    },
    {
      "epoch": 0.5976866645663621,
      "grad_norm": 2.3858344554901123,
      "learning_rate": 9.402313335433638e-05,
      "loss": 0.1906,
      "step": 13280
    },
    {
      "epoch": 0.5981367298258248,
      "grad_norm": 3.407684564590454,
      "learning_rate": 9.401863270174175e-05,
      "loss": 0.1618,
      "step": 13290
    },
    {
      "epoch": 0.5985867950852873,
      "grad_norm": 3.8405888080596924,
      "learning_rate": 9.401413204914713e-05,
      "loss": 0.1982,
      "step": 13300
    },
    {
      "epoch": 0.59903686034475,
      "grad_norm": 2.5701141357421875,
      "learning_rate": 9.40096313965525e-05,
      "loss": 0.1331,
      "step": 13310
    },
    {
      "epoch": 0.5994869256042126,
      "grad_norm": 1.9802557229995728,
      "learning_rate": 9.400513074395787e-05,
      "loss": 0.1252,
      "step": 13320
    },
    {
      "epoch": 0.5999369908636752,
      "grad_norm": 3.0690455436706543,
      "learning_rate": 9.400063009136325e-05,
      "loss": 0.1231,
      "step": 13330
    },
    {
      "epoch": 0.6003870561231378,
      "grad_norm": 0.7870991230010986,
      "learning_rate": 9.399612943876862e-05,
      "loss": 0.1245,
      "step": 13340
    },
    {
      "epoch": 0.6008371213826005,
      "grad_norm": 6.378195285797119,
      "learning_rate": 9.3991628786174e-05,
      "loss": 0.1532,
      "step": 13350
    },
    {
      "epoch": 0.6012871866420632,
      "grad_norm": 4.582437515258789,
      "learning_rate": 9.398712813357937e-05,
      "loss": 0.1641,
      "step": 13360
    },
    {
      "epoch": 0.6017372519015257,
      "grad_norm": 3.6821534633636475,
      "learning_rate": 9.398262748098474e-05,
      "loss": 0.2082,
      "step": 13370
    },
    {
      "epoch": 0.6021873171609884,
      "grad_norm": 3.090397357940674,
      "learning_rate": 9.397812682839012e-05,
      "loss": 0.1705,
      "step": 13380
    },
    {
      "epoch": 0.602637382420451,
      "grad_norm": 1.5199497938156128,
      "learning_rate": 9.397362617579549e-05,
      "loss": 0.1278,
      "step": 13390
    },
    {
      "epoch": 0.6030874476799136,
      "grad_norm": 5.794415473937988,
      "learning_rate": 9.396912552320088e-05,
      "loss": 0.1893,
      "step": 13400
    },
    {
      "epoch": 0.6035375129393762,
      "grad_norm": 3.0348353385925293,
      "learning_rate": 9.396462487060624e-05,
      "loss": 0.1374,
      "step": 13410
    },
    {
      "epoch": 0.6039875781988389,
      "grad_norm": 2.8681371212005615,
      "learning_rate": 9.396012421801161e-05,
      "loss": 0.138,
      "step": 13420
    },
    {
      "epoch": 0.6044376434583014,
      "grad_norm": 3.1814253330230713,
      "learning_rate": 9.3955623565417e-05,
      "loss": 0.1257,
      "step": 13430
    },
    {
      "epoch": 0.6048877087177641,
      "grad_norm": 1.4211701154708862,
      "learning_rate": 9.395112291282236e-05,
      "loss": 0.1341,
      "step": 13440
    },
    {
      "epoch": 0.6053377739772267,
      "grad_norm": 1.6782820224761963,
      "learning_rate": 9.394662226022773e-05,
      "loss": 0.1455,
      "step": 13450
    },
    {
      "epoch": 0.6057878392366893,
      "grad_norm": 3.0862159729003906,
      "learning_rate": 9.394212160763312e-05,
      "loss": 0.2019,
      "step": 13460
    },
    {
      "epoch": 0.6062379044961519,
      "grad_norm": 2.8650248050689697,
      "learning_rate": 9.393762095503848e-05,
      "loss": 0.1934,
      "step": 13470
    },
    {
      "epoch": 0.6066879697556146,
      "grad_norm": 2.810427665710449,
      "learning_rate": 9.393312030244385e-05,
      "loss": 0.1322,
      "step": 13480
    },
    {
      "epoch": 0.6071380350150772,
      "grad_norm": 4.29622745513916,
      "learning_rate": 9.392861964984924e-05,
      "loss": 0.1906,
      "step": 13490
    },
    {
      "epoch": 0.6075881002745398,
      "grad_norm": 2.0648226737976074,
      "learning_rate": 9.392411899725461e-05,
      "loss": 0.13,
      "step": 13500
    },
    {
      "epoch": 0.6080381655340025,
      "grad_norm": 2.5536632537841797,
      "learning_rate": 9.391961834465997e-05,
      "loss": 0.1404,
      "step": 13510
    },
    {
      "epoch": 0.608488230793465,
      "grad_norm": 1.93331778049469,
      "learning_rate": 9.391511769206536e-05,
      "loss": 0.101,
      "step": 13520
    },
    {
      "epoch": 0.6089382960529277,
      "grad_norm": 3.6825754642486572,
      "learning_rate": 9.391061703947073e-05,
      "loss": 0.1521,
      "step": 13530
    },
    {
      "epoch": 0.6093883613123903,
      "grad_norm": 5.03235387802124,
      "learning_rate": 9.39061163868761e-05,
      "loss": 0.1429,
      "step": 13540
    },
    {
      "epoch": 0.6098384265718529,
      "grad_norm": 1.2922577857971191,
      "learning_rate": 9.390161573428148e-05,
      "loss": 0.1295,
      "step": 13550
    },
    {
      "epoch": 0.6102884918313155,
      "grad_norm": 4.166101932525635,
      "learning_rate": 9.389711508168685e-05,
      "loss": 0.2094,
      "step": 13560
    },
    {
      "epoch": 0.6107385570907782,
      "grad_norm": 1.8119741678237915,
      "learning_rate": 9.389261442909221e-05,
      "loss": 0.2484,
      "step": 13570
    },
    {
      "epoch": 0.6111886223502407,
      "grad_norm": 2.084233522415161,
      "learning_rate": 9.38881137764976e-05,
      "loss": 0.1698,
      "step": 13580
    },
    {
      "epoch": 0.6116386876097034,
      "grad_norm": 2.542104721069336,
      "learning_rate": 9.388361312390298e-05,
      "loss": 0.1641,
      "step": 13590
    },
    {
      "epoch": 0.612088752869166,
      "grad_norm": 4.378807067871094,
      "learning_rate": 9.387911247130834e-05,
      "loss": 0.1636,
      "step": 13600
    },
    {
      "epoch": 0.6125388181286286,
      "grad_norm": 3.539639949798584,
      "learning_rate": 9.387461181871372e-05,
      "loss": 0.1786,
      "step": 13610
    },
    {
      "epoch": 0.6129888833880913,
      "grad_norm": 3.9667210578918457,
      "learning_rate": 9.38701111661191e-05,
      "loss": 0.1374,
      "step": 13620
    },
    {
      "epoch": 0.6134389486475539,
      "grad_norm": 1.0371195077896118,
      "learning_rate": 9.386561051352446e-05,
      "loss": 0.1182,
      "step": 13630
    },
    {
      "epoch": 0.6138890139070166,
      "grad_norm": 2.610257625579834,
      "learning_rate": 9.386110986092984e-05,
      "loss": 0.1405,
      "step": 13640
    },
    {
      "epoch": 0.6143390791664791,
      "grad_norm": 1.1639673709869385,
      "learning_rate": 9.385660920833522e-05,
      "loss": 0.1473,
      "step": 13650
    },
    {
      "epoch": 0.6147891444259418,
      "grad_norm": 4.463896751403809,
      "learning_rate": 9.385210855574059e-05,
      "loss": 0.1408,
      "step": 13660
    },
    {
      "epoch": 0.6152392096854044,
      "grad_norm": 3.1853511333465576,
      "learning_rate": 9.384760790314596e-05,
      "loss": 0.1567,
      "step": 13670
    },
    {
      "epoch": 0.615689274944867,
      "grad_norm": 3.9893639087677,
      "learning_rate": 9.384310725055134e-05,
      "loss": 0.1301,
      "step": 13680
    },
    {
      "epoch": 0.6161393402043296,
      "grad_norm": 1.9206324815750122,
      "learning_rate": 9.383860659795671e-05,
      "loss": 0.1506,
      "step": 13690
    },
    {
      "epoch": 0.6165894054637923,
      "grad_norm": 2.4710114002227783,
      "learning_rate": 9.383410594536209e-05,
      "loss": 0.1767,
      "step": 13700
    },
    {
      "epoch": 0.6170394707232548,
      "grad_norm": 3.391404390335083,
      "learning_rate": 9.382960529276746e-05,
      "loss": 0.1728,
      "step": 13710
    },
    {
      "epoch": 0.6174895359827175,
      "grad_norm": 2.8553545475006104,
      "learning_rate": 9.382510464017283e-05,
      "loss": 0.1562,
      "step": 13720
    },
    {
      "epoch": 0.6179396012421802,
      "grad_norm": 3.3408143520355225,
      "learning_rate": 9.38206039875782e-05,
      "loss": 0.1451,
      "step": 13730
    },
    {
      "epoch": 0.6183896665016427,
      "grad_norm": 2.4189765453338623,
      "learning_rate": 9.381610333498358e-05,
      "loss": 0.1808,
      "step": 13740
    },
    {
      "epoch": 0.6188397317611054,
      "grad_norm": 1.635868787765503,
      "learning_rate": 9.381160268238895e-05,
      "loss": 0.1373,
      "step": 13750
    },
    {
      "epoch": 0.619289797020568,
      "grad_norm": 7.059773921966553,
      "learning_rate": 9.380710202979433e-05,
      "loss": 0.1322,
      "step": 13760
    },
    {
      "epoch": 0.6197398622800306,
      "grad_norm": 0.6412557363510132,
      "learning_rate": 9.38026013771997e-05,
      "loss": 0.1068,
      "step": 13770
    },
    {
      "epoch": 0.6201899275394932,
      "grad_norm": 1.8825525045394897,
      "learning_rate": 9.379810072460507e-05,
      "loss": 0.1677,
      "step": 13780
    },
    {
      "epoch": 0.6206399927989559,
      "grad_norm": 2.7242579460144043,
      "learning_rate": 9.379360007201045e-05,
      "loss": 0.145,
      "step": 13790
    },
    {
      "epoch": 0.6210900580584184,
      "grad_norm": 4.624955177307129,
      "learning_rate": 9.378909941941582e-05,
      "loss": 0.2041,
      "step": 13800
    },
    {
      "epoch": 0.6215401233178811,
      "grad_norm": 3.740037202835083,
      "learning_rate": 9.37845987668212e-05,
      "loss": 0.1271,
      "step": 13810
    },
    {
      "epoch": 0.6219901885773437,
      "grad_norm": 1.8866571187973022,
      "learning_rate": 9.378009811422657e-05,
      "loss": 0.144,
      "step": 13820
    },
    {
      "epoch": 0.6224402538368063,
      "grad_norm": 1.5305911302566528,
      "learning_rate": 9.377559746163194e-05,
      "loss": 0.1177,
      "step": 13830
    },
    {
      "epoch": 0.6228903190962689,
      "grad_norm": 3.0019092559814453,
      "learning_rate": 9.377109680903732e-05,
      "loss": 0.1497,
      "step": 13840
    },
    {
      "epoch": 0.6233403843557316,
      "grad_norm": 5.774768829345703,
      "learning_rate": 9.376659615644269e-05,
      "loss": 0.1751,
      "step": 13850
    },
    {
      "epoch": 0.6237904496151943,
      "grad_norm": 3.9708614349365234,
      "learning_rate": 9.376209550384806e-05,
      "loss": 0.1311,
      "step": 13860
    },
    {
      "epoch": 0.6242405148746568,
      "grad_norm": 3.803546190261841,
      "learning_rate": 9.375759485125344e-05,
      "loss": 0.1282,
      "step": 13870
    },
    {
      "epoch": 0.6246905801341195,
      "grad_norm": 2.947557210922241,
      "learning_rate": 9.375309419865881e-05,
      "loss": 0.1573,
      "step": 13880
    },
    {
      "epoch": 0.625140645393582,
      "grad_norm": 0.6501189470291138,
      "learning_rate": 9.374859354606418e-05,
      "loss": 0.1352,
      "step": 13890
    },
    {
      "epoch": 0.6255907106530447,
      "grad_norm": 2.2320902347564697,
      "learning_rate": 9.374409289346956e-05,
      "loss": 0.1826,
      "step": 13900
    },
    {
      "epoch": 0.6260407759125073,
      "grad_norm": 3.0597739219665527,
      "learning_rate": 9.373959224087493e-05,
      "loss": 0.1828,
      "step": 13910
    },
    {
      "epoch": 0.62649084117197,
      "grad_norm": 1.8174386024475098,
      "learning_rate": 9.37350915882803e-05,
      "loss": 0.1374,
      "step": 13920
    },
    {
      "epoch": 0.6269409064314325,
      "grad_norm": 4.421510696411133,
      "learning_rate": 9.373059093568568e-05,
      "loss": 0.1644,
      "step": 13930
    },
    {
      "epoch": 0.6273909716908952,
      "grad_norm": 1.9710592031478882,
      "learning_rate": 9.372609028309105e-05,
      "loss": 0.128,
      "step": 13940
    },
    {
      "epoch": 0.6278410369503578,
      "grad_norm": 2.9508626461029053,
      "learning_rate": 9.372158963049643e-05,
      "loss": 0.1328,
      "step": 13950
    },
    {
      "epoch": 0.6282911022098204,
      "grad_norm": 2.9591567516326904,
      "learning_rate": 9.37170889779018e-05,
      "loss": 0.1133,
      "step": 13960
    },
    {
      "epoch": 0.628741167469283,
      "grad_norm": 2.5954716205596924,
      "learning_rate": 9.371258832530717e-05,
      "loss": 0.102,
      "step": 13970
    },
    {
      "epoch": 0.6291912327287457,
      "grad_norm": 5.468780517578125,
      "learning_rate": 9.370808767271255e-05,
      "loss": 0.1971,
      "step": 13980
    },
    {
      "epoch": 0.6296412979882083,
      "grad_norm": 4.635492324829102,
      "learning_rate": 9.370358702011792e-05,
      "loss": 0.1294,
      "step": 13990
    },
    {
      "epoch": 0.6300913632476709,
      "grad_norm": 6.175202369689941,
      "learning_rate": 9.36990863675233e-05,
      "loss": 0.1711,
      "step": 14000
    },
    {
      "epoch": 0.6305414285071336,
      "grad_norm": 0.5406197309494019,
      "learning_rate": 9.369458571492867e-05,
      "loss": 0.1216,
      "step": 14010
    },
    {
      "epoch": 0.6309914937665961,
      "grad_norm": 1.7900382280349731,
      "learning_rate": 9.369008506233404e-05,
      "loss": 0.1639,
      "step": 14020
    },
    {
      "epoch": 0.6314415590260588,
      "grad_norm": 2.3890979290008545,
      "learning_rate": 9.368558440973941e-05,
      "loss": 0.1362,
      "step": 14030
    },
    {
      "epoch": 0.6318916242855214,
      "grad_norm": 1.1237925291061401,
      "learning_rate": 9.368108375714479e-05,
      "loss": 0.1323,
      "step": 14040
    },
    {
      "epoch": 0.632341689544984,
      "grad_norm": 1.4431953430175781,
      "learning_rate": 9.367658310455016e-05,
      "loss": 0.1453,
      "step": 14050
    },
    {
      "epoch": 0.6327917548044466,
      "grad_norm": 2.339766025543213,
      "learning_rate": 9.367208245195554e-05,
      "loss": 0.1481,
      "step": 14060
    },
    {
      "epoch": 0.6332418200639093,
      "grad_norm": 1.1647820472717285,
      "learning_rate": 9.366758179936091e-05,
      "loss": 0.1348,
      "step": 14070
    },
    {
      "epoch": 0.6336918853233718,
      "grad_norm": 1.1837117671966553,
      "learning_rate": 9.366308114676628e-05,
      "loss": 0.1424,
      "step": 14080
    },
    {
      "epoch": 0.6341419505828345,
      "grad_norm": 2.9081928730010986,
      "learning_rate": 9.365858049417166e-05,
      "loss": 0.1608,
      "step": 14090
    },
    {
      "epoch": 0.6345920158422972,
      "grad_norm": 5.851646423339844,
      "learning_rate": 9.365407984157703e-05,
      "loss": 0.1204,
      "step": 14100
    },
    {
      "epoch": 0.6350420811017597,
      "grad_norm": 4.75813627243042,
      "learning_rate": 9.36495791889824e-05,
      "loss": 0.1524,
      "step": 14110
    },
    {
      "epoch": 0.6354921463612224,
      "grad_norm": 0.23746471107006073,
      "learning_rate": 9.364507853638778e-05,
      "loss": 0.1036,
      "step": 14120
    },
    {
      "epoch": 0.635942211620685,
      "grad_norm": 2.1926074028015137,
      "learning_rate": 9.364057788379315e-05,
      "loss": 0.1875,
      "step": 14130
    },
    {
      "epoch": 0.6363922768801477,
      "grad_norm": 0.7635216116905212,
      "learning_rate": 9.363607723119852e-05,
      "loss": 0.1422,
      "step": 14140
    },
    {
      "epoch": 0.6368423421396102,
      "grad_norm": 2.9684557914733887,
      "learning_rate": 9.36315765786039e-05,
      "loss": 0.2079,
      "step": 14150
    },
    {
      "epoch": 0.6372924073990729,
      "grad_norm": 5.353213310241699,
      "learning_rate": 9.362707592600927e-05,
      "loss": 0.1869,
      "step": 14160
    },
    {
      "epoch": 0.6377424726585355,
      "grad_norm": 2.813227653503418,
      "learning_rate": 9.362257527341464e-05,
      "loss": 0.1241,
      "step": 14170
    },
    {
      "epoch": 0.6381925379179981,
      "grad_norm": 3.707423210144043,
      "learning_rate": 9.361807462082003e-05,
      "loss": 0.2012,
      "step": 14180
    },
    {
      "epoch": 0.6386426031774607,
      "grad_norm": 4.116577625274658,
      "learning_rate": 9.36135739682254e-05,
      "loss": 0.165,
      "step": 14190
    },
    {
      "epoch": 0.6390926684369234,
      "grad_norm": 1.248146891593933,
      "learning_rate": 9.360907331563077e-05,
      "loss": 0.1394,
      "step": 14200
    },
    {
      "epoch": 0.6395427336963859,
      "grad_norm": 1.8788776397705078,
      "learning_rate": 9.360457266303615e-05,
      "loss": 0.1659,
      "step": 14210
    },
    {
      "epoch": 0.6399927989558486,
      "grad_norm": 2.941580295562744,
      "learning_rate": 9.360007201044153e-05,
      "loss": 0.1875,
      "step": 14220
    },
    {
      "epoch": 0.6404428642153113,
      "grad_norm": 2.834425687789917,
      "learning_rate": 9.359557135784689e-05,
      "loss": 0.177,
      "step": 14230
    },
    {
      "epoch": 0.6408929294747738,
      "grad_norm": 3.006150722503662,
      "learning_rate": 9.359107070525227e-05,
      "loss": 0.217,
      "step": 14240
    },
    {
      "epoch": 0.6413429947342365,
      "grad_norm": 2.4979984760284424,
      "learning_rate": 9.358657005265765e-05,
      "loss": 0.1299,
      "step": 14250
    },
    {
      "epoch": 0.6417930599936991,
      "grad_norm": 5.224966049194336,
      "learning_rate": 9.358206940006301e-05,
      "loss": 0.1722,
      "step": 14260
    },
    {
      "epoch": 0.6422431252531617,
      "grad_norm": 2.3667118549346924,
      "learning_rate": 9.35775687474684e-05,
      "loss": 0.1553,
      "step": 14270
    },
    {
      "epoch": 0.6426931905126243,
      "grad_norm": 1.4301928281784058,
      "learning_rate": 9.357306809487377e-05,
      "loss": 0.1444,
      "step": 14280
    },
    {
      "epoch": 0.643143255772087,
      "grad_norm": 3.6923668384552,
      "learning_rate": 9.356856744227913e-05,
      "loss": 0.2141,
      "step": 14290
    },
    {
      "epoch": 0.6435933210315495,
      "grad_norm": 2.850252628326416,
      "learning_rate": 9.356406678968452e-05,
      "loss": 0.1525,
      "step": 14300
    },
    {
      "epoch": 0.6440433862910122,
      "grad_norm": 0.7252766489982605,
      "learning_rate": 9.355956613708989e-05,
      "loss": 0.1342,
      "step": 14310
    },
    {
      "epoch": 0.6444934515504748,
      "grad_norm": 2.2488808631896973,
      "learning_rate": 9.355506548449525e-05,
      "loss": 0.1586,
      "step": 14320
    },
    {
      "epoch": 0.6449435168099374,
      "grad_norm": 1.6086523532867432,
      "learning_rate": 9.355056483190064e-05,
      "loss": 0.1539,
      "step": 14330
    },
    {
      "epoch": 0.6453935820694001,
      "grad_norm": 1.4220646619796753,
      "learning_rate": 9.354606417930601e-05,
      "loss": 0.1379,
      "step": 14340
    },
    {
      "epoch": 0.6458436473288627,
      "grad_norm": 2.5254595279693604,
      "learning_rate": 9.354156352671137e-05,
      "loss": 0.214,
      "step": 14350
    },
    {
      "epoch": 0.6462937125883254,
      "grad_norm": 2.3916447162628174,
      "learning_rate": 9.353706287411676e-05,
      "loss": 0.1446,
      "step": 14360
    },
    {
      "epoch": 0.6467437778477879,
      "grad_norm": 1.7893400192260742,
      "learning_rate": 9.353256222152213e-05,
      "loss": 0.1477,
      "step": 14370
    },
    {
      "epoch": 0.6471938431072506,
      "grad_norm": 0.9125069379806519,
      "learning_rate": 9.352806156892749e-05,
      "loss": 0.1311,
      "step": 14380
    },
    {
      "epoch": 0.6476439083667132,
      "grad_norm": 1.9847749471664429,
      "learning_rate": 9.352356091633288e-05,
      "loss": 0.1887,
      "step": 14390
    },
    {
      "epoch": 0.6480939736261758,
      "grad_norm": 4.618602275848389,
      "learning_rate": 9.351906026373825e-05,
      "loss": 0.1843,
      "step": 14400
    },
    {
      "epoch": 0.6485440388856384,
      "grad_norm": 2.5825278759002686,
      "learning_rate": 9.351455961114361e-05,
      "loss": 0.1727,
      "step": 14410
    },
    {
      "epoch": 0.6489941041451011,
      "grad_norm": 2.1393043994903564,
      "learning_rate": 9.3510058958549e-05,
      "loss": 0.1216,
      "step": 14420
    },
    {
      "epoch": 0.6494441694045636,
      "grad_norm": 3.9058358669281006,
      "learning_rate": 9.350555830595437e-05,
      "loss": 0.1144,
      "step": 14430
    },
    {
      "epoch": 0.6498942346640263,
      "grad_norm": 0.8564847111701965,
      "learning_rate": 9.350105765335975e-05,
      "loss": 0.1942,
      "step": 14440
    },
    {
      "epoch": 0.6503442999234889,
      "grad_norm": 3.2764711380004883,
      "learning_rate": 9.349655700076512e-05,
      "loss": 0.155,
      "step": 14450
    },
    {
      "epoch": 0.6507943651829515,
      "grad_norm": 3.188837766647339,
      "learning_rate": 9.349205634817049e-05,
      "loss": 0.1614,
      "step": 14460
    },
    {
      "epoch": 0.6512444304424142,
      "grad_norm": 3.418671131134033,
      "learning_rate": 9.348755569557587e-05,
      "loss": 0.1264,
      "step": 14470
    },
    {
      "epoch": 0.6516944957018768,
      "grad_norm": 1.3363231420516968,
      "learning_rate": 9.348305504298124e-05,
      "loss": 0.1477,
      "step": 14480
    },
    {
      "epoch": 0.6521445609613394,
      "grad_norm": 3.9536046981811523,
      "learning_rate": 9.347855439038661e-05,
      "loss": 0.1448,
      "step": 14490
    },
    {
      "epoch": 0.652594626220802,
      "grad_norm": 2.967390298843384,
      "learning_rate": 9.347405373779199e-05,
      "loss": 0.1618,
      "step": 14500
    },
    {
      "epoch": 0.6530446914802647,
      "grad_norm": 3.9862782955169678,
      "learning_rate": 9.346955308519736e-05,
      "loss": 0.2176,
      "step": 14510
    },
    {
      "epoch": 0.6534947567397272,
      "grad_norm": 1.5129077434539795,
      "learning_rate": 9.346505243260273e-05,
      "loss": 0.1496,
      "step": 14520
    },
    {
      "epoch": 0.6539448219991899,
      "grad_norm": 1.8780598640441895,
      "learning_rate": 9.346055178000811e-05,
      "loss": 0.2444,
      "step": 14530
    },
    {
      "epoch": 0.6543948872586525,
      "grad_norm": 1.9168992042541504,
      "learning_rate": 9.345605112741348e-05,
      "loss": 0.1102,
      "step": 14540
    },
    {
      "epoch": 0.6548449525181151,
      "grad_norm": 3.1588001251220703,
      "learning_rate": 9.345155047481886e-05,
      "loss": 0.1472,
      "step": 14550
    },
    {
      "epoch": 0.6552950177775777,
      "grad_norm": 3.551433801651001,
      "learning_rate": 9.344704982222423e-05,
      "loss": 0.1256,
      "step": 14560
    },
    {
      "epoch": 0.6557450830370404,
      "grad_norm": 1.742232322692871,
      "learning_rate": 9.34425491696296e-05,
      "loss": 0.1115,
      "step": 14570
    },
    {
      "epoch": 0.6561951482965029,
      "grad_norm": 5.152315139770508,
      "learning_rate": 9.343804851703498e-05,
      "loss": 0.1626,
      "step": 14580
    },
    {
      "epoch": 0.6566452135559656,
      "grad_norm": 1.6805893182754517,
      "learning_rate": 9.343354786444035e-05,
      "loss": 0.1531,
      "step": 14590
    },
    {
      "epoch": 0.6570952788154283,
      "grad_norm": 3.043910264968872,
      "learning_rate": 9.342904721184572e-05,
      "loss": 0.139,
      "step": 14600
    },
    {
      "epoch": 0.6575453440748908,
      "grad_norm": 2.470412492752075,
      "learning_rate": 9.34245465592511e-05,
      "loss": 0.19,
      "step": 14610
    },
    {
      "epoch": 0.6579954093343535,
      "grad_norm": 1.6857399940490723,
      "learning_rate": 9.342004590665647e-05,
      "loss": 0.1029,
      "step": 14620
    },
    {
      "epoch": 0.6584454745938161,
      "grad_norm": 1.1330326795578003,
      "learning_rate": 9.341554525406184e-05,
      "loss": 0.2,
      "step": 14630
    },
    {
      "epoch": 0.6588955398532788,
      "grad_norm": 2.31113600730896,
      "learning_rate": 9.341104460146722e-05,
      "loss": 0.1105,
      "step": 14640
    },
    {
      "epoch": 0.6593456051127413,
      "grad_norm": 1.2438431978225708,
      "learning_rate": 9.340654394887259e-05,
      "loss": 0.1202,
      "step": 14650
    },
    {
      "epoch": 0.659795670372204,
      "grad_norm": 1.3906147480010986,
      "learning_rate": 9.340204329627796e-05,
      "loss": 0.14,
      "step": 14660
    },
    {
      "epoch": 0.6602457356316666,
      "grad_norm": 2.026204824447632,
      "learning_rate": 9.339754264368334e-05,
      "loss": 0.1646,
      "step": 14670
    },
    {
      "epoch": 0.6606958008911292,
      "grad_norm": 0.9066481590270996,
      "learning_rate": 9.339304199108871e-05,
      "loss": 0.128,
      "step": 14680
    },
    {
      "epoch": 0.6611458661505918,
      "grad_norm": 2.789829730987549,
      "learning_rate": 9.338854133849409e-05,
      "loss": 0.1886,
      "step": 14690
    },
    {
      "epoch": 0.6615959314100545,
      "grad_norm": 1.7256718873977661,
      "learning_rate": 9.338404068589946e-05,
      "loss": 0.1806,
      "step": 14700
    },
    {
      "epoch": 0.6620459966695171,
      "grad_norm": 2.1631858348846436,
      "learning_rate": 9.337954003330483e-05,
      "loss": 0.1194,
      "step": 14710
    },
    {
      "epoch": 0.6624960619289797,
      "grad_norm": 2.8588201999664307,
      "learning_rate": 9.33750393807102e-05,
      "loss": 0.1512,
      "step": 14720
    },
    {
      "epoch": 0.6629461271884424,
      "grad_norm": 2.6321496963500977,
      "learning_rate": 9.337053872811558e-05,
      "loss": 0.139,
      "step": 14730
    },
    {
      "epoch": 0.6633961924479049,
      "grad_norm": 4.129528999328613,
      "learning_rate": 9.336603807552095e-05,
      "loss": 0.1346,
      "step": 14740
    },
    {
      "epoch": 0.6638462577073676,
      "grad_norm": 3.4271061420440674,
      "learning_rate": 9.336153742292633e-05,
      "loss": 0.1653,
      "step": 14750
    },
    {
      "epoch": 0.6642963229668302,
      "grad_norm": 2.560624599456787,
      "learning_rate": 9.33570367703317e-05,
      "loss": 0.1592,
      "step": 14760
    },
    {
      "epoch": 0.6647463882262928,
      "grad_norm": 3.7120535373687744,
      "learning_rate": 9.335253611773707e-05,
      "loss": 0.173,
      "step": 14770
    },
    {
      "epoch": 0.6651964534857554,
      "grad_norm": 3.3174538612365723,
      "learning_rate": 9.334803546514245e-05,
      "loss": 0.1219,
      "step": 14780
    },
    {
      "epoch": 0.6656465187452181,
      "grad_norm": 2.412818431854248,
      "learning_rate": 9.334353481254782e-05,
      "loss": 0.1708,
      "step": 14790
    },
    {
      "epoch": 0.6660965840046806,
      "grad_norm": 1.8645296096801758,
      "learning_rate": 9.33390341599532e-05,
      "loss": 0.2122,
      "step": 14800
    },
    {
      "epoch": 0.6665466492641433,
      "grad_norm": 3.7362403869628906,
      "learning_rate": 9.333453350735857e-05,
      "loss": 0.1674,
      "step": 14810
    },
    {
      "epoch": 0.6669967145236059,
      "grad_norm": 2.6485507488250732,
      "learning_rate": 9.333003285476394e-05,
      "loss": 0.1091,
      "step": 14820
    },
    {
      "epoch": 0.6674467797830685,
      "grad_norm": 4.409088611602783,
      "learning_rate": 9.332553220216932e-05,
      "loss": 0.1446,
      "step": 14830
    },
    {
      "epoch": 0.6678968450425312,
      "grad_norm": 1.9869762659072876,
      "learning_rate": 9.332103154957469e-05,
      "loss": 0.1397,
      "step": 14840
    },
    {
      "epoch": 0.6683469103019938,
      "grad_norm": 2.6707754135131836,
      "learning_rate": 9.331653089698008e-05,
      "loss": 0.1804,
      "step": 14850
    },
    {
      "epoch": 0.6687969755614565,
      "grad_norm": 1.4230952262878418,
      "learning_rate": 9.331203024438544e-05,
      "loss": 0.1487,
      "step": 14860
    },
    {
      "epoch": 0.669247040820919,
      "grad_norm": 1.212687611579895,
      "learning_rate": 9.330752959179081e-05,
      "loss": 0.1346,
      "step": 14870
    },
    {
      "epoch": 0.6696971060803817,
      "grad_norm": 2.271085262298584,
      "learning_rate": 9.33030289391962e-05,
      "loss": 0.1456,
      "step": 14880
    },
    {
      "epoch": 0.6701471713398442,
      "grad_norm": 0.7942425012588501,
      "learning_rate": 9.329852828660156e-05,
      "loss": 0.1433,
      "step": 14890
    },
    {
      "epoch": 0.6705972365993069,
      "grad_norm": 4.437504768371582,
      "learning_rate": 9.329402763400693e-05,
      "loss": 0.1587,
      "step": 14900
    },
    {
      "epoch": 0.6710473018587695,
      "grad_norm": 1.6713745594024658,
      "learning_rate": 9.328952698141232e-05,
      "loss": 0.1745,
      "step": 14910
    },
    {
      "epoch": 0.6714973671182322,
      "grad_norm": 4.936830520629883,
      "learning_rate": 9.328502632881768e-05,
      "loss": 0.1222,
      "step": 14920
    },
    {
      "epoch": 0.6719474323776947,
      "grad_norm": 1.9649959802627563,
      "learning_rate": 9.328052567622305e-05,
      "loss": 0.1804,
      "step": 14930
    },
    {
      "epoch": 0.6723974976371574,
      "grad_norm": 2.888786554336548,
      "learning_rate": 9.327602502362844e-05,
      "loss": 0.2049,
      "step": 14940
    },
    {
      "epoch": 0.67284756289662,
      "grad_norm": 2.830181837081909,
      "learning_rate": 9.32715243710338e-05,
      "loss": 0.1964,
      "step": 14950
    },
    {
      "epoch": 0.6732976281560826,
      "grad_norm": 1.8357793092727661,
      "learning_rate": 9.326702371843917e-05,
      "loss": 0.1526,
      "step": 14960
    },
    {
      "epoch": 0.6737476934155453,
      "grad_norm": 3.711264133453369,
      "learning_rate": 9.326252306584456e-05,
      "loss": 0.1309,
      "step": 14970
    },
    {
      "epoch": 0.6741977586750079,
      "grad_norm": 1.1824073791503906,
      "learning_rate": 9.325802241324992e-05,
      "loss": 0.1178,
      "step": 14980
    },
    {
      "epoch": 0.6746478239344705,
      "grad_norm": 0.38866397738456726,
      "learning_rate": 9.325352176065531e-05,
      "loss": 0.1319,
      "step": 14990
    },
    {
      "epoch": 0.6750978891939331,
      "grad_norm": 1.9135061502456665,
      "learning_rate": 9.324902110806068e-05,
      "loss": 0.1552,
      "step": 15000
    },
    {
      "epoch": 0.6755479544533958,
      "grad_norm": 5.675385475158691,
      "learning_rate": 9.324452045546604e-05,
      "loss": 0.1474,
      "step": 15010
    },
    {
      "epoch": 0.6759980197128583,
      "grad_norm": 5.532248497009277,
      "learning_rate": 9.324001980287143e-05,
      "loss": 0.1403,
      "step": 15020
    },
    {
      "epoch": 0.676448084972321,
      "grad_norm": 0.9253267645835876,
      "learning_rate": 9.32355191502768e-05,
      "loss": 0.0741,
      "step": 15030
    },
    {
      "epoch": 0.6768981502317836,
      "grad_norm": 6.017086505889893,
      "learning_rate": 9.323101849768216e-05,
      "loss": 0.1685,
      "step": 15040
    },
    {
      "epoch": 0.6773482154912462,
      "grad_norm": 3.7084054946899414,
      "learning_rate": 9.322651784508755e-05,
      "loss": 0.1621,
      "step": 15050
    },
    {
      "epoch": 0.6777982807507088,
      "grad_norm": 4.654889106750488,
      "learning_rate": 9.322201719249292e-05,
      "loss": 0.1607,
      "step": 15060
    },
    {
      "epoch": 0.6782483460101715,
      "grad_norm": 4.053003311157227,
      "learning_rate": 9.321751653989828e-05,
      "loss": 0.17,
      "step": 15070
    },
    {
      "epoch": 0.6786984112696341,
      "grad_norm": 1.6651194095611572,
      "learning_rate": 9.321301588730367e-05,
      "loss": 0.1558,
      "step": 15080
    },
    {
      "epoch": 0.6791484765290967,
      "grad_norm": 2.672619104385376,
      "learning_rate": 9.320851523470904e-05,
      "loss": 0.1939,
      "step": 15090
    },
    {
      "epoch": 0.6795985417885594,
      "grad_norm": 4.121730327606201,
      "learning_rate": 9.32040145821144e-05,
      "loss": 0.1306,
      "step": 15100
    },
    {
      "epoch": 0.680048607048022,
      "grad_norm": 1.2644952535629272,
      "learning_rate": 9.319951392951979e-05,
      "loss": 0.1568,
      "step": 15110
    },
    {
      "epoch": 0.6804986723074846,
      "grad_norm": 2.041175365447998,
      "learning_rate": 9.319501327692516e-05,
      "loss": 0.0967,
      "step": 15120
    },
    {
      "epoch": 0.6809487375669472,
      "grad_norm": 3.6273365020751953,
      "learning_rate": 9.319051262433052e-05,
      "loss": 0.1404,
      "step": 15130
    },
    {
      "epoch": 0.6813988028264099,
      "grad_norm": 4.162184238433838,
      "learning_rate": 9.318601197173591e-05,
      "loss": 0.158,
      "step": 15140
    },
    {
      "epoch": 0.6818488680858724,
      "grad_norm": 1.7532250881195068,
      "learning_rate": 9.318151131914128e-05,
      "loss": 0.1347,
      "step": 15150
    },
    {
      "epoch": 0.6822989333453351,
      "grad_norm": 1.776175618171692,
      "learning_rate": 9.317701066654664e-05,
      "loss": 0.1686,
      "step": 15160
    },
    {
      "epoch": 0.6827489986047977,
      "grad_norm": 1.9498728513717651,
      "learning_rate": 9.317251001395203e-05,
      "loss": 0.1426,
      "step": 15170
    },
    {
      "epoch": 0.6831990638642603,
      "grad_norm": 4.347827911376953,
      "learning_rate": 9.31680093613574e-05,
      "loss": 0.125,
      "step": 15180
    },
    {
      "epoch": 0.6836491291237229,
      "grad_norm": 2.738114833831787,
      "learning_rate": 9.316350870876277e-05,
      "loss": 0.114,
      "step": 15190
    },
    {
      "epoch": 0.6840991943831856,
      "grad_norm": 6.705068588256836,
      "learning_rate": 9.315900805616815e-05,
      "loss": 0.1898,
      "step": 15200
    },
    {
      "epoch": 0.6845492596426482,
      "grad_norm": 2.560101270675659,
      "learning_rate": 9.315450740357353e-05,
      "loss": 0.1366,
      "step": 15210
    },
    {
      "epoch": 0.6849993249021108,
      "grad_norm": 2.8766167163848877,
      "learning_rate": 9.315000675097889e-05,
      "loss": 0.1286,
      "step": 15220
    },
    {
      "epoch": 0.6854493901615735,
      "grad_norm": 2.756091594696045,
      "learning_rate": 9.314550609838427e-05,
      "loss": 0.1717,
      "step": 15230
    },
    {
      "epoch": 0.685899455421036,
      "grad_norm": 3.7472951412200928,
      "learning_rate": 9.314100544578965e-05,
      "loss": 0.1713,
      "step": 15240
    },
    {
      "epoch": 0.6863495206804987,
      "grad_norm": 2.4310731887817383,
      "learning_rate": 9.313650479319502e-05,
      "loss": 0.193,
      "step": 15250
    },
    {
      "epoch": 0.6867995859399613,
      "grad_norm": 1.678607702255249,
      "learning_rate": 9.31320041406004e-05,
      "loss": 0.1374,
      "step": 15260
    },
    {
      "epoch": 0.6872496511994239,
      "grad_norm": 3.7643656730651855,
      "learning_rate": 9.312750348800577e-05,
      "loss": 0.1777,
      "step": 15270
    },
    {
      "epoch": 0.6876997164588865,
      "grad_norm": 2.451498031616211,
      "learning_rate": 9.312300283541114e-05,
      "loss": 0.1757,
      "step": 15280
    },
    {
      "epoch": 0.6881497817183492,
      "grad_norm": 1.9136762619018555,
      "learning_rate": 9.311850218281652e-05,
      "loss": 0.171,
      "step": 15290
    },
    {
      "epoch": 0.6885998469778117,
      "grad_norm": 1.5942351818084717,
      "learning_rate": 9.311400153022189e-05,
      "loss": 0.1248,
      "step": 15300
    },
    {
      "epoch": 0.6890499122372744,
      "grad_norm": 2.154158115386963,
      "learning_rate": 9.310950087762726e-05,
      "loss": 0.1219,
      "step": 15310
    },
    {
      "epoch": 0.6894999774967371,
      "grad_norm": 3.3539791107177734,
      "learning_rate": 9.310500022503264e-05,
      "loss": 0.1355,
      "step": 15320
    },
    {
      "epoch": 0.6899500427561996,
      "grad_norm": 2.209334373474121,
      "learning_rate": 9.310049957243801e-05,
      "loss": 0.1901,
      "step": 15330
    },
    {
      "epoch": 0.6904001080156623,
      "grad_norm": 5.672548770904541,
      "learning_rate": 9.309599891984338e-05,
      "loss": 0.1468,
      "step": 15340
    },
    {
      "epoch": 0.6908501732751249,
      "grad_norm": 1.5370204448699951,
      "learning_rate": 9.309149826724876e-05,
      "loss": 0.1127,
      "step": 15350
    },
    {
      "epoch": 0.6913002385345876,
      "grad_norm": 2.8363869190216064,
      "learning_rate": 9.308699761465413e-05,
      "loss": 0.1689,
      "step": 15360
    },
    {
      "epoch": 0.6917503037940501,
      "grad_norm": 2.498319625854492,
      "learning_rate": 9.30824969620595e-05,
      "loss": 0.1089,
      "step": 15370
    },
    {
      "epoch": 0.6922003690535128,
      "grad_norm": 2.3421905040740967,
      "learning_rate": 9.307799630946488e-05,
      "loss": 0.1435,
      "step": 15380
    },
    {
      "epoch": 0.6926504343129753,
      "grad_norm": 3.288085699081421,
      "learning_rate": 9.307349565687025e-05,
      "loss": 0.132,
      "step": 15390
    },
    {
      "epoch": 0.693100499572438,
      "grad_norm": 2.853325843811035,
      "learning_rate": 9.306899500427562e-05,
      "loss": 0.1301,
      "step": 15400
    },
    {
      "epoch": 0.6935505648319006,
      "grad_norm": 1.2565680742263794,
      "learning_rate": 9.3064494351681e-05,
      "loss": 0.1327,
      "step": 15410
    },
    {
      "epoch": 0.6940006300913633,
      "grad_norm": 1.0533093214035034,
      "learning_rate": 9.305999369908637e-05,
      "loss": 0.1324,
      "step": 15420
    },
    {
      "epoch": 0.6944506953508258,
      "grad_norm": 4.6876068115234375,
      "learning_rate": 9.305549304649175e-05,
      "loss": 0.1054,
      "step": 15430
    },
    {
      "epoch": 0.6949007606102885,
      "grad_norm": 3.2443718910217285,
      "learning_rate": 9.305099239389712e-05,
      "loss": 0.1274,
      "step": 15440
    },
    {
      "epoch": 0.6953508258697512,
      "grad_norm": 2.5801773071289062,
      "learning_rate": 9.304649174130249e-05,
      "loss": 0.161,
      "step": 15450
    },
    {
      "epoch": 0.6958008911292137,
      "grad_norm": 1.532008409500122,
      "learning_rate": 9.304199108870787e-05,
      "loss": 0.1583,
      "step": 15460
    },
    {
      "epoch": 0.6962509563886764,
      "grad_norm": 0.9852824807167053,
      "learning_rate": 9.303749043611324e-05,
      "loss": 0.1469,
      "step": 15470
    },
    {
      "epoch": 0.696701021648139,
      "grad_norm": 1.1944423913955688,
      "learning_rate": 9.303298978351861e-05,
      "loss": 0.104,
      "step": 15480
    },
    {
      "epoch": 0.6971510869076016,
      "grad_norm": 3.5542590618133545,
      "learning_rate": 9.302848913092399e-05,
      "loss": 0.1976,
      "step": 15490
    },
    {
      "epoch": 0.6976011521670642,
      "grad_norm": 3.3984596729278564,
      "learning_rate": 9.302398847832936e-05,
      "loss": 0.115,
      "step": 15500
    },
    {
      "epoch": 0.6980512174265269,
      "grad_norm": 0.9602628946304321,
      "learning_rate": 9.301948782573473e-05,
      "loss": 0.1112,
      "step": 15510
    },
    {
      "epoch": 0.6985012826859894,
      "grad_norm": 2.3008599281311035,
      "learning_rate": 9.301498717314011e-05,
      "loss": 0.1264,
      "step": 15520
    },
    {
      "epoch": 0.6989513479454521,
      "grad_norm": 1.930281400680542,
      "learning_rate": 9.301048652054548e-05,
      "loss": 0.1362,
      "step": 15530
    },
    {
      "epoch": 0.6994014132049147,
      "grad_norm": 3.4257071018218994,
      "learning_rate": 9.300598586795087e-05,
      "loss": 0.1456,
      "step": 15540
    },
    {
      "epoch": 0.6998514784643773,
      "grad_norm": 2.6981050968170166,
      "learning_rate": 9.300148521535623e-05,
      "loss": 0.161,
      "step": 15550
    },
    {
      "epoch": 0.7003015437238399,
      "grad_norm": 1.7595852613449097,
      "learning_rate": 9.29969845627616e-05,
      "loss": 0.1408,
      "step": 15560
    },
    {
      "epoch": 0.7007516089833026,
      "grad_norm": 0.9207836389541626,
      "learning_rate": 9.299248391016699e-05,
      "loss": 0.1336,
      "step": 15570
    },
    {
      "epoch": 0.7012016742427652,
      "grad_norm": 3.8576600551605225,
      "learning_rate": 9.298798325757235e-05,
      "loss": 0.1893,
      "step": 15580
    },
    {
      "epoch": 0.7016517395022278,
      "grad_norm": 5.204705238342285,
      "learning_rate": 9.298348260497772e-05,
      "loss": 0.1542,
      "step": 15590
    },
    {
      "epoch": 0.7021018047616905,
      "grad_norm": 4.965751647949219,
      "learning_rate": 9.297898195238311e-05,
      "loss": 0.148,
      "step": 15600
    },
    {
      "epoch": 0.702551870021153,
      "grad_norm": 4.447607040405273,
      "learning_rate": 9.297448129978847e-05,
      "loss": 0.1861,
      "step": 15610
    },
    {
      "epoch": 0.7030019352806157,
      "grad_norm": 1.7364798784255981,
      "learning_rate": 9.296998064719384e-05,
      "loss": 0.1198,
      "step": 15620
    },
    {
      "epoch": 0.7034520005400783,
      "grad_norm": 1.8996907472610474,
      "learning_rate": 9.296547999459923e-05,
      "loss": 0.0938,
      "step": 15630
    },
    {
      "epoch": 0.703902065799541,
      "grad_norm": 6.182278156280518,
      "learning_rate": 9.296097934200459e-05,
      "loss": 0.1504,
      "step": 15640
    },
    {
      "epoch": 0.7043521310590035,
      "grad_norm": 1.6298024654388428,
      "learning_rate": 9.295647868940997e-05,
      "loss": 0.1176,
      "step": 15650
    },
    {
      "epoch": 0.7048021963184662,
      "grad_norm": 4.1094489097595215,
      "learning_rate": 9.295197803681535e-05,
      "loss": 0.1347,
      "step": 15660
    },
    {
      "epoch": 0.7052522615779288,
      "grad_norm": 2.472364664077759,
      "learning_rate": 9.294747738422071e-05,
      "loss": 0.1688,
      "step": 15670
    },
    {
      "epoch": 0.7057023268373914,
      "grad_norm": 0.5016542673110962,
      "learning_rate": 9.294297673162609e-05,
      "loss": 0.167,
      "step": 15680
    },
    {
      "epoch": 0.7061523920968541,
      "grad_norm": 2.859314203262329,
      "learning_rate": 9.293847607903147e-05,
      "loss": 0.1378,
      "step": 15690
    },
    {
      "epoch": 0.7066024573563167,
      "grad_norm": 2.8381121158599854,
      "learning_rate": 9.293397542643683e-05,
      "loss": 0.1477,
      "step": 15700
    },
    {
      "epoch": 0.7070525226157793,
      "grad_norm": 3.586155652999878,
      "learning_rate": 9.29294747738422e-05,
      "loss": 0.1141,
      "step": 15710
    },
    {
      "epoch": 0.7075025878752419,
      "grad_norm": 0.7121677994728088,
      "learning_rate": 9.29249741212476e-05,
      "loss": 0.1385,
      "step": 15720
    },
    {
      "epoch": 0.7079526531347046,
      "grad_norm": 4.0491814613342285,
      "learning_rate": 9.292047346865295e-05,
      "loss": 0.1324,
      "step": 15730
    },
    {
      "epoch": 0.7084027183941671,
      "grad_norm": 1.5107834339141846,
      "learning_rate": 9.291597281605833e-05,
      "loss": 0.1101,
      "step": 15740
    },
    {
      "epoch": 0.7088527836536298,
      "grad_norm": 2.788874626159668,
      "learning_rate": 9.291147216346371e-05,
      "loss": 0.1526,
      "step": 15750
    },
    {
      "epoch": 0.7093028489130924,
      "grad_norm": 3.1015796661376953,
      "learning_rate": 9.290697151086907e-05,
      "loss": 0.1324,
      "step": 15760
    },
    {
      "epoch": 0.709752914172555,
      "grad_norm": 1.0502220392227173,
      "learning_rate": 9.290247085827446e-05,
      "loss": 0.192,
      "step": 15770
    },
    {
      "epoch": 0.7102029794320176,
      "grad_norm": 4.639458179473877,
      "learning_rate": 9.289797020567984e-05,
      "loss": 0.2016,
      "step": 15780
    },
    {
      "epoch": 0.7106530446914803,
      "grad_norm": 3.6855721473693848,
      "learning_rate": 9.28934695530852e-05,
      "loss": 0.1431,
      "step": 15790
    },
    {
      "epoch": 0.7111031099509428,
      "grad_norm": 4.385463714599609,
      "learning_rate": 9.288896890049058e-05,
      "loss": 0.1605,
      "step": 15800
    },
    {
      "epoch": 0.7115531752104055,
      "grad_norm": 2.2039730548858643,
      "learning_rate": 9.288446824789596e-05,
      "loss": 0.1185,
      "step": 15810
    },
    {
      "epoch": 0.7120032404698682,
      "grad_norm": 2.946312427520752,
      "learning_rate": 9.287996759530132e-05,
      "loss": 0.1621,
      "step": 15820
    },
    {
      "epoch": 0.7124533057293307,
      "grad_norm": 1.3366318941116333,
      "learning_rate": 9.28754669427067e-05,
      "loss": 0.1588,
      "step": 15830
    },
    {
      "epoch": 0.7129033709887934,
      "grad_norm": 1.2449628114700317,
      "learning_rate": 9.287096629011208e-05,
      "loss": 0.122,
      "step": 15840
    },
    {
      "epoch": 0.713353436248256,
      "grad_norm": 4.965140342712402,
      "learning_rate": 9.286646563751744e-05,
      "loss": 0.1758,
      "step": 15850
    },
    {
      "epoch": 0.7138035015077187,
      "grad_norm": 3.0704538822174072,
      "learning_rate": 9.286196498492282e-05,
      "loss": 0.1347,
      "step": 15860
    },
    {
      "epoch": 0.7142535667671812,
      "grad_norm": 1.1384607553482056,
      "learning_rate": 9.28574643323282e-05,
      "loss": 0.1196,
      "step": 15870
    },
    {
      "epoch": 0.7147036320266439,
      "grad_norm": 3.336487293243408,
      "learning_rate": 9.285296367973356e-05,
      "loss": 0.1583,
      "step": 15880
    },
    {
      "epoch": 0.7151536972861064,
      "grad_norm": 2.6025726795196533,
      "learning_rate": 9.284846302713895e-05,
      "loss": 0.1383,
      "step": 15890
    },
    {
      "epoch": 0.7156037625455691,
      "grad_norm": 2.161944627761841,
      "learning_rate": 9.284396237454432e-05,
      "loss": 0.148,
      "step": 15900
    },
    {
      "epoch": 0.7160538278050317,
      "grad_norm": 1.5275324583053589,
      "learning_rate": 9.283946172194968e-05,
      "loss": 0.1231,
      "step": 15910
    },
    {
      "epoch": 0.7165038930644944,
      "grad_norm": 1.2824434041976929,
      "learning_rate": 9.283496106935507e-05,
      "loss": 0.1589,
      "step": 15920
    },
    {
      "epoch": 0.7169539583239569,
      "grad_norm": 4.0026984214782715,
      "learning_rate": 9.283046041676044e-05,
      "loss": 0.1279,
      "step": 15930
    },
    {
      "epoch": 0.7174040235834196,
      "grad_norm": 2.4551005363464355,
      "learning_rate": 9.28259597641658e-05,
      "loss": 0.3103,
      "step": 15940
    },
    {
      "epoch": 0.7178540888428823,
      "grad_norm": 2.467517137527466,
      "learning_rate": 9.282145911157119e-05,
      "loss": 0.2403,
      "step": 15950
    },
    {
      "epoch": 0.7183041541023448,
      "grad_norm": 1.7367254495620728,
      "learning_rate": 9.281695845897656e-05,
      "loss": 0.138,
      "step": 15960
    },
    {
      "epoch": 0.7187542193618075,
      "grad_norm": 2.7236313819885254,
      "learning_rate": 9.281245780638192e-05,
      "loss": 0.1296,
      "step": 15970
    },
    {
      "epoch": 0.7192042846212701,
      "grad_norm": 3.0094106197357178,
      "learning_rate": 9.280795715378731e-05,
      "loss": 0.1055,
      "step": 15980
    },
    {
      "epoch": 0.7196543498807327,
      "grad_norm": 1.9372676610946655,
      "learning_rate": 9.280345650119268e-05,
      "loss": 0.1394,
      "step": 15990
    },
    {
      "epoch": 0.7201044151401953,
      "grad_norm": 3.7562053203582764,
      "learning_rate": 9.279895584859804e-05,
      "loss": 0.1664,
      "step": 16000
    },
    {
      "epoch": 0.720554480399658,
      "grad_norm": 1.7772645950317383,
      "learning_rate": 9.279445519600343e-05,
      "loss": 0.1433,
      "step": 16010
    },
    {
      "epoch": 0.7210045456591205,
      "grad_norm": 1.4597033262252808,
      "learning_rate": 9.27899545434088e-05,
      "loss": 0.0998,
      "step": 16020
    },
    {
      "epoch": 0.7214546109185832,
      "grad_norm": 2.2363064289093018,
      "learning_rate": 9.278545389081418e-05,
      "loss": 0.1618,
      "step": 16030
    },
    {
      "epoch": 0.7219046761780458,
      "grad_norm": 2.324958562850952,
      "learning_rate": 9.278095323821955e-05,
      "loss": 0.1372,
      "step": 16040
    },
    {
      "epoch": 0.7223547414375084,
      "grad_norm": 3.3567874431610107,
      "learning_rate": 9.277645258562492e-05,
      "loss": 0.1139,
      "step": 16050
    },
    {
      "epoch": 0.7228048066969711,
      "grad_norm": 0.4463735818862915,
      "learning_rate": 9.27719519330303e-05,
      "loss": 0.159,
      "step": 16060
    },
    {
      "epoch": 0.7232548719564337,
      "grad_norm": 2.989716053009033,
      "learning_rate": 9.276745128043567e-05,
      "loss": 0.097,
      "step": 16070
    },
    {
      "epoch": 0.7237049372158963,
      "grad_norm": 1.8935644626617432,
      "learning_rate": 9.276295062784104e-05,
      "loss": 0.1217,
      "step": 16080
    },
    {
      "epoch": 0.7241550024753589,
      "grad_norm": 2.5771284103393555,
      "learning_rate": 9.275844997524642e-05,
      "loss": 0.1403,
      "step": 16090
    },
    {
      "epoch": 0.7246050677348216,
      "grad_norm": 2.7757654190063477,
      "learning_rate": 9.275394932265179e-05,
      "loss": 0.1116,
      "step": 16100
    },
    {
      "epoch": 0.7250551329942841,
      "grad_norm": 4.534438133239746,
      "learning_rate": 9.274944867005716e-05,
      "loss": 0.1622,
      "step": 16110
    },
    {
      "epoch": 0.7255051982537468,
      "grad_norm": 1.6316298246383667,
      "learning_rate": 9.274494801746254e-05,
      "loss": 0.1384,
      "step": 16120
    },
    {
      "epoch": 0.7259552635132094,
      "grad_norm": 2.628617525100708,
      "learning_rate": 9.274044736486791e-05,
      "loss": 0.1217,
      "step": 16130
    },
    {
      "epoch": 0.726405328772672,
      "grad_norm": 3.237226724624634,
      "learning_rate": 9.273594671227329e-05,
      "loss": 0.082,
      "step": 16140
    },
    {
      "epoch": 0.7268553940321346,
      "grad_norm": 4.613758087158203,
      "learning_rate": 9.273144605967866e-05,
      "loss": 0.1793,
      "step": 16150
    },
    {
      "epoch": 0.7273054592915973,
      "grad_norm": 0.32750362157821655,
      "learning_rate": 9.272694540708403e-05,
      "loss": 0.0954,
      "step": 16160
    },
    {
      "epoch": 0.7277555245510599,
      "grad_norm": 2.0022923946380615,
      "learning_rate": 9.27224447544894e-05,
      "loss": 0.1197,
      "step": 16170
    },
    {
      "epoch": 0.7282055898105225,
      "grad_norm": 3.967050313949585,
      "learning_rate": 9.271794410189478e-05,
      "loss": 0.1441,
      "step": 16180
    },
    {
      "epoch": 0.7286556550699852,
      "grad_norm": 3.0722270011901855,
      "learning_rate": 9.271344344930015e-05,
      "loss": 0.1687,
      "step": 16190
    },
    {
      "epoch": 0.7291057203294478,
      "grad_norm": 4.45966100692749,
      "learning_rate": 9.270894279670553e-05,
      "loss": 0.1429,
      "step": 16200
    },
    {
      "epoch": 0.7295557855889104,
      "grad_norm": 4.616537570953369,
      "learning_rate": 9.27044421441109e-05,
      "loss": 0.1793,
      "step": 16210
    },
    {
      "epoch": 0.730005850848373,
      "grad_norm": 1.533402681350708,
      "learning_rate": 9.269994149151627e-05,
      "loss": 0.0954,
      "step": 16220
    },
    {
      "epoch": 0.7304559161078357,
      "grad_norm": 4.250864028930664,
      "learning_rate": 9.269544083892165e-05,
      "loss": 0.1265,
      "step": 16230
    },
    {
      "epoch": 0.7309059813672982,
      "grad_norm": 0.5589705109596252,
      "learning_rate": 9.269094018632702e-05,
      "loss": 0.1156,
      "step": 16240
    },
    {
      "epoch": 0.7313560466267609,
      "grad_norm": 1.311363935470581,
      "learning_rate": 9.26864395337324e-05,
      "loss": 0.146,
      "step": 16250
    },
    {
      "epoch": 0.7318061118862235,
      "grad_norm": 2.223789691925049,
      "learning_rate": 9.268193888113777e-05,
      "loss": 0.159,
      "step": 16260
    },
    {
      "epoch": 0.7322561771456861,
      "grad_norm": 5.083193302154541,
      "learning_rate": 9.267743822854314e-05,
      "loss": 0.1434,
      "step": 16270
    },
    {
      "epoch": 0.7327062424051487,
      "grad_norm": 1.9360116720199585,
      "learning_rate": 9.267293757594852e-05,
      "loss": 0.1745,
      "step": 16280
    },
    {
      "epoch": 0.7331563076646114,
      "grad_norm": 1.4307725429534912,
      "learning_rate": 9.26684369233539e-05,
      "loss": 0.1495,
      "step": 16290
    },
    {
      "epoch": 0.733606372924074,
      "grad_norm": 2.9253733158111572,
      "learning_rate": 9.266393627075926e-05,
      "loss": 0.1773,
      "step": 16300
    },
    {
      "epoch": 0.7340564381835366,
      "grad_norm": 3.284024238586426,
      "learning_rate": 9.265943561816464e-05,
      "loss": 0.1775,
      "step": 16310
    },
    {
      "epoch": 0.7345065034429993,
      "grad_norm": 3.225057601928711,
      "learning_rate": 9.265493496557002e-05,
      "loss": 0.204,
      "step": 16320
    },
    {
      "epoch": 0.7349565687024618,
      "grad_norm": 2.886319398880005,
      "learning_rate": 9.265043431297538e-05,
      "loss": 0.1445,
      "step": 16330
    },
    {
      "epoch": 0.7354066339619245,
      "grad_norm": 5.011139869689941,
      "learning_rate": 9.264593366038076e-05,
      "loss": 0.1526,
      "step": 16340
    },
    {
      "epoch": 0.7358566992213871,
      "grad_norm": 1.3502700328826904,
      "learning_rate": 9.264143300778614e-05,
      "loss": 0.11,
      "step": 16350
    },
    {
      "epoch": 0.7363067644808498,
      "grad_norm": 2.0622398853302,
      "learning_rate": 9.26369323551915e-05,
      "loss": 0.189,
      "step": 16360
    },
    {
      "epoch": 0.7367568297403123,
      "grad_norm": 1.385332465171814,
      "learning_rate": 9.263243170259688e-05,
      "loss": 0.1369,
      "step": 16370
    },
    {
      "epoch": 0.737206894999775,
      "grad_norm": 2.6969988346099854,
      "learning_rate": 9.262793105000227e-05,
      "loss": 0.121,
      "step": 16380
    },
    {
      "epoch": 0.7376569602592375,
      "grad_norm": 2.760432720184326,
      "learning_rate": 9.262343039740763e-05,
      "loss": 0.206,
      "step": 16390
    },
    {
      "epoch": 0.7381070255187002,
      "grad_norm": 1.0768026113510132,
      "learning_rate": 9.2618929744813e-05,
      "loss": 0.1192,
      "step": 16400
    },
    {
      "epoch": 0.7385570907781628,
      "grad_norm": 1.835602879524231,
      "learning_rate": 9.261442909221839e-05,
      "loss": 0.1532,
      "step": 16410
    },
    {
      "epoch": 0.7390071560376255,
      "grad_norm": 4.147184371948242,
      "learning_rate": 9.260992843962375e-05,
      "loss": 0.1472,
      "step": 16420
    },
    {
      "epoch": 0.7394572212970881,
      "grad_norm": 1.0832874774932861,
      "learning_rate": 9.260542778702912e-05,
      "loss": 0.1488,
      "step": 16430
    },
    {
      "epoch": 0.7399072865565507,
      "grad_norm": 4.746262073516846,
      "learning_rate": 9.260092713443451e-05,
      "loss": 0.1204,
      "step": 16440
    },
    {
      "epoch": 0.7403573518160134,
      "grad_norm": 1.326746940612793,
      "learning_rate": 9.259642648183987e-05,
      "loss": 0.1404,
      "step": 16450
    },
    {
      "epoch": 0.7408074170754759,
      "grad_norm": 1.692412257194519,
      "learning_rate": 9.259192582924524e-05,
      "loss": 0.1488,
      "step": 16460
    },
    {
      "epoch": 0.7412574823349386,
      "grad_norm": 1.1953628063201904,
      "learning_rate": 9.258742517665063e-05,
      "loss": 0.1505,
      "step": 16470
    },
    {
      "epoch": 0.7417075475944012,
      "grad_norm": 2.357036828994751,
      "learning_rate": 9.258292452405599e-05,
      "loss": 0.1078,
      "step": 16480
    },
    {
      "epoch": 0.7421576128538638,
      "grad_norm": 3.1520304679870605,
      "learning_rate": 9.257842387146136e-05,
      "loss": 0.1328,
      "step": 16490
    },
    {
      "epoch": 0.7426076781133264,
      "grad_norm": 2.1312451362609863,
      "learning_rate": 9.257392321886675e-05,
      "loss": 0.0913,
      "step": 16500
    },
    {
      "epoch": 0.7430577433727891,
      "grad_norm": 1.9543354511260986,
      "learning_rate": 9.256942256627211e-05,
      "loss": 0.1214,
      "step": 16510
    },
    {
      "epoch": 0.7435078086322516,
      "grad_norm": 0.5242559909820557,
      "learning_rate": 9.256492191367748e-05,
      "loss": 0.0869,
      "step": 16520
    },
    {
      "epoch": 0.7439578738917143,
      "grad_norm": 2.002654552459717,
      "learning_rate": 9.256042126108287e-05,
      "loss": 0.1159,
      "step": 16530
    },
    {
      "epoch": 0.7444079391511769,
      "grad_norm": 6.0955963134765625,
      "learning_rate": 9.255592060848823e-05,
      "loss": 0.1221,
      "step": 16540
    },
    {
      "epoch": 0.7448580044106395,
      "grad_norm": 1.0765103101730347,
      "learning_rate": 9.25514199558936e-05,
      "loss": 0.1485,
      "step": 16550
    },
    {
      "epoch": 0.7453080696701022,
      "grad_norm": 1.7944862842559814,
      "learning_rate": 9.254691930329899e-05,
      "loss": 0.1163,
      "step": 16560
    },
    {
      "epoch": 0.7457581349295648,
      "grad_norm": 4.123690605163574,
      "learning_rate": 9.254241865070435e-05,
      "loss": 0.1302,
      "step": 16570
    },
    {
      "epoch": 0.7462082001890274,
      "grad_norm": 4.874723434448242,
      "learning_rate": 9.253791799810974e-05,
      "loss": 0.1192,
      "step": 16580
    },
    {
      "epoch": 0.74665826544849,
      "grad_norm": 2.604010581970215,
      "learning_rate": 9.253341734551511e-05,
      "loss": 0.1637,
      "step": 16590
    },
    {
      "epoch": 0.7471083307079527,
      "grad_norm": 0.3739587068557739,
      "learning_rate": 9.252891669292047e-05,
      "loss": 0.118,
      "step": 16600
    },
    {
      "epoch": 0.7475583959674152,
      "grad_norm": 4.831381797790527,
      "learning_rate": 9.252441604032586e-05,
      "loss": 0.1094,
      "step": 16610
    },
    {
      "epoch": 0.7480084612268779,
      "grad_norm": 2.7921862602233887,
      "learning_rate": 9.251991538773123e-05,
      "loss": 0.1727,
      "step": 16620
    },
    {
      "epoch": 0.7484585264863405,
      "grad_norm": 2.3183624744415283,
      "learning_rate": 9.251541473513659e-05,
      "loss": 0.1538,
      "step": 16630
    },
    {
      "epoch": 0.7489085917458032,
      "grad_norm": 1.580297827720642,
      "learning_rate": 9.251091408254198e-05,
      "loss": 0.16,
      "step": 16640
    },
    {
      "epoch": 0.7493586570052657,
      "grad_norm": 3.1273269653320312,
      "learning_rate": 9.250641342994735e-05,
      "loss": 0.1174,
      "step": 16650
    },
    {
      "epoch": 0.7498087222647284,
      "grad_norm": 0.683324933052063,
      "learning_rate": 9.250191277735271e-05,
      "loss": 0.1406,
      "step": 16660
    },
    {
      "epoch": 0.7502587875241911,
      "grad_norm": 3.8269264698028564,
      "learning_rate": 9.24974121247581e-05,
      "loss": 0.1621,
      "step": 16670
    },
    {
      "epoch": 0.7507088527836536,
      "grad_norm": 0.7378717660903931,
      "learning_rate": 9.249291147216347e-05,
      "loss": 0.1611,
      "step": 16680
    },
    {
      "epoch": 0.7511589180431163,
      "grad_norm": 0.46000081300735474,
      "learning_rate": 9.248841081956883e-05,
      "loss": 0.1174,
      "step": 16690
    },
    {
      "epoch": 0.7516089833025789,
      "grad_norm": 1.4203518629074097,
      "learning_rate": 9.248391016697422e-05,
      "loss": 0.1609,
      "step": 16700
    },
    {
      "epoch": 0.7520590485620415,
      "grad_norm": 1.5620003938674927,
      "learning_rate": 9.24794095143796e-05,
      "loss": 0.1846,
      "step": 16710
    },
    {
      "epoch": 0.7525091138215041,
      "grad_norm": 1.323598027229309,
      "learning_rate": 9.247490886178495e-05,
      "loss": 0.1653,
      "step": 16720
    },
    {
      "epoch": 0.7529591790809668,
      "grad_norm": 8.56309986114502,
      "learning_rate": 9.247040820919034e-05,
      "loss": 0.1989,
      "step": 16730
    },
    {
      "epoch": 0.7534092443404293,
      "grad_norm": 3.7867798805236816,
      "learning_rate": 9.246590755659571e-05,
      "loss": 0.1229,
      "step": 16740
    },
    {
      "epoch": 0.753859309599892,
      "grad_norm": 5.117978572845459,
      "learning_rate": 9.246140690400107e-05,
      "loss": 0.1918,
      "step": 16750
    },
    {
      "epoch": 0.7543093748593546,
      "grad_norm": 3.309520959854126,
      "learning_rate": 9.245690625140646e-05,
      "loss": 0.1483,
      "step": 16760
    },
    {
      "epoch": 0.7547594401188172,
      "grad_norm": 0.18607620894908905,
      "learning_rate": 9.245240559881184e-05,
      "loss": 0.1266,
      "step": 16770
    },
    {
      "epoch": 0.7552095053782798,
      "grad_norm": 4.409985065460205,
      "learning_rate": 9.24479049462172e-05,
      "loss": 0.148,
      "step": 16780
    },
    {
      "epoch": 0.7556595706377425,
      "grad_norm": 4.1591081619262695,
      "learning_rate": 9.244340429362258e-05,
      "loss": 0.1393,
      "step": 16790
    },
    {
      "epoch": 0.7561096358972051,
      "grad_norm": 2.2093958854675293,
      "learning_rate": 9.243890364102796e-05,
      "loss": 0.1147,
      "step": 16800
    },
    {
      "epoch": 0.7565597011566677,
      "grad_norm": 1.3231713771820068,
      "learning_rate": 9.243440298843332e-05,
      "loss": 0.1441,
      "step": 16810
    },
    {
      "epoch": 0.7570097664161304,
      "grad_norm": 3.150338888168335,
      "learning_rate": 9.24299023358387e-05,
      "loss": 0.1443,
      "step": 16820
    },
    {
      "epoch": 0.7574598316755929,
      "grad_norm": 0.9539566040039062,
      "learning_rate": 9.242540168324408e-05,
      "loss": 0.1463,
      "step": 16830
    },
    {
      "epoch": 0.7579098969350556,
      "grad_norm": 4.076531887054443,
      "learning_rate": 9.242090103064945e-05,
      "loss": 0.11,
      "step": 16840
    },
    {
      "epoch": 0.7583599621945182,
      "grad_norm": 2.7057571411132812,
      "learning_rate": 9.241640037805482e-05,
      "loss": 0.2277,
      "step": 16850
    },
    {
      "epoch": 0.7588100274539809,
      "grad_norm": 0.8307493925094604,
      "learning_rate": 9.24118997254602e-05,
      "loss": 0.1218,
      "step": 16860
    },
    {
      "epoch": 0.7592600927134434,
      "grad_norm": 1.0674445629119873,
      "learning_rate": 9.240739907286557e-05,
      "loss": 0.11,
      "step": 16870
    },
    {
      "epoch": 0.7597101579729061,
      "grad_norm": 1.5728408098220825,
      "learning_rate": 9.240289842027095e-05,
      "loss": 0.0889,
      "step": 16880
    },
    {
      "epoch": 0.7601602232323686,
      "grad_norm": 4.127352237701416,
      "learning_rate": 9.239839776767632e-05,
      "loss": 0.1635,
      "step": 16890
    },
    {
      "epoch": 0.7606102884918313,
      "grad_norm": 2.582637071609497,
      "learning_rate": 9.239389711508169e-05,
      "loss": 0.1684,
      "step": 16900
    },
    {
      "epoch": 0.7610603537512939,
      "grad_norm": 1.4504468441009521,
      "learning_rate": 9.238939646248707e-05,
      "loss": 0.1696,
      "step": 16910
    },
    {
      "epoch": 0.7615104190107566,
      "grad_norm": 0.7892587184906006,
      "learning_rate": 9.238489580989244e-05,
      "loss": 0.1237,
      "step": 16920
    },
    {
      "epoch": 0.7619604842702192,
      "grad_norm": 2.3245320320129395,
      "learning_rate": 9.238039515729781e-05,
      "loss": 0.1771,
      "step": 16930
    },
    {
      "epoch": 0.7624105495296818,
      "grad_norm": 2.607485294342041,
      "learning_rate": 9.237589450470319e-05,
      "loss": 0.1489,
      "step": 16940
    },
    {
      "epoch": 0.7628606147891445,
      "grad_norm": 1.9054477214813232,
      "learning_rate": 9.237139385210856e-05,
      "loss": 0.147,
      "step": 16950
    },
    {
      "epoch": 0.763310680048607,
      "grad_norm": 1.2250744104385376,
      "learning_rate": 9.236689319951393e-05,
      "loss": 0.1161,
      "step": 16960
    },
    {
      "epoch": 0.7637607453080697,
      "grad_norm": 1.616797685623169,
      "learning_rate": 9.236239254691931e-05,
      "loss": 0.1482,
      "step": 16970
    },
    {
      "epoch": 0.7642108105675323,
      "grad_norm": 0.8446435332298279,
      "learning_rate": 9.235789189432468e-05,
      "loss": 0.149,
      "step": 16980
    },
    {
      "epoch": 0.7646608758269949,
      "grad_norm": 1.8776774406433105,
      "learning_rate": 9.235339124173005e-05,
      "loss": 0.1258,
      "step": 16990
    },
    {
      "epoch": 0.7651109410864575,
      "grad_norm": 2.8326354026794434,
      "learning_rate": 9.234889058913543e-05,
      "loss": 0.1032,
      "step": 17000
    },
    {
      "epoch": 0.7655610063459202,
      "grad_norm": 1.9641565084457397,
      "learning_rate": 9.23443899365408e-05,
      "loss": 0.1297,
      "step": 17010
    },
    {
      "epoch": 0.7660110716053827,
      "grad_norm": 1.9775991439819336,
      "learning_rate": 9.233988928394618e-05,
      "loss": 0.1399,
      "step": 17020
    },
    {
      "epoch": 0.7664611368648454,
      "grad_norm": 4.441198825836182,
      "learning_rate": 9.233538863135155e-05,
      "loss": 0.1798,
      "step": 17030
    },
    {
      "epoch": 0.7669112021243081,
      "grad_norm": 3.791489839553833,
      "learning_rate": 9.233088797875692e-05,
      "loss": 0.18,
      "step": 17040
    },
    {
      "epoch": 0.7673612673837706,
      "grad_norm": 2.1068546772003174,
      "learning_rate": 9.23263873261623e-05,
      "loss": 0.1218,
      "step": 17050
    },
    {
      "epoch": 0.7678113326432333,
      "grad_norm": 1.4162602424621582,
      "learning_rate": 9.232188667356767e-05,
      "loss": 0.1186,
      "step": 17060
    },
    {
      "epoch": 0.7682613979026959,
      "grad_norm": 2.5225491523742676,
      "learning_rate": 9.231738602097304e-05,
      "loss": 0.1189,
      "step": 17070
    },
    {
      "epoch": 0.7687114631621585,
      "grad_norm": 5.676379203796387,
      "learning_rate": 9.231288536837842e-05,
      "loss": 0.1548,
      "step": 17080
    },
    {
      "epoch": 0.7691615284216211,
      "grad_norm": 2.115676164627075,
      "learning_rate": 9.230838471578379e-05,
      "loss": 0.138,
      "step": 17090
    },
    {
      "epoch": 0.7696115936810838,
      "grad_norm": 3.9808189868927,
      "learning_rate": 9.230388406318918e-05,
      "loss": 0.2069,
      "step": 17100
    },
    {
      "epoch": 0.7700616589405463,
      "grad_norm": 0.557465672492981,
      "learning_rate": 9.229938341059454e-05,
      "loss": 0.1483,
      "step": 17110
    },
    {
      "epoch": 0.770511724200009,
      "grad_norm": 1.0572724342346191,
      "learning_rate": 9.229488275799991e-05,
      "loss": 0.1834,
      "step": 17120
    },
    {
      "epoch": 0.7709617894594716,
      "grad_norm": 6.1835737228393555,
      "learning_rate": 9.22903821054053e-05,
      "loss": 0.2022,
      "step": 17130
    },
    {
      "epoch": 0.7714118547189343,
      "grad_norm": 5.54265832901001,
      "learning_rate": 9.228588145281066e-05,
      "loss": 0.1242,
      "step": 17140
    },
    {
      "epoch": 0.7718619199783968,
      "grad_norm": 0.35579556226730347,
      "learning_rate": 9.228138080021603e-05,
      "loss": 0.1943,
      "step": 17150
    },
    {
      "epoch": 0.7723119852378595,
      "grad_norm": 1.8084031343460083,
      "learning_rate": 9.227688014762142e-05,
      "loss": 0.1129,
      "step": 17160
    },
    {
      "epoch": 0.7727620504973222,
      "grad_norm": 1.9317880868911743,
      "learning_rate": 9.227237949502678e-05,
      "loss": 0.1384,
      "step": 17170
    },
    {
      "epoch": 0.7732121157567847,
      "grad_norm": 1.5163383483886719,
      "learning_rate": 9.226787884243215e-05,
      "loss": 0.1405,
      "step": 17180
    },
    {
      "epoch": 0.7736621810162474,
      "grad_norm": 1.7061249017715454,
      "learning_rate": 9.226337818983754e-05,
      "loss": 0.1458,
      "step": 17190
    },
    {
      "epoch": 0.77411224627571,
      "grad_norm": 2.9696953296661377,
      "learning_rate": 9.22588775372429e-05,
      "loss": 0.1633,
      "step": 17200
    },
    {
      "epoch": 0.7745623115351726,
      "grad_norm": 1.7004817724227905,
      "learning_rate": 9.225437688464827e-05,
      "loss": 0.1042,
      "step": 17210
    },
    {
      "epoch": 0.7750123767946352,
      "grad_norm": 2.4743950366973877,
      "learning_rate": 9.224987623205366e-05,
      "loss": 0.1461,
      "step": 17220
    },
    {
      "epoch": 0.7754624420540979,
      "grad_norm": 3.0676138401031494,
      "learning_rate": 9.224537557945902e-05,
      "loss": 0.1421,
      "step": 17230
    },
    {
      "epoch": 0.7759125073135604,
      "grad_norm": 1.1921775341033936,
      "learning_rate": 9.22408749268644e-05,
      "loss": 0.1273,
      "step": 17240
    },
    {
      "epoch": 0.7763625725730231,
      "grad_norm": 4.718379497528076,
      "learning_rate": 9.223637427426978e-05,
      "loss": 0.1154,
      "step": 17250
    },
    {
      "epoch": 0.7768126378324857,
      "grad_norm": 4.708554267883301,
      "learning_rate": 9.223187362167514e-05,
      "loss": 0.1302,
      "step": 17260
    },
    {
      "epoch": 0.7772627030919483,
      "grad_norm": 5.537763595581055,
      "learning_rate": 9.222737296908052e-05,
      "loss": 0.1346,
      "step": 17270
    },
    {
      "epoch": 0.7777127683514109,
      "grad_norm": 2.5620737075805664,
      "learning_rate": 9.22228723164859e-05,
      "loss": 0.1249,
      "step": 17280
    },
    {
      "epoch": 0.7781628336108736,
      "grad_norm": 0.7639665007591248,
      "learning_rate": 9.221837166389126e-05,
      "loss": 0.1148,
      "step": 17290
    },
    {
      "epoch": 0.7786128988703362,
      "grad_norm": 2.495435953140259,
      "learning_rate": 9.221387101129664e-05,
      "loss": 0.1704,
      "step": 17300
    },
    {
      "epoch": 0.7790629641297988,
      "grad_norm": 0.9222325682640076,
      "learning_rate": 9.220937035870202e-05,
      "loss": 0.181,
      "step": 17310
    },
    {
      "epoch": 0.7795130293892615,
      "grad_norm": 2.2321622371673584,
      "learning_rate": 9.220486970610738e-05,
      "loss": 0.1187,
      "step": 17320
    },
    {
      "epoch": 0.779963094648724,
      "grad_norm": 2.3704278469085693,
      "learning_rate": 9.220036905351276e-05,
      "loss": 0.1608,
      "step": 17330
    },
    {
      "epoch": 0.7804131599081867,
      "grad_norm": 3.5955145359039307,
      "learning_rate": 9.219586840091814e-05,
      "loss": 0.145,
      "step": 17340
    },
    {
      "epoch": 0.7808632251676493,
      "grad_norm": 0.30701199173927307,
      "learning_rate": 9.21913677483235e-05,
      "loss": 0.1294,
      "step": 17350
    },
    {
      "epoch": 0.781313290427112,
      "grad_norm": 6.061793804168701,
      "learning_rate": 9.218686709572889e-05,
      "loss": 0.1702,
      "step": 17360
    },
    {
      "epoch": 0.7817633556865745,
      "grad_norm": 2.731043815612793,
      "learning_rate": 9.218236644313427e-05,
      "loss": 0.1343,
      "step": 17370
    },
    {
      "epoch": 0.7822134209460372,
      "grad_norm": 2.031649351119995,
      "learning_rate": 9.217786579053963e-05,
      "loss": 0.1362,
      "step": 17380
    },
    {
      "epoch": 0.7826634862054997,
      "grad_norm": 4.35007905960083,
      "learning_rate": 9.217336513794501e-05,
      "loss": 0.1427,
      "step": 17390
    },
    {
      "epoch": 0.7831135514649624,
      "grad_norm": 3.136857509613037,
      "learning_rate": 9.216886448535039e-05,
      "loss": 0.1293,
      "step": 17400
    },
    {
      "epoch": 0.7835636167244251,
      "grad_norm": 1.6426923274993896,
      "learning_rate": 9.216436383275575e-05,
      "loss": 0.1833,
      "step": 17410
    },
    {
      "epoch": 0.7840136819838877,
      "grad_norm": 6.118438243865967,
      "learning_rate": 9.215986318016113e-05,
      "loss": 0.1349,
      "step": 17420
    },
    {
      "epoch": 0.7844637472433503,
      "grad_norm": 2.3990187644958496,
      "learning_rate": 9.215536252756651e-05,
      "loss": 0.1243,
      "step": 17430
    },
    {
      "epoch": 0.7849138125028129,
      "grad_norm": 1.9955055713653564,
      "learning_rate": 9.215086187497187e-05,
      "loss": 0.1154,
      "step": 17440
    },
    {
      "epoch": 0.7853638777622756,
      "grad_norm": 3.806432008743286,
      "learning_rate": 9.214636122237725e-05,
      "loss": 0.1492,
      "step": 17450
    },
    {
      "epoch": 0.7858139430217381,
      "grad_norm": 0.8865319490432739,
      "learning_rate": 9.214186056978263e-05,
      "loss": 0.1359,
      "step": 17460
    },
    {
      "epoch": 0.7862640082812008,
      "grad_norm": 1.167365312576294,
      "learning_rate": 9.213735991718799e-05,
      "loss": 0.1187,
      "step": 17470
    },
    {
      "epoch": 0.7867140735406634,
      "grad_norm": 3.5649936199188232,
      "learning_rate": 9.213285926459338e-05,
      "loss": 0.1269,
      "step": 17480
    },
    {
      "epoch": 0.787164138800126,
      "grad_norm": 3.3876075744628906,
      "learning_rate": 9.212835861199875e-05,
      "loss": 0.1469,
      "step": 17490
    },
    {
      "epoch": 0.7876142040595886,
      "grad_norm": 1.8177564144134521,
      "learning_rate": 9.212385795940411e-05,
      "loss": 0.1319,
      "step": 17500
    },
    {
      "epoch": 0.7880642693190513,
      "grad_norm": 0.9812599420547485,
      "learning_rate": 9.21193573068095e-05,
      "loss": 0.1545,
      "step": 17510
    },
    {
      "epoch": 0.7885143345785138,
      "grad_norm": 0.6003332138061523,
      "learning_rate": 9.211485665421487e-05,
      "loss": 0.1237,
      "step": 17520
    },
    {
      "epoch": 0.7889643998379765,
      "grad_norm": 2.509955644607544,
      "learning_rate": 9.211035600162023e-05,
      "loss": 0.1296,
      "step": 17530
    },
    {
      "epoch": 0.7894144650974392,
      "grad_norm": 0.8351231813430786,
      "learning_rate": 9.210585534902562e-05,
      "loss": 0.1275,
      "step": 17540
    },
    {
      "epoch": 0.7898645303569017,
      "grad_norm": 2.0382394790649414,
      "learning_rate": 9.210135469643099e-05,
      "loss": 0.1037,
      "step": 17550
    },
    {
      "epoch": 0.7903145956163644,
      "grad_norm": 0.9527712464332581,
      "learning_rate": 9.209685404383635e-05,
      "loss": 0.1262,
      "step": 17560
    },
    {
      "epoch": 0.790764660875827,
      "grad_norm": 0.5973502993583679,
      "learning_rate": 9.209235339124174e-05,
      "loss": 0.1117,
      "step": 17570
    },
    {
      "epoch": 0.7912147261352896,
      "grad_norm": 2.4449329376220703,
      "learning_rate": 9.208785273864711e-05,
      "loss": 0.1348,
      "step": 17580
    },
    {
      "epoch": 0.7916647913947522,
      "grad_norm": 3.6282436847686768,
      "learning_rate": 9.208335208605247e-05,
      "loss": 0.1392,
      "step": 17590
    },
    {
      "epoch": 0.7921148566542149,
      "grad_norm": 1.6372612714767456,
      "learning_rate": 9.207885143345786e-05,
      "loss": 0.1777,
      "step": 17600
    },
    {
      "epoch": 0.7925649219136774,
      "grad_norm": 2.7582051753997803,
      "learning_rate": 9.207435078086323e-05,
      "loss": 0.1743,
      "step": 17610
    },
    {
      "epoch": 0.7930149871731401,
      "grad_norm": 2.7249600887298584,
      "learning_rate": 9.20698501282686e-05,
      "loss": 0.1585,
      "step": 17620
    },
    {
      "epoch": 0.7934650524326027,
      "grad_norm": 1.3243719339370728,
      "learning_rate": 9.206534947567398e-05,
      "loss": 0.1626,
      "step": 17630
    },
    {
      "epoch": 0.7939151176920654,
      "grad_norm": 1.4075901508331299,
      "learning_rate": 9.206084882307935e-05,
      "loss": 0.1159,
      "step": 17640
    },
    {
      "epoch": 0.794365182951528,
      "grad_norm": 3.2436864376068115,
      "learning_rate": 9.205634817048473e-05,
      "loss": 0.1694,
      "step": 17650
    },
    {
      "epoch": 0.7948152482109906,
      "grad_norm": 4.217824935913086,
      "learning_rate": 9.20518475178901e-05,
      "loss": 0.1501,
      "step": 17660
    },
    {
      "epoch": 0.7952653134704533,
      "grad_norm": 3.7079339027404785,
      "learning_rate": 9.204734686529547e-05,
      "loss": 0.12,
      "step": 17670
    },
    {
      "epoch": 0.7957153787299158,
      "grad_norm": 0.793079137802124,
      "learning_rate": 9.204284621270085e-05,
      "loss": 0.1184,
      "step": 17680
    },
    {
      "epoch": 0.7961654439893785,
      "grad_norm": 2.0903120040893555,
      "learning_rate": 9.203834556010622e-05,
      "loss": 0.1751,
      "step": 17690
    },
    {
      "epoch": 0.7966155092488411,
      "grad_norm": 3.8195462226867676,
      "learning_rate": 9.20338449075116e-05,
      "loss": 0.174,
      "step": 17700
    },
    {
      "epoch": 0.7970655745083037,
      "grad_norm": 2.911067247390747,
      "learning_rate": 9.202934425491697e-05,
      "loss": 0.1102,
      "step": 17710
    },
    {
      "epoch": 0.7975156397677663,
      "grad_norm": 1.7895578145980835,
      "learning_rate": 9.202484360232234e-05,
      "loss": 0.1816,
      "step": 17720
    },
    {
      "epoch": 0.797965705027229,
      "grad_norm": 2.5023751258850098,
      "learning_rate": 9.202034294972772e-05,
      "loss": 0.17,
      "step": 17730
    },
    {
      "epoch": 0.7984157702866915,
      "grad_norm": 1.9271093606948853,
      "learning_rate": 9.201584229713309e-05,
      "loss": 0.1076,
      "step": 17740
    },
    {
      "epoch": 0.7988658355461542,
      "grad_norm": 3.0933990478515625,
      "learning_rate": 9.201134164453846e-05,
      "loss": 0.1035,
      "step": 17750
    },
    {
      "epoch": 0.7993159008056168,
      "grad_norm": 2.015049457550049,
      "learning_rate": 9.200684099194384e-05,
      "loss": 0.1239,
      "step": 17760
    },
    {
      "epoch": 0.7997659660650794,
      "grad_norm": 2.3992063999176025,
      "learning_rate": 9.200234033934921e-05,
      "loss": 0.1065,
      "step": 17770
    },
    {
      "epoch": 0.8002160313245421,
      "grad_norm": 2.0576348304748535,
      "learning_rate": 9.199783968675458e-05,
      "loss": 0.083,
      "step": 17780
    },
    {
      "epoch": 0.8006660965840047,
      "grad_norm": 1.3129780292510986,
      "learning_rate": 9.199333903415996e-05,
      "loss": 0.1792,
      "step": 17790
    },
    {
      "epoch": 0.8011161618434673,
      "grad_norm": 5.192595481872559,
      "learning_rate": 9.198883838156533e-05,
      "loss": 0.1683,
      "step": 17800
    },
    {
      "epoch": 0.8015662271029299,
      "grad_norm": 2.670334577560425,
      "learning_rate": 9.19843377289707e-05,
      "loss": 0.1593,
      "step": 17810
    },
    {
      "epoch": 0.8020162923623926,
      "grad_norm": 3.9704627990722656,
      "learning_rate": 9.197983707637608e-05,
      "loss": 0.1536,
      "step": 17820
    },
    {
      "epoch": 0.8024663576218551,
      "grad_norm": 3.0390102863311768,
      "learning_rate": 9.197533642378145e-05,
      "loss": 0.146,
      "step": 17830
    },
    {
      "epoch": 0.8029164228813178,
      "grad_norm": 4.070493221282959,
      "learning_rate": 9.197083577118682e-05,
      "loss": 0.1483,
      "step": 17840
    },
    {
      "epoch": 0.8033664881407804,
      "grad_norm": 4.461430072784424,
      "learning_rate": 9.19663351185922e-05,
      "loss": 0.1095,
      "step": 17850
    },
    {
      "epoch": 0.803816553400243,
      "grad_norm": 5.537361145019531,
      "learning_rate": 9.196183446599757e-05,
      "loss": 0.1998,
      "step": 17860
    },
    {
      "epoch": 0.8042666186597056,
      "grad_norm": 3.052152156829834,
      "learning_rate": 9.195733381340295e-05,
      "loss": 0.1153,
      "step": 17870
    },
    {
      "epoch": 0.8047166839191683,
      "grad_norm": 1.8531025648117065,
      "learning_rate": 9.195283316080833e-05,
      "loss": 0.104,
      "step": 17880
    },
    {
      "epoch": 0.8051667491786308,
      "grad_norm": 2.3409578800201416,
      "learning_rate": 9.194833250821369e-05,
      "loss": 0.1295,
      "step": 17890
    },
    {
      "epoch": 0.8056168144380935,
      "grad_norm": 2.5926835536956787,
      "learning_rate": 9.194383185561907e-05,
      "loss": 0.195,
      "step": 17900
    },
    {
      "epoch": 0.8060668796975562,
      "grad_norm": 5.483746528625488,
      "learning_rate": 9.193933120302445e-05,
      "loss": 0.1175,
      "step": 17910
    },
    {
      "epoch": 0.8065169449570188,
      "grad_norm": 3.101273775100708,
      "learning_rate": 9.193483055042981e-05,
      "loss": 0.1223,
      "step": 17920
    },
    {
      "epoch": 0.8069670102164814,
      "grad_norm": 2.746648073196411,
      "learning_rate": 9.193032989783519e-05,
      "loss": 0.1215,
      "step": 17930
    },
    {
      "epoch": 0.807417075475944,
      "grad_norm": 3.055281639099121,
      "learning_rate": 9.192582924524057e-05,
      "loss": 0.1568,
      "step": 17940
    },
    {
      "epoch": 0.8078671407354067,
      "grad_norm": 2.548034429550171,
      "learning_rate": 9.192132859264593e-05,
      "loss": 0.1137,
      "step": 17950
    },
    {
      "epoch": 0.8083172059948692,
      "grad_norm": 2.907315969467163,
      "learning_rate": 9.191682794005131e-05,
      "loss": 0.1285,
      "step": 17960
    },
    {
      "epoch": 0.8087672712543319,
      "grad_norm": 4.63835334777832,
      "learning_rate": 9.19123272874567e-05,
      "loss": 0.1547,
      "step": 17970
    },
    {
      "epoch": 0.8092173365137945,
      "grad_norm": 2.896240711212158,
      "learning_rate": 9.190782663486206e-05,
      "loss": 0.1081,
      "step": 17980
    },
    {
      "epoch": 0.8096674017732571,
      "grad_norm": 3.45812726020813,
      "learning_rate": 9.190332598226743e-05,
      "loss": 0.2193,
      "step": 17990
    },
    {
      "epoch": 0.8101174670327197,
      "grad_norm": 3.5115513801574707,
      "learning_rate": 9.189882532967282e-05,
      "loss": 0.1194,
      "step": 18000
    },
    {
      "epoch": 0.8105675322921824,
      "grad_norm": 2.6138758659362793,
      "learning_rate": 9.189432467707818e-05,
      "loss": 0.1523,
      "step": 18010
    },
    {
      "epoch": 0.811017597551645,
      "grad_norm": 7.997592449188232,
      "learning_rate": 9.188982402448355e-05,
      "loss": 0.1821,
      "step": 18020
    },
    {
      "epoch": 0.8114676628111076,
      "grad_norm": 3.4923362731933594,
      "learning_rate": 9.188532337188894e-05,
      "loss": 0.1257,
      "step": 18030
    },
    {
      "epoch": 0.8119177280705703,
      "grad_norm": 2.944624662399292,
      "learning_rate": 9.18808227192943e-05,
      "loss": 0.1486,
      "step": 18040
    },
    {
      "epoch": 0.8123677933300328,
      "grad_norm": 1.1262832880020142,
      "learning_rate": 9.187632206669967e-05,
      "loss": 0.1326,
      "step": 18050
    },
    {
      "epoch": 0.8128178585894955,
      "grad_norm": 4.726383686065674,
      "learning_rate": 9.187182141410506e-05,
      "loss": 0.1244,
      "step": 18060
    },
    {
      "epoch": 0.8132679238489581,
      "grad_norm": 3.143449306488037,
      "learning_rate": 9.186732076151042e-05,
      "loss": 0.1193,
      "step": 18070
    },
    {
      "epoch": 0.8137179891084207,
      "grad_norm": 6.842077255249023,
      "learning_rate": 9.186282010891579e-05,
      "loss": 0.2,
      "step": 18080
    },
    {
      "epoch": 0.8141680543678833,
      "grad_norm": 3.7314324378967285,
      "learning_rate": 9.185831945632118e-05,
      "loss": 0.151,
      "step": 18090
    },
    {
      "epoch": 0.814618119627346,
      "grad_norm": 4.939847469329834,
      "learning_rate": 9.185381880372654e-05,
      "loss": 0.1306,
      "step": 18100
    },
    {
      "epoch": 0.8150681848868085,
      "grad_norm": 1.4172877073287964,
      "learning_rate": 9.184931815113191e-05,
      "loss": 0.1446,
      "step": 18110
    },
    {
      "epoch": 0.8155182501462712,
      "grad_norm": 0.107855886220932,
      "learning_rate": 9.18448174985373e-05,
      "loss": 0.1232,
      "step": 18120
    },
    {
      "epoch": 0.8159683154057338,
      "grad_norm": 1.071458339691162,
      "learning_rate": 9.184031684594266e-05,
      "loss": 0.1028,
      "step": 18130
    },
    {
      "epoch": 0.8164183806651965,
      "grad_norm": 2.288278102874756,
      "learning_rate": 9.183581619334803e-05,
      "loss": 0.13,
      "step": 18140
    },
    {
      "epoch": 0.8168684459246591,
      "grad_norm": 3.71799635887146,
      "learning_rate": 9.183131554075342e-05,
      "loss": 0.1233,
      "step": 18150
    },
    {
      "epoch": 0.8173185111841217,
      "grad_norm": 3.9585459232330322,
      "learning_rate": 9.182681488815878e-05,
      "loss": 0.1373,
      "step": 18160
    },
    {
      "epoch": 0.8177685764435844,
      "grad_norm": 1.2635184526443481,
      "learning_rate": 9.182231423556417e-05,
      "loss": 0.149,
      "step": 18170
    },
    {
      "epoch": 0.8182186417030469,
      "grad_norm": 2.169806480407715,
      "learning_rate": 9.181781358296954e-05,
      "loss": 0.1388,
      "step": 18180
    },
    {
      "epoch": 0.8186687069625096,
      "grad_norm": 1.0393073558807373,
      "learning_rate": 9.18133129303749e-05,
      "loss": 0.1239,
      "step": 18190
    },
    {
      "epoch": 0.8191187722219722,
      "grad_norm": 7.200502872467041,
      "learning_rate": 9.180881227778029e-05,
      "loss": 0.1035,
      "step": 18200
    },
    {
      "epoch": 0.8195688374814348,
      "grad_norm": 3.880626678466797,
      "learning_rate": 9.180431162518566e-05,
      "loss": 0.1198,
      "step": 18210
    },
    {
      "epoch": 0.8200189027408974,
      "grad_norm": 4.868533611297607,
      "learning_rate": 9.179981097259102e-05,
      "loss": 0.1517,
      "step": 18220
    },
    {
      "epoch": 0.8204689680003601,
      "grad_norm": 1.6461901664733887,
      "learning_rate": 9.179531031999641e-05,
      "loss": 0.1576,
      "step": 18230
    },
    {
      "epoch": 0.8209190332598226,
      "grad_norm": 3.8889575004577637,
      "learning_rate": 9.179080966740178e-05,
      "loss": 0.1338,
      "step": 18240
    },
    {
      "epoch": 0.8213690985192853,
      "grad_norm": 2.600682258605957,
      "learning_rate": 9.178630901480714e-05,
      "loss": 0.1534,
      "step": 18250
    },
    {
      "epoch": 0.8218191637787479,
      "grad_norm": 2.7547059059143066,
      "learning_rate": 9.178180836221253e-05,
      "loss": 0.1505,
      "step": 18260
    },
    {
      "epoch": 0.8222692290382105,
      "grad_norm": 4.080878257751465,
      "learning_rate": 9.17773077096179e-05,
      "loss": 0.1471,
      "step": 18270
    },
    {
      "epoch": 0.8227192942976732,
      "grad_norm": 3.8701961040496826,
      "learning_rate": 9.177280705702326e-05,
      "loss": 0.1307,
      "step": 18280
    },
    {
      "epoch": 0.8231693595571358,
      "grad_norm": 1.9950637817382812,
      "learning_rate": 9.176830640442865e-05,
      "loss": 0.1817,
      "step": 18290
    },
    {
      "epoch": 0.8236194248165984,
      "grad_norm": 1.9104334115982056,
      "learning_rate": 9.176380575183402e-05,
      "loss": 0.0829,
      "step": 18300
    },
    {
      "epoch": 0.824069490076061,
      "grad_norm": 2.5181615352630615,
      "learning_rate": 9.175930509923938e-05,
      "loss": 0.1777,
      "step": 18310
    },
    {
      "epoch": 0.8245195553355237,
      "grad_norm": 3.371283769607544,
      "learning_rate": 9.175480444664477e-05,
      "loss": 0.1292,
      "step": 18320
    },
    {
      "epoch": 0.8249696205949862,
      "grad_norm": 3.4520392417907715,
      "learning_rate": 9.175030379405014e-05,
      "loss": 0.082,
      "step": 18330
    },
    {
      "epoch": 0.8254196858544489,
      "grad_norm": 1.5205352306365967,
      "learning_rate": 9.17458031414555e-05,
      "loss": 0.1353,
      "step": 18340
    },
    {
      "epoch": 0.8258697511139115,
      "grad_norm": 1.6400233507156372,
      "learning_rate": 9.174130248886089e-05,
      "loss": 0.114,
      "step": 18350
    },
    {
      "epoch": 0.8263198163733741,
      "grad_norm": 2.9049482345581055,
      "learning_rate": 9.173680183626627e-05,
      "loss": 0.1574,
      "step": 18360
    },
    {
      "epoch": 0.8267698816328367,
      "grad_norm": 1.5425869226455688,
      "learning_rate": 9.173230118367163e-05,
      "loss": 0.1525,
      "step": 18370
    },
    {
      "epoch": 0.8272199468922994,
      "grad_norm": 3.424471378326416,
      "learning_rate": 9.172780053107701e-05,
      "loss": 0.1173,
      "step": 18380
    },
    {
      "epoch": 0.8276700121517621,
      "grad_norm": 7.012673377990723,
      "learning_rate": 9.172329987848239e-05,
      "loss": 0.1417,
      "step": 18390
    },
    {
      "epoch": 0.8281200774112246,
      "grad_norm": 3.1587910652160645,
      "learning_rate": 9.171879922588775e-05,
      "loss": 0.1399,
      "step": 18400
    },
    {
      "epoch": 0.8285701426706873,
      "grad_norm": 1.294756293296814,
      "learning_rate": 9.171429857329313e-05,
      "loss": 0.1189,
      "step": 18410
    },
    {
      "epoch": 0.8290202079301499,
      "grad_norm": 1.2688673734664917,
      "learning_rate": 9.170979792069851e-05,
      "loss": 0.122,
      "step": 18420
    },
    {
      "epoch": 0.8294702731896125,
      "grad_norm": 2.9548895359039307,
      "learning_rate": 9.170529726810388e-05,
      "loss": 0.1166,
      "step": 18430
    },
    {
      "epoch": 0.8299203384490751,
      "grad_norm": 3.9567627906799316,
      "learning_rate": 9.170079661550925e-05,
      "loss": 0.1182,
      "step": 18440
    },
    {
      "epoch": 0.8303704037085378,
      "grad_norm": 4.042390823364258,
      "learning_rate": 9.169629596291463e-05,
      "loss": 0.1829,
      "step": 18450
    },
    {
      "epoch": 0.8308204689680003,
      "grad_norm": 2.910024404525757,
      "learning_rate": 9.169179531032e-05,
      "loss": 0.139,
      "step": 18460
    },
    {
      "epoch": 0.831270534227463,
      "grad_norm": 4.6999711990356445,
      "learning_rate": 9.168729465772538e-05,
      "loss": 0.1616,
      "step": 18470
    },
    {
      "epoch": 0.8317205994869256,
      "grad_norm": 4.356289863586426,
      "learning_rate": 9.168279400513075e-05,
      "loss": 0.1017,
      "step": 18480
    },
    {
      "epoch": 0.8321706647463882,
      "grad_norm": 3.2559635639190674,
      "learning_rate": 9.167829335253612e-05,
      "loss": 0.1125,
      "step": 18490
    },
    {
      "epoch": 0.8326207300058508,
      "grad_norm": 0.6573967337608337,
      "learning_rate": 9.16737926999415e-05,
      "loss": 0.0855,
      "step": 18500
    },
    {
      "epoch": 0.8330707952653135,
      "grad_norm": 0.6509031653404236,
      "learning_rate": 9.166929204734687e-05,
      "loss": 0.111,
      "step": 18510
    },
    {
      "epoch": 0.8335208605247761,
      "grad_norm": 3.1050851345062256,
      "learning_rate": 9.166479139475224e-05,
      "loss": 0.1042,
      "step": 18520
    },
    {
      "epoch": 0.8339709257842387,
      "grad_norm": 1.0648406744003296,
      "learning_rate": 9.166029074215762e-05,
      "loss": 0.1246,
      "step": 18530
    },
    {
      "epoch": 0.8344209910437014,
      "grad_norm": 5.229645252227783,
      "learning_rate": 9.165579008956299e-05,
      "loss": 0.1356,
      "step": 18540
    },
    {
      "epoch": 0.8348710563031639,
      "grad_norm": 3.6591432094573975,
      "learning_rate": 9.165128943696836e-05,
      "loss": 0.1506,
      "step": 18550
    },
    {
      "epoch": 0.8353211215626266,
      "grad_norm": 2.729477643966675,
      "learning_rate": 9.164678878437374e-05,
      "loss": 0.1388,
      "step": 18560
    },
    {
      "epoch": 0.8357711868220892,
      "grad_norm": 2.602220058441162,
      "learning_rate": 9.164228813177911e-05,
      "loss": 0.1428,
      "step": 18570
    },
    {
      "epoch": 0.8362212520815518,
      "grad_norm": 2.064692974090576,
      "learning_rate": 9.163778747918449e-05,
      "loss": 0.1588,
      "step": 18580
    },
    {
      "epoch": 0.8366713173410144,
      "grad_norm": 0.8974580764770508,
      "learning_rate": 9.163328682658986e-05,
      "loss": 0.1069,
      "step": 18590
    },
    {
      "epoch": 0.8371213826004771,
      "grad_norm": 3.350451946258545,
      "learning_rate": 9.162878617399523e-05,
      "loss": 0.1564,
      "step": 18600
    },
    {
      "epoch": 0.8375714478599396,
      "grad_norm": 0.6297135949134827,
      "learning_rate": 9.16242855214006e-05,
      "loss": 0.1056,
      "step": 18610
    },
    {
      "epoch": 0.8380215131194023,
      "grad_norm": 1.1152896881103516,
      "learning_rate": 9.161978486880598e-05,
      "loss": 0.2023,
      "step": 18620
    },
    {
      "epoch": 0.838471578378865,
      "grad_norm": 3.5409765243530273,
      "learning_rate": 9.161528421621135e-05,
      "loss": 0.1404,
      "step": 18630
    },
    {
      "epoch": 0.8389216436383276,
      "grad_norm": 3.3987574577331543,
      "learning_rate": 9.161078356361673e-05,
      "loss": 0.1211,
      "step": 18640
    },
    {
      "epoch": 0.8393717088977902,
      "grad_norm": 0.9276980757713318,
      "learning_rate": 9.16062829110221e-05,
      "loss": 0.1187,
      "step": 18650
    },
    {
      "epoch": 0.8398217741572528,
      "grad_norm": 1.7880051136016846,
      "learning_rate": 9.160178225842747e-05,
      "loss": 0.1088,
      "step": 18660
    },
    {
      "epoch": 0.8402718394167155,
      "grad_norm": 1.8774569034576416,
      "learning_rate": 9.159728160583285e-05,
      "loss": 0.1105,
      "step": 18670
    },
    {
      "epoch": 0.840721904676178,
      "grad_norm": 4.945840835571289,
      "learning_rate": 9.159278095323822e-05,
      "loss": 0.1492,
      "step": 18680
    },
    {
      "epoch": 0.8411719699356407,
      "grad_norm": 2.4843571186065674,
      "learning_rate": 9.158828030064361e-05,
      "loss": 0.1679,
      "step": 18690
    },
    {
      "epoch": 0.8416220351951033,
      "grad_norm": 2.2045414447784424,
      "learning_rate": 9.158377964804897e-05,
      "loss": 0.1311,
      "step": 18700
    },
    {
      "epoch": 0.8420721004545659,
      "grad_norm": 1.1792408227920532,
      "learning_rate": 9.157927899545434e-05,
      "loss": 0.0705,
      "step": 18710
    },
    {
      "epoch": 0.8425221657140285,
      "grad_norm": 5.917766094207764,
      "learning_rate": 9.157477834285973e-05,
      "loss": 0.1504,
      "step": 18720
    },
    {
      "epoch": 0.8429722309734912,
      "grad_norm": 3.1944310665130615,
      "learning_rate": 9.157027769026509e-05,
      "loss": 0.1252,
      "step": 18730
    },
    {
      "epoch": 0.8434222962329537,
      "grad_norm": 1.3184089660644531,
      "learning_rate": 9.156577703767046e-05,
      "loss": 0.1226,
      "step": 18740
    },
    {
      "epoch": 0.8438723614924164,
      "grad_norm": 6.401217937469482,
      "learning_rate": 9.156127638507585e-05,
      "loss": 0.1534,
      "step": 18750
    },
    {
      "epoch": 0.8443224267518791,
      "grad_norm": 1.8715286254882812,
      "learning_rate": 9.155677573248121e-05,
      "loss": 0.1899,
      "step": 18760
    },
    {
      "epoch": 0.8447724920113416,
      "grad_norm": 3.385608673095703,
      "learning_rate": 9.155227507988658e-05,
      "loss": 0.1237,
      "step": 18770
    },
    {
      "epoch": 0.8452225572708043,
      "grad_norm": 2.551588773727417,
      "learning_rate": 9.154777442729197e-05,
      "loss": 0.1401,
      "step": 18780
    },
    {
      "epoch": 0.8456726225302669,
      "grad_norm": 2.1310722827911377,
      "learning_rate": 9.154327377469733e-05,
      "loss": 0.1719,
      "step": 18790
    },
    {
      "epoch": 0.8461226877897295,
      "grad_norm": 3.074324131011963,
      "learning_rate": 9.15387731221027e-05,
      "loss": 0.1186,
      "step": 18800
    },
    {
      "epoch": 0.8465727530491921,
      "grad_norm": 0.88127201795578,
      "learning_rate": 9.153427246950809e-05,
      "loss": 0.1033,
      "step": 18810
    },
    {
      "epoch": 0.8470228183086548,
      "grad_norm": 2.2751431465148926,
      "learning_rate": 9.152977181691345e-05,
      "loss": 0.1239,
      "step": 18820
    },
    {
      "epoch": 0.8474728835681173,
      "grad_norm": 0.7994321584701538,
      "learning_rate": 9.152527116431883e-05,
      "loss": 0.1065,
      "step": 18830
    },
    {
      "epoch": 0.84792294882758,
      "grad_norm": 1.254898190498352,
      "learning_rate": 9.152077051172421e-05,
      "loss": 0.1549,
      "step": 18840
    },
    {
      "epoch": 0.8483730140870426,
      "grad_norm": 4.882152080535889,
      "learning_rate": 9.151626985912957e-05,
      "loss": 0.1583,
      "step": 18850
    },
    {
      "epoch": 0.8488230793465052,
      "grad_norm": 1.7512731552124023,
      "learning_rate": 9.151176920653495e-05,
      "loss": 0.1429,
      "step": 18860
    },
    {
      "epoch": 0.8492731446059678,
      "grad_norm": 2.6266589164733887,
      "learning_rate": 9.150726855394033e-05,
      "loss": 0.1285,
      "step": 18870
    },
    {
      "epoch": 0.8497232098654305,
      "grad_norm": 1.5804643630981445,
      "learning_rate": 9.150276790134569e-05,
      "loss": 0.1144,
      "step": 18880
    },
    {
      "epoch": 0.8501732751248932,
      "grad_norm": 4.347955226898193,
      "learning_rate": 9.149826724875107e-05,
      "loss": 0.2336,
      "step": 18890
    },
    {
      "epoch": 0.8506233403843557,
      "grad_norm": 2.9436724185943604,
      "learning_rate": 9.149376659615645e-05,
      "loss": 0.0771,
      "step": 18900
    },
    {
      "epoch": 0.8510734056438184,
      "grad_norm": 5.633575916290283,
      "learning_rate": 9.148926594356181e-05,
      "loss": 0.179,
      "step": 18910
    },
    {
      "epoch": 0.851523470903281,
      "grad_norm": 3.766378402709961,
      "learning_rate": 9.148476529096719e-05,
      "loss": 0.14,
      "step": 18920
    },
    {
      "epoch": 0.8519735361627436,
      "grad_norm": 1.5927655696868896,
      "learning_rate": 9.148026463837257e-05,
      "loss": 0.0694,
      "step": 18930
    },
    {
      "epoch": 0.8524236014222062,
      "grad_norm": 4.541767597198486,
      "learning_rate": 9.147576398577793e-05,
      "loss": 0.1124,
      "step": 18940
    },
    {
      "epoch": 0.8528736666816689,
      "grad_norm": 2.6369271278381348,
      "learning_rate": 9.147126333318332e-05,
      "loss": 0.1147,
      "step": 18950
    },
    {
      "epoch": 0.8533237319411314,
      "grad_norm": 2.3413302898406982,
      "learning_rate": 9.14667626805887e-05,
      "loss": 0.1397,
      "step": 18960
    },
    {
      "epoch": 0.8537737972005941,
      "grad_norm": 3.68106746673584,
      "learning_rate": 9.146226202799406e-05,
      "loss": 0.1513,
      "step": 18970
    },
    {
      "epoch": 0.8542238624600567,
      "grad_norm": 3.324063777923584,
      "learning_rate": 9.145776137539944e-05,
      "loss": 0.1591,
      "step": 18980
    },
    {
      "epoch": 0.8546739277195193,
      "grad_norm": 1.98650062084198,
      "learning_rate": 9.145326072280482e-05,
      "loss": 0.0877,
      "step": 18990
    },
    {
      "epoch": 0.855123992978982,
      "grad_norm": 0.867867648601532,
      "learning_rate": 9.144876007021018e-05,
      "loss": 0.1423,
      "step": 19000
    },
    {
      "epoch": 0.8555740582384446,
      "grad_norm": 1.4866453409194946,
      "learning_rate": 9.144425941761556e-05,
      "loss": 0.1216,
      "step": 19010
    },
    {
      "epoch": 0.8560241234979072,
      "grad_norm": 3.2737298011779785,
      "learning_rate": 9.143975876502094e-05,
      "loss": 0.1375,
      "step": 19020
    },
    {
      "epoch": 0.8564741887573698,
      "grad_norm": 1.5889016389846802,
      "learning_rate": 9.14352581124263e-05,
      "loss": 0.0776,
      "step": 19030
    },
    {
      "epoch": 0.8569242540168325,
      "grad_norm": 1.1083946228027344,
      "learning_rate": 9.143075745983168e-05,
      "loss": 0.1537,
      "step": 19040
    },
    {
      "epoch": 0.857374319276295,
      "grad_norm": 2.6534111499786377,
      "learning_rate": 9.142625680723706e-05,
      "loss": 0.1157,
      "step": 19050
    },
    {
      "epoch": 0.8578243845357577,
      "grad_norm": 3.556314706802368,
      "learning_rate": 9.142175615464242e-05,
      "loss": 0.1337,
      "step": 19060
    },
    {
      "epoch": 0.8582744497952203,
      "grad_norm": 3.910140037536621,
      "learning_rate": 9.14172555020478e-05,
      "loss": 0.1318,
      "step": 19070
    },
    {
      "epoch": 0.858724515054683,
      "grad_norm": 5.072172164916992,
      "learning_rate": 9.141275484945318e-05,
      "loss": 0.1358,
      "step": 19080
    },
    {
      "epoch": 0.8591745803141455,
      "grad_norm": 4.10018253326416,
      "learning_rate": 9.140825419685854e-05,
      "loss": 0.1637,
      "step": 19090
    },
    {
      "epoch": 0.8596246455736082,
      "grad_norm": 2.5809056758880615,
      "learning_rate": 9.140375354426393e-05,
      "loss": 0.1648,
      "step": 19100
    },
    {
      "epoch": 0.8600747108330707,
      "grad_norm": 0.45007359981536865,
      "learning_rate": 9.13992528916693e-05,
      "loss": 0.107,
      "step": 19110
    },
    {
      "epoch": 0.8605247760925334,
      "grad_norm": 2.1896042823791504,
      "learning_rate": 9.139475223907466e-05,
      "loss": 0.1654,
      "step": 19120
    },
    {
      "epoch": 0.8609748413519961,
      "grad_norm": 2.5347156524658203,
      "learning_rate": 9.139025158648005e-05,
      "loss": 0.1069,
      "step": 19130
    },
    {
      "epoch": 0.8614249066114587,
      "grad_norm": 2.98152494430542,
      "learning_rate": 9.138575093388542e-05,
      "loss": 0.1071,
      "step": 19140
    },
    {
      "epoch": 0.8618749718709213,
      "grad_norm": 2.479907751083374,
      "learning_rate": 9.138125028129078e-05,
      "loss": 0.1281,
      "step": 19150
    },
    {
      "epoch": 0.8623250371303839,
      "grad_norm": 5.849672794342041,
      "learning_rate": 9.137674962869617e-05,
      "loss": 0.1579,
      "step": 19160
    },
    {
      "epoch": 0.8627751023898466,
      "grad_norm": 5.533705711364746,
      "learning_rate": 9.137224897610154e-05,
      "loss": 0.1537,
      "step": 19170
    },
    {
      "epoch": 0.8632251676493091,
      "grad_norm": 2.012515068054199,
      "learning_rate": 9.13677483235069e-05,
      "loss": 0.1459,
      "step": 19180
    },
    {
      "epoch": 0.8636752329087718,
      "grad_norm": 1.1050567626953125,
      "learning_rate": 9.136324767091229e-05,
      "loss": 0.1619,
      "step": 19190
    },
    {
      "epoch": 0.8641252981682344,
      "grad_norm": 3.1661596298217773,
      "learning_rate": 9.135874701831766e-05,
      "loss": 0.15,
      "step": 19200
    },
    {
      "epoch": 0.864575363427697,
      "grad_norm": 3.3874239921569824,
      "learning_rate": 9.135424636572304e-05,
      "loss": 0.1623,
      "step": 19210
    },
    {
      "epoch": 0.8650254286871596,
      "grad_norm": 3.014469623565674,
      "learning_rate": 9.134974571312841e-05,
      "loss": 0.1453,
      "step": 19220
    },
    {
      "epoch": 0.8654754939466223,
      "grad_norm": 4.811290740966797,
      "learning_rate": 9.134524506053378e-05,
      "loss": 0.1296,
      "step": 19230
    },
    {
      "epoch": 0.8659255592060848,
      "grad_norm": 3.1590230464935303,
      "learning_rate": 9.134074440793916e-05,
      "loss": 0.1645,
      "step": 19240
    },
    {
      "epoch": 0.8663756244655475,
      "grad_norm": 2.720381736755371,
      "learning_rate": 9.133624375534453e-05,
      "loss": 0.1543,
      "step": 19250
    },
    {
      "epoch": 0.8668256897250102,
      "grad_norm": 3.7248082160949707,
      "learning_rate": 9.13317431027499e-05,
      "loss": 0.138,
      "step": 19260
    },
    {
      "epoch": 0.8672757549844727,
      "grad_norm": 1.9018551111221313,
      "learning_rate": 9.132724245015528e-05,
      "loss": 0.1834,
      "step": 19270
    },
    {
      "epoch": 0.8677258202439354,
      "grad_norm": 2.056544065475464,
      "learning_rate": 9.132274179756065e-05,
      "loss": 0.127,
      "step": 19280
    },
    {
      "epoch": 0.868175885503398,
      "grad_norm": 2.8656067848205566,
      "learning_rate": 9.131824114496602e-05,
      "loss": 0.1547,
      "step": 19290
    },
    {
      "epoch": 0.8686259507628606,
      "grad_norm": 2.2965519428253174,
      "learning_rate": 9.13137404923714e-05,
      "loss": 0.1595,
      "step": 19300
    },
    {
      "epoch": 0.8690760160223232,
      "grad_norm": 2.066397190093994,
      "learning_rate": 9.130923983977677e-05,
      "loss": 0.1033,
      "step": 19310
    },
    {
      "epoch": 0.8695260812817859,
      "grad_norm": 2.022189140319824,
      "learning_rate": 9.130473918718215e-05,
      "loss": 0.1324,
      "step": 19320
    },
    {
      "epoch": 0.8699761465412484,
      "grad_norm": 1.9084446430206299,
      "learning_rate": 9.130023853458752e-05,
      "loss": 0.1119,
      "step": 19330
    },
    {
      "epoch": 0.8704262118007111,
      "grad_norm": 0.7203531861305237,
      "learning_rate": 9.129573788199289e-05,
      "loss": 0.1693,
      "step": 19340
    },
    {
      "epoch": 0.8708762770601737,
      "grad_norm": 3.261261224746704,
      "learning_rate": 9.129123722939827e-05,
      "loss": 0.1522,
      "step": 19350
    },
    {
      "epoch": 0.8713263423196363,
      "grad_norm": 0.41186147928237915,
      "learning_rate": 9.128673657680364e-05,
      "loss": 0.1422,
      "step": 19360
    },
    {
      "epoch": 0.871776407579099,
      "grad_norm": 5.220098972320557,
      "learning_rate": 9.128223592420901e-05,
      "loss": 0.1398,
      "step": 19370
    },
    {
      "epoch": 0.8722264728385616,
      "grad_norm": 5.4834113121032715,
      "learning_rate": 9.127773527161439e-05,
      "loss": 0.1321,
      "step": 19380
    },
    {
      "epoch": 0.8726765380980243,
      "grad_norm": 2.0204296112060547,
      "learning_rate": 9.127323461901976e-05,
      "loss": 0.1212,
      "step": 19390
    },
    {
      "epoch": 0.8731266033574868,
      "grad_norm": 3.3863086700439453,
      "learning_rate": 9.126873396642513e-05,
      "loss": 0.1053,
      "step": 19400
    },
    {
      "epoch": 0.8735766686169495,
      "grad_norm": 1.1632035970687866,
      "learning_rate": 9.126423331383051e-05,
      "loss": 0.1223,
      "step": 19410
    },
    {
      "epoch": 0.874026733876412,
      "grad_norm": 1.5377757549285889,
      "learning_rate": 9.125973266123588e-05,
      "loss": 0.162,
      "step": 19420
    },
    {
      "epoch": 0.8744767991358747,
      "grad_norm": 2.8033666610717773,
      "learning_rate": 9.125523200864125e-05,
      "loss": 0.115,
      "step": 19430
    },
    {
      "epoch": 0.8749268643953373,
      "grad_norm": 2.41225004196167,
      "learning_rate": 9.125073135604663e-05,
      "loss": 0.1173,
      "step": 19440
    },
    {
      "epoch": 0.8753769296548,
      "grad_norm": 1.7096517086029053,
      "learning_rate": 9.1246230703452e-05,
      "loss": 0.1396,
      "step": 19450
    },
    {
      "epoch": 0.8758269949142625,
      "grad_norm": 1.1693792343139648,
      "learning_rate": 9.124173005085738e-05,
      "loss": 0.1481,
      "step": 19460
    },
    {
      "epoch": 0.8762770601737252,
      "grad_norm": 6.080179214477539,
      "learning_rate": 9.123722939826276e-05,
      "loss": 0.0896,
      "step": 19470
    },
    {
      "epoch": 0.8767271254331878,
      "grad_norm": 2.9311842918395996,
      "learning_rate": 9.123272874566812e-05,
      "loss": 0.1189,
      "step": 19480
    },
    {
      "epoch": 0.8771771906926504,
      "grad_norm": 1.7386597394943237,
      "learning_rate": 9.12282280930735e-05,
      "loss": 0.1296,
      "step": 19490
    },
    {
      "epoch": 0.8776272559521131,
      "grad_norm": 3.5210721492767334,
      "learning_rate": 9.122372744047888e-05,
      "loss": 0.1145,
      "step": 19500
    },
    {
      "epoch": 0.8780773212115757,
      "grad_norm": 2.2900428771972656,
      "learning_rate": 9.121922678788424e-05,
      "loss": 0.1561,
      "step": 19510
    },
    {
      "epoch": 0.8785273864710383,
      "grad_norm": 6.355503082275391,
      "learning_rate": 9.121472613528962e-05,
      "loss": 0.1665,
      "step": 19520
    },
    {
      "epoch": 0.8789774517305009,
      "grad_norm": 1.1876555681228638,
      "learning_rate": 9.1210225482695e-05,
      "loss": 0.1038,
      "step": 19530
    },
    {
      "epoch": 0.8794275169899636,
      "grad_norm": 2.2629852294921875,
      "learning_rate": 9.120572483010036e-05,
      "loss": 0.1105,
      "step": 19540
    },
    {
      "epoch": 0.8798775822494261,
      "grad_norm": 2.7768261432647705,
      "learning_rate": 9.120122417750574e-05,
      "loss": 0.1346,
      "step": 19550
    },
    {
      "epoch": 0.8803276475088888,
      "grad_norm": 2.4019668102264404,
      "learning_rate": 9.119672352491113e-05,
      "loss": 0.1725,
      "step": 19560
    },
    {
      "epoch": 0.8807777127683514,
      "grad_norm": 5.334766387939453,
      "learning_rate": 9.119222287231649e-05,
      "loss": 0.1954,
      "step": 19570
    },
    {
      "epoch": 0.881227778027814,
      "grad_norm": 2.662142753601074,
      "learning_rate": 9.118772221972186e-05,
      "loss": 0.0971,
      "step": 19580
    },
    {
      "epoch": 0.8816778432872766,
      "grad_norm": 2.52620267868042,
      "learning_rate": 9.118322156712725e-05,
      "loss": 0.1381,
      "step": 19590
    },
    {
      "epoch": 0.8821279085467393,
      "grad_norm": 4.022175312042236,
      "learning_rate": 9.11787209145326e-05,
      "loss": 0.1215,
      "step": 19600
    },
    {
      "epoch": 0.882577973806202,
      "grad_norm": 1.122896671295166,
      "learning_rate": 9.117422026193798e-05,
      "loss": 0.1201,
      "step": 19610
    },
    {
      "epoch": 0.8830280390656645,
      "grad_norm": 2.9470560550689697,
      "learning_rate": 9.116971960934337e-05,
      "loss": 0.1423,
      "step": 19620
    },
    {
      "epoch": 0.8834781043251272,
      "grad_norm": 2.412872314453125,
      "learning_rate": 9.116521895674873e-05,
      "loss": 0.1327,
      "step": 19630
    },
    {
      "epoch": 0.8839281695845898,
      "grad_norm": 3.9493980407714844,
      "learning_rate": 9.11607183041541e-05,
      "loss": 0.1371,
      "step": 19640
    },
    {
      "epoch": 0.8843782348440524,
      "grad_norm": 3.683940887451172,
      "learning_rate": 9.115621765155949e-05,
      "loss": 0.1152,
      "step": 19650
    },
    {
      "epoch": 0.884828300103515,
      "grad_norm": 5.1376495361328125,
      "learning_rate": 9.115171699896485e-05,
      "loss": 0.1583,
      "step": 19660
    },
    {
      "epoch": 0.8852783653629777,
      "grad_norm": 2.6522254943847656,
      "learning_rate": 9.114721634637022e-05,
      "loss": 0.124,
      "step": 19670
    },
    {
      "epoch": 0.8857284306224402,
      "grad_norm": 3.6896982192993164,
      "learning_rate": 9.114271569377561e-05,
      "loss": 0.1228,
      "step": 19680
    },
    {
      "epoch": 0.8861784958819029,
      "grad_norm": 1.661468744277954,
      "learning_rate": 9.113821504118097e-05,
      "loss": 0.0802,
      "step": 19690
    },
    {
      "epoch": 0.8866285611413655,
      "grad_norm": 2.6613638401031494,
      "learning_rate": 9.113371438858634e-05,
      "loss": 0.1103,
      "step": 19700
    },
    {
      "epoch": 0.8870786264008281,
      "grad_norm": 3.307471513748169,
      "learning_rate": 9.112921373599173e-05,
      "loss": 0.16,
      "step": 19710
    },
    {
      "epoch": 0.8875286916602907,
      "grad_norm": 0.8501153588294983,
      "learning_rate": 9.112471308339709e-05,
      "loss": 0.1548,
      "step": 19720
    },
    {
      "epoch": 0.8879787569197534,
      "grad_norm": 4.525439262390137,
      "learning_rate": 9.112021243080248e-05,
      "loss": 0.1075,
      "step": 19730
    },
    {
      "epoch": 0.888428822179216,
      "grad_norm": 1.0344043970108032,
      "learning_rate": 9.111571177820785e-05,
      "loss": 0.1249,
      "step": 19740
    },
    {
      "epoch": 0.8888788874386786,
      "grad_norm": 1.6501730680465698,
      "learning_rate": 9.111121112561321e-05,
      "loss": 0.126,
      "step": 19750
    },
    {
      "epoch": 0.8893289526981413,
      "grad_norm": 1.6881452798843384,
      "learning_rate": 9.11067104730186e-05,
      "loss": 0.1164,
      "step": 19760
    },
    {
      "epoch": 0.8897790179576038,
      "grad_norm": 1.7872772216796875,
      "learning_rate": 9.110220982042397e-05,
      "loss": 0.1385,
      "step": 19770
    },
    {
      "epoch": 0.8902290832170665,
      "grad_norm": 3.702113389968872,
      "learning_rate": 9.109770916782933e-05,
      "loss": 0.1348,
      "step": 19780
    },
    {
      "epoch": 0.8906791484765291,
      "grad_norm": 1.6670315265655518,
      "learning_rate": 9.109320851523472e-05,
      "loss": 0.1016,
      "step": 19790
    },
    {
      "epoch": 0.8911292137359917,
      "grad_norm": 0.9313731789588928,
      "learning_rate": 9.108870786264009e-05,
      "loss": 0.126,
      "step": 19800
    },
    {
      "epoch": 0.8915792789954543,
      "grad_norm": 2.1061770915985107,
      "learning_rate": 9.108420721004545e-05,
      "loss": 0.1135,
      "step": 19810
    },
    {
      "epoch": 0.892029344254917,
      "grad_norm": 3.1583943367004395,
      "learning_rate": 9.107970655745084e-05,
      "loss": 0.1425,
      "step": 19820
    },
    {
      "epoch": 0.8924794095143795,
      "grad_norm": 2.9713382720947266,
      "learning_rate": 9.107520590485621e-05,
      "loss": 0.1324,
      "step": 19830
    },
    {
      "epoch": 0.8929294747738422,
      "grad_norm": 5.235668659210205,
      "learning_rate": 9.107070525226157e-05,
      "loss": 0.1703,
      "step": 19840
    },
    {
      "epoch": 0.8933795400333048,
      "grad_norm": 3.7633519172668457,
      "learning_rate": 9.106620459966696e-05,
      "loss": 0.1225,
      "step": 19850
    },
    {
      "epoch": 0.8938296052927674,
      "grad_norm": 3.8314454555511475,
      "learning_rate": 9.106170394707233e-05,
      "loss": 0.1279,
      "step": 19860
    },
    {
      "epoch": 0.8942796705522301,
      "grad_norm": 0.7969566583633423,
      "learning_rate": 9.10572032944777e-05,
      "loss": 0.0997,
      "step": 19870
    },
    {
      "epoch": 0.8947297358116927,
      "grad_norm": 3.414194345474243,
      "learning_rate": 9.105270264188308e-05,
      "loss": 0.1853,
      "step": 19880
    },
    {
      "epoch": 0.8951798010711554,
      "grad_norm": 3.6606104373931885,
      "learning_rate": 9.104820198928845e-05,
      "loss": 0.1487,
      "step": 19890
    },
    {
      "epoch": 0.8956298663306179,
      "grad_norm": 2.337751865386963,
      "learning_rate": 9.104370133669381e-05,
      "loss": 0.1531,
      "step": 19900
    },
    {
      "epoch": 0.8960799315900806,
      "grad_norm": 0.5966399312019348,
      "learning_rate": 9.10392006840992e-05,
      "loss": 0.1285,
      "step": 19910
    },
    {
      "epoch": 0.8965299968495432,
      "grad_norm": 7.442532539367676,
      "learning_rate": 9.103470003150457e-05,
      "loss": 0.2137,
      "step": 19920
    },
    {
      "epoch": 0.8969800621090058,
      "grad_norm": 2.197458267211914,
      "learning_rate": 9.103019937890994e-05,
      "loss": 0.1017,
      "step": 19930
    },
    {
      "epoch": 0.8974301273684684,
      "grad_norm": 2.0686919689178467,
      "learning_rate": 9.102569872631532e-05,
      "loss": 0.1108,
      "step": 19940
    },
    {
      "epoch": 0.8978801926279311,
      "grad_norm": 4.959066390991211,
      "learning_rate": 9.10211980737207e-05,
      "loss": 0.1635,
      "step": 19950
    },
    {
      "epoch": 0.8983302578873936,
      "grad_norm": 1.3888808488845825,
      "learning_rate": 9.101669742112606e-05,
      "loss": 0.0938,
      "step": 19960
    },
    {
      "epoch": 0.8987803231468563,
      "grad_norm": 5.589383602142334,
      "learning_rate": 9.101219676853144e-05,
      "loss": 0.1482,
      "step": 19970
    },
    {
      "epoch": 0.899230388406319,
      "grad_norm": 3.169602155685425,
      "learning_rate": 9.100769611593682e-05,
      "loss": 0.1512,
      "step": 19980
    },
    {
      "epoch": 0.8996804536657815,
      "grad_norm": 0.8084275722503662,
      "learning_rate": 9.100319546334219e-05,
      "loss": 0.1386,
      "step": 19990
    },
    {
      "epoch": 0.9001305189252442,
      "grad_norm": 0.6774579882621765,
      "learning_rate": 9.099869481074756e-05,
      "loss": 0.1169,
      "step": 20000
    },
    {
      "epoch": 0.9005805841847068,
      "grad_norm": 5.281501293182373,
      "learning_rate": 9.099419415815294e-05,
      "loss": 0.1294,
      "step": 20010
    },
    {
      "epoch": 0.9010306494441694,
      "grad_norm": 2.5252978801727295,
      "learning_rate": 9.098969350555831e-05,
      "loss": 0.1362,
      "step": 20020
    },
    {
      "epoch": 0.901480714703632,
      "grad_norm": 1.2710578441619873,
      "learning_rate": 9.098519285296368e-05,
      "loss": 0.1063,
      "step": 20030
    },
    {
      "epoch": 0.9019307799630947,
      "grad_norm": 8.529067993164062,
      "learning_rate": 9.098069220036906e-05,
      "loss": 0.1299,
      "step": 20040
    },
    {
      "epoch": 0.9023808452225572,
      "grad_norm": 2.6735637187957764,
      "learning_rate": 9.097619154777443e-05,
      "loss": 0.1037,
      "step": 20050
    },
    {
      "epoch": 0.9028309104820199,
      "grad_norm": 6.126858711242676,
      "learning_rate": 9.09716908951798e-05,
      "loss": 0.1392,
      "step": 20060
    },
    {
      "epoch": 0.9032809757414825,
      "grad_norm": 6.239830493927002,
      "learning_rate": 9.096719024258518e-05,
      "loss": 0.1405,
      "step": 20070
    },
    {
      "epoch": 0.9037310410009451,
      "grad_norm": 2.4416961669921875,
      "learning_rate": 9.096268958999055e-05,
      "loss": 0.1133,
      "step": 20080
    },
    {
      "epoch": 0.9041811062604077,
      "grad_norm": 0.42750248312950134,
      "learning_rate": 9.095818893739593e-05,
      "loss": 0.1019,
      "step": 20090
    },
    {
      "epoch": 0.9046311715198704,
      "grad_norm": 3.2492566108703613,
      "learning_rate": 9.09536882848013e-05,
      "loss": 0.1987,
      "step": 20100
    },
    {
      "epoch": 0.905081236779333,
      "grad_norm": 5.015666484832764,
      "learning_rate": 9.094918763220667e-05,
      "loss": 0.1684,
      "step": 20110
    },
    {
      "epoch": 0.9055313020387956,
      "grad_norm": 1.7033504247665405,
      "learning_rate": 9.094468697961205e-05,
      "loss": 0.1536,
      "step": 20120
    },
    {
      "epoch": 0.9059813672982583,
      "grad_norm": 0.7175154685974121,
      "learning_rate": 9.094018632701742e-05,
      "loss": 0.1495,
      "step": 20130
    },
    {
      "epoch": 0.9064314325577209,
      "grad_norm": 3.675729990005493,
      "learning_rate": 9.09356856744228e-05,
      "loss": 0.1125,
      "step": 20140
    },
    {
      "epoch": 0.9068814978171835,
      "grad_norm": 3.750624179840088,
      "learning_rate": 9.093118502182817e-05,
      "loss": 0.0808,
      "step": 20150
    },
    {
      "epoch": 0.9073315630766461,
      "grad_norm": 1.9631855487823486,
      "learning_rate": 9.092668436923354e-05,
      "loss": 0.1863,
      "step": 20160
    },
    {
      "epoch": 0.9077816283361088,
      "grad_norm": 4.066760540008545,
      "learning_rate": 9.092218371663892e-05,
      "loss": 0.1794,
      "step": 20170
    },
    {
      "epoch": 0.9082316935955713,
      "grad_norm": 2.554882526397705,
      "learning_rate": 9.091768306404429e-05,
      "loss": 0.1264,
      "step": 20180
    },
    {
      "epoch": 0.908681758855034,
      "grad_norm": 2.4847607612609863,
      "learning_rate": 9.091318241144966e-05,
      "loss": 0.1262,
      "step": 20190
    },
    {
      "epoch": 0.9091318241144966,
      "grad_norm": 2.2024824619293213,
      "learning_rate": 9.090868175885504e-05,
      "loss": 0.122,
      "step": 20200
    },
    {
      "epoch": 0.9095818893739592,
      "grad_norm": 0.7380905747413635,
      "learning_rate": 9.090418110626041e-05,
      "loss": 0.1343,
      "step": 20210
    },
    {
      "epoch": 0.9100319546334218,
      "grad_norm": 1.0060783624649048,
      "learning_rate": 9.089968045366578e-05,
      "loss": 0.1712,
      "step": 20220
    },
    {
      "epoch": 0.9104820198928845,
      "grad_norm": 1.9557946920394897,
      "learning_rate": 9.089517980107116e-05,
      "loss": 0.1451,
      "step": 20230
    },
    {
      "epoch": 0.9109320851523471,
      "grad_norm": 1.690629005432129,
      "learning_rate": 9.089067914847653e-05,
      "loss": 0.1297,
      "step": 20240
    },
    {
      "epoch": 0.9113821504118097,
      "grad_norm": 4.280935287475586,
      "learning_rate": 9.08861784958819e-05,
      "loss": 0.1,
      "step": 20250
    },
    {
      "epoch": 0.9118322156712724,
      "grad_norm": 2.176001787185669,
      "learning_rate": 9.088167784328728e-05,
      "loss": 0.1102,
      "step": 20260
    },
    {
      "epoch": 0.9122822809307349,
      "grad_norm": 1.1899874210357666,
      "learning_rate": 9.087717719069265e-05,
      "loss": 0.09,
      "step": 20270
    },
    {
      "epoch": 0.9127323461901976,
      "grad_norm": 1.3072861433029175,
      "learning_rate": 9.087267653809804e-05,
      "loss": 0.1241,
      "step": 20280
    },
    {
      "epoch": 0.9131824114496602,
      "grad_norm": 3.6529324054718018,
      "learning_rate": 9.08681758855034e-05,
      "loss": 0.1288,
      "step": 20290
    },
    {
      "epoch": 0.9136324767091228,
      "grad_norm": 1.8330596685409546,
      "learning_rate": 9.086367523290877e-05,
      "loss": 0.1338,
      "step": 20300
    },
    {
      "epoch": 0.9140825419685854,
      "grad_norm": 1.2280356884002686,
      "learning_rate": 9.085917458031416e-05,
      "loss": 0.1326,
      "step": 20310
    },
    {
      "epoch": 0.9145326072280481,
      "grad_norm": 2.0925588607788086,
      "learning_rate": 9.085467392771952e-05,
      "loss": 0.1152,
      "step": 20320
    },
    {
      "epoch": 0.9149826724875106,
      "grad_norm": 3.6273140907287598,
      "learning_rate": 9.085017327512489e-05,
      "loss": 0.1599,
      "step": 20330
    },
    {
      "epoch": 0.9154327377469733,
      "grad_norm": 3.605586051940918,
      "learning_rate": 9.084567262253028e-05,
      "loss": 0.1287,
      "step": 20340
    },
    {
      "epoch": 0.915882803006436,
      "grad_norm": 5.054049491882324,
      "learning_rate": 9.084117196993564e-05,
      "loss": 0.1647,
      "step": 20350
    },
    {
      "epoch": 0.9163328682658985,
      "grad_norm": 2.5631093978881836,
      "learning_rate": 9.083667131734101e-05,
      "loss": 0.1426,
      "step": 20360
    },
    {
      "epoch": 0.9167829335253612,
      "grad_norm": 2.7683615684509277,
      "learning_rate": 9.08321706647464e-05,
      "loss": 0.1219,
      "step": 20370
    },
    {
      "epoch": 0.9172329987848238,
      "grad_norm": 3.603595495223999,
      "learning_rate": 9.082767001215176e-05,
      "loss": 0.1662,
      "step": 20380
    },
    {
      "epoch": 0.9176830640442865,
      "grad_norm": 2.5962183475494385,
      "learning_rate": 9.082316935955713e-05,
      "loss": 0.0846,
      "step": 20390
    },
    {
      "epoch": 0.918133129303749,
      "grad_norm": 1.799464464187622,
      "learning_rate": 9.081866870696252e-05,
      "loss": 0.1356,
      "step": 20400
    },
    {
      "epoch": 0.9185831945632117,
      "grad_norm": 3.317852258682251,
      "learning_rate": 9.081416805436788e-05,
      "loss": 0.125,
      "step": 20410
    },
    {
      "epoch": 0.9190332598226743,
      "grad_norm": 3.3886406421661377,
      "learning_rate": 9.080966740177326e-05,
      "loss": 0.1154,
      "step": 20420
    },
    {
      "epoch": 0.9194833250821369,
      "grad_norm": 4.259196758270264,
      "learning_rate": 9.080516674917864e-05,
      "loss": 0.1493,
      "step": 20430
    },
    {
      "epoch": 0.9199333903415995,
      "grad_norm": 2.2279577255249023,
      "learning_rate": 9.0800666096584e-05,
      "loss": 0.1433,
      "step": 20440
    },
    {
      "epoch": 0.9203834556010622,
      "grad_norm": 4.113779544830322,
      "learning_rate": 9.079616544398938e-05,
      "loss": 0.1767,
      "step": 20450
    },
    {
      "epoch": 0.9208335208605247,
      "grad_norm": 3.1179516315460205,
      "learning_rate": 9.079166479139476e-05,
      "loss": 0.1088,
      "step": 20460
    },
    {
      "epoch": 0.9212835861199874,
      "grad_norm": 5.652376174926758,
      "learning_rate": 9.078716413880012e-05,
      "loss": 0.1745,
      "step": 20470
    },
    {
      "epoch": 0.9217336513794501,
      "grad_norm": 2.632307767868042,
      "learning_rate": 9.07826634862055e-05,
      "loss": 0.0966,
      "step": 20480
    },
    {
      "epoch": 0.9221837166389126,
      "grad_norm": 1.9751405715942383,
      "learning_rate": 9.077816283361088e-05,
      "loss": 0.1315,
      "step": 20490
    },
    {
      "epoch": 0.9226337818983753,
      "grad_norm": 3.037780284881592,
      "learning_rate": 9.077366218101624e-05,
      "loss": 0.1386,
      "step": 20500
    },
    {
      "epoch": 0.9230838471578379,
      "grad_norm": 3.2824552059173584,
      "learning_rate": 9.076916152842162e-05,
      "loss": 0.1731,
      "step": 20510
    },
    {
      "epoch": 0.9235339124173005,
      "grad_norm": 2.945110559463501,
      "learning_rate": 9.0764660875827e-05,
      "loss": 0.1352,
      "step": 20520
    },
    {
      "epoch": 0.9239839776767631,
      "grad_norm": 4.042733669281006,
      "learning_rate": 9.076016022323236e-05,
      "loss": 0.1197,
      "step": 20530
    },
    {
      "epoch": 0.9244340429362258,
      "grad_norm": 1.6827598810195923,
      "learning_rate": 9.075565957063775e-05,
      "loss": 0.1089,
      "step": 20540
    },
    {
      "epoch": 0.9248841081956883,
      "grad_norm": 2.1490914821624756,
      "learning_rate": 9.075115891804313e-05,
      "loss": 0.1581,
      "step": 20550
    },
    {
      "epoch": 0.925334173455151,
      "grad_norm": 2.7881128787994385,
      "learning_rate": 9.074665826544849e-05,
      "loss": 0.1121,
      "step": 20560
    },
    {
      "epoch": 0.9257842387146136,
      "grad_norm": 1.3209604024887085,
      "learning_rate": 9.074215761285387e-05,
      "loss": 0.146,
      "step": 20570
    },
    {
      "epoch": 0.9262343039740762,
      "grad_norm": 2.2840397357940674,
      "learning_rate": 9.073765696025925e-05,
      "loss": 0.1504,
      "step": 20580
    },
    {
      "epoch": 0.9266843692335389,
      "grad_norm": 1.2739177942276,
      "learning_rate": 9.07331563076646e-05,
      "loss": 0.1024,
      "step": 20590
    },
    {
      "epoch": 0.9271344344930015,
      "grad_norm": 3.140734910964966,
      "learning_rate": 9.072865565507e-05,
      "loss": 0.1104,
      "step": 20600
    },
    {
      "epoch": 0.9275844997524642,
      "grad_norm": 1.5807219743728638,
      "learning_rate": 9.072415500247537e-05,
      "loss": 0.1391,
      "step": 20610
    },
    {
      "epoch": 0.9280345650119267,
      "grad_norm": 5.351121425628662,
      "learning_rate": 9.071965434988073e-05,
      "loss": 0.1111,
      "step": 20620
    },
    {
      "epoch": 0.9284846302713894,
      "grad_norm": 0.6642085313796997,
      "learning_rate": 9.071515369728611e-05,
      "loss": 0.2148,
      "step": 20630
    },
    {
      "epoch": 0.928934695530852,
      "grad_norm": 4.031376838684082,
      "learning_rate": 9.071065304469149e-05,
      "loss": 0.0866,
      "step": 20640
    },
    {
      "epoch": 0.9293847607903146,
      "grad_norm": 3.8358941078186035,
      "learning_rate": 9.070615239209685e-05,
      "loss": 0.1598,
      "step": 20650
    },
    {
      "epoch": 0.9298348260497772,
      "grad_norm": 2.3509981632232666,
      "learning_rate": 9.070165173950224e-05,
      "loss": 0.1249,
      "step": 20660
    },
    {
      "epoch": 0.9302848913092399,
      "grad_norm": 7.447418689727783,
      "learning_rate": 9.069715108690761e-05,
      "loss": 0.1239,
      "step": 20670
    },
    {
      "epoch": 0.9307349565687024,
      "grad_norm": 2.0877554416656494,
      "learning_rate": 9.069265043431298e-05,
      "loss": 0.0997,
      "step": 20680
    },
    {
      "epoch": 0.9311850218281651,
      "grad_norm": 6.039350986480713,
      "learning_rate": 9.068814978171836e-05,
      "loss": 0.187,
      "step": 20690
    },
    {
      "epoch": 0.9316350870876277,
      "grad_norm": 1.4443708658218384,
      "learning_rate": 9.068364912912373e-05,
      "loss": 0.1024,
      "step": 20700
    },
    {
      "epoch": 0.9320851523470903,
      "grad_norm": 2.2745466232299805,
      "learning_rate": 9.06791484765291e-05,
      "loss": 0.1383,
      "step": 20710
    },
    {
      "epoch": 0.932535217606553,
      "grad_norm": 1.978812336921692,
      "learning_rate": 9.067464782393448e-05,
      "loss": 0.1158,
      "step": 20720
    },
    {
      "epoch": 0.9329852828660156,
      "grad_norm": 2.3416032791137695,
      "learning_rate": 9.067014717133985e-05,
      "loss": 0.1323,
      "step": 20730
    },
    {
      "epoch": 0.9334353481254782,
      "grad_norm": 3.218820810317993,
      "learning_rate": 9.066564651874522e-05,
      "loss": 0.1118,
      "step": 20740
    },
    {
      "epoch": 0.9338854133849408,
      "grad_norm": 6.817435264587402,
      "learning_rate": 9.06611458661506e-05,
      "loss": 0.159,
      "step": 20750
    },
    {
      "epoch": 0.9343354786444035,
      "grad_norm": 6.733662128448486,
      "learning_rate": 9.065664521355597e-05,
      "loss": 0.1371,
      "step": 20760
    },
    {
      "epoch": 0.934785543903866,
      "grad_norm": 3.3377273082733154,
      "learning_rate": 9.065214456096134e-05,
      "loss": 0.1439,
      "step": 20770
    },
    {
      "epoch": 0.9352356091633287,
      "grad_norm": 1.2997997999191284,
      "learning_rate": 9.064764390836672e-05,
      "loss": 0.1228,
      "step": 20780
    },
    {
      "epoch": 0.9356856744227913,
      "grad_norm": 2.116713285446167,
      "learning_rate": 9.064314325577209e-05,
      "loss": 0.1593,
      "step": 20790
    },
    {
      "epoch": 0.9361357396822539,
      "grad_norm": 3.6882660388946533,
      "learning_rate": 9.063864260317747e-05,
      "loss": 0.128,
      "step": 20800
    },
    {
      "epoch": 0.9365858049417165,
      "grad_norm": 2.723226547241211,
      "learning_rate": 9.063414195058284e-05,
      "loss": 0.1358,
      "step": 20810
    },
    {
      "epoch": 0.9370358702011792,
      "grad_norm": 4.251904010772705,
      "learning_rate": 9.062964129798821e-05,
      "loss": 0.1278,
      "step": 20820
    },
    {
      "epoch": 0.9374859354606417,
      "grad_norm": 2.278221607208252,
      "learning_rate": 9.062514064539359e-05,
      "loss": 0.0974,
      "step": 20830
    },
    {
      "epoch": 0.9379360007201044,
      "grad_norm": 2.309103488922119,
      "learning_rate": 9.062063999279896e-05,
      "loss": 0.1663,
      "step": 20840
    },
    {
      "epoch": 0.9383860659795671,
      "grad_norm": 8.768143653869629,
      "learning_rate": 9.061613934020433e-05,
      "loss": 0.1261,
      "step": 20850
    },
    {
      "epoch": 0.9388361312390296,
      "grad_norm": 2.651258945465088,
      "learning_rate": 9.061163868760971e-05,
      "loss": 0.1656,
      "step": 20860
    },
    {
      "epoch": 0.9392861964984923,
      "grad_norm": 3.4526889324188232,
      "learning_rate": 9.060713803501508e-05,
      "loss": 0.1046,
      "step": 20870
    },
    {
      "epoch": 0.9397362617579549,
      "grad_norm": 1.8392599821090698,
      "learning_rate": 9.060263738242045e-05,
      "loss": 0.1206,
      "step": 20880
    },
    {
      "epoch": 0.9401863270174176,
      "grad_norm": 2.2207119464874268,
      "learning_rate": 9.059813672982583e-05,
      "loss": 0.1301,
      "step": 20890
    },
    {
      "epoch": 0.9406363922768801,
      "grad_norm": 1.086066722869873,
      "learning_rate": 9.05936360772312e-05,
      "loss": 0.1543,
      "step": 20900
    },
    {
      "epoch": 0.9410864575363428,
      "grad_norm": 1.2816107273101807,
      "learning_rate": 9.058913542463658e-05,
      "loss": 0.1625,
      "step": 20910
    },
    {
      "epoch": 0.9415365227958054,
      "grad_norm": 3.989062547683716,
      "learning_rate": 9.058463477204195e-05,
      "loss": 0.1315,
      "step": 20920
    },
    {
      "epoch": 0.941986588055268,
      "grad_norm": 2.1003873348236084,
      "learning_rate": 9.058013411944732e-05,
      "loss": 0.1139,
      "step": 20930
    },
    {
      "epoch": 0.9424366533147306,
      "grad_norm": 4.234762668609619,
      "learning_rate": 9.05756334668527e-05,
      "loss": 0.1468,
      "step": 20940
    },
    {
      "epoch": 0.9428867185741933,
      "grad_norm": 2.502829074859619,
      "learning_rate": 9.057113281425807e-05,
      "loss": 0.1213,
      "step": 20950
    },
    {
      "epoch": 0.9433367838336559,
      "grad_norm": 1.7809226512908936,
      "learning_rate": 9.056663216166344e-05,
      "loss": 0.105,
      "step": 20960
    },
    {
      "epoch": 0.9437868490931185,
      "grad_norm": 1.2575222253799438,
      "learning_rate": 9.056213150906882e-05,
      "loss": 0.1055,
      "step": 20970
    },
    {
      "epoch": 0.9442369143525812,
      "grad_norm": 2.205376386642456,
      "learning_rate": 9.055763085647419e-05,
      "loss": 0.2149,
      "step": 20980
    },
    {
      "epoch": 0.9446869796120437,
      "grad_norm": 3.91947865486145,
      "learning_rate": 9.055313020387956e-05,
      "loss": 0.1778,
      "step": 20990
    },
    {
      "epoch": 0.9451370448715064,
      "grad_norm": 1.3321207761764526,
      "learning_rate": 9.054862955128494e-05,
      "loss": 0.0881,
      "step": 21000
    },
    {
      "epoch": 0.945587110130969,
      "grad_norm": 6.3087544441223145,
      "learning_rate": 9.054412889869031e-05,
      "loss": 0.1196,
      "step": 21010
    },
    {
      "epoch": 0.9460371753904316,
      "grad_norm": 5.049933910369873,
      "learning_rate": 9.053962824609568e-05,
      "loss": 0.1333,
      "step": 21020
    },
    {
      "epoch": 0.9464872406498942,
      "grad_norm": 1.7802019119262695,
      "learning_rate": 9.053512759350106e-05,
      "loss": 0.1678,
      "step": 21030
    },
    {
      "epoch": 0.9469373059093569,
      "grad_norm": 1.3350489139556885,
      "learning_rate": 9.053062694090643e-05,
      "loss": 0.1359,
      "step": 21040
    },
    {
      "epoch": 0.9473873711688194,
      "grad_norm": 4.137603759765625,
      "learning_rate": 9.05261262883118e-05,
      "loss": 0.1056,
      "step": 21050
    },
    {
      "epoch": 0.9478374364282821,
      "grad_norm": 3.5738251209259033,
      "learning_rate": 9.052162563571719e-05,
      "loss": 0.067,
      "step": 21060
    },
    {
      "epoch": 0.9482875016877447,
      "grad_norm": 4.306380271911621,
      "learning_rate": 9.051712498312255e-05,
      "loss": 0.1858,
      "step": 21070
    },
    {
      "epoch": 0.9487375669472073,
      "grad_norm": 1.1155155897140503,
      "learning_rate": 9.051262433052793e-05,
      "loss": 0.1145,
      "step": 21080
    },
    {
      "epoch": 0.94918763220667,
      "grad_norm": 1.1415026187896729,
      "learning_rate": 9.050812367793331e-05,
      "loss": 0.1227,
      "step": 21090
    },
    {
      "epoch": 0.9496376974661326,
      "grad_norm": 2.067178249359131,
      "learning_rate": 9.050362302533867e-05,
      "loss": 0.1089,
      "step": 21100
    },
    {
      "epoch": 0.9500877627255953,
      "grad_norm": 5.5782012939453125,
      "learning_rate": 9.049912237274405e-05,
      "loss": 0.1591,
      "step": 21110
    },
    {
      "epoch": 0.9505378279850578,
      "grad_norm": 2.464270830154419,
      "learning_rate": 9.049462172014943e-05,
      "loss": 0.1215,
      "step": 21120
    },
    {
      "epoch": 0.9509878932445205,
      "grad_norm": 3.2185792922973633,
      "learning_rate": 9.04901210675548e-05,
      "loss": 0.0959,
      "step": 21130
    },
    {
      "epoch": 0.951437958503983,
      "grad_norm": 2.08712100982666,
      "learning_rate": 9.048562041496017e-05,
      "loss": 0.1351,
      "step": 21140
    },
    {
      "epoch": 0.9518880237634457,
      "grad_norm": 3.1836557388305664,
      "learning_rate": 9.048111976236556e-05,
      "loss": 0.1514,
      "step": 21150
    },
    {
      "epoch": 0.9523380890229083,
      "grad_norm": 1.0727397203445435,
      "learning_rate": 9.047661910977092e-05,
      "loss": 0.1004,
      "step": 21160
    },
    {
      "epoch": 0.952788154282371,
      "grad_norm": 3.477308511734009,
      "learning_rate": 9.047211845717629e-05,
      "loss": 0.1099,
      "step": 21170
    },
    {
      "epoch": 0.9532382195418335,
      "grad_norm": 3.6574015617370605,
      "learning_rate": 9.046761780458168e-05,
      "loss": 0.1233,
      "step": 21180
    },
    {
      "epoch": 0.9536882848012962,
      "grad_norm": 4.975758075714111,
      "learning_rate": 9.046311715198704e-05,
      "loss": 0.1761,
      "step": 21190
    },
    {
      "epoch": 0.9541383500607588,
      "grad_norm": 1.6875261068344116,
      "learning_rate": 9.045861649939241e-05,
      "loss": 0.1493,
      "step": 21200
    },
    {
      "epoch": 0.9545884153202214,
      "grad_norm": 5.4680891036987305,
      "learning_rate": 9.04541158467978e-05,
      "loss": 0.1219,
      "step": 21210
    },
    {
      "epoch": 0.9550384805796841,
      "grad_norm": 1.1364253759384155,
      "learning_rate": 9.044961519420316e-05,
      "loss": 0.1074,
      "step": 21220
    },
    {
      "epoch": 0.9554885458391467,
      "grad_norm": 0.24374531209468842,
      "learning_rate": 9.044511454160853e-05,
      "loss": 0.0669,
      "step": 21230
    },
    {
      "epoch": 0.9559386110986093,
      "grad_norm": 1.5562630891799927,
      "learning_rate": 9.044061388901392e-05,
      "loss": 0.1361,
      "step": 21240
    },
    {
      "epoch": 0.9563886763580719,
      "grad_norm": 2.081063747406006,
      "learning_rate": 9.043611323641928e-05,
      "loss": 0.0916,
      "step": 21250
    },
    {
      "epoch": 0.9568387416175346,
      "grad_norm": 2.9691567420959473,
      "learning_rate": 9.043161258382465e-05,
      "loss": 0.1412,
      "step": 21260
    },
    {
      "epoch": 0.9572888068769971,
      "grad_norm": 1.9303195476531982,
      "learning_rate": 9.042711193123004e-05,
      "loss": 0.1201,
      "step": 21270
    },
    {
      "epoch": 0.9577388721364598,
      "grad_norm": 1.386347770690918,
      "learning_rate": 9.04226112786354e-05,
      "loss": 0.1379,
      "step": 21280
    },
    {
      "epoch": 0.9581889373959224,
      "grad_norm": 2.647794008255005,
      "learning_rate": 9.041811062604077e-05,
      "loss": 0.1052,
      "step": 21290
    },
    {
      "epoch": 0.958639002655385,
      "grad_norm": 0.6657639145851135,
      "learning_rate": 9.041360997344616e-05,
      "loss": 0.1321,
      "step": 21300
    },
    {
      "epoch": 0.9590890679148476,
      "grad_norm": 5.518654823303223,
      "learning_rate": 9.040910932085152e-05,
      "loss": 0.1745,
      "step": 21310
    },
    {
      "epoch": 0.9595391331743103,
      "grad_norm": 0.26680606603622437,
      "learning_rate": 9.04046086682569e-05,
      "loss": 0.0742,
      "step": 21320
    },
    {
      "epoch": 0.959989198433773,
      "grad_norm": 0.8755590915679932,
      "learning_rate": 9.040010801566228e-05,
      "loss": 0.1296,
      "step": 21330
    },
    {
      "epoch": 0.9604392636932355,
      "grad_norm": 1.7326775789260864,
      "learning_rate": 9.039560736306765e-05,
      "loss": 0.0824,
      "step": 21340
    },
    {
      "epoch": 0.9608893289526982,
      "grad_norm": 2.966296672821045,
      "learning_rate": 9.039110671047303e-05,
      "loss": 0.1105,
      "step": 21350
    },
    {
      "epoch": 0.9613393942121607,
      "grad_norm": 7.923210144042969,
      "learning_rate": 9.03866060578784e-05,
      "loss": 0.1332,
      "step": 21360
    },
    {
      "epoch": 0.9617894594716234,
      "grad_norm": 0.5411672592163086,
      "learning_rate": 9.038210540528377e-05,
      "loss": 0.0953,
      "step": 21370
    },
    {
      "epoch": 0.962239524731086,
      "grad_norm": 0.4701060354709625,
      "learning_rate": 9.037760475268915e-05,
      "loss": 0.177,
      "step": 21380
    },
    {
      "epoch": 0.9626895899905487,
      "grad_norm": 2.7491259574890137,
      "learning_rate": 9.037310410009452e-05,
      "loss": 0.101,
      "step": 21390
    },
    {
      "epoch": 0.9631396552500112,
      "grad_norm": 1.654144287109375,
      "learning_rate": 9.03686034474999e-05,
      "loss": 0.1367,
      "step": 21400
    },
    {
      "epoch": 0.9635897205094739,
      "grad_norm": 4.117226600646973,
      "learning_rate": 9.036410279490527e-05,
      "loss": 0.1633,
      "step": 21410
    },
    {
      "epoch": 0.9640397857689365,
      "grad_norm": 1.3932247161865234,
      "learning_rate": 9.035960214231064e-05,
      "loss": 0.1568,
      "step": 21420
    },
    {
      "epoch": 0.9644898510283991,
      "grad_norm": 1.919480562210083,
      "learning_rate": 9.035510148971602e-05,
      "loss": 0.1484,
      "step": 21430
    },
    {
      "epoch": 0.9649399162878617,
      "grad_norm": 2.364436626434326,
      "learning_rate": 9.035060083712139e-05,
      "loss": 0.1178,
      "step": 21440
    },
    {
      "epoch": 0.9653899815473244,
      "grad_norm": 2.6406149864196777,
      "learning_rate": 9.034610018452676e-05,
      "loss": 0.197,
      "step": 21450
    },
    {
      "epoch": 0.965840046806787,
      "grad_norm": 3.377906322479248,
      "learning_rate": 9.034159953193214e-05,
      "loss": 0.1451,
      "step": 21460
    },
    {
      "epoch": 0.9662901120662496,
      "grad_norm": 5.396683692932129,
      "learning_rate": 9.033709887933751e-05,
      "loss": 0.1133,
      "step": 21470
    },
    {
      "epoch": 0.9667401773257123,
      "grad_norm": 2.2525827884674072,
      "learning_rate": 9.033259822674288e-05,
      "loss": 0.1453,
      "step": 21480
    },
    {
      "epoch": 0.9671902425851748,
      "grad_norm": 0.2920132875442505,
      "learning_rate": 9.032809757414826e-05,
      "loss": 0.1243,
      "step": 21490
    },
    {
      "epoch": 0.9676403078446375,
      "grad_norm": 2.4085304737091064,
      "learning_rate": 9.032359692155363e-05,
      "loss": 0.108,
      "step": 21500
    },
    {
      "epoch": 0.9680903731041001,
      "grad_norm": 2.7101879119873047,
      "learning_rate": 9.0319096268959e-05,
      "loss": 0.0701,
      "step": 21510
    },
    {
      "epoch": 0.9685404383635627,
      "grad_norm": 6.156461715698242,
      "learning_rate": 9.031459561636438e-05,
      "loss": 0.1249,
      "step": 21520
    },
    {
      "epoch": 0.9689905036230253,
      "grad_norm": 5.565495491027832,
      "learning_rate": 9.031009496376975e-05,
      "loss": 0.1409,
      "step": 21530
    },
    {
      "epoch": 0.969440568882488,
      "grad_norm": 1.2804557085037231,
      "learning_rate": 9.030559431117513e-05,
      "loss": 0.1061,
      "step": 21540
    },
    {
      "epoch": 0.9698906341419505,
      "grad_norm": 2.432809829711914,
      "learning_rate": 9.03010936585805e-05,
      "loss": 0.1226,
      "step": 21550
    },
    {
      "epoch": 0.9703406994014132,
      "grad_norm": 5.392012119293213,
      "learning_rate": 9.029659300598587e-05,
      "loss": 0.1055,
      "step": 21560
    },
    {
      "epoch": 0.9707907646608759,
      "grad_norm": 2.3082382678985596,
      "learning_rate": 9.029209235339125e-05,
      "loss": 0.1011,
      "step": 21570
    },
    {
      "epoch": 0.9712408299203384,
      "grad_norm": 2.6265788078308105,
      "learning_rate": 9.028759170079662e-05,
      "loss": 0.1399,
      "step": 21580
    },
    {
      "epoch": 0.9716908951798011,
      "grad_norm": 1.1726679801940918,
      "learning_rate": 9.0283091048202e-05,
      "loss": 0.1069,
      "step": 21590
    },
    {
      "epoch": 0.9721409604392637,
      "grad_norm": 0.5744592547416687,
      "learning_rate": 9.027859039560737e-05,
      "loss": 0.0938,
      "step": 21600
    },
    {
      "epoch": 0.9725910256987264,
      "grad_norm": 1.5596067905426025,
      "learning_rate": 9.027408974301274e-05,
      "loss": 0.089,
      "step": 21610
    },
    {
      "epoch": 0.9730410909581889,
      "grad_norm": 2.7910068035125732,
      "learning_rate": 9.026958909041811e-05,
      "loss": 0.1471,
      "step": 21620
    },
    {
      "epoch": 0.9734911562176516,
      "grad_norm": 2.365460157394409,
      "learning_rate": 9.026508843782349e-05,
      "loss": 0.1857,
      "step": 21630
    },
    {
      "epoch": 0.9739412214771141,
      "grad_norm": 4.42111349105835,
      "learning_rate": 9.026058778522886e-05,
      "loss": 0.1435,
      "step": 21640
    },
    {
      "epoch": 0.9743912867365768,
      "grad_norm": 1.7528640031814575,
      "learning_rate": 9.025608713263424e-05,
      "loss": 0.1324,
      "step": 21650
    },
    {
      "epoch": 0.9748413519960394,
      "grad_norm": 3.8017444610595703,
      "learning_rate": 9.025158648003961e-05,
      "loss": 0.1297,
      "step": 21660
    },
    {
      "epoch": 0.9752914172555021,
      "grad_norm": 2.761383533477783,
      "learning_rate": 9.024708582744498e-05,
      "loss": 0.1356,
      "step": 21670
    },
    {
      "epoch": 0.9757414825149646,
      "grad_norm": 6.743072509765625,
      "learning_rate": 9.024258517485036e-05,
      "loss": 0.1451,
      "step": 21680
    },
    {
      "epoch": 0.9761915477744273,
      "grad_norm": 2.3933908939361572,
      "learning_rate": 9.023808452225573e-05,
      "loss": 0.1343,
      "step": 21690
    },
    {
      "epoch": 0.97664161303389,
      "grad_norm": 2.3786466121673584,
      "learning_rate": 9.02335838696611e-05,
      "loss": 0.0627,
      "step": 21700
    },
    {
      "epoch": 0.9770916782933525,
      "grad_norm": 2.2669763565063477,
      "learning_rate": 9.022908321706648e-05,
      "loss": 0.107,
      "step": 21710
    },
    {
      "epoch": 0.9775417435528152,
      "grad_norm": 3.1395599842071533,
      "learning_rate": 9.022458256447185e-05,
      "loss": 0.1599,
      "step": 21720
    },
    {
      "epoch": 0.9779918088122778,
      "grad_norm": 1.9829987287521362,
      "learning_rate": 9.022008191187722e-05,
      "loss": 0.0878,
      "step": 21730
    },
    {
      "epoch": 0.9784418740717404,
      "grad_norm": 2.9144465923309326,
      "learning_rate": 9.02155812592826e-05,
      "loss": 0.1619,
      "step": 21740
    },
    {
      "epoch": 0.978891939331203,
      "grad_norm": 3.389885425567627,
      "learning_rate": 9.021108060668797e-05,
      "loss": 0.1429,
      "step": 21750
    },
    {
      "epoch": 0.9793420045906657,
      "grad_norm": 1.621601939201355,
      "learning_rate": 9.020657995409335e-05,
      "loss": 0.1057,
      "step": 21760
    },
    {
      "epoch": 0.9797920698501282,
      "grad_norm": 5.864419460296631,
      "learning_rate": 9.020207930149872e-05,
      "loss": 0.1195,
      "step": 21770
    },
    {
      "epoch": 0.9802421351095909,
      "grad_norm": 2.3133208751678467,
      "learning_rate": 9.019757864890409e-05,
      "loss": 0.0992,
      "step": 21780
    },
    {
      "epoch": 0.9806922003690535,
      "grad_norm": 2.28163743019104,
      "learning_rate": 9.019307799630947e-05,
      "loss": 0.1083,
      "step": 21790
    },
    {
      "epoch": 0.9811422656285161,
      "grad_norm": 4.233122825622559,
      "learning_rate": 9.018857734371484e-05,
      "loss": 0.1276,
      "step": 21800
    },
    {
      "epoch": 0.9815923308879787,
      "grad_norm": 2.5172722339630127,
      "learning_rate": 9.018407669112021e-05,
      "loss": 0.1067,
      "step": 21810
    },
    {
      "epoch": 0.9820423961474414,
      "grad_norm": 1.5428260564804077,
      "learning_rate": 9.017957603852559e-05,
      "loss": 0.1659,
      "step": 21820
    },
    {
      "epoch": 0.982492461406904,
      "grad_norm": 3.2052724361419678,
      "learning_rate": 9.017507538593096e-05,
      "loss": 0.1034,
      "step": 21830
    },
    {
      "epoch": 0.9829425266663666,
      "grad_norm": 6.166163921356201,
      "learning_rate": 9.017057473333633e-05,
      "loss": 0.168,
      "step": 21840
    },
    {
      "epoch": 0.9833925919258293,
      "grad_norm": 2.507985830307007,
      "learning_rate": 9.016607408074171e-05,
      "loss": 0.1595,
      "step": 21850
    },
    {
      "epoch": 0.9838426571852918,
      "grad_norm": 3.020531415939331,
      "learning_rate": 9.016157342814708e-05,
      "loss": 0.153,
      "step": 21860
    },
    {
      "epoch": 0.9842927224447545,
      "grad_norm": 2.993878126144409,
      "learning_rate": 9.015707277555247e-05,
      "loss": 0.1544,
      "step": 21870
    },
    {
      "epoch": 0.9847427877042171,
      "grad_norm": 2.3151981830596924,
      "learning_rate": 9.015257212295783e-05,
      "loss": 0.1148,
      "step": 21880
    },
    {
      "epoch": 0.9851928529636798,
      "grad_norm": 3.4107115268707275,
      "learning_rate": 9.01480714703632e-05,
      "loss": 0.1484,
      "step": 21890
    },
    {
      "epoch": 0.9856429182231423,
      "grad_norm": 2.1439740657806396,
      "learning_rate": 9.014357081776859e-05,
      "loss": 0.2134,
      "step": 21900
    },
    {
      "epoch": 0.986092983482605,
      "grad_norm": 2.473459482192993,
      "learning_rate": 9.013907016517395e-05,
      "loss": 0.1061,
      "step": 21910
    },
    {
      "epoch": 0.9865430487420676,
      "grad_norm": 3.0567848682403564,
      "learning_rate": 9.013456951257932e-05,
      "loss": 0.0795,
      "step": 21920
    },
    {
      "epoch": 0.9869931140015302,
      "grad_norm": 5.450728893280029,
      "learning_rate": 9.013006885998471e-05,
      "loss": 0.1669,
      "step": 21930
    },
    {
      "epoch": 0.9874431792609929,
      "grad_norm": 2.420055389404297,
      "learning_rate": 9.012556820739007e-05,
      "loss": 0.1418,
      "step": 21940
    },
    {
      "epoch": 0.9878932445204555,
      "grad_norm": 3.3664333820343018,
      "learning_rate": 9.012106755479544e-05,
      "loss": 0.1633,
      "step": 21950
    },
    {
      "epoch": 0.9883433097799181,
      "grad_norm": 1.4993159770965576,
      "learning_rate": 9.011656690220083e-05,
      "loss": 0.1421,
      "step": 21960
    },
    {
      "epoch": 0.9887933750393807,
      "grad_norm": 3.0778892040252686,
      "learning_rate": 9.011206624960619e-05,
      "loss": 0.1319,
      "step": 21970
    },
    {
      "epoch": 0.9892434402988434,
      "grad_norm": 1.7274562120437622,
      "learning_rate": 9.010756559701156e-05,
      "loss": 0.0943,
      "step": 21980
    },
    {
      "epoch": 0.9896935055583059,
      "grad_norm": 4.278997898101807,
      "learning_rate": 9.010306494441695e-05,
      "loss": 0.1125,
      "step": 21990
    },
    {
      "epoch": 0.9901435708177686,
      "grad_norm": 3.8030171394348145,
      "learning_rate": 9.009856429182231e-05,
      "loss": 0.155,
      "step": 22000
    },
    {
      "epoch": 0.9905936360772312,
      "grad_norm": 1.2478641271591187,
      "learning_rate": 9.009406363922769e-05,
      "loss": 0.1249,
      "step": 22010
    },
    {
      "epoch": 0.9910437013366938,
      "grad_norm": 1.5573720932006836,
      "learning_rate": 9.008956298663307e-05,
      "loss": 0.0952,
      "step": 22020
    },
    {
      "epoch": 0.9914937665961564,
      "grad_norm": 4.906781196594238,
      "learning_rate": 9.008506233403845e-05,
      "loss": 0.1434,
      "step": 22030
    },
    {
      "epoch": 0.9919438318556191,
      "grad_norm": 4.616943359375,
      "learning_rate": 9.00805616814438e-05,
      "loss": 0.1062,
      "step": 22040
    },
    {
      "epoch": 0.9923938971150816,
      "grad_norm": 1.6846987009048462,
      "learning_rate": 9.007606102884919e-05,
      "loss": 0.1494,
      "step": 22050
    },
    {
      "epoch": 0.9928439623745443,
      "grad_norm": 3.155241012573242,
      "learning_rate": 9.007156037625457e-05,
      "loss": 0.1419,
      "step": 22060
    },
    {
      "epoch": 0.993294027634007,
      "grad_norm": 2.5987064838409424,
      "learning_rate": 9.006705972365993e-05,
      "loss": 0.0784,
      "step": 22070
    },
    {
      "epoch": 0.9937440928934695,
      "grad_norm": 3.058516263961792,
      "learning_rate": 9.006255907106531e-05,
      "loss": 0.1194,
      "step": 22080
    },
    {
      "epoch": 0.9941941581529322,
      "grad_norm": 5.833133220672607,
      "learning_rate": 9.005805841847069e-05,
      "loss": 0.1886,
      "step": 22090
    },
    {
      "epoch": 0.9946442234123948,
      "grad_norm": 2.2403059005737305,
      "learning_rate": 9.005355776587605e-05,
      "loss": 0.1415,
      "step": 22100
    },
    {
      "epoch": 0.9950942886718575,
      "grad_norm": 3.71816349029541,
      "learning_rate": 9.004905711328143e-05,
      "loss": 0.1391,
      "step": 22110
    },
    {
      "epoch": 0.99554435393132,
      "grad_norm": 3.475827217102051,
      "learning_rate": 9.004455646068681e-05,
      "loss": 0.144,
      "step": 22120
    },
    {
      "epoch": 0.9959944191907827,
      "grad_norm": 3.8423101902008057,
      "learning_rate": 9.004005580809218e-05,
      "loss": 0.1423,
      "step": 22130
    },
    {
      "epoch": 0.9964444844502452,
      "grad_norm": 2.6813511848449707,
      "learning_rate": 9.003555515549756e-05,
      "loss": 0.1535,
      "step": 22140
    },
    {
      "epoch": 0.9968945497097079,
      "grad_norm": 2.706270694732666,
      "learning_rate": 9.003105450290293e-05,
      "loss": 0.1383,
      "step": 22150
    },
    {
      "epoch": 0.9973446149691705,
      "grad_norm": 1.1561757326126099,
      "learning_rate": 9.00265538503083e-05,
      "loss": 0.1097,
      "step": 22160
    },
    {
      "epoch": 0.9977946802286332,
      "grad_norm": 4.628810882568359,
      "learning_rate": 9.002205319771368e-05,
      "loss": 0.1617,
      "step": 22170
    },
    {
      "epoch": 0.9982447454880957,
      "grad_norm": 5.418337821960449,
      "learning_rate": 9.001755254511905e-05,
      "loss": 0.1239,
      "step": 22180
    },
    {
      "epoch": 0.9986948107475584,
      "grad_norm": 2.7324612140655518,
      "learning_rate": 9.001305189252442e-05,
      "loss": 0.1301,
      "step": 22190
    },
    {
      "epoch": 0.9991448760070211,
      "grad_norm": 2.96389102935791,
      "learning_rate": 9.00085512399298e-05,
      "loss": 0.1087,
      "step": 22200
    },
    {
      "epoch": 0.9995949412664836,
      "grad_norm": 3.311373472213745,
      "learning_rate": 9.000405058733517e-05,
      "loss": 0.1428,
      "step": 22210
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.9474146127404374,
      "eval_loss": 0.12219391018152237,
      "eval_runtime": 16.4449,
      "eval_samples_per_second": 10808.793,
      "eval_steps_per_second": 337.796,
      "step": 22219
    }
  ],
  "logging_steps": 10,
  "max_steps": 222190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5173488495504000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
